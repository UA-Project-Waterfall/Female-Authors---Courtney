"#",Jurisdiction,Kind,Display Key,Lens ID,Publication Date,Publication Year,Application Number,Application Date,Priority Numbers,Earliest Priority Date,Title,Abstract,Applicants,Inventors,Owners,URL,Document Type,Has Full Text,Cites Patent Count,Cited by Patent Count,Simple Family Size,Extended Family Size,Sequence Count,CPC Classifications,IPCR Classifications,US Classifications,NPL Citation Count,NPL Resolved Citation Count,NPL Resolved Lens ID(s),NPL Resolved External ID(s),NPL Citations,Legal Status
1,US,B2,US 7988695 B2,157-189-642-310-373,2011-08-02,2011,US 61454006 A,2006-12-21,US 61454006 A;;US 75254405 P,2005-12-21,Articulated delivery instrument,"An articulated delivery instrument for the proper positioning and placements of inserts, for example, an insert such as a lumbar interbody fusion device (“LIF”). The instrument may comprise a body and a first member slidingly coupled to the body. A rotating member for releasably retaining an insert may be pivotally coupled to a distal end of the body and the first member. A first actuator may function to translate the first member relative to the body. Translation of the first member relative to the body may rotate the rotating member relative to the instrument. A second actuator may function to transition the rotating member between release and retention of the insert.",THEKEN SPINE LLC,DYE JUSTIN,INNOVATIVE SPINAL TECHNOLOGIES (2006-12-20);;THEKEN SPINE LLC (2009-09-10),https://lens.org/157-189-642-310-373,Granted Patent,yes,108,60,2,2,0,A61F2/4611;;A61F2/4611;;A61F2/4465;;A61F2/4465;;A61F2002/30131;;A61F2002/30131;;A61F2002/30538;;A61F2002/30538;;A61F2002/30593;;A61F2002/30593;;A61F2002/4627;;A61F2002/4627;;A61F2002/4628;;A61F2002/4628;;A61F2230/0013;;A61F2230/0013;;A61F2250/0006;;A61F2250/0006,A61B17/70,606 86A;;606/99,0,0,,,,ACTIVE
2,US,A1,US 2008/0065219 A1,092-219-422-206-740,2008-03-13,2008,US 76786807 A,2007-06-25,US 76786807 A;;US 82508906 P;;US 82508406 P,2006-09-08,OFFSET RADIUS LORDOSIS,"A vertebral body replacement or spacer that re-creates a lordosis angle (or other angle) of a human spine. An embodiment of the spacer may comprise contoured superior and inferior bearing surfaces. More particularly, the contoured surfaces may be defined by compound curves such as two radii substantially orthogonal to each other. As a result, the bearing surfaces may conform to the convex end plates of adjacent vertebra. In another embodiment, the present invention may provide a method of establishing a lordosis angle. The method may comprise inserting a spacer into an intervertebral space and positioning the spacer in such a manner that the contoured surfaces generally correspond to the end plates of the adjacent vertebra. However, the spacers and methods of the embodiments of the present invention may be used to re-create other angles in the human spine.",DYE JUSTIN,DYE JUSTIN,INNOVATIVE SPINAL TECHNOLOGIES (2007-08-15);;THEKEN SPINE LLC (2009-09-10),https://lens.org/092-219-422-206-740,Patent Application,yes,100,260,2,5,0,A61F2/4611;;A61F2/4611;;A61F2/4465;;A61F2/4465;;A61F2002/2835;;A61F2002/2835;;A61F2002/3008;;A61F2002/3008;;A61F2002/30133;;A61F2002/30133;;A61F2002/30538;;A61F2002/30538;;A61F2002/30593;;A61F2002/30593;;A61F2002/30616;;A61F2002/30616;;A61F2002/30787;;A61F2002/30787;;A61F2002/30841;;A61F2002/30841;;A61F2002/4627;;A61F2002/4627;;A61F2230/0015;;A61F2230/0015;;A61F2250/0006;;A61F2250/0006;;A61F2250/0098;;A61F2250/0098,A61F2/44,623/17.16,0,0,,,,ACTIVE
3,US,B2,US 8506636 B2,068-855-916-105-947,2013-08-13,2013,US 76786807 A,2007-06-25,US 76786807 A;;US 82508906 P;;US 82508406 P,2006-09-08,Offset radius lordosis,"A vertebral body replacement or spacer that re-creates a lordosis angle (or other angle) of a human spine. An embodiment of the spacer may comprise contoured superior and inferior bearing surfaces. More particularly, the contoured surfaces may be defined by compound curves such as two radii substantially orthogonal to each other. As a result, the bearing surfaces may conform to the convex end plates of adjacent vertebra. In another embodiment, the present invention may provide a method of establishing a lordosis angle. The method may comprise inserting a spacer into an intervertebral space and positioning the spacer in such a manner that the contoured surfaces generally correspond to the end plates of the adjacent vertebra. However, the spacers and methods of the embodiments of the present invention may be used to re-create other angles in the human spine.",DYE JUSTIN;;THEKEN SPINE LLC,DYE JUSTIN,INNOVATIVE SPINAL TECHNOLOGIES (2007-08-15);;THEKEN SPINE LLC (2009-09-10),https://lens.org/068-855-916-105-947,Granted Patent,yes,107,36,2,5,0,A61F2/4611;;A61F2/4611;;A61F2/4465;;A61F2/4465;;A61F2002/2835;;A61F2002/2835;;A61F2002/3008;;A61F2002/3008;;A61F2002/30133;;A61F2002/30133;;A61F2002/30538;;A61F2002/30538;;A61F2002/30593;;A61F2002/30593;;A61F2002/30616;;A61F2002/30616;;A61F2002/30787;;A61F2002/30787;;A61F2002/30841;;A61F2002/30841;;A61F2002/4627;;A61F2002/4627;;A61F2230/0015;;A61F2230/0015;;A61F2250/0006;;A61F2250/0006;;A61F2250/0098;;A61F2250/0098,A61F2/44,623/17.16;;623/17.11,0,0,,,,ACTIVE
4,US,A1,US 2007/0142843 A1,156-193-101-191-32X,2007-06-21,2007,US 61454006 A,2006-12-21,US 61454006 A;;US 75254405 P,2005-12-21,ARTICULATED DELIVERY INSTRUMENT,"An articulated delivery instrument for the proper positioning and placements of inserts, for example, an insert such as a lumbar interbody fusion device (“LIF”). The instrument may comprise a body and a first member slidingly coupled to the body. A rotating member for releasably retaining an insert may be pivotally coupled to a distal end of the body and the first member. A first actuator may function to translate the first member relative to the body. Translation of the first member relative to the body may rotate the rotating member relative to the instrument. A second actuator may function to transition the rotating member between release and retention of the insert.",DYE JUSTIN,DYE JUSTIN,INNOVATIVE SPINAL TECHNOLOGIES (2006-12-20);;THEKEN SPINE LLC (2009-09-10),https://lens.org/156-193-101-191-32X,Patent Application,yes,98,140,2,2,0,A61F2/4611;;A61F2/4611;;A61F2/4465;;A61F2/4465;;A61F2002/30131;;A61F2002/30131;;A61F2002/30538;;A61F2002/30538;;A61F2002/30593;;A61F2002/30593;;A61F2002/4627;;A61F2002/4627;;A61F2002/4628;;A61F2002/4628;;A61F2230/0013;;A61F2230/0013;;A61F2250/0006;;A61F2250/0006,A61F2/00,606/99,0,0,,,,ACTIVE
5,US,B2,US 7976549 B2,172-831-933-500-272,2011-07-12,2011,US 69069207 A,2007-03-23,US 69069207 A;;US 78531806 P;;US 82508406 P;;US 82508906 P,2006-03-23,Instruments for delivering spinal implants,"A method, apparatus, and system are provided to place an insert in a space between boney structures. The insert may be rotatably coupled to the delivery instrument. The delivery instrument may comprise a body and an articulating member. The articulating member may slidably interact with the insert to rotate the insert about a pivot point. A first actuator is operatively coupled to the articulating member such that actuating the first actuator translates the articulating member relative to the body. An engagement member may be coupled to the body and adapted to releasably and rotatably secure the insert to the delivery instrument. The articulating member and the engagement member may be offset from each other in such a manner that when the articulating member engages the insert, the insert rotates relative to the delivery instrument. Alternatively, the insert may be coupled to the delivery instrument via rotatable attachment members.",THEKEN SPINE LLC,DYE JUSTIN;;DYE NOELLE;;COLLERAN DENNIS,INNOVATIVE SPINAL TECHNOLOGIES (2007-04-24);;THEKEN SPINE LLC (2009-09-10),https://lens.org/172-831-933-500-272,Granted Patent,yes,103,72,2,5,0,A61F2/4465;;A61F2/4465;;A61F2/4611;;A61F2/4611;;A61F2002/30112;;A61F2002/30112;;A61F2002/30168;;A61F2002/30168;;A61F2002/30172;;A61F2002/30172;;A61F2002/30428;;A61F2002/30428;;A61F2002/30471;;A61F2002/30471;;A61F2002/30538;;A61F2002/30538;;A61F2002/30601;;A61F2002/30601;;A61F2002/30772;;A61F2002/30772;;A61F2002/4627;;A61F2002/4627;;A61F2002/4681;;A61F2002/4681;;A61F2220/0025;;A61F2220/0025;;A61F2220/0091;;A61F2220/0091;;A61F2230/0004;;A61F2230/0004;;A61F2230/0043;;A61F2230/0043;;A61F2230/0052;;A61F2230/0052;;A61F2250/0006;;A61F2250/0006,A61B17/58;;A61B17/60;;A61F2/00,606/99;;X606 86 A,0,0,,,,ACTIVE
6,US,A1,US 2007/0225726 A1,127-392-218-431-737,2007-09-27,2007,US 69069207 A,2007-03-23,US 69069207 A;;US 78531806 P;;US 82508406 P;;US 82508906 P,2006-03-23,INSTRUMENTS FOR DELIVERING SPINAL IMPLANTS,"A method, apparatus, and system are provided to place an insert in a space between boney structures. The insert may be rotatably coupled to the delivery instrument. The delivery instrument may comprise a body and an articulating member. The articulating member may slidably interact with the insert to rotate the insert about a pivot point. A first actuator is operatively coupled to the articulating member such that actuating the first actuator translates the articulating member relative to the body. An engagement member may be coupled to the body and adapted to releasably and rotatably secure the insert to the delivery instrument. The articulating member and the engagement member may be offset from each other in such a manner that when the articulating member engages the insert, the insert rotates relative to the delivery instrument. Alternatively, the insert may be coupled to the delivery instrument via rotatable attachment members.",DYE JUSTIN;;DYE NOELLE;;COLLERAN DENNIS,DYE JUSTIN;;DYE NOELLE;;COLLERAN DENNIS,INNOVATIVE SPINAL TECHNOLOGIES (2007-04-24);;THEKEN SPINE LLC (2009-09-10),https://lens.org/127-392-218-431-737,Patent Application,yes,99,203,2,5,0,A61F2/4465;;A61F2/4465;;A61F2/4611;;A61F2/4611;;A61F2002/30112;;A61F2002/30112;;A61F2002/30168;;A61F2002/30168;;A61F2002/30172;;A61F2002/30172;;A61F2002/30428;;A61F2002/30428;;A61F2002/30471;;A61F2002/30471;;A61F2002/30538;;A61F2002/30538;;A61F2002/30601;;A61F2002/30601;;A61F2002/30772;;A61F2002/30772;;A61F2002/4627;;A61F2002/4627;;A61F2002/4681;;A61F2002/4681;;A61F2220/0025;;A61F2220/0025;;A61F2220/0091;;A61F2220/0091;;A61F2230/0004;;A61F2230/0004;;A61F2230/0043;;A61F2230/0043;;A61F2230/0052;;A61F2230/0052;;A61F2250/0006;;A61F2250/0006,A61F2/00,606/99,0,0,,,,ACTIVE
7,DE,D1,DE 69934060 D1,038-525-766-298-842,2007-01-04,2007,DE 69934060 T,1999-09-08,US 15012298 A,1998-09-09,Femoraler Schaftbausatz für eine modulare Knieprothese,,DEPUY PRODUCTS INC,O'NEIL MICHAEL;;DYE JUSTIN,,https://lens.org/038-525-766-298-842,Granted Patent,no,0,0,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/38;;A61F2/00;;A61F2/02;;A61F2/30;;A61F2/46,,0,0,,,,EXPIRED
8,DE,T2,DE 69934060 T2,048-529-529-128-103,2007-05-03,2007,DE 69934060 T,1999-09-08,US 15012298 A,1998-09-09,Femoraler Schaftbausatz für eine modulare Knieprothese,,DEPUY PRODUCTS INC,O'NEIL MICHAEL;;DYE JUSTIN,,https://lens.org/048-529-529-128-103,Granted Patent,no,0,0,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/38;;A61F2/00;;A61F2/02;;A61F2/30;;A61F2/46,,0,0,,,,EXPIRED
9,US,B1,US 6527807 B1,141-252-902-273-619,2003-03-04,2003,US 15012298 A,1998-09-09,US 15012298 A,1998-09-09,Femoral stem attachment for a modular knee prosthesis,"
    The present invention provides a knee prosthesis having a femoral component having a pair of spaced apart condylar portions and a boss structure extending between the condylar portions. The boss structure has a top surface that extends generally horizontally in a transverse plane and an opposed inferior surface. The knee prosthesis also includes a stem component having a proximal end and a distal end. The knee prosthesis further includes an attachment nut for securing the stem member to the femoral component. 
",JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL;;DYE JUSTIN,DEPUY ORTHOPAEDICS INC (1999-07-03);;JOHNSON & JOHNSON PROFESSIONAL INC (1998-09-08),https://lens.org/141-252-902-273-619,Granted Patent,yes,51,83,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/00;;A61F2/02;;A61F2/30;;A61F2/38;;A61F2/46,623/20.15,1,0,,,"Johnson & Johnson Orthopaedics Research & Development ""P.F.C.(R) Modular Knee System Research Data and Laboratory Testing,"" cover and pp. 8, 36 and 37 (1989).",EXPIRED
10,WO,A1,WO 2004/002333 A1,006-222-134-768-51X,2004-01-08,2004,US 0319098 W,2003-06-19,US 18482902 A,2002-06-28,SOFT TISSUE REPAIR TOOL,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/006-222-134-768-51X,Patent Application,yes,5,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/16;;A61B17/17;;A61B17/56,,0,0,,,,PENDING
11,AT,T1,AT E504244 T1,126-247-747-741-258,2011-04-15,2011,AT 03739167 T,2003-06-19,US 18482902 A;;US 0319098 W,2002-06-28,WERKZEUG ZUR AUSBESSERUNG VON WEICHTEILGEWEBE,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/126-247-747-741-258,Granted Patent,no,0,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/56;;A61B17/16;;A61B17/17,,0,0,,,,EXPIRED
12,EP,A1,EP 1517643 A1,056-481-617-017-69X,2005-03-30,2005,EP 03739167 A,2003-06-19,US 0319098 W;;US 18482902 A,2002-06-28,SOFT TISSUE REPAIR TOOL,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/056-481-617-017-69X,Patent Application,yes,0,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/56;;A61B17/16;;A61B17/17,,0,0,,,,EXPIRED
13,AU,A1,AU 2003/245542 A1,104-992-217-034-822,2004-01-19,2004,AU 2003/245542 A,2003-06-19,US 18482902 A;;US 0319098 W,2002-06-28,SOFT TISSUE REPAIR TOOL,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/104-992-217-034-822,Patent Application,no,0,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/56;;A61B17/16;;A61B17/17,,0,0,,,,EXPIRED
14,AU,B2,AU 2003/245542 B2,189-356-859-303-656,2008-11-20,2008,AU 2003/245542 A,2003-06-19,US 18482902 A;;US 0319098 W,2002-06-28,Soft tissue repair tool,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/189-356-859-303-656,Granted Patent,no,6,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/56;;A61B17/16;;A61B17/17,,0,0,,,,EXPIRED
15,WO,A1,WO 2003/061530 A1,035-536-569-209-382,2003-07-31,2003,US 0300986 W,2003-01-14,US 4629002 A,2002-01-16,TISSUE ANCHOR INSERTION TOOL,"A tissue anchor insertion tool (1) includes a first member (3) defining a region (121) configured to receive a tissue anchor 100), and a second member (4) positioned to substantially cover the tissue anchor (100) during introduction to a surgical site. The second member (4) is coupled to the first member (3) such that relative motion between the members (3, 4) deploys the tissue anchor (100) from the region (121). The first member (3) includes an applicator (5) configured to move laterally to deploy the anchor (100) from the region (121). A method includes providing first and second members (3, 4) coupled for relative motion, inserting a tissue anchor (100) into tissue using the first and second members (3, 4), and relatively moving the first and second members (3, 4) to deploy the tissue anchor (100) from the first member (3). The tissue anchor (100) is mounted to the first member (3). The second member (4) substantially covers the tissue anchor (100) during the insertion into the tissue.",SMITH & NEPHEW,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/035-536-569-209-382,Patent Application,yes,4,0,2,2,0,A61B17/0401;;A61B2017/0409;;A61B2017/0414;;A61F2/0805;;A61F2/0805;;A61B17/0401;;A61B2017/0414;;A61B2017/0409,A61B17/04;;A61F2/08,,0,0,,,,PENDING
16,EP,A2,EP 0985386 A2,097-613-688-245-525,2000-03-15,2000,EP 99307120 A,1999-09-08,US 15012298 A,1998-09-09,Femoral stem attachment for a modular knee prosthesis,The present invention provides a knee prosthesis having a femoral component having a pair of spaced apart condylar portions and a boss structure extending between the condylar portions. The boss structure has a top surface that extends generally horizontally in a transverse plane and an opposed inferior surface. The knee prosthesis also includes a stem component having a proximal end and a distal end. The knee prosthesis further includes an attachment nut for securing the stem member to the femoral component.,JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/097-613-688-245-525,Patent Application,yes,0,15,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/00;;A61F2/02;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
17,US,A1,US 2004/0002709 A1,070-545-741-481-921,2004-01-01,2004,US 18482902 A,2002-06-28,US 18482902 A,2002-06-28,Soft tissue repair tool,"
   A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire. 
",GABRIEL STEFAN;;DYE JUSTIN,GABRIEL STEFAN;;DYE JUSTIN,SMITH & NEPHEW INC (2002-09-30),https://lens.org/070-545-741-481-921,Patent Application,yes,48,5,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/16;;A61B17/56;;A61B17/17,606/72,0,0,,,,EXPIRED
18,US,A1,US 2003/0135239 A1,024-528-744-615-654,2003-07-17,2003,US 4629002 A,2002-01-16,US 4629002 A,2002-01-16,Tissue anchor insertion tool,"
   A tissue anchor insertion tool includes a first member defining a region configured to receive a tissue anchor, and a second member positioned to substantially cover the tissue anchor during introduction to a surgical site. The second member is coupled to the first member such that relative motion between the members deploys the tissue anchor from the region. The first member includes an applicator configured to move laterally to deploy the anchor from the region. A method includes providing first and second members coupled for relative motion, inserting a tissue anchor into tissue using the first and second members, and relatively moving the first and second members to deploy the tissue anchor from the first member. The tissue anchor is mounted to the first member. The second member substantially covers the tissue anchor during the insertion into tissue. 
",GABRIEL STEFAN;;DYE JUSTIN,GABRIEL STEFAN;;DYE JUSTIN,SMITH & NEPHEW INC (2001-12-19),https://lens.org/024-528-744-615-654,Patent Application,yes,13,104,2,2,0,A61B17/0401;;A61B2017/0409;;A61B2017/0414;;A61F2/0805;;A61F2/0805;;A61B17/0401;;A61B2017/0414;;A61B2017/0409,A61B17/04;;A61F2/08,606/232;;606/104,0,0,,,,DISCONTINUED
19,EP,B1,EP 1517643 B1,115-316-753-792-26X,2011-04-06,2011,EP 03739167 A,2003-06-19,US 0319098 W;;US 18482902 A,2002-06-28,SOFT TISSUE REPAIR TOOL,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/115-316-753-792-26X,Granted Patent,yes,4,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/17;;A61B17/56;;A61B17/16,,0,0,,,,EXPIRED
20,US,B2,US 6955678 B2,182-375-042-863-316,2005-10-18,2005,US 18482902 A,2002-06-28,US 18482902 A,2002-06-28,Soft tissue repair tool,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,SMITH & NEPHEW INC (2002-09-30),https://lens.org/182-375-042-863-316,Granted Patent,yes,66,47,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/16;;A61B17/17;;A61B17/56,606/104;;606/72,4,0,,,"""Acufex introduces Suretac II with Spikes"", Russel Warren, Acufex Microsurgical, Inc., Document No. 994-3, 1994, 1 page.;;Arthrex, ""TissueTak(TM)II"", Arthrex Inc., Document LS0504A, 2001, 1 page.;;Arthrex, ""TissueTak II Surgical Technique-Bankart or SLAP Repair"", Literature provided by Arthrex of Naples, FL. with the TissueTakII product, 2001, 5 pages.;;""Surgical Technique for Suretac"", Russell Warren, Smith & Nephew, Inc., Document 5M1030169C, Feb., 1999, 9 pages.",EXPIRED
21,US,A1,US 2008/0065082 A1,156-428-006-339-983,2008-03-13,2008,US 85218307 A,2007-09-07,US 85218307 A;;US 82509106 P;;US 86802206 P,2006-09-08,STEERABLE RASP/TRIAL INSERTER,"Instruments and methods are provided for inserting a rasp into an intervertebral space of a spine and using the rasp to decorticate the adjacent vertebra. More particularly, one embodiment provides an instrument that actively changes the angle of the rasp relative to the instrument. The delivery instrument may use a gear portion to articulate the rasp. A second gear on the rasp may mate with a corresponding gear on the instrument. As the instrument gear rotates relative to the instrument, the instrument gear drives the rasp gear, thereby rotating the rasp to decorticate the vertebra. Trial inserts and methods are also provided to determine an appropriate size of a rasp for decortication.",CHANG NARISSA;;DYE JUSTIN,CHANG NARISSA;;DYE JUSTIN,INNOVATIVE SPINAL TECHNOLOGIES (2007-09-18);;THEKEN SPINE LLC (2009-09-10),https://lens.org/156-428-006-339-983,Patent Application,yes,0,204,1,1,0,A61B17/1659;;A61B17/1659;;A61B17/1671;;A61B17/1671;;A61B2017/00473;;A61B2017/00473;;A61B2017/320028;;A61B2017/320028;;A61F2/4611;;A61F2/4611;;A61F2/4684;;A61F2/4684;;A61F2002/30538;;A61F2002/30538;;A61F2250/0006;;A61F2250/0006,A61B17/00;;A61B17/58,606/85;;606/99,0,0,,,,DISCONTINUED
22,DE,D1,DE 60336648 D1,073-495-957-442-186,2011-05-19,2011,DE 60336648 T,2003-06-19,US 18482902 A;;US 0319098 W,2002-06-28,WERKZEUG ZUR AUSBESSERUNG VON WEICHTEILGEWEBE,"A surgical tool includes a member, a guide wire received within the member by a friction fit, and a guide wire pusher for application of a force to the guide wire to overcome the friction fit and advance the guide wire relative to the member. The member includes a guide wire retainer that provides the friction fit and allows the guide wire to be held in such a way that it is pre-assembled and secure while the tool is being introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer allows the remainder of the tool to be removed leaving the guide wire in place at the site. The guide wire pusher allows the guide wire to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire.",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/073-495-957-442-186,Granted Patent,no,0,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/17;;A61B17/56;;A61B17/16,,0,0,,,,EXPIRED
23,JP,A,JP 2000107211 A,167-408-666-972-232,2000-04-18,2000,JP 25462899 A,1999-09-08,US 15012298 A,1998-09-09,FEMUR STEM FITTING METHOD FOR MODULE TYPE KNEE PROTHESIS,"PROBLEM TO BE SOLVED: To obtain a wide variety by providing stem configuration parts having a base end part and a tip part and, besides, a fitting nut for fixing the stem configuration parts to femur configuration parts in a knee prothesis. SOLUTION: A collar 14 is fitted to the upper surface part 40B of a boss 40 by positioning its flat surface part at a swelling part 44 by engagement. A stem 12 is engaged with the collar 14 by putting a tip side connector part 27 through a collar hole 34 to permit an engagement surface or a shoulder part 25 to be supported on the stem support surface of the collar 14. The tip part 24 of the stem 12 penetrates a boss hole 47 and a part of the connecter end part 27 is projected inside the boss circular opening part by extension. The fitting nut 20 is inserted to the boss circular opening part from the lower end of a boss structure part 40 and engaged with the tip side connecter part 27 of the stem 12 by screwing. Then, the spherical engagement surface 60 of the fitting nut 20 is joined to an end wall which is formed to be the same shape in the boss circular opening part.",JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL;;DYE JUSTIN,,https://lens.org/167-408-666-972-232,Patent Application,no,9,0,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/00;;A61F2/02;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
24,EP,B1,EP 0985386 B1,036-575-450-399-586,2006-11-22,2006,EP 99307120 A,1999-09-08,US 15012298 A,1998-09-09,Femoral stem attachment for a modular knee prosthesis,,DEPUY PRODUCTS INC,O'NEIL MICHAEL;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/036-575-450-399-586,Granted Patent,yes,3,0,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/38;;A61F2/00;;A61F2/02;;A61F2/30;;A61F2/46,,0,0,,,,EXPIRED
25,EP,A3,EP 0985386 A3,107-942-616-799-64X,2002-03-20,2002,EP 99307120 A,1999-09-08,US 15012298 A,1998-09-09,Femoral stem attachment for a modular knee prosthesis,The present invention provides a knee prosthesis having a femoral component having a pair of spaced apart condylar portions and a boss structure extending between the condylar portions. The boss structure has a top surface that extends generally horizontally in a transverse plane and an opposed inferior surface. The knee prosthesis also includes a stem component having a proximal end and a distal end. The knee prosthesis further includes an attachment nut for securing the stem member to the femoral component.,JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/107-942-616-799-64X,Search Report,yes,3,0,8,8,0,A61F2/3859;;A61F2002/30154;;A61F2002/30266;;A61F2002/30405;;A61F2002/30538;;A61F2002/30604;;A61F2002/30616;;A61F2002/30708;;A61F2002/30729;;A61F2002/30828;;A61F2002/30878;;A61F2002/30886;;A61F2002/4638;;A61F2220/0025;;A61F2220/0041;;A61F2230/0021;;A61F2230/0082;;A61F2250/0006;;A61F2250/0084;;A61F2002/30433;;A61F2/3859;;A61F2002/30886;;A61F2250/0006;;A61F2220/0041;;A61F2002/30266;;A61F2002/30616;;A61F2230/0082;;A61F2002/30878;;A61F2002/30708;;A61F2002/30154;;A61F2220/0025;;A61F2002/30538;;A61F2002/30729;;A61F2002/30828;;A61F2230/0021;;A61F2002/4638;;A61F2250/0084;;A61F2002/30405;;A61F2002/30604;;A61F2002/30433,A61F2/00;;A61F2/02;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
26,JP,A,JP 2011183168 A,154-492-520-848-40X,2011-09-22,2011,JP 2011083887 A,2011-04-05,US 18482902 A,2002-06-28,SOFT TISSUE REPAIR TOOL,"<P>PROBLEM TO BE SOLVED: To provide a surgical tool for making a hole in bone for receiving an implant. <P>SOLUTION: The surgical tool includes a member 2, a guide wire 4 received within the member by a friction fit, and a guide wire pusher 5 for application of a force to the guide wire 4 to overcome the friction fit and advance the guide wire 4 relative to the member. The member includes a guide wire retainer 6 that provides the friction fit and allows the guide wire 4 to be held in such a way that it is pre-assembled and secure while the tool is introduced to a surgical site. At the same time, once a hole is drilled into bone, the guide wire retainer 6 allows the tool to be removed leaving the guide wire 4 in place at the site. The guide wire pusher 5 allows the guide wire 4 to be impacted into the bone before drilling and limits any possibility of drilling past the end of the guide wire 4. <P>COPYRIGHT: (C)2011,JPO&INPIT",SMITH & NEPHEW INC,GABRIEL STEFAN;;DYE JUSTIN,,https://lens.org/154-492-520-848-40X,Patent Application,no,7,0,12,12,0,A61B17/1637;;A61B17/1697;;A61B17/1714;;Y10S606/916;;A61B17/1714;;A61B17/1697;;A61B17/1637;;Y10S606/916,A61B17/56;;A61B17/16;;A61B17/17,,0,0,,,,PENDING
27,EP,A1,EP 0970667 A1,186-771-344-224-317,2000-01-12,2000,EP 99305390 A,1999-07-07,US 11225298 A,1998-07-08,Rotatable and translatable joint prosthesis with posterior stabilization,"A joint prosthesis system includes a tibial bearing insert (12), a tibial tray (14), a separate stabilizing post (22) and a femoral component (100) that are joinable to each other. The tibial bearing insert is mounted so that it can both rotate and translate with respect to the tibial tray. The stabilizing post and the femoral component cooperate to force roll back of the femoral component with respect to the tibial components.",JOHNSON & JOHNSON PROFESSIONAL,COLLERAN DENNIS P;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/186-771-344-224-317,Patent Application,yes,5,29,7,7,0,A61F2/3868;;A61F2/3868;;A61F2/3886;;A61F2/3886,A61F2/30;;A61F2/38,,0,0,,,,EXPIRED
28,DE,T2,DE 69729781 T2,173-124-623-827-492,2005-07-14,2005,DE 69729781 T,1997-12-22,US 77272796 A,1996-12-23,Modulares Vergrösserungssystem für Gelenkprothese,,DEPUY PRODUCTS INC,O'NEIL MICHAEL J;;DYE JUSTIN,,https://lens.org/173-124-623-827-492,Granted Patent,no,0,0,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
29,DE,T2,DE 69913254 T2,189-942-940-523-295,2004-12-02,2004,DE 69913254 T,1999-07-07,US 11225298 A,1998-07-08,Drehbare und verschiebbare Gelenkprothese mit hinterer Stabilität,,DEPUY PRODUCTS INC,COLLERAN DENNIS P;;DYE JUSTIN,,https://lens.org/189-942-940-523-295,Granted Patent,no,0,0,7,7,0,A61F2/3868;;A61F2/3868;;A61F2/3886;;A61F2/3886,A61F2/30;;A61F2/38,,0,0,,,,EXPIRED
30,JP,A,JP 2000051252 A,090-688-913-466-810,2000-02-22,2000,JP 19354099 A,1999-07-07,US 11225298 A,1998-07-08,FREELY ROTATABLE AND MOVABLE ARTICULAR PROSTHESIS STABILIZED BACKWARD,"PROBLEM TO BE SOLVED: To make it possible to deal with a stress acting on the knee by providing first tibia constituting parts with second tibia constituting parts rotatably and movably with respect to the former are providing these parts with a stabilizing post member cooperating with the turning motion of femur constituting parts while maintaining the tight contact joining of the femur and tibia bone head of the system. SOLUTION: The tibia constituting parts 11 of the articular prosthesis system comprise the first constituting parts in the form of a tibia tray 14 and the stabilizing positive member 22 separated from the second constituting parts in the form of tibia supporting insertion parts 12. Further, these constituting parts are provided with the constituting parts in the form of the femur constituting parts 100. The tibia supporting insertion parts 12 are mounted rotatably and movably relative to the front surface 32 of the tibia tray 14. An engagement shoulder 28 is formed in an aperture 50 of the tibia supporting insertion parts 12 so as to support a complementary front end side opposite shoulder 78 formed at the stabilizing positive member 22. As a result, the adequate positioning of the tibia tray 14 and the stabilizing positive member 22 is made possible and the dealing with a stress acting on the knee is made possible.",JOHNSON & JOHNSON PROFESSIONAL,COLLERAN DENNIS P;;DYE JUSTIN,,https://lens.org/090-688-913-466-810,Patent Application,no,0,6,7,7,0,A61F2/3868;;A61F2/3868;;A61F2/3886;;A61F2/3886,A61F2/30;;A61F2/38,,0,0,,,,EXPIRED
31,DE,D1,DE 69913254 D1,023-808-505-265-757,2004-01-15,2004,DE 69913254 T,1999-07-07,US 11225298 A,1998-07-08,Drehbare und verschiebbare Gelenkprothese mit hinterer Stabilität,,DEPUY PRODUCTS INC,COLLERAN DENNIS P;;DYE JUSTIN,,https://lens.org/023-808-505-265-757,Granted Patent,no,0,0,7,7,0,A61F2/3868;;A61F2/3868;;A61F2/3886;;A61F2/3886,A61F2/30;;A61F2/38,,0,0,,,,EXPIRED
32,US,A,US 5755800 A,146-302-060-611-320,1998-05-26,1998,US 77272796 A,1996-12-23,US 77272796 A,1996-12-23,Modular joint prosthesis augmentation system,"A modular joint prosthesis system includes an articulation member, such as a cruciate retaining femoral component of a knee joint prosthesis, having a superior bone engaging surface, an inferior articulation surface and one or more fixation pegs extending from the superior surface. An augmentation block mounts on the superior surface of the articulation member and has an aperture surrounding a respective fixation peg. The system further includes a compression collet seated between the aperture of the augmentation block and the fixation peg. In assembly, a securement device mounted over the fixation peg compresses the compression collet so as to engage the fixation peg and maintain the augmentation block on the articulation member.",JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL J;;DYE JUSTIN,,https://lens.org/146-302-060-611-320,Granted Patent,yes,41,121,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,623/20,0,0,,,,EXPIRED
33,EP,B1,EP 0850608 B1,093-755-457-261-470,2004-07-07,2004,EP 97310437 A,1997-12-22,US 77272796 A,1996-12-23,Modular joint prosthesis augmentation system,,DEPUY PRODUCTS INC,O'NEIL MICHAEL J;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/093-755-457-261-470,Granted Patent,yes,4,1,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
34,EP,B1,EP 0970667 B1,016-309-542-630-231,2003-12-03,2003,EP 99305390 A,1999-07-07,US 11225298 A,1998-07-08,Rotatable and translatable joint prosthesis with posterior stabilization,,DEPUY PRODUCTS INC,COLLERAN DENNIS P;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/016-309-542-630-231,Granted Patent,yes,5,3,7,7,0,A61F2/3868;;A61F2/3868;;A61F2/3886;;A61F2/3886,A61F2/30;;A61F2/38,,0,0,,,,EXPIRED
35,EP,A3,EP 0850608 A3,157-216-665-968-89X,1998-12-16,1998,EP 97310437 A,1997-12-22,US 77272796 A,1996-12-23,Modular joint prosthesis augmentation system,"A modular joint prosthesis system includes an articulation member, such as a cruciate retaining femoral component of a knee joint prosthesis, having a superior bone engaging surface, an inferior articulation surface and one or more fixation pegs extending from the superior surface. An augmentation block mounts on the superior surface of the articulation member and has an aperture surrounding a respective fixation peg. The system further includes a compression collet seated between the aperture of the augmentation block and the fixation peg. In assembly, a securement device mounted over the fixation peg compresses the compression collet so as to engage the fixation peg and maintain the augmentation block on the articulation member.",JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL J;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/157-216-665-968-89X,Search Report,yes,4,0,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
36,CA,C,CA 2225704 C,161-076-335-572-844,2006-12-05,2006,CA 2225704 A,1997-12-22,US 77272796 A,1996-12-23,MODULAR JOINT PROSTHESIS AUGMENTATION SYSTEM,"A modular joint prosthesis system includes an articulation member, such as a cruciate retaining femoral component of a knee joint prosthesis, having a superior bone engaging surface, an inferior articulation surface and one or more fixation pegs extending from the superior surface. An augmentation block mounts on the superior surface of the articulation member and has an aperture surrounding a respective fixation pe g. The system further includes a compression collet seated between the aperture of the augmentation block and the fixation peg. In assembly, a securement device mounted over the fixation peg compresses the compression collet so as to engage the fixation peg and maintain the augmentation block on the articulation member.",JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL J;;DYE JUSTIN,,https://lens.org/161-076-335-572-844,Granted Patent,no,0,0,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/46;;A61F2/00;;A61F2/30;;A61F2/38,,0,0,,,,EXPIRED
37,CA,A1,CA 2225704 A1,122-923-291-738-602,1998-06-23,1998,CA 2225704 A,1997-12-22,US 77272796 A,1996-12-23,ALIGNMENT GUIDE FOR INSERTION OF FLUTED OR KEYED ORTHOPEDIC COMPONENTS,"A modular joint prosthesis system includes an articulation member, such as a cruciate retaining femoral component of a knee joint prosthesis, having a superi or bone engaging surface, an inferior articulation surface and one or more fixation pegs extending from the superior surface. An augmentation block mounts on the superior surface of the articulation member and has an aperture surrounding a respective fixation peg. T he system further includes a compression collet seated between the aperture of the augmentation block and the fixation peg. In assembly, a securement device mounte d over the fixation peg compresses the compression collet so as to engage the fixation peg and maintain the augmentation block on the articulation member.",JOHNSON & JOHNSON PROFESSIONAL,DYE JUSTIN;;O'NEIL MICHAEL J,,https://lens.org/122-923-291-738-602,Patent Application,no,0,0,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
38,US,A,US 6080195 A,135-777-187-992-036,2000-06-27,2000,US 11225298 A,1998-07-08,US 11225298 A,1998-07-08,Rotatable and translatable joint prosthesis with posterior stabilization,"A joint prosthesis system includes a tibial bearing insert, a tibial tray, a separate stabilizing post and a femoral component that are joinable to each other. The tibial bearing insert is mounted so that it can both rotate and translate with respect to the tibial tray. The stabilizing post and the femoral component cooperate to force roll back of the femoral component with respect to the tibial components.",JOHNSON & JOHNSON PROFESSIONAL,COLLERAN DENNIS P;;DYE JUSTIN,DEPUY ORTHOPAEDICS INC (1999-07-03);;JOHNSON & JOHNSON PROFESSIONAL INC (1998-07-06),https://lens.org/135-777-187-992-036,Granted Patent,yes,11,175,7,7,0,A61F2/3868;;A61F2/3868;;A61F2/3886;;A61F2/3886,A61F2/30;;A61F2/38,623/20,0,0,,,,EXPIRED
39,DE,D1,DE 69729781 D1,112-725-155-071-575,2004-08-12,2004,DE 69729781 T,1997-12-22,US 77272796 A,1996-12-23,Modulares Vergrösserungssystem für Gelenkprothese,,DEPUY PRODUCTS INC,O'NEIL MICHAEL J;;DYE JUSTIN,,https://lens.org/112-725-155-071-575,Granted Patent,no,0,0,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
40,EP,A2,EP 0850608 A2,163-769-904-779-349,1998-07-01,1998,EP 97310437 A,1997-12-22,US 77272796 A,1996-12-23,Modular joint prosthesis augmentation system,"A modular joint prosthesis system includes an articulation member, such as a cruciate retaining femoral component of a knee joint prosthesis, having a superior bone engaging surface, an inferior articulation surface and one or more fixation pegs extending from the superior surface. An augmentation block mounts on the superior surface of the articulation member and has an aperture surrounding a respective fixation peg. The system further includes a compression collet seated between the aperture of the augmentation block and the fixation peg. In assembly, a securement device mounted over the fixation peg compresses the compression collet so as to engage the fixation peg and maintain the augmentation block on the articulation member.",JOHNSON & JOHNSON PROFESSIONAL,O'NEIL MICHAEL J;;DYE JUSTIN,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/163-769-904-779-349,Patent Application,yes,1,4,8,8,0,A61F2/3859;;A61F2/3859;;A61F2/30734;;A61F2/30734;;A61F2002/30014;;A61F2002/30014;;A61F2002/30016;;A61F2002/30016;;A61F2002/30332;;A61F2002/30332;;A61F2002/30355;;A61F2002/30355;;A61F2002/30405;;A61F2002/30405;;A61F2002/30474;;A61F2002/30474;;A61F2002/30484;;A61F2002/30484;;A61F2002/30507;;A61F2002/30507;;A61F2002/30594;;A61F2002/30594;;A61F2002/30604;;A61F2002/30604;;A61F2002/30616;;A61F2002/30616;;A61F2002/30708;;A61F2002/30708;;A61F2002/30736;;A61F2002/30736;;A61F2002/30774;;A61F2002/30774;;A61F2002/30777;;A61F2002/30777;;A61F2002/30805;;A61F2002/30805;;A61F2002/30892;;A61F2002/30892;;A61F2002/4638;;A61F2002/4638;;A61F2220/0025;;A61F2220/0025;;A61F2220/0033;;A61F2220/0033;;A61F2250/0018;;A61F2250/0018;;A61F2250/0019;;A61F2250/0019;;A61F2250/0084;;A61F2250/0084;;A61F2310/00017;;A61F2310/00017;;A61F2310/00023;;A61F2310/00023;;A61F2310/00029;;A61F2310/00029;;A61F2310/00179;;A61F2310/00179,A61F2/00;;A61F2/30;;A61F2/38;;A61F2/46,,0,0,,,,EXPIRED
41,US,A1,US 2006/0142858 A1,150-399-318-246-42X,2006-06-29,2006,US 30331105 A,2005-12-16,US 30331105 A;;US 63731204 P;;US 66042205 P;;US 70086105 P,2004-12-16,Expandable implants for spinal disc replacement,"Multiple embodiments of the present invention provide methods and apparatuses for maintaining spacing between neighboring vertebrae, while minimizing the size of the surgical opening required. In one embodiment, an expandable spinal implant is made having movable parts that can arranged so as to have a small maximum cross-sectional width so that the cage can be inserted through a smaller surgical opening and then expanded to a full size assembly between the vertebrae.",COLLERAN DENNIS;;ROGERS CAROLYN;;DYE JUSTIN,COLLERAN DENNIS;;ROGERS CAROLYN;;DYE JUSTIN,INNOVATIVE SPINAL TECHNOLOGIES (2006-02-28);;THEKEN SPINE LLC (2009-09-10),https://lens.org/150-399-318-246-42X,Patent Application,yes,80,448,3,3,0,A61F2/4465;;A61F2002/302;;A61F2002/30291;;A61F2002/30387;;A61F2002/30471;;A61F2002/30545;;A61F2002/30556;;A61F2002/30579;;A61F2002/30604;;A61F2002/4415;;A61F2220/0025;;A61F2220/0091;;A61F2230/0065;;A61F2230/0091;;A61F2250/0009;;A61F2250/001;;A61F2/4465;;A61F2002/30471;;A61F2230/0091;;A61F2002/4415;;A61F2002/30545;;A61F2002/30556;;A61F2230/0065;;A61F2220/0025;;A61F2002/30387;;A61F2220/0091;;A61F2250/001;;A61F2002/302;;A61F2002/30579;;A61F2250/0009;;A61F2002/30291;;A61F2002/30604,A61F2/44,623/17.11,0,0,,,,DISCONTINUED
42,WO,A3,WO 2006/066228 A3,057-467-324-000-97X,2006-08-24,2006,US 2005/0045995 W,2005-12-16,US 63731204 P;;US 66042205 P;;US 70086105 P,2004-12-16,EXPANDABLE IMPLANTS FOR SPINAL DISC REPLACEMENT,"Multiple embodiments of the present invention provide methods and apparatuses for maintaining spacing between neighboring vertebrae, while minimizing the size of the surgical opening required. In one embodiment, an expandable spinal implant (100) is made having movable parts (10, 20), that can arranged so as to have a small maximum cross-sectional width so that the cage can be inserted through a smaller surgical opening and then expanded to a full size assembly between the vertebrae.",INNOVATIVE SPINAL TECHNOLOGIES;;COLLERAN DENNIS;;ROGERS CAROLYN;;DYE JUSTIN,COLLERAN DENNIS;;ROGERS CAROLYN;;DYE JUSTIN,,https://lens.org/057-467-324-000-97X,Search Report,yes,9,0,3,3,0,A61F2/4465;;A61F2002/302;;A61F2002/30291;;A61F2002/30387;;A61F2002/30471;;A61F2002/30545;;A61F2002/30556;;A61F2002/30579;;A61F2002/30604;;A61F2002/4415;;A61F2220/0025;;A61F2220/0091;;A61F2230/0065;;A61F2230/0091;;A61F2250/0009;;A61F2250/001;;A61F2/4465;;A61F2002/30471;;A61F2230/0091;;A61F2002/4415;;A61F2002/30545;;A61F2002/30556;;A61F2230/0065;;A61F2220/0025;;A61F2002/30387;;A61F2220/0091;;A61F2250/001;;A61F2002/302;;A61F2002/30579;;A61F2250/0009;;A61F2002/30291;;A61F2002/30604,A61F2/44,,0,0,,,,PENDING
43,WO,A2,WO 2006/066228 A2,048-283-152-970-992,2006-06-22,2006,US 2005/0045995 W,2005-12-16,US 63731204 P;;US 66042205 P;;US 70086105 P,2004-12-16,EXPANDABLE IMPLANTS FOR SPINAL DISC REPLACEMENT,"Multiple embodiments of the present invention provide methods and apparatuses for maintaining spacing between neighboring vertebrae, while minimizing the size of the surgical opening required. In one embodiment, an expandable spinal implant (100) is made having movable parts (10, 20), that can arranged so as to have a small maximum cross-sectional width so that the cage can be inserted through a smaller surgical opening and then expanded to a full size assembly between the vertebrae.",INNOVATIVE SPINAL TECHNOLOGIES;;COLLERAN DENNIS;;ROGERS CAROLYN;;DYE JUSTIN,COLLERAN DENNIS;;ROGERS CAROLYN;;DYE JUSTIN,,https://lens.org/048-283-152-970-992,Patent Application,yes,0,86,3,3,0,A61F2/4465;;A61F2002/302;;A61F2002/30291;;A61F2002/30387;;A61F2002/30471;;A61F2002/30545;;A61F2002/30556;;A61F2002/30579;;A61F2002/30604;;A61F2002/4415;;A61F2220/0025;;A61F2220/0091;;A61F2230/0065;;A61F2230/0091;;A61F2250/0009;;A61F2250/001;;A61F2/4465;;A61F2002/30471;;A61F2230/0091;;A61F2002/4415;;A61F2002/30545;;A61F2002/30556;;A61F2230/0065;;A61F2220/0025;;A61F2002/30387;;A61F2220/0091;;A61F2250/001;;A61F2002/302;;A61F2002/30579;;A61F2250/0009;;A61F2002/30291;;A61F2002/30604,A61F2/44,,0,0,,,,PENDING
44,US,A,US 5944723 A,026-716-418-868-534,1999-08-31,1999,US 4953598 A,1998-03-27,US 4953598 A,1998-03-27,Locking orthopaedic clamping tool,"A self-locking orthopaedic clamp includes first and second jaws, each jaw having a work engaging surface and a handle comprising first and second actuation members, each actuation member having a first end proximate to the first and second jaws and a second opposed end, and the second actuation member being rigidly coupled to and integral with the second jaw. A four-bar linkage connects the first and second jaws and the first and second actuation members. The design of the clamp and the four-bar linkage is such that the clamp is self-locking. The clamp may be configured for use in a variety of orthopaedic procedures, but it is especially useful for clamping a prosthesis to a resected natural patella.",JOHNSON & JOHNSON PROFESSIONAL,COLLERAN DENNIS P;;DYE JUSTIN;;DUFFY BRIAN,DEPUY ORTHOPAEDICS INC (1999-07-03);;JOHNSON & JOHNSON PROFESSIONAL INC (1998-03-24),https://lens.org/026-716-418-868-534,Granted Patent,yes,11,66,1,1,0,A61B17/8866;;A61B17/8866;;A61B17/1767;;A61B17/1767;;A61F2/3877;;A61F2/3877;;A61F2/461;;A61F2/461;;A61F2002/4628;;A61F2002/4628,A61B17/17;;A61B17/88;;A61F2/38;;A61F2/46,606/88;;606/208,2,0,,,"Surgical Technique For use with PFC Modular Total Knee System , Universal Inset Patella, consisting of three pages including cover page unnumbered, page 10 and page 12.;;Product Display Craftsman Professional Auto Lock, Automatic Self Sizing Locking Pliers 7 Straight Jaw , made in the USA.",EXPIRED
45,US,A1,US 2020/0372302 A1,067-243-760-084-698,2020-11-26,2020,US 202016877923 A,2020-05-19,US 202016877923 A;;US 201962850184 P,2019-05-20,FORECASTING WITH STATE TRANSITIONS AND CONFIDENCE FACTORS,"Various embodiments described herein relate to techniques for forecasting with state transitions and confidence factors. In this regard, a system is configured to segment data associated with one or more assets to determine a set of classifications for one or more attributes related to the one or more assets. The system is also configured to generate a state machine associated with a Markov chain model based on the set of classifications for the data. Furthermore, the system is configured to perform a machine learning process associated with the state machine to determine one or more behavior changes associated with the one or more attributes related to the one or more assets. The system is also configured to predict, based on the one or more behavior changes associated with the one or more attributes related to the one or more assets, a change in demand data for the one or more assets during a future interval of time.",HONEYWELL INT INC,TADEPALLI SRIKANTH;;SHANKAR JAY;;DYE JUSTIN;;SETH ABHISHEK,HONEYWELL INTERNATIONAL INC (2019-06-28),https://lens.org/067-243-760-084-698,Patent Application,yes,9,0,2,2,0,G06N20/20;;G06N3/02;;G06N7/01;;G06F18/256;;G06F18/295;;G06N20/20;;G06F18/2163;;G06F18/22;;G06F18/251;;G06F18/2415;;G06F18/2431;;G06N3/047;;G06V10/765;;G06V10/85,G06K9/62;;G06N20/20,,2,1,040-330-083-649-852,10.1109/icnp.2016.7785328,"Paul, S. S., et al. ""Application of object oriented image classification and Markov chain modeling for land use and land cover change analysis."" Journal of Environmental Informatics 31.1 (2018): 30-40. (Year: 2018);;Chen, Zhitang, Jiayao Wen, and Yanhui Geng. ""Predicting future traffic using hidden Markov models."" 2016 IEEE 24th international conference on network protocols (ICNP). IEEE, 2016. (Year: 2016)",ACTIVE
46,US,B2,US 11687840 B2,165-874-971-049-239,2023-06-27,2023,US 202016877923 A,2020-05-19,US 202016877923 A;;US 201962850184 P,2019-05-20,Forecasting with state transitions and confidence factors,"Various embodiments described herein relate to techniques for forecasting with state transitions and confidence factors. In this regard, a system is configured to segment data associated with one or more assets to determine a set of classifications for one or more attributes related to the one or more assets. The system is also configured to generate a state machine associated with a Markov chain model based on the set of classifications for the data. Furthermore, the system is configured to perform a machine learning process associated with the state machine to determine one or more behavior changes associated with the one or more attributes related to the one or more assets. The system is also configured to predict, based on the one or more behavior changes associated with the one or more attributes related to the one or more assets, a change in demand data for the one or more assets during a future interval of time.",HONEYWELL INT INC,TADEPALLI SRIKANTH;;SHANKAR JAY;;DYE JUSTIN;;SETH ABHISHEK,HONEYWELL INTERNATIONAL INC (2019-06-28),https://lens.org/165-874-971-049-239,Granted Patent,yes,33,0,2,2,0,G06N20/20;;G06N3/02;;G06N7/01;;G06F18/256;;G06F18/295;;G06N20/20;;G06F18/2163;;G06F18/22;;G06F18/251;;G06F18/2415;;G06F18/2431;;G06N3/047;;G06V10/765;;G06V10/85,G06N20/20;;G06F18/21;;G06F18/22;;G06F18/2415;;G06F18/2431;;G06F18/25,,10,3,040-330-083-649-852;;027-312-541-214-857;;011-581-567-842-346,10.1109/icnp.2016.7785328;;10.1007/978-1-84882-634-2_10;;10.2139/ssrn.1868085,"Paul, S. S., et al. “Application of object oriented image classification and Markov chain modeling for land use and land cover change analysis.” Journal of Environmental Informatics 31.1 (2018): 30-40. (Year: 2018).;;Chen, Zhitang, Jiayao Wen, and Yanhui Geng. “Predicting future traffic using hidden Markov models.” 2016 IEEE 24th international conference on network protocols (ICNP). IEEE, 2016. (Year: 2016).;;Datta et al., Forecasting and Risk Analysis in Supply Chain Management, [2008] [retrieved Jul. 7, 2020] retrieved from the Internet URL: https://dspace.mit.edU/bitstream/handle/1721.1/43948/garchproofofconcept_datta_granger_graham_sagar_doody_slone_hilmola_18december2008_final.pdf?sequence=1, 23 pages.;;Deflem et al., A Discrete Time Markov Chain Model for a Periodic Inventory System With One-Way Substitution, [retrieved on Jul. 30, 2020], retrieved from the Internet URL: https://lirias.kuleuven.be/bitstream/123456789/308952/1/KBI_1111.pdf, 19 pages.;;Fedriani, Framework for Spare Parts Management. Methods to Improve Decision Making., [2017] [retrieved Jul. 30, 2020], retrieved from the Internet URL: http://bibing.us.es/proyectos/abreproy/91212/fichero/TFG_Def_FJCFpdf.pdf, 137 pages.;;Kocer, Forecasting Intermittent Demand by Markov Chain Model, 2012, retrieved on Jul. 30, 2020, retrieved from the Internet URL: http://www.ijicic.org/ijicic-12-06020.pdf, 12 pages.;;Martin, Strategic Forecasting in the Supply Chain for Manufacturers, [2019] [retrieved Aug. 18, 2020] retrieved from the Internet URL: https://www.thebalance.com/forecasting-in-the-supply-chain-2221207, 3 pages.;;Sigma Themal, 7 Things to Consider for Successful Ppare Parts Management [2017] [retrieved Aug. 17, 2020] retrieved from the Internet: https://www.sigmathermal.com/spare-parts-management/, 16 pages.;;Vishnuvsve, Demand Forecasting in Supply Chain, [2016] [retrieved Aug. 18, 2020] retrieved from the Internet URL: https://www.slideshare.net/vishnuvsvn/demand-forecasting-in-supply-chain/5, 41 pages.;;Vorhies, Predictive Analytics in the Supply Chain, [2015] [retrieved Aug. 17, 2020] retrieved from the Internet URL: https://www.datasciencecentral.com/profiles/blogs/predictive-analytics-in-the-supply-chain, 5 pages.",ACTIVE
47,US,A,US 6080162 A,153-294-832-267-205,2000-06-27,2000,US 16192598 A,1998-09-28,US 16192598 A,1998-09-28,Modular orthopaedic clamping tool,"A modular orthopaedic clamping tool system includes a clamp and a plurality of modular tools. The clamp has a handle having substantially parallel first and second actuation members with a jaw member integral with the first actuation member and a modular attachment element integral with the second actuation member. A linkage connects the first and second actuation members and operates to maintain a substantially parallel orientation between the actuation members while the clamp moves between open and closed positions. In addition, the orthopaedic clamping tool may be locked without causing an excessive clamping force on a clamped bone.",DEPUY ORTHOPAEDICS INC,DYE JUSTIN;;CIPOLLETTI GEORGE;;BOYKO JAMES;;MCCUE DIANA,DEPUY ORTHOPAEDICS INC (1999-07-03);;JOHNSON & JOHNSON PROFESSIONAL INC (1998-09-18),https://lens.org/153-294-832-267-205,Granted Patent,yes,7,84,4,4,0,A61B17/1767;;A61B17/2812;;A61B17/1767;;A61B17/2812,A61B17/17;;A61B17/28;;A61B17/56,606/80,1,0,,,"Surgical Technique For use with PFC Modular Total Knee System , Universal Inset Patella, consisting of three pages including cover page unnumbered, p. 10 and p. 12.",EXPIRED
48,EP,A3,EP 0992222 A3,064-360-517-015-581,2000-04-19,2000,EP 99307588 A,1999-09-27,US 16192598 A,1998-09-28,Modular orthopaedic clamping tool,"A modular orthopaedic clamping tool system includes a clamp and a plurality of modular tools. The clamp has a handle having substantially parallel first and second actuation members with a jaw member integral with the first actuation member and a modular attachment element integral with the second actuation member. A linkage connects the first and second actuation members and operates to maintain a substantially parallel orientation between the actuation members while the clamp moves between open and closed positions. In addition, the orthopaedic clamping tool may be locked without causing an excessive clamping force on a clamped bone.",JOHNSON & JOHNSON PROFESSIONAL,DYE JUSTIN;;CIPOLLETTI GEORGE;;BOYKO JAMES;;MCCUE DIANA,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/064-360-517-015-581,Search Report,yes,3,0,4,4,0,A61B17/1767;;A61B17/2812;;A61B17/1767;;A61B17/2812,A61B17/28;;A61B17/17;;A61B17/56,,0,0,,,,DISCONTINUED
49,JP,A,JP 2000139935 A,119-620-209-601-281,2000-05-23,2000,JP 27305399 A,1999-09-27,US 16192598 A,1998-09-28,FORCEPS APPARATUS SYSTEM FOR ORTHOPEDIC SURGERY AND FORCEPS APPARATUS,"PROBLEM TO BE SOLVED: To provide a forceps not required to be prudently used by a surgeon not to overtighten it by arranging a jaw member on a first operation member, arranging a module type fitting element on a second operation member, and maintaining the operation members nearly in parallel when the forceps is moved between an opened state and a closed state. SOLUTION: A jaw member 18 is integrally formed on the operation member 14 of a forceps 10 for orthopedic surgery, and a module type fitting element 66 is integrally provided on an operation member 16 at a grip end section 24. The operation members 14, 16 are connected at a junction 20, and a skew member 32 is rotatably connected to the operation member 14 at a rotation point 36 and is rotatably and slidably connected to the operation member 16 at a sliding rotation point 38. A skew member 34 is rotatably connected to the operation member 16 at a rotation point 40 and is rotatably and slidably connected to the operation member 14 at a sliding rotation point 42. The skew member 32 is rotatably connected to the skew member 34 at a rotation point 44.",JOHNSON & JOHNSON PROFESSIONAL,DYE JUSTIN;;CIPOLLETTI GEORGE;;BOYKO JAMES;;MCCUE DIANA,,https://lens.org/119-620-209-601-281,Patent Application,no,0,1,4,4,0,A61B17/1767;;A61B17/2812;;A61B17/1767;;A61B17/2812,A61B17/28;;A61B17/17;;A61B17/56,,0,0,,,,PENDING
50,EP,A2,EP 0992222 A2,143-989-576-467-782,2000-04-12,2000,EP 99307588 A,1999-09-27,US 16192598 A,1998-09-28,Modular orthopaedic clamping tool,"A modular orthopaedic clamping tool system includes a clamp and a plurality of modular tools. The clamp has a handle having substantially parallel first and second actuation members with a jaw member integral with the first actuation member and a modular attachment element integral with the second actuation member. A linkage connects the first and second actuation members and operates to maintain a substantially parallel orientation between the actuation members while the clamp moves between open and closed positions. In addition, the orthopaedic clamping tool may be locked without causing an excessive clamping force on a clamped bone.",JOHNSON & JOHNSON PROFESSIONAL,DYE JUSTIN;;CIPOLLETTI GEORGE;;BOYKO JAMES;;MCCUE DIANA,"DEPUY PRODUCTS, INC. (2003-05-02)",https://lens.org/143-989-576-467-782,Patent Application,yes,4,23,4,4,0,A61B17/1767;;A61B17/2812;;A61B17/1767;;A61B17/2812,A61B17/28;;A61B17/17;;A61B17/56,,0,0,,,,DISCONTINUED
51,US,A1,US 2008/0058723 A1,056-820-469-409-408,2008-03-06,2008,US 93133507 A,2007-10-31,US 93133507 A;;US 80538004 A,2004-03-22,Medical Cannula Assembly,"A medical assembly includes a cannula and a scaling cap releasably coupled to the cannula. The cap includes a body and a sealing member integrally molded with the body to form a fluid-tight seal between the cap and cannula. The cap includes a member defining an opening for passage of a medical instrument therethrough in a fluid-tight manner. The member includes a first portion surrounding the opening and being thickened to limit tearing of the first portion, and a second portion surrounding the first portion being tapered down in thickness toward the first portion to increase flexibility of the member. The assembly includes a shaft receivable in a lumen defined by an inner surface of the cannula. The shaft includes a protrusion and the inner surface further defines a protrusion receiving formation.",SMITH & NEPHEW INC,LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL A,SMITH & NEPHEW INC (2001-06-30),https://lens.org/056-820-469-409-408,Patent Application,yes,42,16,6,6,0,A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/0218,A61B17/00;;A61M25/00;;A61B17/34,604/164.08;;604/165.01,0,0,,,,ACTIVE
52,WO,A1,WO 2005/092217 A1,116-231-210-338-849,2005-10-06,2005,US 2005/0009267 W,2005-03-21,US 80538004 A,2004-03-22,MEDICAL CANNULA ASSEMBLY,"A medical assembly includes a cannula (20) and a sealing cap (40) in releasable fluid-tight engagement with the cannula. The cap includes a body and a sealing member (50) integrally coupled with the body to form a fluid-tight seal between the cap and cannula. The cap includes a member defining an opening for passage of a medical instrument therethrough in a fluid-tight manner. The member includes a first portion surrounding the opening and being thickened (64) to limit tearing of the first portion, and a second portion surrounding the first portion and being of less thickness than the first portion to increase flexibility of the member. The assembly includes a shaft (85) receivable in a lumen defined by an inner surface of the cannula. The shaft includes a protrusion (89) and the inner surface further defines a protrusion receiving formation.",SMITH & NEPHEW INC;;LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL ALEXANDER,LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL ALEXANDER,,https://lens.org/116-231-210-338-849,Patent Application,yes,6,4,6,6,0,A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/0218,A61B17/00;;A61B17/34,,0,0,,,,PENDING
53,CA,A1,CA 2757837 A1,133-151-715-010-765,2010-10-14,2010,CA 2757837 A,2010-04-07,US 16729909 P;;US 2010/0030275 W,2009-04-07,PHOTODYNAMIC BONE STABILIZATION SYSTEMS AND METHODS FOR TREATING SPINE CONDITIONS,"In an embodiment, a system for treating the spine includes a catheter (101) having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable interspinous process spacer device (900), and a longitudinal axis therebetween, wherein an inner void of the catheter (101) is sufficiently designed for passage of a liquid light-curable material to the interspinous process spacer device (900), wherein an inner lumen of the catheter (101) is sufficiently designed for passage of a light-conducting fiber to the interspinous process spacer device (900), wherein the interspinous process spacer device (900) includes a circumferential groove (930), wherein the interspinous process spacer device (900) is sufficiently designed to inflate and deflate as the liquid light-curable material is added, and wherein the interspinous process spacer device (900), when positioned between two spinous processes (980) and inflated, is configured to engage the spinous processes (980) at the groove (930).",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,,https://lens.org/133-151-715-010-765,Patent Application,no,0,0,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/88,,0,0,,,,DISCONTINUED
54,US,A1,US 2005/0209607 A1,049-157-443-396-74X,2005-09-22,2005,US 80538004 A,2004-03-22,US 80538004 A,2004-03-22,Medical cannula assembly,"A medical assembly includes a cannula and a sealing cap releasably coupled to the cannula. The cap includes a body and a sealing member integrally molded with the body to form a fluid-tight seal between the cap and cannula. The cap includes a member defining an opening for passage of a medical instrument therethrough in a fluid-tight manner. The member includes a first portion surrounding the opening and being thickened to limit tearing of the first portion, and a second portion surrounding the first portion being tapered down in thickness toward the first portion to increase flexibility of the member. The assembly includes a shaft receivable in a lumen defined by an inner surface of the cannula. The shaft includes a protrusion and the inner surface further defines a protrusion receiving formation.",LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL A,LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL A,SMITH & NEPHEW INC (2004-06-29),https://lens.org/049-157-443-396-74X,Patent Application,yes,39,41,6,6,0,A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/0218,A61B17/00;;A61B17/34,606/108;;251/149.1;;606/185,0,0,,,,DISCONTINUED
55,WO,A1,WO 2021/150726 A1,156-299-113-919-125,2021-07-29,2021,US 2021/0014375 W,2021-01-21,US 202062965359 P,2020-01-24,MECHANICAL SPARK CONTAINMENT FOR DISCONNECTOR,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,DYE JUSTIN;;VAN BESOUW BASTIAAN;;IYER SIDHARTH;;HUO XINGNIU,,https://lens.org/156-299-113-919-125,Patent Application,yes,4,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H01T4/02;;H01H39/00;;H02H3/02;;H02H3/20,,0,0,,,,PENDING
56,US,A1,US 2010/0262188 A1,095-653-004-617-388,2010-10-14,2010,US 75601410 A,2010-04-07,US 75601410 A;;US 16729909 P,2009-04-07,Photodynamic Bone Stabilization Systems and Methods for Treating Spine Conditions,"In an embodiment, an interspinous process spacer system includes a light-conducting fiber configured to transmit light energy; a liquid light-curable material; and a catheter having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable interspinous process spacer device, and a longitudinal axis therebetween, wherein an inner void of the catheter is sufficiently designed for passage of the liquid light-curable material to the interspinous process spacer device, wherein an inner lumen of the catheter is sufficiently designed for passage of the light-conducting fiber to the interspinous process spacer device, wherein the interspinous process spacer device includes a circumferential groove, wherein the interspinous process spacer device is sufficiently designed to inflate and deflate as the liquid light-curable material is added, and wherein the interspinous process spacer device, when positioned between two spinous processes and inflated, is configured to engage the spinous processes at the groove.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/095-653-004-617-388,Patent Application,yes,104,39,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/70,606/249,0,0,,,,DISCONTINUED
57,EP,A4,EP 2416722 A4,136-625-336-540-820,2013-12-11,2013,EP 10762390 A,2010-04-07,US 2010/0030275 W;;US 16729909 P,2009-04-07,PHOTODYNAMIC BONE STABILIZATION SYSTEMS AND METHODS FOR TREATING SPINE CONDITIONS,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,,https://lens.org/136-625-336-540-820,Search Report,no,1,0,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/70;;A61F2/44,,0,0,,,,DISCONTINUED
58,EP,A1,EP 2416722 A1,086-426-985-839-896,2012-02-15,2012,EP 10762390 A,2010-04-07,US 2010/0030275 W;;US 16729909 P,2009-04-07,PHOTODYNAMIC BONE STABILIZATION SYSTEMS AND METHODS FOR TREATING SPINE CONDITIONS,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,,https://lens.org/086-426-985-839-896,Patent Application,yes,0,0,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/70;;A61F2/44,,0,0,,,,DISCONTINUED
59,AU,A1,AU 2010/234448 A1,152-805-155-545-700,2011-10-27,2011,AU 2010/234448 A,2010-04-07,US 16729909 P;;US 2010/0030275 W,2009-04-07,Photodynamic bone stabilization systems and methods for treating spine conditions,"In an embodiment, a system for treating the spine includes a catheter (101) having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable interspinous process spacer device (900), and a longitudinal axis therebetween, wherein an inner void of the catheter (101) is sufficiently designed for passage of a liquid light-curable material to the interspinous process spacer device (900), wherein an inner lumen of the catheter (101) is sufficiently designed for passage of a light-conducting fiber to the interspinous process spacer device (900), wherein the interspinous process spacer device (900) includes a circumferential groove (930), wherein the interspinous process spacer device (900) is sufficiently designed to inflate and deflate as the liquid light-curable material is added, and wherein the interspinous process spacer device (900), when positioned between two spinous processes (980) and inflated, is configured to engage the spinous processes (980) at the groove (930).",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,,https://lens.org/152-805-155-545-700,Patent Application,no,0,0,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/88,,0,0,,,,DISCONTINUED
60,CA,A1,CA 3168822 A1,156-475-113-936-881,2021-07-29,2021,CA 3168822 A,2021-01-21,US 202062965359 P;;US 2021/0014375 W,2020-01-24,MECHANICAL SPARK CONTAINMENT FOR DISCONNECTOR,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,DYE JUSTIN;;VAN BESOUW BASTIAAN;;IYER SIDHARTH;;HUO XINGNIU,,https://lens.org/156-475-113-936-881,Patent Application,no,0,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H01T4/02;;H01H39/00;;H02H3/02;;H02H3/20,,0,0,,,,PENDING
61,BR,A2,BR PI1015207 A2,136-195-295-933-54X,2016-05-03,2016,BR PI1015207 A,2010-04-07,US 2010/0030275 W;;US 16729909 P,2009-04-07,sistemas e métodos de estabilização óssea fotodinâmicos para tratar de condições da espinha,,ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;DYE JUSTIN G;;RABINER ROBERT A,,https://lens.org/136-195-295-933-54X,Patent Application,no,0,0,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/88,,0,0,,,,DISCONTINUED
62,WO,A1,WO 2010/118158 A1,096-377-285-024-682,2010-10-14,2010,US 2010/0030275 W,2010-04-07,US 16729909 P,2009-04-07,PHOTODYNAMIC BONE STABILIZATION SYSTEMS AND METHODS FOR TREATING SPINE CONDITIONS,"In an embodiment, a system for treating the spine includes a catheter (101) having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable interspinous process spacer device (900), and a longitudinal axis therebetween, wherein an inner void of the catheter (101) is sufficiently designed for passage of a liquid light-curable material to the interspinous process spacer device (900), wherein an inner lumen of the catheter (101) is sufficiently designed for passage of a light-conducting fiber to the interspinous process spacer device (900), wherein the interspinous process spacer device (900) includes a circumferential groove (930), wherein the interspinous process spacer device (900) is sufficiently designed to inflate and deflate as the liquid light-curable material is added, and wherein the interspinous process spacer device (900), when positioned between two spinous processes (980) and inflated, is configured to engage the spinous processes (980) at the groove (930).",ILLUMINOSS MEDICAL INC;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,,https://lens.org/096-377-285-024-682,Patent Application,yes,3,19,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/88,,1,0,,,See also references of EP 2416722A4,PENDING
63,US,A1,US 2013/0006304 A1,047-406-249-329-975,2013-01-03,2013,US 201213617058 A,2012-09-14,US 201213617058 A;;US 75601410 A;;US 16729909 P,2009-04-07,PHOTODYNAMIC BONE STABILIZATION SYSTEMS AND METHODS FOR TREATING SPINE CONDITIONS,"In an embodiment, an interspinous process spacer system includes a light-conducting fiber configured to transmit light energy; a liquid light-curable material; and a catheter having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable interspinous process spacer device, and a longitudinal axis therebetween, wherein an inner void of the catheter is sufficiently designed for passage of the liquid light-curable material to the interspinous process spacer device, wherein an inner lumen of the catheter is sufficiently designed for passage of the light-conducting fiber to the interspinous process spacer device, wherein the interspinous process spacer device includes a circumferential groove, wherein the interspinous process spacer device is sufficiently designed to inflate and deflate as the liquid light-curable material is added, and wherein the interspinous process spacer device, when positioned between two spinous processes and inflated, is configured to engage the spinous processes at the groove.",ILLUMINOSS MEDICAL INC;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/047-406-249-329-975,Patent Application,yes,0,30,8,8,0,A61B17/7004;;A61B17/7065;;A61F2/30965;;A61F2/441;;A61F2/4455;;A61F2/4611;;A61F2002/3008;;A61F2002/302;;A61F2002/30579;;A61F2002/30583;;A61F2002/30925;;A61F2002/4495;;A61F2210/0085;;A61F2230/0065;;A61F2250/0098;;A61F2310/0097;;A61F2310/00976;;A61B17/7013;;A61B2017/00557;;A61F2002/30593;;A61B17/7004;;A61F2002/30579;;A61F2230/0065;;A61F2/441;;A61F2/4611;;A61F2/4455;;A61F2002/3008;;A61F2210/0085;;A61F2002/30925;;A61F2250/0098;;A61F2002/302;;A61B17/7065;;A61F2310/0097;;A61F2002/30583;;A61F2/30965;;A61F2310/00976;;A61F2002/4495;;A61B2017/00557;;A61B17/7013;;A61F2002/30593,A61B17/88;;A61B17/70,606/249;;606/279,0,0,,,,DISCONTINUED
64,US,B2,US 8377089 B2,107-180-830-197-625,2013-02-19,2013,US 93133507 A,2007-10-31,US 93133507 A;;US 80538004 A,2004-03-22,Medical cannula assembly,"A medical assembly includes a cannula and a scaling cap releasably coupled to the cannula. The cap includes a body and a sealing member integrally molded with the body to form a fluid-tight seal between the cap and cannula. The cap includes a member defining an opening for passage of a medical instrument therethrough in a fluid-tight manner. The member includes a first portion surrounding the opening and being thickened to limit tearing of the first portion, and a second portion surrounding the first portion being tapered down in thickness toward the first portion to increase flexibility of the member. The assembly includes a shaft receivable in a lumen defined by an inner surface of the cannula. The shaft includes a protrusion and the inner surface further defines a protrusion receiving formation.",SMITH & NEPHEW INC;;LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL ALEXANDER,LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE ROD;;TORRIE PAUL ALEXANDER,SMITH & NEPHEW INC (2001-06-30),https://lens.org/107-180-830-197-625,Granted Patent,yes,76,26,6,6,0,A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/0218,A61B17/00;;A61B17/34,606/185;;606/108;;600/184,14,0,,,"""Caps-Lock Cannula System"" http://www.atlantech-md.co.uk/products/shoulder/shoulder1.html (Oct. 6, 2003).;;""SPS(TM)-The Karl Storz Secure Portal System"" , ENDOWORLD OSM-21, Karl Storz-Sports Medicine, Inc. (Jan. 2003).;;Stephen J. Snyder, M.D., ""Crystal(TM) Cannula"" Endoscopic Carpal Tunnel Release System, http://www.arthrex.com/English/private/featured-product-november.phtml (May 2, 2002).;;""Translucent Twist-In Cannula System"" Arthrex, http://www.arthrex.com/English/private/catalog/11/11-2.htm (Sep. 17, 2002).;;""Instrument Cannula"" Arthrex, http://www.arthrex.com/English/private/catalog/11/11-3.htm (Sep. 17, 2002).;;""Crystal(TM) Cannula"" Arthrex, http://www.arthrex.com/English/private/catalog/11/11-1.htm (Sep. 17, 2002).;;""Clear Cannula System"" Mitek Products (Jun. 2000).;;""Applied Premium Disposable Trocar System"" Applied Medical (2000).;;""Entry Systems Inflow Devices and Accessories"" Linvatec (undated).;;""Products The Main Genicon Products Catalog"" http://www.genicon.co.uk/products.html (Sep. 18, 2002).;;""A New Disposable Cannula for Shoulder Arthroscopy"" ""Small Joint Arthroscopy Instruments"" Arthroscopic Instruments, Linvatec Source (undated).;;International Search Report for PCT/US2005/009267, filed Mar. 21, 2005 dated Jul. 26, 2005.;;Written Opinion for PCT/US2005/009267, filed Mar. 21, 2005 dated Jul. 26, 2005.;;European Patent Office, Supplementary Partial European Search Report for PCT application No. PCT/US01/45567.",ACTIVE
65,WO,A8,WO 2004/049958 A8,056-441-020-207-080,2005-05-12,2005,US 0338298 W,2003-11-26,US 30599802 A,2002-11-27,REATTACHMENT OF TISSUE TO BASE TISSUE,An anchor (401) includes an anchor body configured to be retained within base tissue. The anchor body includes a unidirectional mechanism to selectively restrict passage of a flexible member (450) through the anchor. The flexible member includes a loop (474) to enable attachment of candidate tissue to base tissue without the use of knots.,SMITH & NEPHEWS INC;;COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFEN;;DYE JUSTIN;;SIKORA GEORGE,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFEN;;DYE JUSTIN;;SIKORA GEORGE,,https://lens.org/056-441-020-207-080,Patent Application,no,0,0,7,7,0,A61B17/0401;;A61B17/0401;;A61B17/0487;;A61B17/0487;;A61B2017/0412;;A61B2017/0412;;A61B2017/0414;;A61B2017/0414;;A61B2017/0427;;A61B2017/0427;;A61B2017/0437;;A61B2017/0437;;A61B2017/0438;;A61B2017/0438;;A61B2017/0456;;A61B2017/0456;;A61B2017/0496;;A61B2017/0496,A61B17/04,,0,0,,,,PENDING
66,US,A1,US 2011/0152928 A1,025-477-977-891-691,2011-06-23,2011,US 97025910 A,2010-12-16,US 97025910 A;;US 30599802 A;;US 98637601 A,2001-11-08,REATTACHMENT OF TISSUE TO BASE TISSUE,An anchor includes an anchor body configured to be retained within base tissue. The anchor body includes a unidirectional mechanism to selectively restrict passage of a flexible member through the anchor. The flexible member includes a loop to enable attachment of candidate tissue to base tissue without the use of knots.,SMITH & NEPHEW INC,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFAN;;DYE JUSTIN;;SIKORA GEORGE,SMITH & NEPHEW INC (2003-01-06),https://lens.org/025-477-977-891-691,Patent Application,yes,1,43,7,7,0,A61B17/0401;;A61B17/0401;;A61B17/0487;;A61B17/0487;;A61B2017/0412;;A61B2017/0412;;A61B2017/0414;;A61B2017/0414;;A61B2017/0427;;A61B2017/0427;;A61B2017/0437;;A61B2017/0437;;A61B2017/0438;;A61B2017/0438;;A61B2017/0456;;A61B2017/0456;;A61B2017/0496;;A61B2017/0496,A61B17/04,606/232,0,0,,,,EXPIRED
67,US,B2,US 9060762 B2,063-495-141-709-308,2015-06-23,2015,US 97025910 A,2010-12-16,US 97025910 A;;US 30599802 A;;US 98637601 A,2001-11-08,Reattachment of tissue to base tissue,An anchor includes an anchor body configured to be retained within base tissue. The anchor body includes a unidirectional mechanism to selectively restrict passage of a flexible member through the anchor. The flexible member includes a loop to enable attachment of candidate tissue to base tissue without the use of knots.,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFAN;;DYE JUSTIN;;SIKORA GEORGE;;SMITH & NEPHEW INC,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFAN;;DYE JUSTIN;;SIKORA GEORGE,SMITH & NEPHEW INC (2003-01-06),https://lens.org/063-495-141-709-308,Granted Patent,yes,100,2,7,7,0,A61B17/0401;;A61B17/0401;;A61B17/0487;;A61B17/0487;;A61B2017/0412;;A61B2017/0412;;A61B2017/0414;;A61B2017/0414;;A61B2017/0427;;A61B2017/0427;;A61B2017/0437;;A61B2017/0437;;A61B2017/0438;;A61B2017/0438;;A61B2017/0456;;A61B2017/0456;;A61B2017/0496;;A61B2017/0496,A61B17/04,,13,0,,,"PCT International Search Report, May 4, 2004, 9 pages.;;Panalok Anchor with Panacryl Suture 1997, 2 pages.;;Office Action in U.S. Appl. No. 09/986,376 mailed Jan. 21, 2003, 7 pages.;;Office Action in U.S. Appl. No. 90/006,989 mailed Dec. 7, 2004, 5 pages.;;Office Action in U.S. Appl. No. 90/006,989 mailed May 9, 2005, 8 pages.;;Office Action in U.S. Appl. No. 90/006,989, mailed May 20, 2004.;;Office Action in U.S. Appl. No. 90/006,989, mailed Aug. 16, 2005.;;Office Action in U.S. Appl. No. 90/006,989, mailed Aug. 23, 2006.;;Office Action in U.S. Appl. No. 90/006,989, mailed Jul. 26, 2007.;;Notification of Transmittal of the International Search Report and the Written Opinion of the International Searching Authority, or the Declaration of International Application No. PCT/US2008/061267 dated Oct. 30, 2008, 16 pages.;;Office Action for U.S. Appl. No. 10/724,121, mailed Dec. 8, 2005, 13 pages.;;Office Action for U.S. Appl. No. 10/724,121, mailed Oct. 25, 2006, 5 pages.;;Office Action for U.S. Appl. No. 10/724,121, mailed May 4, 2007, 5 pages.",INACTIVE
68,AU,A1,AU 2003/293245 A1,002-036-825-867-061,2004-06-23,2004,AU 2003/293245 A,2003-11-26,US 30599802 A;;US 0338298 W,2002-11-27,REATTACHMENT OF TISSUE TO BASE TISSUE,,SMITH AND NEPHEWS INC,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFEN;;DYE JUSTIN;;SIKORA GEORGE,,https://lens.org/002-036-825-867-061,Patent Application,no,0,0,7,7,0,A61B17/0401;;A61B17/0401;;A61B17/0487;;A61B17/0487;;A61B2017/0412;;A61B2017/0412;;A61B2017/0414;;A61B2017/0414;;A61B2017/0427;;A61B2017/0427;;A61B2017/0437;;A61B2017/0437;;A61B2017/0438;;A61B2017/0438;;A61B2017/0456;;A61B2017/0456;;A61B2017/0496;;A61B2017/0496,A61B17/04,,0,0,,,,DISCONTINUED
69,WO,A1,WO 2004/049958 A1,118-715-606-485-697,2004-06-17,2004,US 0338298 W,2003-11-26,US 30599802 A,2002-11-27,REATTACHMENT OF TISSUE TO BASE TISSUE,An anchor (401) includes an anchor body configured to be retained within base tissue. The anchor body includes a unidirectional mechanism to selectively restrict passage of a flexible member (450) through the anchor. The flexible member includes a loop (474) to enable attachment of candidate tissue to base tissue without the use of knots.,SMITH & NEPHEWS INC;;COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFEN;;DYE JUSTIN;;SIKORA GEORGE,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFEN;;DYE JUSTIN;;SIKORA GEORGE,,https://lens.org/118-715-606-485-697,Patent Application,yes,6,13,7,7,0,A61B17/0401;;A61B17/0401;;A61B17/0487;;A61B17/0487;;A61B2017/0412;;A61B2017/0412;;A61B2017/0414;;A61B2017/0414;;A61B2017/0427;;A61B2017/0427;;A61B2017/0437;;A61B2017/0437;;A61B2017/0438;;A61B2017/0438;;A61B2017/0456;;A61B2017/0456;;A61B2017/0496;;A61B2017/0496,A61B17/04,,0,0,,,,PENDING
70,US,A1,US 2003/0120309 A1,188-071-366-469-863,2003-06-26,2003,US 30599802 A,2002-11-27,US 30599802 A;;US 98637601 A,2001-11-08,Reattachment of tissue to base tissue,"
   An anchor includes an anchor body configured to be retained within base tissue. The anchor body includes a unidirectional mechanism to selectively restrict passage of a flexible member through the anchor. The flexible member includes a loop to enable attachment of candidate tissue to base tissue without the use of knots. 
",COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFAN;;DYE JUSTIN;;SIKORA GEORGE,COLLERAN DENNIS;;TRAIL IAN;;GABRIEL STEFAN;;DYE JUSTIN;;SIKORA GEORGE,SMITH & NEPHEW INC (2003-01-06),https://lens.org/188-071-366-469-863,Patent Application,yes,99,232,7,7,0,A61B17/0401;;A61B17/0401;;A61B17/0487;;A61B17/0487;;A61B2017/0412;;A61B2017/0412;;A61B2017/0414;;A61B2017/0414;;A61B2017/0427;;A61B2017/0427;;A61B2017/0437;;A61B2017/0437;;A61B2017/0438;;A61B2017/0438;;A61B2017/0456;;A61B2017/0456;;A61B2017/0496;;A61B2017/0496,A61B17/04,606/232,0,0,,,,EXPIRED
71,US,B2,US 10052090 B2,108-559-099-104-17X,2018-08-21,2018,US 201313743527 A,2013-01-17,US 201313743527 A;;US 93133507 A;;US 80538004 A,2004-03-22,Medical cannula assembly,"A medical assembly includes a cannula and a sealing cap releasably coupled to the cannula. The cap includes a body and a sealing member integrally molded with the body to form a fluid-tight seal between the cap and cannula. The cap includes a member defining an opening for passage of a medical instrument therethrough in a fluid-tight manner. The member includes a first portion surrounding the opening and being thickened to limit tearing of the first portion, and a second portion surrounding the first portion being tapered down in thickness toward the first portion to increase flexibility of the member. The assembly includes a shaft receivable in a lumen defined by an inner surface of the cannula. The shaft includes a protrusion and the inner surface further defines a protrusion receiving formation.",SMITH & NEPHEW INC,LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE JR ALFRED RODRIGUE;;TORRIE PAUL ALEXANDER,SMITH & NEPHEW INC (2004-06-29),https://lens.org/108-559-099-104-17X,Granted Patent,yes,79,0,6,6,0,A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/0218,A61B17/02;;A61B17/00;;A61B17/34,,14,0,,,"“Caps-Lock Cannula System” http://www.atlantech-md.co.uk/products/shoulder/shoulder1.html (Oct. 6, 2003).;;“SPS™—The Karl Storz Secure Portal System”, Endoworld OSM-21, Karl Storz-Sports Medicine, Inc. (Jan. 2003).;;Stephen J. Snyder, M.D., “Crystal™ Cannula” Endoscopic Carpal Tunnel Release System, http://www.arthrex.com/English/private/featured_product_november.phtml (May 2, 2002).;;“Translucent Twist-In Cannula System” Arthrex, http://www.arthrex.com/English/private/catalog/11/11-2.htm (Sep. 17, 2002).;;“Instrument Cannula” Arthrex, http://www.arthrex.com/English/private/catalog/11/11-3.htm (Sep. 17, 2002).;;“Crystal™ Cannula” Arthrex, http://www.arthrex.com/English/private/catalog/11/11-1.htm (Sep. 17, 2002).;;“Clear Cannula System” Mitek Products (Jun. 2000).;;“Applied Premium Disposable Trocar System” Applied Medical (2000).;;“Entry Systems Inflow Devices and Accessories” Linvatec (undated).;;“Products The Main Genicon Products Catalog” http://www.genicon.co.uk/products.html (Sep. 18, 2002).;;“A New Disposable Cannula for Shoulder Arthroscopy” “Small Joint Arthroscopy Instruments” Arthroscopic Instruments, Linvatec Source (undated).;;International Search Report for PCT/US2005/009267, filed Mar. 21, 2005 dated Jul. 26, 2005.;;Written Opinion for PCT/US2005/009267, filed Mar. 21, 2005 dated Jul. 26, 2005.;;European Patent Office, Supplementary Partial European Search Report for PCT application No. PCT/US01/45567.",INACTIVE
72,US,A1,US 2013/0131455 A1,091-907-905-781-515,2013-05-23,2013,US 201313743527 A,2013-01-17,US 201313743527 A;;US 93133507 A;;US 80538004 A,2004-03-22,MEDICAL CANNULA ASSEMBLY,"A medical assembly includes a cannula and a sealing cap releasably coupled to the cannula. The cap includes a body and a sealing member integrally molded with the body to form a fluid-tight seal between the cap and cannula. The cap includes a member defining an opening for passage of a medical instrument therethrough in a fluid-tight manner. The member includes a first portion surrounding the opening and being thickened to limit tearing of the first portion, and a second portion surrounding the first portion being tapered down in thickness toward the first portion to increase flexibility of the member. The assembly includes a shaft receivable in a lumen defined by an inner surface of the cannula. The shaft includes a protrusion and the inner surface further defines a protrusion receiving formation.",LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE JR ALFRED RODRIGUE;;TORRIE PAUL ALEXANDER;;SMITH & NEPHEW INC,LIPCHITZ JOHN;;DYE JUSTIN;;BERUBE JR ALFRED RODRIGUE;;TORRIE PAUL ALEXANDER,SMITH & NEPHEW INC (2004-06-29),https://lens.org/091-907-905-781-515,Patent Application,yes,3,0,6,6,0,A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/3421;;A61B17/3498;;A61B2017/00477;;A61B2017/3482;;A61B2017/349;;A61B17/0218,A61B17/02;;A61B17/00;;A61B17/34,600/201,0,0,,,,INACTIVE
73,US,B2,US 9427289 B2,189-183-402-645-610,2016-08-30,2016,US 26237008 A,2008-10-31,US 26237008 A;;US 98424107 P,2007-10-31,Light source,"Disposable light sources are disclosed herein. A device for connecting a fiber to a light source includes a light source, light director to focus light from the light source, the light director surrounding at least a portion of the light source, a power source providing energy to the light source, and a connector communicating light from the light source to a catheter.",RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2008-11-03),https://lens.org/189-183-402-645-610,Granted Patent,yes,109,23,4,4,0,A61B90/30;;A61B90/30;;A61B2017/00734;;A61B2017/00734;;A61B2090/306;;A61B2090/306,A61B18/18;;A61B17/00,,99,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;Jovanovic et al., Fixion Nails for Humeral Fractures, Injury, Int. J. Care Injured, vol. 34, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison, Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, pp. 9-12, 1996.;;Waris et al., Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures, Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study, The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 30, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 30, 2012.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;PCT International Search Report for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Mar. 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/616,416 mailed Mar. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/772,947 mailed Jun. 19, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jul. 9, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Sep. 16, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Sep. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Sep. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Oct. 9, 2013.;;Extended European Search Report based on EP 10 76 2390 dated Oct. 30, 2013.;;USPTO Office Action in U.S. Appl. No. 12/983,496 mailed Feb. 5, 2014.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Feb. 13, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,181 mailed Feb. 25, 2014.;;PCT International Search Report based on PCT/US13/076598 dated Mar. 19, 2014.;;USPTO Office Action in U.S. Appl. No. 13/655,808 mailed Mar. 27, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed May 7, 2014.;;Extended European Search Report based on EP 14156473 dated May 13, 2014.;;USPTO Office Action in U.S. Appl. No. 13/800,518 mailed Jun. 10, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jun. 27, 2014.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Jul. 31, 2014.;;USPTO Office Action in U.S. Appl. No. 13/616,781 mailed Aug. 26, 2014.;;USPTO Office Action in U.S. Appl. No. 13/730,521 mailed Sep. 8, 2014.;;PCT International Search Report based on PCT/US13/049773 dated Oct. 1, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 7, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,450 mailed Oct. 24, 2014.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Oct. 24, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed Dec. 5, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Dec. 23, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jan. 15, 2015.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Feb. 9, 2015.;;USPTO Office Action in U.S. Appl. No. 13/796,085 mailed Feb. 12, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Mar. 31, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Sep. 11, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed Sep. 23, 2015.;;USPTO Office Action in U.S. Appl. No. 14/164,846 mailed Oct. 14, 2015.;;USPTO Office Action in U.S. Appl. No. 14/171,036 mailed Oct. 15, 2015.;;USPTO Office Action in U.S. Appl. No. 13/796,085 mailed Nov. 27, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Jan. 6, 2016.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jan. 14, 2016.;;USPTO Office Action in U.S. Appl. No. 14/177,748 mailed Jan. 25, 2016.;;USPTO Office Action in U.S. Appl. No. 14/535,913 mailed Feb. 22, 2016.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed Mar. 2, 2016.;;USPTO Office Action in U.S. Appl. No. 14/535,971 mailed Mar. 4, 2016.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed May 1, 2015.;;USPTO Office Action in U.S. Appl. No. 13/297,097 mailed May 29, 2015.;;USPTO Office Action in U.S. Appl. No. 14/171,036 mailed Jun. 1, 2015.;;USPTO Office Action in U.S. Appl. No. 14/164,846 mailed Jun. 4, 2015.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jul. 15, 2015.;;USPTO Office Action in U.S. Appl. No. 13/796,085 mailed Jul. 17, 2015.",ACTIVE
74,US,A1,US 2009/0171358 A1,080-354-713-293-422,2009-07-02,2009,US 33924408 A,2008-12-19,US 33924408 A;;US 1736707 P,2007-12-28,Internal Bone Fixation Sizing Device and Methods,"An internal bone fixation sizing device and methods for using this device during a procedure for repairing a weakened or fractured bone are disclosed herein. A medical device for determining a depth and a diameter of a medullary cavity of a bone includes an outer shaft having a proximal end engaging an activation mechanism, a distal end having a first opening at an upper surface and a second opening at a lower surface, and a longitudinal axis between the proximal end and the distal end, wherein the longitudinal axis of the outer shaft includes a plurality of markers; and an inner shaft having a proximal end engaging the activation mechanism, a distal end terminating in two sizing arms, and a longitudinal axis therebetween, wherein the two sizing arms are able to move from a retracted position to an extended position extending beyond the outer shaft.",IIIUMINOSS MEDICAL INC,CHANG NARISSA Y;;COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2008-12-23),https://lens.org/080-354-713-293-422,Patent Application,yes,12,59,2,2,0,A61B17/7266;;A61B17/7266;;A61B5/417;;A61B5/417;;A61B5/4504;;A61B5/4504;;A61B6/12;;A61B6/12;;A61B17/72;;A61B17/72;;A61B90/06;;A61B90/06;;A61B2090/061;;A61B2090/061,A61B17/56;;A61B19/00,606/63;;606/62;;128/898,0,0,,,,ACTIVE
75,US,B2,US 8012157 B2,055-675-914-901-261,2011-09-06,2011,US 33924408 A,2008-12-19,US 33924408 A;;US 1736707 P,2007-12-28,Internal bone fixation sizing device and methods,"An internal bone fixation sizing device and methods for using this device during a procedure for repairing a weakened or fractured bone are disclosed herein. A medical device for determining a depth and a diameter of a medullary cavity of a bone includes an outer shaft having a proximal end engaging an activation mechanism, a distal end having a first opening at an upper surface and a second opening at a lower surface, and a longitudinal axis between the proximal end and the distal end, wherein the longitudinal axis of the outer shaft includes a plurality of markers; and an inner shaft having a proximal end engaging the activation mechanism, a distal end terminating in two sizing arms, and a longitudinal axis therebetween, wherein the two sizing arms are able to move from a retracted position to an extended position extending beyond the outer shaft.",ILLUMINOSS MEDICAL INC,CHANG NARISSA Y;;COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2008-12-23),https://lens.org/055-675-914-901-261,Granted Patent,yes,12,22,2,2,0,A61B17/7266;;A61B17/7266;;A61B5/417;;A61B5/417;;A61B5/4504;;A61B5/4504;;A61B6/12;;A61B6/12;;A61B17/72;;A61B17/72;;A61B90/06;;A61B90/06;;A61B2090/061;;A61B2090/061,A61B17/58;;A61B17/60;;A61F2/00,606/102;;606/62;;606/63;;606/95;;X606 86 R;;128/898,0,0,,,,ACTIVE
76,US,A1,US 2004/0073219 A1,196-012-859-322-78X,2004-04-15,2004,US 30307602 A,2002-11-25,US 30307602 A;;US 27026202 A,2002-10-15,Insertion instrument,"
   A method of deploying a fixation mechanism includes providing an insertion instrument and a fixation mechanism, creating an insertion tunnel within tissue of a patient, and positioning the insertion instrument with the fixation mechanism in the insertion tunnel. The insertion instrument includes a main member connected to an instrument handle and a secondary member connected to a pushing handle and positioned within the main member. The main member and the secondary member extend along a longitudinal axis. The fixation mechanism includes a first portion coupled to the main member and a second portion coupled to the secondary member. The method includes translating the pushing handle along the longitudinal axis relative to the instrument handle such that translating causes the secondary member to move the second portion relative to the first portion. 
",SKIBA JEFFRY B.;;BALDWIN JEFFREY P.;;COLLERAN DENNIS;;GABRIEL STEFAN;;DYE JUSTIN,SKIBA JEFFRY B;;BALDWIN JEFFREY P;;COLLERAN DENNIS;;GABRIEL STEFAN;;DYE JUSTIN,SMITH & NEPHEW INC (2003-03-04),https://lens.org/196-012-859-322-78X,Patent Application,yes,99,49,1,1,0,A61F2/0811;;A61F2/0811;;A61B17/0401;;A61B17/0401;;A61B2017/0409;;A61B2017/0409;;A61B2017/0417;;A61B2017/0417;;A61F2/0805;;A61F2/0805;;A61F2002/0829;;A61F2002/0829;;A61F2002/0852;;A61F2002/0852;;A61F2002/0882;;A61F2002/0882,A61B17/04;;A61F2/08,606/72,0,0,,,,DISCONTINUED
77,US,A1,US 2013/0013010 A1,197-618-333-757-845,2013-01-10,2013,US 201213617557 A,2012-09-14,US 201213617557 A;;US 26237008 A;;US 98424107 P,2007-10-31,LIGHT SOURCE,"Disposable light sources are disclosed herein. A device for connecting a fiber to a light source includes a light source, light director to focus light from the light source, the light director surrounding at least a portion of the light source, a power source providing energy to the light source, and a connector communicating light from the light source to a catheter.",ILLUMINOSS MEDICAL INC;;RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2008-11-03),https://lens.org/197-618-333-757-845,Patent Application,yes,6,31,4,4,0,A61B90/30;;A61B90/30;;A61B2017/00734;;A61B2017/00734;;A61B2090/306;;A61B2090/306,A61B17/88,606 86 R,0,0,,,,DISCONTINUED
78,WO,A1,WO 2009/059090 A1,103-170-789-703-076,2009-05-07,2009,US 2008/0081929 W,2008-10-31,US 98424107 P,2007-10-31,LIGHT SOURCE,"Disposable light sources (140) are disclosed herein. A device for connecting a fiber (300) to a light source (140) includes a light source (140), light director (200) to focus light from the light source (140), the light director (200) surrounding at least a portion of the light source (140), a power source providing energy to the light source (140), and a connector (280) communicating light from the light source (140) to a catheter (320).",ILLUMINOSS MEDICAL INC;;RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G,,https://lens.org/103-170-789-703-076,Patent Application,yes,4,20,4,4,0,A61B90/30;;A61B90/30;;A61B2017/00734;;A61B2017/00734;;A61B2090/306;;A61B2090/306,A61N1/30,,0,0,,,,PENDING
79,MX,A,MX 2022009076 A,166-808-087-893-608,2022-10-20,2022,MX 2022009076 A,2021-01-21,US 202062965359 P;;US 2021/0014375 W,2020-01-24,MECHANICAL SPARK CONTAINMENT FOR DISCONNECTOR.,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,HUO XINGNIU;;VAN BESOUW BASTIAAN HUBERTUS;;DYE JUSTIN LEE;;IYER SIDHARTH SURESH,,https://lens.org/166-808-087-893-608,Patent Application,no,0,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H01T4/02;;H01H39/00;;H02H3/02;;H02H3/08;;H02H3/20,,0,0,,,,PENDING
80,US,A1,US 2021/0234359 A1,193-615-665-322-953,2021-07-29,2021,US 202117154545 A,2021-01-21,US 202117154545 A;;US 202062965359 P,2020-01-24,MECHANICAL SPARK CONTAINMENT FOR DISCONNECTOR,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,DYE JUSTIN LEE;;VAN BESOUW BASTIAAN HUBERTUS;;IYER SIDHARTH SURESH;;HUO XINGNIU,HUBBELL INCORPORATED (2021-01-26),https://lens.org/193-615-665-322-953,Patent Application,yes,0,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H02H3/08,,0,0,,,,ACTIVE
81,US,B2,US 11616356 B2,080-899-739-831-532,2023-03-28,2023,US 202117154545 A,2021-01-21,US 202117154545 A;;US 202062965359 P,2020-01-24,Mechanical spark containment for disconnector,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,DYE JUSTIN LEE;;VAN BESOUW BASTIAAN HUBERTUS;;IYER SIDHARTH SURESH;;HUO XINGNIU,HUBBELL INCORPORATED (2021-01-26),https://lens.org/080-899-739-831-532,Granted Patent,yes,6,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H01C7/12;;H02H1/00;;H02H1/04;;H02H3/08;;H02H3/22;;H02H9/06,,1,0,,,"PCT/US2021/014375 International Search Report and Written Opinion dated Apr. 14, 2021 (14 pages).",ACTIVE
82,US,A1,US 2009/0112196 A1,147-544-649-987-281,2009-04-30,2009,US 26237008 A,2008-10-31,US 26237008 A;;US 98424107 P,2007-10-31,Light Source,"Disposable light sources are disclosed herein. A device for connecting a fiber to a light source includes a light source, light director to focus light from the light source, the light director surrounding at least a portion of the light source, a power source providing energy to the light source, and a connector communicating light from the light source to a catheter.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G,ILLUMINOSS MEDICAL INC (2008-11-03),https://lens.org/147-544-649-987-281,Patent Application,yes,107,52,4,4,0,A61B90/30;;A61B90/30;;A61B2017/00734;;A61B2017/00734;;A61B2090/306;;A61B2090/306,A61B18/18,606/13,0,0,,,,ACTIVE
83,US,A1,US 2023/0231374 A1,170-082-372-005-133,2023-07-20,2023,US 202318125436 A,2023-03-23,US 202318125436 A;;US 202117154545 A;;US 202062965359 P,2020-01-24,MECHANICAL SPARK CONTAINMENT FOR DISCONNECTOR,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,DYE JUSTIN LEE;;VAN BESOUW BASTIAAN HUBERTUS;;IYER SIDHARTH SURESH;;HUO XINGNIU,HUBBELL INCORPORATED (2021-01-26),https://lens.org/170-082-372-005-133,Patent Application,yes,0,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H01H9/04,,0,0,,,,ACTIVE
84,US,B2,US 11831142 B2,148-655-620-231-307,2023-11-28,2023,US 202318125436 A,2023-03-23,US 202318125436 A;;US 202117154545 A;;US 202062965359 P,2020-01-24,Mechanical spark containment for disconnector,"In one aspect, the application provides an electrical system including a conductor, a ground, an arrester electrically connected to the conductor, and a disconnector assembly electrically connected between the arrester and the ground. The disconnector assembly includes an isolator configured to perform an operating function in response to the occurrence of an event and a housing configured to surround the isolator. The isolator includes a first terminal electrically connected to the arrester by a first wire and a second terminal electrically connected to the ground by a second wire. The housing includes a first opening through which the first terminal extends, a second opening through which the second terminal extends, and a retention mechanism configured to hold the isolator in place relative to the arrester.",HUBBELL INC,DYE JUSTIN LEE;;VAN BESOUW BASTIAAN HUBERTUS;;IYER SIDHARTH SURESH;;HUO XINGNIU,HUBBELL INCORPORATED (2021-01-26),https://lens.org/148-655-620-231-307,Granted Patent,yes,6,0,7,7,0,H01H39/00;;H01H9/043;;H01H9/046;;H02H3/08;;H01H9/042,H01C7/12;;H01H9/04;;H02H1/00;;H02H1/04;;H02H3/08;;H02H3/22;;H02H9/06,,1,0,,,"PCT/US2021/014375 International Search Report and Written Opinion dated Apr. 14, 2021 (14 pages).",ACTIVE
85,US,A1,US 2015/0066028 A1,035-008-764-252-854,2015-03-05,2015,US 201414535971 A,2014-11-07,US 201414535971 A;;US 201213616781 A;;US 98349611 A;;US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and Methods for Internal Bone Fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device for repairing a fractured bone that includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/035-008-764-252-854,Patent Application,yes,6,23,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/88;;A61B17/72,606/63,0,0,,,,ACTIVE
86,GB,A,GB 2476621 A,126-502-808-737-38X,2011-06-29,2011,GB 201106777 A,2008-10-31,US 2008/0081924 W,2008-10-31,System and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that includes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/126-502-808-737-38X,Patent Application,no,7,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61B17/72;;A61B17/88;;A61F2/46;;A61M25/10,,0,0,,,,ACTIVE
87,US,B2,US 9433450 B2,006-194-099-772-162,2016-09-06,2016,US 201414535971 A,2014-11-07,US 201414535971 A;;US 201213616781 A;;US 98349611 A;;US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device for repairing a fractured bone that includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/006-194-099-772-162,Granted Patent,yes,105,23,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/72;;A61B17/00;;A61B17/68;;A61B17/70;;A61B17/88,,99,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"USPTO Office Action in U.S. Appl. No. 13/553,247 mailed May 1, 2015.;;USPTO Office Action in U.S. Appl. No. 13/297,097 mailed May 29, 2015.;;USPTO Office Action in U.S. Appl. No. 14/171,036 mailed Jun. 1, 2015.;;USPTO Office Action in U.S. Appl. No. 14/164,846 mailed Jun. 4, 2015.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jul. 15, 2015.;;USPTO Office Action in U.S. Appl. No. 13/796,085 mailed Jul. 17, 2015.;;Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;PCT International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;PCT International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;PCT International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;PCT International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;USPTO Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;PCT International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;PCT International Search Report based on PCT/US10/46003 dated May 24, 2011.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 19, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Dec. 14, 2012.;;International Search Report and Written Opinion for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Mar. 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/616,416 mailed Mar. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Apr. 26, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.;;Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/772,947 mailed Jun. 19, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jul. 9, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Sep. 16, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Sep. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Sep. 25, 2013.;;PCT International Search Report based on PCT/US13/049773 dated Oct. 1, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Oct. 9, 2013.;;Extended European Search Report based on EP 10 76 2390 dated Oct. 30, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Nov. 21, 2013.;;USPTO Office Action in U.S. Appl. No. 12/983,496 mailed Feb. 5, 2014.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Feb. 13, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,181 mailed Feb. 25, 2014.;;PCT International Search Report based on PCT/US13/076598 dated Mar. 19, 2014.;;USPTO Office Action in U.S. Appl. No. 13/655,808 mailed Mar. 27, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed May 7, 2014.;;Extended European Search Report based on EP 14156473 dated May 13, 2014.;;USPTO Office Action in U.S. Appl. No. 13/800,518 mailed Jun. 10, 2014.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Jun. 26, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jun. 27, 2014.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Jul. 31, 2014.;;USPTO Office Action in U.S. Appl. No. 13/616,781 mailed Aug. 26, 2014.;;USPTO Office Action in U.S. Appl. No. 13/730,521 mailed Sep. 8, 2014.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 7, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,450 mailed Oct. 24, 2014.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Oct. 24, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed Dec. 5, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Dec. 23, 2014.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Jan. 14, 2015.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jan. 15, 2015.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Feb. 9, 2015.;;USPTO Office Action in U.S. Appl. No. 13/796,085 mailed Feb. 12, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Mar. 31, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,051 mailed Sep. 11, 2015.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed Sep. 23, 2015.;;USPTO Office Action in U.S. Appl. No. 14/164,846 mailed Oct. 14, 2015.",ACTIVE
88,EP,A1,EP 2362753 A1,142-096-663-354-925,2011-09-07,2011,EP 08877881 A,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/142-096-663-354-925,Patent Application,yes,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
89,US,B2,US 8734460 B2,162-402-743-222-832,2014-05-27,2014,US 98349611 A,2011-01-03,US 98349611 A;;US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device for repairing a fractured bone that includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A;;ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/162-402-743-222-832,Granted Patent,yes,106,31,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/58,606/93,66,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 30, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 30, 2012.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.;;Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Mar. 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/616,416 mailed Mar. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Apr. 26, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Dec. 14, 2012.;;International Search Report and Written Opinion for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 13/772,947 mailed Jun. 19, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jul. 9, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Sep. 16, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Sep. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Sep. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Oct. 9, 2013.;;International Search Report based on PCT/US10/46003 dated May 24, 2011.;;Final Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;Extended European Search Report based on EP 10 76 2390 dated Oct. 30, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Nov. 21, 2013.",ACTIVE
90,US,A1,US 2013/0013009 A1,057-682-546-093-034,2013-01-10,2013,US 201213617327 A,2012-09-14,US 201213617327 A;;US 34740508 A;;US 1901908 P,2008-01-04,Apparatus and Methods for Separating Internal Bone Fixation Device from Introducer,Apparatus and methods for separating an internal bone fixation device from an introducer are disclosed herein. A device for separating an internal bone fixation device from an introducer includes a functional portion having an outer shaft surrounding and controlling operation of a cutting mechanism; and a control portion having an actuating mechanism for initiating activation of the outer shaft.,ILLUMINOSS MEDICAL INC;;COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2009-01-06),https://lens.org/057-682-546-093-034,Patent Application,yes,1,30,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/88,606 86 R,0,0,,,,ACTIVE
91,WO,A1,WO 2009/088927 A1,100-610-019-287-632,2009-07-16,2009,US 2008/0088638 W,2008-12-31,US 1901908 P,2008-01-04,APPARATUS AND METHODS FOR SEPARATING INTERNAL BONE FIXATION DEVICE FROM INTRODUCER,Apparatus and methods for separating an internal bone fixation device from an introducer are disclosed herein. A device (100) for separating an internal bone fixation device (210) from an introducer (201) includes a functional portion (110) having an outer shaft (115) surrounding and controlling operation of a cutting mechanism (105); and a control portion (101) having an actuating mechanism (160) for initiating activation of the outer shaft (115).,ILLUMINOSS MEDICAL INC;;COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,,https://lens.org/100-610-019-287-632,Patent Application,yes,5,22,10,10,0,A61B17/7097;;A61B17/8863;;A61B2017/2905;;A61B17/7275;;A61B17/8863;;A61B17/7097;;A61B17/8863;;A61B2017/2905;;A61B17/7275,A61B17/88,,0,0,,,,PENDING
92,AU,C1,AU 2008/363622 C1,124-434-846-477-561,2014-08-14,2014,AU 2008/363622 A,2008-10-31,US 2008/0081924 W,2008-10-31,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that includes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/124-434-846-477-561,Amended Patent,no,1,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,INACTIVE
93,EP,A4,EP 2227161 A4,048-338-669-416-973,2013-03-13,2013,EP 08869840 A,2008-12-31,US 2008/0088638 W;;US 1901908 P,2008-01-04,APPARATUS AND METHODS FOR SEPARATING INTERNAL BONE FIXATION DEVICE FROM INTRODUCER,,ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,,https://lens.org/048-338-669-416-973,Search Report,no,4,0,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/88;;A61B17/70;;A61B17/72,,1,0,,,See also references of WO 2009088927A1,DISCONTINUED
94,US,B2,US 9101419 B2,139-105-331-676-294,2015-08-11,2015,US 201213617327 A,2012-09-14,US 201213617327 A;;US 34740508 A;;US 1901908 P,2008-01-04,Apparatus and methods for separating internal bone fixation device from introducer,Apparatus and methods for separating an internal bone fixation device from an introducer are disclosed herein. A device for separating an internal bone fixation device from an introducer includes a functional portion having an outer shaft surrounding and controlling operation of a cutting mechanism; and a control portion having an actuating mechanism for initiating activation of the outer shaft.,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2009-01-06),https://lens.org/139-105-331-676-294,Granted Patent,yes,31,25,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/72;;A61B17/29;;A61B17/70;;A61B17/88,,6,0,,,"PCT International Search Report based on PCT/US13/049773 dated Oct. 1, 2013.;;USPTO Office Action in U.S. Appl. No. 12/347,405 mailed Feb. 6, 2014.;;PCT International Search Report based on PCT/US2008/088638 dated Feb. 27, 2009.;;Extended European Search Report for EP 08869840.2 dated Feb. 8, 2013.;;Office Action for U.S. Appl. No. 12/347,405 mailed Oct. 3, 2012.;;Office Action for U.S. Appl. No. 12/347,405 mailed Apr. 27, 2012.",ACTIVE
95,CA,C,CA 2741719 C,064-994-196-904-269,2013-10-15,2013,CA 2741719 A,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that in-cludes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a de-flated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/064-994-196-904-269,Granted Patent,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/88;;A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
96,WO,A1,WO 2010/050965 A1,019-680-124-020-794,2010-05-06,2010,US 2008/0081924 W,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that includes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC;;RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/019-680-124-020-794,Patent Application,yes,7,20,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,1,0,,,See also references of EP 2362753A4,PENDING
97,CN,A,CN 102196778 A,050-934-175-859-793,2011-09-21,2011,CN 200880131754 A,2008-10-31,US 2008/0081924 W,2008-10-31,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that includes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/050-934-175-859-793,Patent Application,no,0,9,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
98,US,A1,US 2013/0066326 A1,067-890-947-921-944,2013-03-14,2013,US 201213616781 A,2012-09-14,US 201213616781 A;;US 98349611 A;;US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. In an aspect, a device for repairing a fractured bone includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A;;ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/067-890-947-921-944,Patent Application,yes,11,26,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/88,606/93,0,0,,,,ACTIVE
99,GB,B,GB 2468452 B,125-587-599-079-323,2012-04-04,2012,GB 201010617 A,2008-12-31,US 2008/0088638 W;;US 1901908 P,2008-01-04,Apparatus and methods for separating internal bone fixation device from introducer,,ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,,https://lens.org/125-587-599-079-323,Granted Patent,no,5,0,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/88,,0,0,,,,INACTIVE
100,AU,B2,AU 2008/363622 B2,029-513-572-441-300,2014-04-17,2014,AU 2008/363622 A,2008-10-31,US 2008/0081924 W,2008-10-31,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that includes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/029-513-572-441-300,Granted Patent,no,1,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,INACTIVE
101,CN,B,CN 102196778 B,021-193-708-040-936,2014-07-30,2014,CN 200880131754 A,2008-10-31,US 2008/0081924 W,2008-10-31,Systems and methods for internal bone fixation,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/021-193-708-040-936,Granted Patent,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
102,US,A1,US 2009/0054900 A1,153-005-781-282-97X,2009-02-26,2009,US 26241108 A,2008-10-31,US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and Methods for Internal Bone Fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device for repairing a fractured bone that includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/153-005-781-282-97X,Patent Application,yes,99,57,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/58,606/93;;606/92,0,0,,,,ACTIVE
103,US,B2,US 7879041 B2,017-376-966-977-219,2011-02-01,2011,US 26241108 A,2008-10-31,US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device for repairing a fractured bone that includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/017-376-966-977-219,Granted Patent,yes,105,56,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/58,606/93;;606/92,16,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"Jovanovic et al., Fixion Nails for Humeral Fractures, Injury, Int. J. Care Injured, vol. 34, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison, Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, pp. 9-12, 1996.;;Waris et al., Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures, Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study, The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;PCT International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.",ACTIVE
104,GB,B,GB 2476621 B,045-752-246-296-409,2011-11-30,2011,GB 201106777 A,2008-10-31,US 2008/0081924 W,2008-10-31,System and methods for internal bone fixation,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/045-752-246-296-409,Granted Patent,no,14,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/88;;A61B17/56;;A61F2/46;;A61M25/10,,0,0,,,,ACTIVE
105,BR,A2,BR PI0823138 A2,066-035-877-365-108,2015-06-16,2015,BR PI0823138 A,2008-10-31,US 2008/0081924 W,2008-10-31,Sistemas e métodos para fixação interna de osso,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/066-035-877-365-108,Patent Application,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,DISCONTINUED
106,AU,A1,AU 2008/363622 A1,072-352-634-573-224,2010-05-06,2010,AU 2008/363622 A,2008-10-31,US 2008/0081924 W,2008-10-31,Systems and methods for internal bone fixation,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/072-352-634-573-224,Patent Application,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,INACTIVE
107,ZA,B,ZA 201102995 B,003-751-559-203-260,2012-06-27,2012,ZA 201102995 A,2011-04-20,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/003-751-559-203-260,Granted Patent,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61M25/10,,0,0,,,,ACTIVE
108,US,B2,US 8777950 B2,128-965-513-650-90X,2014-07-15,2014,US 34740508 A,2008-12-31,US 34740508 A;;US 1901908 P,2008-01-04,Apparatus and methods for separating internal bone fixation device from introducer,Apparatus and methods for separating an internal bone fixation device from an introducer are disclosed herein. A device for separating an internal bone fixation device from an introducer includes a functional portion having an outer shaft surrounding and controlling operation of a cutting mechanism; and a control portion having an actuating mechanism for initiating activation of the outer shaft.,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2009-01-06),https://lens.org/128-965-513-650-90X,Granted Patent,yes,30,17,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61F2/46;;A61B17/29;;A61B17/70;;A61B17/72;;A61B17/88,606 86A;;606/60;;606/53,3,0,,,"International Search Report based on PCT/US2008/088638 dated Feb. 27, 2009.;;Extended European Search Report for EP 08869840.2 dated Feb. 8, 2013.;;PCT International Search Report based on PCT/US13/49773 dated Oct. 1, 2013.",ACTIVE
109,CA,A1,CA 2741719 A1,038-705-062-796-964,2010-05-06,2010,CA 2741719 A,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device (700) for repairing a fractured bone that includes a delivery (710) having an elongated shaft (701) with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter (710) having an inner void (713) for passing at least one reinforcing material, and an inner lumen (711) for accepting a light pipe (652), wherein a distal end (723) of the inner lumen (711) terminates in an optical lens (754); a conformable member (703) releasably engaging the distal end of the delivery catheter (710), the conformable member (703) moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member (703); and an adapter releasably engaging the proximal end of the delivery catheter (710) for receiving the light pipe (652) and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/038-705-062-796-964,Patent Application,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
110,HK,A1,HK 1159451 A1,085-279-944-024-953,2012-08-03,2012,HK 11113908 A,2011-12-23,US 2008/0081924 W,2008-10-31,SYSTEM AND METHODS FOR INTERNAL BONE FIXATION,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/085-279-944-024-953,Patent Application,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61M25/10,,0,0,,,,PENDING
111,EP,A1,EP 2227161 A1,080-770-434-250-270,2010-09-15,2010,EP 08869840 A,2008-12-31,US 2008/0088638 W;;US 1901908 P,2008-01-04,APPARATUS AND METHODS FOR SEPARATING INTERNAL BONE FIXATION DEVICE FROM INTRODUCER,,ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,,https://lens.org/080-770-434-250-270,Patent Application,yes,0,0,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/88;;A61B17/70;;A61B17/72,,0,0,,,,DISCONTINUED
112,ES,T3,ES 2544256 T3,109-807-277-743-836,2015-08-28,2015,ES 08877881 T,2008-10-31,US 2008/0081924 W,2008-10-31,Sistemas y métodos para fijación interna de huesos,"Un dispositivo (100, 300) para reparar un hueso fracturado que comprende: un catéter de administración (110, 310) que tiene un tronco alargado (101, 301) con un extremo proximal (102), un extremo distal (104) y un eje longitudinal entre los mismos, el catéter de administración (110, 310) tiene un espacio vacío interior para el paso de por lo menos un material reforzador, y un paso interno interior para aceptar una fibra óptica (852, 900, 910, 920, 930, 940); un miembro conformable (103, 303) que se acopla de manera liberable al extremo distal (104) del catéter de administración (110), el miembro conformable (103, 303) se mueve desde un estado desinflado a un estado inflado cuando el por lo menos un material reforzador se pasa al miembro conformable (103, 303); y una fibra óptica (852, 900, 910, 920, 930, 940) en donde por lo menos una parte distal de la fibra óptica (852, 900, 910, 920, 930, 940) está modificada por eliminación de una parte de un recubrimiento que rodea la fibra óptica (852, 900, 910, 920, 930, 940) y en donde la fibra óptica es capaz de dispersar la energía lumínica a lo largo de la longitud de la fibra óptica (852, 900, 910, 920, 930, 940) para iniciar el endurecimiento de por lo menos un material reforzador dentro del miembro conformable (103, 303).",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/109-807-277-743-836,Granted Patent,no,0,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
113,US,A1,US 2009/0177204 A1,140-925-525-269-67X,2009-07-09,2009,US 34740508 A,2008-12-31,US 34740508 A;;US 1901908 P,2008-01-04,Apparatus and Methods for Separating Internal Bone Fixation Device from Introducer,Apparatus and methods for separating an internal bone fixation device from an introducer are disclosed herein. A device for separating an internal bone fixation device from an introducer includes a functional portion having an outer shaft surrounding and controlling operation of a cutting mechanism; and a control portion having an actuating mechanism for initiating activation of the outer shaft.,ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2009-01-06),https://lens.org/140-925-525-269-67X,Patent Application,yes,24,35,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/58;;A61B19/00,606/90;;128/898,0,0,,,,ACTIVE
114,EP,B8,EP 2362753 B8,087-267-857-779-199,2015-07-22,2015,EP 08877881 A,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/087-267-857-779-199,Amended Patent,yes,9,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
115,EP,A4,EP 2362753 A4,122-894-229-737-457,2013-06-26,2013,EP 08877881 A,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/122-894-229-737-457,Search Report,no,2,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,1,0,,,See also references of WO 2010050965A1,ACTIVE
116,US,A1,US 2011/0098713 A1,032-652-470-597-062,2011-04-28,2011,US 98349611 A,2011-01-03,US 98349611 A;;US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and Methods for Internal Bone Fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. According to aspects illustrated herein, there is provided a device for repairing a fractured bone that includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/032-652-470-597-062,Patent Application,yes,104,33,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/58,606/93,0,0,,,,ACTIVE
117,US,B2,US 8906030 B2,062-377-178-597-545,2014-12-09,2014,US 201213616781 A,2012-09-14,US 201213616781 A;;US 98349611 A;;US 26241108 A;;US 90312307 A;;US 85820206 P;;US 88064607 P,2006-11-10,Systems and methods for internal bone fixation,"Internal bone fixation devices and methods for using the devices for repairing a weakened or fractured bone are disclosed herein. In an aspect, a device for repairing a fractured bone includes a delivery catheter having an elongated shaft with a proximal end, a distal end, and a longitudinal axis therebetween, the delivery catheter having an inner void for passing at least one reinforcing material, and an inner lumen for accepting a light pipe, wherein a distal end of the inner lumen terminates in an optical lens; a conformable member releasably engaging the distal end of the delivery catheter, the conformable member moving from a deflated state to an inflated state when the at least one reinforcing material is delivered to the conformable member; and an adapter releasably engaging the proximal end of the delivery catheter for receiving the light pipe and the at least one reinforcing material.",RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A;;ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,ILLUMINOSS MEDICAL INC (2008-11-04),https://lens.org/062-377-178-597-545,Granted Patent,yes,110,34,8,83,0,A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/68;;A61B17/7097;;A61B17/7275;;A61B17/8819;;A61B17/8833;;A61B17/8836;;A61B2017/00557;;A61B2090/306;;A61B17/7291;;A61B17/8816,A61B17/88;;A61B17/00;;A61B17/68;;A61B17/70;;A61B17/72;;A61B19/00,606/93,78,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Dec. 14, 2012.;;International Search Report and Written Opinion for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;Extended European Search Report based on EP 10 76 2390 dated Oct. 30, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Nov. 21, 2013.;;Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Mar. 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/616,416 mailed Mar. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Apr. 26, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.;;Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;PCT International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;PCT International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;PCT International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;PCT International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;PCT International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;PCT International Search Report based on PCT/US10/46003 dated May 24, 2011.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 30, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 30, 2012.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.;;USPTO Office Action in U.S. Appl. No. 13/772,947 mailed Jun. 19, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jul. 9, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Sep. 16, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Sep. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Sep. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Oct. 9, 2013.;;USPTO Office Action in U.S. Appl. No. 12/983,496 mailed Feb. 5, 2014.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Feb. 13, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,181 mailed Feb. 25, 2014.;;PCT International Search Report based on PCT/US13/076598 dated Mar. 19, 2014.;;USPTO Office Action in U.S. Appl. No. 13/655,808 mailed Mar. 27, 2014.;;USPTO Office Action in U.S. Appl. No. 13/553,247 mailed May 7, 2014.;;Extended European Search Report based on EP 14156473 dated May 13, 2014.;;USPTO Office Action in U.S. Appl. No. 13/800,518 mailed Jun. 10, 2014.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Jun. 26, 2014.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Jun. 27, 2014.;;USPTO Office Action in U.S. Appl. No. 13/335,110 mailed Jul. 31, 2014.;;USPTO Office Action in U.S. Appl. No. 13/730,521 mailed Sep. 8, 2014.",ACTIVE
118,EP,B1,EP 2362753 B1,099-853-077-335-818,2015-06-10,2015,EP 08877881 A,2008-10-31,US 2008/0081924 W,2008-10-31,SYSTEMS AND METHODS FOR INTERNAL BONE FIXATION,,ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;DYE JUSTIN G;;DREW MARK A,,https://lens.org/099-853-077-335-818,Granted Patent,yes,9,0,23,23,0,A61B17/8836;;A61B2090/3983;;A61B2090/306;;A61B90/39;;A61B17/56;;A61B17/8836,A61B17/56;;A61M25/10,,0,0,,,,ACTIVE
119,GB,A,GB 2468452 A,109-775-460-923-081,2010-09-08,2010,GB 201010617 A,2008-12-31,US 2008/0088638 W;;US 1901908 P,2008-01-04,Apparatus and methods for separating internal bone fixation device from introducer,Apparatus and methods for separating an internal bone fixation device from an introducer are disclosed herein. A device (100) for separating an internal bone fixation device (210) from an introducer (201) includes a functional portion (110) having an outer shaft (115) surrounding and controlling operation of a cutting mechanism (105); and a control portion (101) having an actuating mechanism (160) for initiating activation of the outer shaft (115).,ILLUMINOSS MEDICAL INC,COLLERAN DENNIS P;;RABINER ROBERT A;;DYE JUSTIN G;;CHANG NARISSA Y;;MORIN JOSHUA M,,https://lens.org/109-775-460-923-081,Patent Application,no,5,0,10,10,0,A61B17/8863;;A61B17/7275;;A61B17/7275;;A61B17/7097;;A61B17/7097;;A61B17/8863;;A61B17/8863;;A61B2017/2905;;A61B2017/2905,A61B17/88,,0,0,,,,INACTIVE
120,US,A1,US 2013/0023877 A1,057-941-772-814-905,2013-01-24,2013,US 201213616416 A,2012-09-14,US 201213616416 A;;US 75578410 A;;US 16727609 P,2009-04-07,PHOTODYNAMIC BONE STABILIZATION SYSTEMS AND METHODS FOR REINFORCING BONE,"Photodynamic bone stabilization systems are disclosed herein. In an embodiment, a photodynamic bone stabilization system includes a catheter having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable portion, and a longitudinal axis therebetween; a light-conducting fiber configured to transmit light energy to the expandable portion; a light-sensitive liquid monomer comprising an initiator, wherein the initiator is activated when the light-conducting fiber transmits the light energy to initiate polymerization of the light-sensitive liquid monomer; and a cooling medium configured to control polymerization temperature, wherein the catheter comprises an inner void sufficiently designed to pass the light-sensitive liquid monomer into the expandable portion, and wherein the catheter comprises an inner lumen sufficiently designed to pass the light-conducting fiber into the expandable portion and configured to circulate the cooling medium.",ILLUMINOSS MEDICAL INC;;RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/057-941-772-814-905,Patent Application,yes,6,27,4,4,0,A61B17/8836;;A61B17/8836;;A61B17/7097;;A61B17/7097;;A61B17/7275;;A61B17/7275;;A61B2017/00411;;A61B2017/00411;;A61B2018/1807;;A61B2018/1807;;A61N5/0601;;A61N5/0601;;A61N5/062;;A61N5/062;;A61N2005/063;;A61N2005/063,A61B17/72,606/63,0,0,,,,ACTIVE
121,US,B2,US 8936382 B2,085-779-582-756-866,2015-01-20,2015,US 201213613982 A,2012-09-13,US 201213613982 A;;US 201213538138 A;;US 75510510 A;;US 16696009 P,2009-04-06,Attachment system for light-conducting fibers,"In an embodiment, an attachment system for communicating light energy from a light source to a light-conducting fiber includes a light pipe body sufficiently designed to engage a distal end of a light pipe, the light pipe body comprising at least one opening configured to dissipate heat buildup from light energy; a front assembly sufficiently designed to engage the light pipe body, the front assembly comprising an orifice and at least one opening configured to dissipate heat buildup from light energy; a light-conducting fiber body sufficiently designed to engage the front assembly and to hold a proximal portion of a light-conducting fiber, the light-conducting fiber body positioned in the orifice of the front assembly; and an optical taper assembly sufficiently designed to hold an optical taper, the optical taper assembly positioned between and spaced apart from the front assembly, and positioned between and spaced apart from the light pipe.",O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/085-779-582-756-866,Granted Patent,yes,99,23,6,6,0,G02B6/0006;;G02B6/0006;;G02B6/3814;;G02B6/3814;;Y10T29/49002;;Y10T29/49002;;Y10T29/49826;;Y10T29/49826,A61B1/00;;F21V8/00;;G02B6/38,362/572;;362/555,66,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Mar. 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/616,416 mailed Mar. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Apr. 26, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Dec. 14, 2012.;;International Search Report and Written Opinion for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 13/772,947 mailed Jun. 19, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jul. 9, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Sep. 16, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Sep. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Sep. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Oct. 9, 2013.;;Extended European Search Report based on EP 10 76 2390 dated Oct. 30, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Nov. 21, 2013.;;Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;PCT International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;PCT International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;PCT International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;PCT International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;PCT International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;PCT International Search Report based on PCT/US10/46003 dated May 24, 2011.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 30, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 30, 2012.;;USPTO Office Action in US U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in US U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.",ACTIVE
122,US,A1,US 2013/0003406 A1,011-183-545-646-797,2013-01-03,2013,US 201213613982 A,2012-09-13,US 201213613982 A;;US 201213538138 A;;US 75510510 A;;US 16696009 P,2009-04-06,Attachment System for Light-Conducting Fibers,"In an embodiment, an attachment system for communicating light energy from a light source to a light-conducting fiber includes a light pipe body sufficiently designed to engage a distal end of a light pipe, the light pipe body comprising at least one opening configured to dissipate heat buildup from light energy; a front assembly sufficiently designed to engage the light pipe body, the front assembly comprising an orifice and at least one opening configured to dissipate heat buildup from light energy; a light-conducting fiber body sufficiently designed to engage the front assembly and to hold a proximal portion of a light-conducting fiber, the light-conducting fiber body positioned in the orifice of the front assembly; and an optical taper assembly sufficiently designed to hold an optical taper, the optical taper assembly positioned between and spaced apart from the front assembly, and positioned between and spaced apart from the light pipe.",ILLUMINOSS MEDICAL INC;;O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/011-183-545-646-797,Patent Application,yes,0,28,6,6,0,G02B6/0006;;G02B6/0006;;G02B6/3814;;G02B6/3814;;Y10T29/49002;;Y10T29/49002;;Y10T29/49826;;Y10T29/49826,G02B6/00;;F21V29/00;;H05K13/00,362/580;;29/592.1,0,0,,,,ACTIVE
123,US,A1,US 2012/0262939 A1,017-083-669-448-020,2012-10-18,2012,US 201213538138 A,2012-06-29,US 201213538138 A;;US 75510510 A;;US 16696009 P,2009-04-06,Attachment System for Light-Conducting Fibers,"In an embodiment, an attachment system for communicating light energy from a light source to a light-conducting fiber includes a light pipe body sufficiently designed to engage a distal end of a light pipe, the light pipe body comprising at least one opening configured to dissipate heat buildup from light energy; a front assembly sufficiently designed to engage the light pipe body, the front assembly comprising an orifice and at least one opening configured to dissipate heat buildup from light energy; a light-conducting fiber body sufficiently designed to engage the front assembly and to hold a proximal portion of a light-conducting fiber, the light-conducting fiber body positioned in the orifice of the front assembly; and an optical taper assembly sufficiently designed to hold an optical taper, the optical taper assembly positioned between and spaced apart from the front assembly, and positioned between and spaced apart from the light pipe.",O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/017-083-669-448-020,Patent Application,yes,0,22,6,6,0,G02B6/0006;;G02B6/0006;;G02B6/3814;;G02B6/3814;;Y10T29/49002;;Y10T29/49002;;Y10T29/49826;;Y10T29/49826,G02B6/00;;B23P11/00;;F21V29/00,362/580;;29/428,0,0,,,,ACTIVE
124,US,B2,US 8512338 B2,190-444-221-154-669,2013-08-20,2013,US 75578410 A,2010-04-07,US 75578410 A;;US 16727609 P,2009-04-07,Photodynamic bone stabilization systems and methods for reinforcing bone,"Photodynamic bone stabilization systems are disclosed herein. In an embodiment, a photodynamic bone stabilization system includes a catheter having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable portion, and a longitudinal axis therebetween; a light-conducting fiber configured to transmit light energy to the expandable portion; a light-sensitive liquid monomer comprising an initiator, wherein the initiator is activated when the light-conducting fiber transmits the light energy to initiate polymerization of the light-sensitive liquid monomer; and a cooling medium configured to control polymerization temperature, wherein the catheter comprises an inner void sufficiently designed to pass the light-sensitive liquid monomer into the expandable portion, and wherein the catheter comprises an inner lumen sufficiently designed to pass the light-conducting fiber into the expandable portion and configured to circulate the cooling medium.",RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/190-444-221-154-669,Granted Patent,yes,106,47,4,4,0,A61B17/8836;;A61B17/8836;;A61B17/7097;;A61B17/7097;;A61B17/7275;;A61B17/7275;;A61B2017/00411;;A61B2017/00411;;A61B2018/1807;;A61B2018/1807;;A61N5/0601;;A61N5/0601;;A61N5/062;;A61N5/062;;A61N2005/063;;A61N2005/063,A61B17/72,606/63;;606/62;;606/92;;606/262,55,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"International Search Report based on PCT/US10/46003 dated May 24, 2011.;;Final Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 30, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 30, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Dec. 14, 2012.;;International Search Report and Written Opinion for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 13/616,416 mailed Mar. 25, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Apr. 26, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.",ACTIVE
125,US,A1,US 2010/0265733 A1,147-343-510-702-404,2010-10-21,2010,US 75510510 A,2010-04-06,US 75510510 A;;US 16696009 P,2009-04-06,Attachment System for Light-Conducting Fibers,"In an embodiment, an attachment system for communicating light energy from a light source to a light-conducting fiber includes a light pipe body sufficiently designed to engage a distal end of a light pipe, the light pipe body comprising at least one opening configured to dissipate heat buildup from light energy; a front assembly sufficiently designed to engage the light pipe body, the front assembly comprising an orifice and at least one opening configured to dissipate heat buildup from light energy; a light-conducting fiber body sufficiently designed to engage the front assembly and to hold a proximal portion of a light-conducting fiber, the light-conducting fiber body positioned in the orifice of the front assembly; and an optical taper assembly sufficiently designed to hold an optical taper, the optical taper assembly positioned between and spaced apart from the front assembly, and positioned between and spaced apart from the light pipe.",ILLUMINOSS MEDICAL INC,O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/147-343-510-702-404,Patent Application,yes,104,27,6,6,0,G02B6/0006;;G02B6/0006;;G02B6/3814;;G02B6/3814;;Y10T29/49002;;Y10T29/49002;;Y10T29/49826;;Y10T29/49826,H01L33/00;;F21V29/00;;G02B6/00,362/555;;362/580;;362/551,0,0,,,,ACTIVE
126,US,B2,US 8210729 B2,049-652-438-384-638,2012-07-03,2012,US 75510510 A,2010-04-06,US 75510510 A;;US 16696009 P,2009-04-06,Attachment system for light-conducting fibers,"In an embodiment, an attachment system for communicating light energy from a light source to a light-conducting fiber includes a light pipe body sufficiently designed to engage a distal end of a light pipe, the light pipe body comprising at least one opening configured to dissipate heat buildup from light energy; a front assembly sufficiently designed to engage the light pipe body, the front assembly comprising an orifice and at least one opening configured to dissipate heat buildup from light energy; a light-conducting fiber body sufficiently designed to engage the front assembly and to hold a proximal portion of a light-conducting fiber, the light-conducting fiber body positioned in the orifice of the front assembly; and an optical taper assembly sufficiently designed to hold an optical taper, the optical taper assembly positioned between and spaced apart from the front assembly, and positioned between and spaced apart from the light pipe.",O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/049-652-438-384-638,Granted Patent,yes,104,24,6,6,0,G02B6/0006;;G02B6/0006;;G02B6/3814;;G02B6/3814;;Y10T29/49002;;Y10T29/49002;;Y10T29/49826;;Y10T29/49826,A61B1/00,362/555;;362/572,26,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;International Search Report based on PCT/US10/46003 dated May 24, 2011.;;Final Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.",ACTIVE
127,US,A1,US 2010/0262069 A1,089-600-690-035-09X,2010-10-14,2010,US 75578410 A,2010-04-07,US 75578410 A;;US 16727609 P,2009-04-07,Photodynamic Bone Stabilization Systems and Methods for Reinforcing Bone,"Photodynamic bone stabilization systems are disclosed herein. In an embodiment, a photodynamic bone stabilization system includes a catheter having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable portion, and a longitudinal axis therebetween; a light-conducting fiber configured to transmit light energy to the expandable portion; a light-sensitive liquid monomer comprising an initiator, wherein the initiator is activated when the light-conducting fiber transmits the light energy to initiate polymerization of the light-sensitive liquid monomer; and a cooling medium configured to control polymerization temperature, wherein the catheter comprises an inner void sufficiently designed to pass the light-sensitive liquid monomer into the expandable portion, and wherein the catheter comprises an inner lumen sufficiently designed to pass the light-conducting fiber into the expandable portion and configured to circulate the cooling medium.",ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/089-600-690-035-09X,Patent Application,yes,102,39,4,4,0,A61B17/8836;;A61B17/8836;;A61B17/7097;;A61B17/7097;;A61B17/7275;;A61B17/7275;;A61B2017/00411;;A61B2017/00411;;A61B2018/1807;;A61B2018/1807;;A61N5/0601;;A61N5/0601;;A61N5/062;;A61N5/062;;A61N2005/063;;A61N2005/063,A61N1/00,604/21,0,0,,,,ACTIVE
128,US,B2,US 8328402 B2,135-045-578-362-265,2012-12-11,2012,US 201213538138 A,2012-06-29,US 201213538138 A;;US 75510510 A;;US 16696009 P,2009-04-06,Attachment system for light-conducting fibers,"In an embodiment, an attachment system for communicating light energy from a light source to a light-conducting fiber includes a light pipe body sufficiently designed to engage a distal end of a light pipe, the light pipe body comprising at least one opening configured to dissipate heat buildup from light energy; a front assembly sufficiently designed to engage the light pipe body, the front assembly comprising an orifice and at least one opening configured to dissipate heat buildup from light energy; a light-conducting fiber body sufficiently designed to engage the front assembly and to hold a proximal portion of a light-conducting fiber, the light-conducting fiber body positioned in the orifice of the front assembly; and an optical taper assembly sufficiently designed to hold an optical taper, the optical taper assembly positioned between and spaced apart from the front assembly, and positioned between and spaced apart from the light pipe.",O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,O'LEARY ANTHONY W;;RABINER ROBERT A;;COLLERAN DENNIS P;;DYE JUSTIN G;;KORNBLUTH DOUGLAS A;;CHANG NARISSA Y;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/135-045-578-362-265,Granted Patent,yes,100,28,6,6,0,G02B6/0006;;G02B6/0006;;G02B6/3814;;G02B6/3814;;Y10T29/49002;;Y10T29/49002;;Y10T29/49826;;Y10T29/49826,A61B1/00,362/555;;362/572,36,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;PCT International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;PCT International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;PCT International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;PCT International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;PCT International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;PCT International Search Report based on PCT/US10/46003 dated May 24, 2011.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.",ACTIVE
129,US,B2,US 8574233 B2,153-683-164-399-534,2013-11-05,2013,US 201213616416 A,2012-09-14,US 201213616416 A;;US 75578410 A;;US 16727609 P,2009-04-07,Photodynamic bone stabilization systems and methods for reinforcing bone,"Photodynamic bone stabilization systems are disclosed herein. In an embodiment, a photodynamic bone stabilization system includes a catheter having an elongated shaft with a proximal end adapter, a distal end releasably engaging an expandable portion, and a longitudinal axis therebetween; a light-conducting fiber configured to transmit light energy to the expandable portion; a light-sensitive liquid monomer comprising an initiator, wherein the initiator is activated when the light-conducting fiber transmits the light energy to initiate polymerization of the light-sensitive liquid monomer; and a cooling medium configured to control polymerization temperature, wherein the catheter comprises an inner void sufficiently designed to pass the light-sensitive liquid monomer into the expandable portion, and wherein the catheter comprises an inner lumen sufficiently designed to pass the light-conducting fiber into the expandable portion and configured to circulate the cooling medium.",RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M;;ILLUMINOSS MEDICAL INC,RABINER ROBERT A;;COLLERAN DENNIS P;;O'LEARY ANTHONY W;;CHANG NARISSA Y;;KORNBLUTH DOUGLAS A;;DYE JUSTIN G;;MORIN JOSHUA M,ILLUMINOSS MEDICAL INC (2010-04-13),https://lens.org/153-683-164-399-534,Granted Patent,yes,105,29,4,4,0,A61B17/8836;;A61B17/8836;;A61B17/7097;;A61B17/7097;;A61B17/7275;;A61B17/7275;;A61B2017/00411;;A61B2017/00411;;A61B2018/1807;;A61B2018/1807;;A61N5/0601;;A61N5/0601;;A61N5/062;;A61N5/062;;A61N2005/063;;A61N2005/063,A61B17/72,606/63;;606/62;;606/92;;606/262,59,4,038-611-642-676-830;;081-591-126-429-28X;;062-111-001-530-136;;089-046-606-402-497,10.1016/j.injury.2004.01.020;;15488506;;10.1002/(sici)1097-4636(199621)33:1<9::aid-jbm2>3.0.co;2-w;;8734068;;12771846;;10.1097/01.blo.0000063789.32430.c6;;10.1053/jhsu.2002.35082;;12239683,"Jovanovic et al., ""Fixion Nails for Humeral Fractures, Injury"", Int. J. Care Injured, vol. 35, Issue 11, pp. 1140-1142, Nov. 2004.;;Maruyama et al., ""Metacarpal Fracture Fixation with Absorbable Polyglycolide Rods and Stainless Steel K Wires: A Biomechanical Comparison"", Journal of Biomedical Materials Research (Applied Biomaterials), vol. 33, Issue 1, pp. 9-12, Apr. 1996.;;Waris et al., ""Bioabsorbable Miniplating Versus Metallic Fixation for Metacarpal Fractures"", Clinical Orthopaedics and Related Research, No. 410, pp. 310-319, May 2003.;;Waris et al., ""Self-Reinforced Bioabsorbable Versus Metallic Fixation Systems for Metacarpal and Phalangeal Fractures: A Biomechanical Study"", The Journal of Hand Surgery, vol. 27A, No. 5, pp. 902-909, Sep. 2002.;;PCT International Search Report based on PCT/US07/20402 dated Apr. 1, 2008.;;PCT International Search Report based on PCT/US07/10050 dated Apr. 17, 2008.;;PCT International Search Report based on PCT/US07/10038 dated Aug. 27, 2008.;;PCT International Search Report based on PCT/US08/81929 dated Jan. 12, 2009.;;PCT International Search Report based on PCT/US08/81924 dated Feb. 9, 2009.;;PCT International Search Report based on PCT/US08/87630 dated Feb. 24, 2009.;;PCT International Search Report based on PCT/US10/30275 dated Aug. 11, 2010.;;PCT International Search Report based on PCT/US10/56219 dated Jan. 20, 2011.;;PCT International Search Report based on PCT/US10/46003 dated May 24, 2011.;;PCT International Search Report based on PCT/US11/38389 dated Sep. 22, 2011.;;PCT International Search Report based on PCT/US11/66871 dated May 1, 2012.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 29, 2009.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Mar. 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,906 mailed Apr. 30, 2010.;;USPTO Office Action in U.S. Appl. No. 11/789,907 mailed May 11, 2010.;;USPTO Office Action in U.S. Appl. No. 11/903,123 mailed Jul. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Dec. 9, 2010.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Apr. 28, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Sep. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Mar. 16, 2012.;;USPTO Office Action in U.S. Appl. No. 12/262,411 mailed Sep. 1, 2010.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Dec. 23, 2011.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed May 11, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Oct. 24, 2011.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Apr. 4, 2012.;;USPTO Office Action in U.S. Appl. No. 12/875,460 mailed Mar. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Dec. 27, 2011.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed May 29, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Jun. 8, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Jun. 26, 2012.;;USPTO Office Action in U.S. Appl. No. 11/964,370 mailed Jul. 6, 2012.;;Extended European Search Report based on EP 07 75 6022 dated Jul. 30, 2012.;;Extended European Search Report based on EP 07 75 6016 dated Jul. 30, 2012.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Aug. 1, 2012.;;USPTO Office Action in U.S. Appl. No. 12/858,924 mailed Aug. 2, 2012.;;USPTO Office Action in U.S. Appl. No. 12/886,288 mailed Aug. 15, 2012.;;PCT International Search Report based on PCT/US12/47447 dated Oct. 2, 2012.;;PCT International Search Report based on PCT/US12/47446 dated Oct. 15, 2012.;;PCT International Search Report based on PCT/US12/47444 dated Oct. 18, 2012.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Oct. 25, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Nov. 9, 2012.;;USPTO Office Action in U.S. Appl. No. 12/943,544 mailed Dec. 3, 2012.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jan. 17, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Dec. 14, 2012.;;International Search Report and Written Opinion for PCT/US2012/061047 mailed Jan. 7, 2013.;;USPTO Office Action in U.S. Appl. No. 12/756,014 mailed Jan. 22, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed Jan. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 13/772,947 mailed Jun. 19, 2013.;;USPTO Office Action in U.S. Appl. No. 12/859,680 mailed Jul. 9, 2013.;;Supplemental European Search Report based on EP 08 87 7881 dated May 15, 2013.;;USPTO Office Action in U.S. Appl. No. 13/617,557 mailed Feb. 4, 2013.;;USPTO Office Action in U.S. Appl. No. 12/755,784 mailed Mar. 13, 2013.;;USPTO Office Action in U.S. Appl. No. 13/561,249 mailed Apr. 23, 2013.;;USPTO Office Action in U.S. Appl. No. 12/262,370 mailed Apr. 26, 2013.;;USPTO Office Action in U.S. Appl. No. 13/088,916 mailed May 13, 2013.",ACTIVE
130,CN,A,CN 112231496 A,027-674-985-773-586,2021-01-15,2021,CN 202011127969 A,2017-05-31,DK PA201670608 A;;DK PA201670609 A;;US 201662349109 P;;CN 201780033901 A,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The invention relates to a user interface for retrieving contextually relevant media content. The present disclosure generally relates to retrieving and displaying contextually-relevant media content.In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device.In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event,that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,IRANI CYRUS DANIEL;;MIURA BRITT S;;LEMAY STEPHEN O;;DYE ALAN C;;TITI JUSTIN S;;BOVET SIMON;;GOBERA RUBALCAVA DANIEL E;;LANGOLANT BRENDAN J;;CIRCLAEYS ERIC,,https://lens.org/027-674-985-773-586,Patent Application,no,10,1,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/44;;G06F3/0484;;G06F3/0488,,1,0,,,"任金昌等: ""多模态界面技术及其在多媒体检索中的应用"", 《计算机应用研究》",PENDING
131,KR,A,KR 20200090876 A,127-551-549-425-302,2020-07-29,2020,KR 20207018255 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;KR 20207005314 A;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"본 발명은, 일반적으로, 정황상 관련있는 미디어 콘텐츠를 검색 및 디스플레이하는 것에 관한 것이다. 일부 실시예들에서, 디바이스는 정황상 관련있는 미디어를 디스플레이하라는 요청을 수신하고, 이에 응답하여, 디바이스의 정황과 관련있는 미디어 아이템들의 컬렉션의 표현을 디스플레이한다. 일부 실시예들에서, 디바이스는 아이템들의 시퀀스의 시각적 미디어 아이템을 디스플레이하고, 스와이프 제스처를 수신한 것에 응답하여, 미디어 아이템에 대한 관련 콘텐츠를 포함하는 세부 사용자 인터페이스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 제1 세부 사용자 인터페이스를 디스플레이하는 동안, 선택 시, 개인들이 참석한 복수의 이벤트들에 대응하는 시각적 미디어의 디스플레이를 야기하는 제1 이벤트에 참석했던 것으로 식별된 복수의 개인들에 대응하는 어포던스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 사용자 입력에 응답하여, 시각적 미디어의 자동으로 생성된 컬렉션을 획득하고, 대응하는 어포던스를 디스플레이한다.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;O'ROURKE RYAN;;TITI JUSTIN S,,https://lens.org/127-551-549-425-302,Patent Application,no,10,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/23;;G06F3/0488,,1,0,,,"Neil Hughes, Apple explores merging cloud content with locally stored media library, (2011. 02)",ACTIVE
132,US,A1,US 2018/0364872 A1,125-700-084-033-803,2018-12-20,2018,US 201816109487 A,2018-08-22,US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S,,https://lens.org/125-700-084-033-803,Patent Application,yes,0,28,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0481;;G06F3/0354;;G06F3/0484;;G06F3/0488;;G06F17/30;;G06T1/00,,0,0,,,,ACTIVE
133,US,A1,US 2021/0191578 A1,079-087-167-277-169,2021-06-24,2021,US 202017125744 A,2020-12-17,US 202017125744 A;;US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S,,https://lens.org/079-087-167-277-169,Patent Application,yes,0,12,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0354;;G06F3/0481;;G06F3/0484;;G06F3/0488;;G06F16/178;;G06F16/435;;G06F16/438;;G06F16/44,,0,0,,,,ACTIVE
134,KR,A,KR 20200022541 A,019-706-813-629-231,2020-03-03,2020,KR 20207005314 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"본 발명은, 일반적으로, 정황상 관련있는 미디어 콘텐츠를 검색 및 디스플레이하는 것에 관한 것이다. 일부 실시예들에서, 디바이스는 정황상 관련있는 미디어를 디스플레이하라는 요청을 수신하고, 이에 응답하여, 디바이스의 정황과 관련있는 미디어 아이템들의 컬렉션의 표현을 디스플레이한다. 일부 실시예들에서, 디바이스는 아이템들의 시퀀스의 시각적 미디어 아이템을 디스플레이하고, 스와이프 제스처를 수신한 것에 응답하여, 미디어 아이템에 대한 관련 콘텐츠를 포함하는 세부 사용자 인터페이스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 제1 세부 사용자 인터페이스를 디스플레이하는 동안, 선택 시, 개인들이 참석한 복수의 이벤트들에 대응하는 시각적 미디어의 디스플레이를 야기하는 제1 이벤트에 참석했던 것으로 식별된 복수의 개인들에 대응하는 어포던스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 사용자 입력에 응답하여, 시각적 미디어의 자동으로 생성된 컬렉션을 획득하고, 대응하는 어포던스를 디스플레이한다.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;O'ROURKE RYAN;;TITI JUSTIN S,,https://lens.org/019-706-813-629-231,Patent Application,no,6,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/23;;G06F3/0488,,1,0,,,"Neil Hughes, Apple explores merging cloud content with locally stored media library, (2011. 02)",ACTIVE
135,US,B2,US 11334209 B2,078-508-528-510-242,2022-05-17,2022,US 202017125744 A,2020-12-17,US 202017125744 A;;US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S,,https://lens.org/078-508-528-510-242,Granted Patent,yes,489,0,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0354;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/178;;G06F16/435;;G06F16/438;;G06F16/44;;G06T1/00,,266,7,027-954-411-824-598;;015-170-949-710-284;;052-835-691-615-436;;087-439-027-914-345;;044-447-761-889-885;;015-071-346-705-597;;051-775-327-653-999,10.1145/1645953.1646021;;10.1145/1386352.1386397;;10.1145/1459359.1459458;;10.1145/1054972.1055001;;10.1016/j.patcog.2005.01.025;;10.1016/j.physleta.2006.08.058;;10.1109/infvis.1999.801851,"US 2002/0018582 A1, 02/2002, Hagiwara et al. (withdrawn);;Corrected Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Mar. 31, 2021, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Mar. 18, 2021, 11 pages.;;Office Action received for European Patent Application No. 17853657.9, dated Apr. 1, 2021, 6 pages.;;Brief Communication Regarding Oral Proceedings received for European Patent Application No. 19724963.4, dated Jun. 22, 2021, 2 pages.;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Jul. 6, 2021, 113 pages.;;Office Action received for Australian Patent Application No. 2019266054, dated Jun. 29, 2021, 3 pages.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jun. 10, 2021, 13 pages (7 pages of English Translation and 6 pages of Official Copy).;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,783, dated May 4, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Nov. 24, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/450,531, dated Aug. 11, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,776, dated May 13, 2020, 9 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,776, dated Nov. 25, 2020, 5 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Nov. 12, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Oct. 30, 2020, 2 pages.;;Examiner's Answer to Appeal Brief received for U.S. Appl. No. 16/259,771, dated Oct. 23, 2020, 15 pages.;;Examiner's Pre-Review Report received for Japanese Patent Application No. 2018-138559, dated Jul. 29, 2020, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Sep. 22, 2020, 49 pages.;;Final Office Action received for U.S. Appl. No. 16/584,783, dated May 19, 2020, 19 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2019/024790, dated Nov. 19, 2020, 11 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/031442, dated Oct. 30, 2020, 28 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2020/031442, dated Aug. 25, 2020, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,776, dated Aug. 18, 2020, 36 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,776, dated Feb. 13, 2020, 31 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,783, dated Jan. 30, 2020, 18 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019264623, dated Jan. 4, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019271873, dated Nov. 30, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020213402, dated Sep. 21, 2020, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-123115, dated Nov. 30, 2020, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2019-7005369, dated Oct. 26, 2020, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/450,531 dated Sep. 25, 2020, 7 pages.;;Office Action received for Australian Patent Application No. 2019264623, dated Sep. 14, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2019271873, dated Oct. 5, 2020, 3 pages.;;Office Action received for Chinese Patent Application No. 201811136445.7, dated Oct. 28, 2020, 17 pages (10 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201970535, dated May 20, 2020, 3 pages.;;Office Action received for Danish Patent Application No. PA201970535, dated Oct. 27, 2020, 6 pages.;;Office Action received for European Patent Application No. 17813778.2, dated Nov. 26, 2020, 10 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201970535, dated Nov. 5, 2019, 10 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Dec. 23, 2020, 8 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Sep. 3, 2021, 6 pages.;;Notice of Allowance received for Japanese Patent Application No. 2021-094529, dated Sep. 6, 2021, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Feb. 9, 2021, 55 pages.;;Notice of Allowance received for U.S. Appl. No. 16/584,776, dated Feb. 1, 2021, 9 pages.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jan. 20, 2021, 19 pages (11 pages of English Translation and 8 pages of Official Copy).;;ZY News, “Generate Cartoon Face within Three Seconds, You are the New-generation Expression Emperor”, Online available at: <http://inews.ifeng.com/48551936/news.shtml>, Apr. 22, 2016, 3 pages (Official Copy Only). {See Communication under 37 CFR § 1.98(a) (3)}.;;Notice of Allowance received for Japanese Patent Application No. 2021-000224, dated May 7, 2021, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2018-138559, dated Apr. 9, 2021, 30 pages (6 pages of English Translation and 24 pages of Official Copy).;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/584,776, dated May 13, 2021, 4 pages.;;Advisory Action received for U.S. Appl. No. 14/253,783, dated Feb. 15, 2017, 6 pages.;;Advisory Action received for U.S. Appl. No. 16/259,771, dated Feb. 26, 2020, 3 pages.;;Advisory Action received for U.S. Appl. No. 16/259,771, dated Jul. 14, 2020, 6 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/109,487, dated Apr. 21, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/259,771, dated May 5, 2020, 10 pages.;;Applicant-Initiated Interview Summary for U.S. Appl. No. 16/402,057, dated Mar. 16, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Jun. 29, 2020, 5 pages.;;Board Opinion received for Chinese Reexamination Patent Application No. 200780001142.8, dated Oct. 21, 2014, 13 pages.;;Certificate of Examination received for Australian Patent Application No. 2019100490, dated Oct. 16, 2019, 2 pages.;;Chen et al., “Event Detection from Flickr Data through Wavelet-based Spatial Analysis”, Proceeding of the 18th ACM Conference on Information and Knowledge Management, CIKM, Jan. 1, 2009, pp. 523-532.;;Corrected Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Aug. 11, 2016, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Jun. 3, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/713,490, dated May 1, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Jul. 6, 2020, 2 pages.;;Cyr Jim, “Apple Watch—Customize Modular Watch Face”, available online at: https://www.youtube.com/watch?v=02W93HbKIK8, May 13, 2015, 2 pages.;;Das et al., “Event Classification in Personal Image Collections”, IEEE Intl. Workshop on Media Information Analysis for Personal and Social Applications at ICME, 2009, pp. 1660-1663.;;Das et al., “Event-based Location Matching for Consumer Image Collections”, CIVR, 2008, Proc. of the ACM Int. Conf. on Image and Video Retrieval, 2008, 5 pages.;;Decision to Grant received for Danish Patent Application No. PA201870385, dated Mar. 26, 2020, 2 pages.;;Decision to Grant received for European Patent Application No. 11178259.5, dated Apr. 4, 2019, 3 pages.;;Decision to Grant received for Japanese Patent Application No. 2009-526943, dated Dec. 2, 2011,3 pages.;;Decision to Grant received for the European Patent Application No. 07814633.9, dated Sep. 2, 2010, 3 pages.;;Decision to Grant received for the European Patent Application No. 10172417.7, dated Nov. 14, 2013, 3 pages.;;Decision to Grant received for the European Patent Application No. 11178257.9, dated Jun. 20, 2013, 3 pages.;;European Search Report received for the European Application No. 11178259.5, dated Oct. 31, 2011, 8 pages.;;European Search Report received for the European Patent Application No. 10172417.7, dated Jan. 7, 2011, 4 pages.;;Extended European Search Report received for European Patent Application No. 11178257.9, dated Oct. 31, 2011, 5 pages.;;Extended European Search Report received for European Patent Application No. 17813778.2, dated Jan. 10, 2020, 12 pages.;;Extended European Search Report received for European Patent Application No. 17853657.9, dated May 28, 2020, 9 pages.;;Extended European Search Report received for European Patent Application No. 18197554.1, dated Jun. 3, 2019, 11 pages.;;Extended European Search Report received for European Patent Application No. 19212057.4, dated Feb. 27, 2020, 8 pages.;;Final Office Action received for U.S. Appl. No. 15/281,524, dated Dec. 27, 2018, 6 pages.;;Final Office Action received for U.S. Appl. No. 15/881,544, dated Jan. 29, 2019, 14 pages.;;Final Office Action received for U.S. Appl. No. 16/259,771, dated Nov. 18, 2019, 13 pages.;;Final Office Action received for U.S. Appl. No. 16/402,057, dated Oct. 17, 2019, 23 pages.;;Final Office Action received for U.S. Appl. No. 14/253,783, dated Sep. 30, 2016, 18 pages.;;Gallagher et al., “Image Annotation Using Personal Calendars as Context”, ACM Intl. Conf. on Multimedia, 2008, 4 pages.;;Geek, “How to Put the Day of the Week into the Windows Taskbar Clock”, available online at: https://www.howtogeek.com/194103/how-to-put-the-day-of-the-week-into-the-windows-taskbar-clock/, 2014, 3 pages.;;Han et al., “Density-Based Methods”, Data Mining Concepts and Techniques, Elsevier, 2006, pp. 418-420.;;Hinckley et al., “Sensing Techniques for Mobile Interaction”, Symposium on User Interface Software and Technology, CHI Letters, vol. 2, No. 2, Nov. 2000, pp. 91-100.;;Hughes Neil, “Apple Explores Merging Cloud Content with Locally Stored Media Library”, Available at <http://appleinsider.com/articles/11/02/10/apple_explores_merging_cloud_content_with_locally_stored_media_library.html>, XP55040717, Feb. 10, 2011, 2 pages.;;Intention to Grant received for Danish Patent Application No. PA201870385, dated Jan. 24, 2020, 2 pages.;;Intention to Grant received for European Patent Application No. 10172417.7, dated Jul. 9, 2013, 10 pages.;;Intention to Grant received for European Patent Application No. 11178257.9, dated Jan. 30, 2013, 9 pages.;;Intention to Grant received for European Patent Application No. 11178259.5, dated Nov. 8, 2018, 16 pages.;;Intention to Grant received for the European Patent Application No. 07814633.9, dated Mar. 19, 2010, 4 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2007/077441, dated Mar. 10, 2009, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2011/020403, dated Jul. 19, 2012, 10 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2016/035090, dated Dec. 14, 2017, 14 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035322, dated Dec. 27, 2018, 13 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/049795, dated Apr. 4, 2019, 16 pages.;;International Search Report and Written Opinion received for PCT Application No. PCT/US2017/049795, dated Dec. 27, 2017, 26 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/020403, dated May 26, 2011, 14 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/048169, dated Oct. 21, 2011, 9 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/035090, dated Oct. 4, 2016, 17 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2017/035322, dated Oct. 5, 2017, 18 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024790, dated Sep. 11, 2019, 18 pages.;;International Search Report and Written Opinion, received for PCT Patent Application No. PCT/US2007/077441, dated May 8, 2008, 13 pages.;;Invitation to Pay Additional Fee received for PCT Patent Application No. PCT/US2019/024790, dated Jul. 18, 2019, 10 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2007/077441, dated Jan. 28, 2008, 5 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2016/035090, dated Jul. 15, 2016, 2 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035322, dated Aug. 7, 2017, 4 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/049795, dated Nov. 3, 2017, 3 pages.;;Jobs Steve, “iPhone Introduction in 2007 (Complete)”, available at <https://www.youtube.com/watch?v=9hUlxyE2Ns8>, Jan. 10, 2013, 3 pages.;;Karlson et al., “AppLens and LaunchTile: Two Designs for One-Handed Thumb Use on Small Devices”, CHI 2005, Papers: Small Devices 1, Apr. 2-7, 2005, pp. 201-210.;;Liao, T.W., “Clustering of Time Series Data-a Survey”, Pattern Recognition, vol. 38, 2005, pp. 1857-1874.;;Marwan et al., “Generalised Recurrence Plot Analysis for Spatial Data”, Physics Letters A, vol. 360, 2007, pp. 545-551.;;Minutes of Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Nov. 2, 2018, 9 pages.;;Mozilla Developer Network, “Mouse Gesture Events”, Available online at <https://developer.mozilla.org/en-US/docs/Web/Guide/Events/Mouse_gesture_events>, May 14, 2009, 3 pages.;;MS Excel 2013, Jan. 29, 2013, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 11/848,210, dated Jun. 30, 2011, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/361,912, dated Mar. 22, 2012, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,889, dated Mar. 7, 2017, 26 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Dec. 23, 2016, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Nov. 3, 2017, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/281,524, dated Jun. 19, 2018, 23 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/391,269, dated Aug. 22, 2019, 44 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/687,384, dated Jul. 6, 2018, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/881,544, dated Jun. 7, 2018, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/109,487, dated Feb. 5, 2020, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Mar. 4, 2020, 50 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/259,771, dated May 8, 2019, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/402,057, dated May 23, 2019, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/450,531, dated Jun. 10, 2020, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/789,441, dated Jan. 17, 2013, 24 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/666,943, dated Oct. 26, 2015, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/253,783, dated Feb. 23, 2016, 18 pages.;;Notice of Acceptance received for Australian Patent Application No. 2011265412, dated Nov. 12, 2014, 2 pages.;;Notice of Acceptance received for Australian Patent Application No. 2015201028, dated Mar. 21, 2017, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017201548, dated Sep. 3, 2018, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017330212, dated Apr. 28, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018214074, dated Aug. 6, 2019, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017284958, dated Sep. 3, 2019, 3 pages.;;Notice of Allowance received for Canadian Patent Application No. 2,935,875, dated May 3, 2017, 1 page.;;Notice of Allowance received for Canadian Patent Application No. 2,984,527, dated Apr. 30, 2020, 1 page.;;Notice of Allowance received for Chinese Patent Application No. 201811616429.8, dated Aug. 5, 2020, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2013-140171, dated May 29, 2015, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2014-259225, dated Feb. 27, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2015-129152, dated May 8, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-057997, dated Apr. 23, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-132229, dated Jun. 25, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-511767, dated Mar. 30, 2020, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2018-7034875, dated Dec. 12, 2018, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Dec. 19, 2019, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Mar. 12, 2020, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2020-7005314, dated Mar. 23, 2020, 6 pages.;;Notice of Allowance received for the Canadian Patent Application No. 2,853,273, dated Jan. 12, 2016, 1 page.;;Notice of Allowance received for U.S. Appl. No. 11/848,210, dated Dec. 20, 2011, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Dec. 6, 2013, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 13/361,912, dated Jul. 2, 2012, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 2, 2016, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 17, 2015, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Apr. 14, 2017, 12 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Jul. 12, 2017, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Sep. 5, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,889, dated Oct. 30, 2017, 16 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 6, 2018, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 30, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Apr. 11, 2019, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/687,384, dated Jan. 8, 2019, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/713,490, dated Mar. 20, 2019, 15 pages.;;Notice of Allowance received for U.S. Appl. No. 15/881,544, dated Jun. 26, 2019, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 15/881,544, dated Nov. 7, 2019, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Aug. 18, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated May 12, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Nov. 23, 2020, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Mar. 25, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Aug. 20, 2013, 9 pages.;;Office Action received for Australian Patent Application No. 2015201028, dated Mar. 15, 2016, 2 pages.;;Office Action received for Australian Patent Application No. 2017201548, dated Feb. 26, 2018, 2 pages.;;Office Action received for Australian Patent Application No. 2017330212, dated Feb. 21, 2020, 2 pages.;;Office Action received for Australian Patent Application No. 2018214074, dated May 9, 2019, 2 pages.;;Office Action received for Australian Patent Application No. 2019100490, dated Jul. 26, 2019, 4 pages.;;Office Action received for Australian Patent Application No. 2017284958, dated Dec. 13, 2018, 3 pages.;;Office Action received for Canadian Patent Application No. 2,853,273, dated Feb. 23, 2015, 5 pages.;;Office Action received for Canadian Patent Application No. 2,984,527 dated Sep. 11, 2018, 5 pages.;;Office Action received for Canadian Patent Application No. 2,984,527, dated Jul. 25, 2019, 4 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated May 7, 2020, 8 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated Sep. 4, 2019, 26 pages.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jul. 3, 2020, 15 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 14, 2019, 7 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 23, 2018, 10 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Jan. 26, 2018, 8 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Mar. 1, 2019, 9 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 4, 2020, 7 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 7, 2018, 4 pages.;;Office Action received for Danish Patent Application No. PA201870385, dated Aug. 23, 2019, 3 pages.;;Office Action received for European Patent Application No. 07814633.9, dated Aug. 10, 2009, 3 pages.;;Office Action received for European Patent Application No. 10172417.7, dated Oct. 31, 2011, 6 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Jan. 4, 2013, 8 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Nov. 10, 2015, 4 pages.;;Office Action received for European Patent Application No. 18197554.1, dated Jun. 15, 2020, 4 pages.;;Office Action received for European Patent Application No. 19724963.4, dated Jul. 28, 2020, 6 pages.;;Office Action received for Indian Patent Application No. 9044/CHENP/2014, dated Jan. 24, 2020, 6 pages.;;Office action received for Indian Patent Application No. 2797/CHENP/2008 , dated Jan. 29, 2014, 3 pages.;;Office Action received for Japanese Patent Application No. 2013-140171, dated Jul. 22, 2014, 4 pages.;;Office Action received for Japanese Patent Application No. 2014-259225, dated May 27, 2016, 4 pages.;;Office Action received for Japanese Patent Application No. 2014-259225, dated Nov. 20, 2015, 2 pages.;;Office Action received for Japanese Patent Application No. 2015-129152, dated Sep. 23, 2016, 3 pages.;;Office Action received for Japanese Patent Application No. 2017-057997, dated Jan. 9, 2018, 6 pages.;;Office Action received for Japanese Patent Application No. 2017-132229, dated Mar. 16, 2018, 7 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated Jan. 27, 2020, 7 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated May 13, 2019, 10 pages.;;Office Action received for Japanese Patent Application No. 2019-123115, dated Aug. 31, 2020, 9 pages.;;Office Action received for Japanese Patent Application No. 2019-215503, dated Jul. 3, 2020, 12 pages.;;Office Action received for Korean Patent Application No. 10-2019-7005369, dated Mar. 13, 2020, 12 pages.;;Office Action received for Korean Patent Application No. 10-2019-7007053, dated Mar. 18, 2019, 12 pages.;;Office Action received for Korean Patent Application No. 10-2019-7007053, dated Sep. 26, 2019, 9 pages.;;Office Action received for Korean Patent Application No. 10-2020-7018255, dated Sep. 10, 2020, 12 pages.;;Partial European Search Report received for European Patent Application No. 18197554.1, dated Jan. 22, 2019, 8 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201670608, dated Jan. 3, 2017, 15 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201670609, dated Feb. 1, 2017, 11 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201870385, dated Nov. 16, 2018, 10 Pages.;;Summons to Attend Oral Proceeding received for European Patent Application No. 10172417.7, Jan. 28, 2013, 6 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 11, 2015, 9 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 19, 2018, 12 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/713,490, dated May 30, 2019, 2 pages.;;Van Wijk et al., “Cluster and Calendar based Visualization of Time Series Data”, IEEE Comput. Soc., 1999, 7 pages.;;Way to Use a Camera, JP, Nov. 18, 2005, pp. 206-212.;;Willcom, “Operation Manual for WS003SH”, JP, Dec. 2005, pp. 4-1 to 4-7.;;Result of Consultation received for European Patent Application No. 19724963.4, dated May 31, 2021, 3 pages.;;Office Action received for Australian Patent Application No. 2019266054, dated Aug. 23, 2021, 4 pages.;;Examiner's Answer to Appeal Brief received for U.S. Appl. No. 16/584,783, dated Feb. 17, 2021, 9 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/584,776, dated Feb. 18, 2021, 3 pages.;;Result of Consultation received for European Patent Application No. 19724963.4, dated Jul. 8, 2021, 3 pages.;;Decision on Appeal received for U.S. Appl. No. 16/259,771, dated Aug. 19, 2021, 12 pages.;;Notice of Allowance received for Chinese Patent Application No. 201811136445.7, dated Aug. 11, 2021, 2 pages (1 page of English Translation and 1 page of Official Copy).;;Office Action received for Japanese Patent Application No. 2018-138559, dated Jul. 26, 2021, 37 pages (5 pages of English Translation and 32 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-079486, dated Jul. 16, 2021, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Summons to Attend Oral Proceedings received for European Patent Application No. 17813778.2, dated Aug. 13, 2021, 13 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Apr. 30, 2021, 4 pages.;;Office Action received for Chinese Patent Application No. 201811136445.7, dated Apr. 14, 2021, 7 pages (4 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2021-7002582, dated Apr. 16, 2021, 13 pages (6 pages of English Translation and 7 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Jul. 26, 2021, 3 pages.;;Record of Oral Hearing received for U.S. Appl. No. 16/259,771, dated Aug. 4, 2021, 15 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2020-7018255, dated Feb. 24, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for European Patent Application No. 19212057.4, dated Mar. 9, 2021, 6 pages.;;Office Action received for Japanese Patent Application No. 2019-215503, dated Feb. 5, 2021, 12 pages (6 pages of English Translation and 6 pages of Official Copy).;;Applivgames, ““Super Mario Run” Stickers for iMessage: Free Delivery Started!”, Available online at: <https://games.app-liv.jp/archives/178627>, Sep. 13, 2016, 3 pages (Official Copy Only) (See Communication under 37 CFR § 1.98(a) (3)).;;Contents Pocket, “Line Stamp Information”, Available online at: <https://web.archive.org/web/20150404080541/http://contents-pocket.net/linestamp.html>, Apr. 2015, 2 pages (Official Copy Only) (See Communication under 37 CFR § 1.98(a) (3)).;;Office Action received for Australian Patent Application No. 2020267310, dated Nov. 4, 2021, 2 pages.;;Result of Consultation received for European Patent Application No. 17813778.2, dated Dec. 6, 2021, 17 pages.;;Advisory Action received for U.S. Appl. No. 16/145,033, dated Nov. 2, 2021, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Oct. 7, 2021, 4 pages.;;Decision on Appeal received for U.S. Appl. No. 16/584,783, dated Oct. 14, 2021, 12 pages.;;Examiner's Pre-Review Report received for Japanese Patent Application No. 2019-215503, dated Aug. 20, 2021, 15 pages (8 pages of English Translation and 7 pages of Official Copy).;;Intention to Grant received for European Patent Application No. 19724963.4, dated Sep. 20, 2021, 7 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2020/031442, dated Nov. 18, 2021, 21 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019266054, dated Nov. 25, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020267396, dated Dec. 7, 2021, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-138559, dated Dec. 3, 2021, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/584,783, dated Dec. 20, 2021, 7 pages.;;Office Action received for Australian Patent Application No. 2020294208, dated Dec. 17, 2021, 2 pages.;;Office Action received for Chinese Patent Application No. 201910315328.5, dated Nov. 30, 2021, 21 pages (10 pages of English Translation and 11 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2021-7002582, dated Oct. 29, 2021, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Summons to Oral Proceedings received for German Patent Application No. 112007000067.8, dated Dec. 8, 2021, 11 pages (5 pages of English Translation and 6 pages of Official Copy).;;Decision to Refuse received for European Patent Application No. 17813778.2, dated Jan. 24, 2022, 17 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 17813778.2, dated Jan. 21, 2022, 7 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020267310, dated Feb. 23, 2022, 3 pages.",ACTIVE
136,US,B2,US 10891013 B2,008-000-527-254-404,2021-01-12,2021,US 201816109487 A,2018-08-22,US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S,,https://lens.org/008-000-527-254-404,Granted Patent,yes,424,2,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0481;;G06F3/0354;;G06F3/0484;;G06F3/0488;;G06F16/178;;G06F16/435;;G06F16/438;;G06F16/44;;G06T1/00,,175,7,027-954-411-824-598;;015-170-949-710-284;;052-835-691-615-436;;087-439-027-914-345;;044-447-761-889-885;;015-071-346-705-597;;051-775-327-653-999,10.1145/1645953.1646021;;10.1145/1386352.1386397;;10.1145/1459359.1459458;;10.1145/1054972.1055001;;10.1016/j.patcog.2005.01.025;;10.1016/j.physleta.2006.08.058;;10.1109/infvis.1999.801851,"US 2002/0018582 A1, 02/2002, Hagiwara et al. (withdrawn);;Notice of Acceptance received for Australian Patent Application No. 2017201548, dated Sep. 3, 2018, 3 pages.;;Office Action received for Canadian Patent Application No. 2,984,527 dated Sep. 11, 2018, 5 pages.;;Advisory Action received for U.S. Appl. No. 14/253,783, dated Feb. 15, 2017, 6 pages.;;Board Opinion received for Chinese Reexamination Patent Application No. 200780001142.8, dated Oct. 21, 2014, 19 pages.;;Chen, et al., “Event Detection from Flickr Data through Wavelet-based Spatial Analysis”, Proceeding of the 18th ACM Conference on Information and Knowledge Management, CIKM, Jan. 1, 2009, pp. 523-532.;;Communication Regarding Intention to Grant received for the European Patent Application No. 07814633.9, dated Mar. 19, 2010, 4 pages.;;Cyr, Jim, “Apple Watch—Customize Modular Watch Face”, available online at: https://www.youtube.com/watch?v=02W93HbKIK8, May 13, 2015, 2 pages.;;Das, et al., “Event Classification in Personal Image Collections”, IEEE Intl. Workshop on Media Information Analysis for Personal and Social Applications at ICME, 2009, 2009, pp. 1660-1663.;;Das, et al., “Event-based Location Matching for Consumer Image Collections”, CIVR, 2008, Proc. of the ACM Int. Conf. on Image and Video Retrieval, 2008, 5 pages.;;Decision to Grant received for Japanese Patent Application No. 2009-526943, dated Dec. 2, 2011, dated Dec. 2, 2011, 3 pages.;;Decision to Grant received for the European Patent Application No. 07814633.9, dated Sep. 2, 2010, 3 pages.;;Decision to Grant received for the European Patent Application No. 10172417.7, dated Nov. 14, 2013, 3 pages.;;Decision to Grant received for the European Patent Application No. 11178257.9, dated Jun. 20, 2013, 3 pages.;;European Search Report received for European Patent Application No. 11178257.9, dated Oct. 31, 2011, 5 pages.;;European Search Report received for the European Application No. 11178259.5, dated Oct. 31, 2011, 8 pages.;;European Search Report received for the European Patent Application No. 10172417.7, dated Jan. 7, 2011, 4 pages.;;Final Office Action received for U.S. Appl. No. 14/253,783, dated Sep. 30, 2016, 18 pages.;;Gallagher, et al., “Image Annotation Using Personal Calendars as Context”, ACM Intl. Conf. on Multimedia, 2008, 2008, 4 pages.;;Geek, “How to Put the Day of the Week into the Windows Taskbar Clock”, available online at: https://www.howtogeek.com/194103/how-to-put-the-day-of-the-week-into-the-windows-taskbar-clock/, 2014, 3 pages.;;Han, et al., “Density-Based Methods”, Data Mining Concepts and Techniques, Elsevier, 2006, pp. 418-420.;;Hinckley, et al., “Sensing Techniques for Mobile Interaction”, Symposium on User Interface Software and Technology, CHI Letters, vol. 2, No. 2, Nov. 2000, pp. 91-100.;;Intention to Grant received for European Patent Application No. 10172417.7, dated Jul. 9, 2013, 10 pages.;;Intention to Grant received for European Patent Application No. 11178257.9, dated Jan. 30, 2013, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2007/077441, dated Mar. 10, 2009, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2011/020403, dated Jul. 19, 2012, 10 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2016/035090, dated Dec. 14, 2017, 14 pages.;;International Search Report and Written Opinion received for PCT Application No. PCT/US2017/049795, dated Dec. 27, 2017, 26 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/020403, dated May 26, 2011, 14 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/048169, dated Oct. 21, 2011, 9 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/035090, dated Oct. 4, 2016, 17 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2017/035322, dated Oct. 5, 2017, 18 pages.;;International Search Report and Written Opinion received for International PCT Patent Application No. PCT/US2007/077441, dated May 8, 2008, 13 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2007/077441, dated Jan. 28, 2008, 5 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2016/035090, dated Jul. 15, 2016, 2 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035322, dated Aug. 7, 2017, 4 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/049795, dated Nov. 3, 2017, 3 pages.;;Jobs, Steve, “iPhone Introduction in 2007 (Complete)”, available at <https://www.youtube.com/watch?v=9hUlxyE2Ns8>, Jan. 10, 2013, 3 pages.;;Karlson, et al., “AppLens and LaunchTile: Two Designs for One-Handed Thumb Use on Small Devices”, CHI 2005, Papers: Small Devices 1, Apr. 2-7, 2005, pp. 201-210.;;Kyocera WX300K, “Way to Use a Camera”, JP, Nov. 18, 2005, pp. 206-212.;;Mozilla Developer Network, “Mouse Gesture Events”, Available online at <https://developermozilla.org/en-US/docs/Web/Guide/Events/Mouse_gesture_events>, May 14, 2009, 3 pages.;;Non Final Office Action received for U.S. Appl. No. 12/789,441, dated Jan. 17, 2013, dated Jan. 17, 2013, 24 pages.;;Non Final Office Action received for U.S. Appl. No. 14/253,783, dated Feb. 23, 2016, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 11/848,210, dated Jun. 30, 2011, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/361,912, dated Mar. 22, 2012, dated Mar. 22, 2012, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,889, dated Mar. 7, 2017, 26 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Dec. 23, 2016, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Nov. 3, 2017, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/666,943, dated Oct. 26, 2015, 12 pages.;;Notice of Acceptance received for Australian Patent Application No. 2011265412, dated Nov. 12, 2014, 2 pages.;;Notice of Allowance received for Australian Patent Application No. 2015201028, dated Mar. 21, 2017, 3 pages.;;Notice of Allowance received for Canadian Patent Application No. 2,935,875, dated May 3, 2017, 1 page.;;Notice of Allowance received for Japanese Patent Application No. 2013-140171, dated May 29, 2015, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2014-259225, dated Feb. 27, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2015-129152, dated May 8, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-057997, dated Apr. 23, 2018, 4 pages.;;Notice of Allowance received for the Canadian Patent Application No. 2,853,273, dated Jan. 12, 2016, dated Jan. 12, 2016, 1 page.;;Notice of Allowance received for U.S. Appl. No. 11/848,210, dated Dec. 20, 2011, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Dec. 6, 2013, dated Dec. 6, 2013, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 13/361,912, dated Jul. 2, 2012, dated Jul. 2, 2012, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Aug. 11, 2016, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 2, 2016, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 17, 2015, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Apr. 14, 2017, 12 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Jul. 12, 2017, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Sep. 5, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,889, dated Oct. 30, 2017, 16 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 6, 2018, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 30, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Aug. 20, 2013, dated Aug. 20, 2013, 9 pages.;;Office Action received for Australian Patent Application No. 2015201028, dated Mar. 15, 2016, 2 pages.;;Office Action received for Australian Patent Application No. 2017201548, dated Feb. 26, 2018, 2 pages.;;Office Action received for Canadian Patent Application No. 2,853,273, dated Feb. 23, 2015, 5 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 23, 2018, 10 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Jan. 26, 2018, 8 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 7, 2018, 4 pages.;;Office Action received for European Patent Application No. 07814633.9, dated Aug. 10, 2009, 3 pages.;;Office Action received for European Patent Application No. 10172417.7, dated Oct. 31, 2011, 6 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Jan. 4, 2013, 8 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Nov. 10, 2015, 4 pages.;;Office action received for Indian Patent Application No. 2797CHENP2008, dated Jan. 29, 2014, 3 pages.;;Office Action Received for Japanese Patent Application No. 2014-259225, dated Nov. 20, 2015, 2 pages.;;Office Action received for Japanese Patent Application No. 2017-057997, dated Jan. 9, 2018, 6 pages.;;Office Action received for Japanese Patent Application No. 2017-132229, dated Mar. 16, 2018, 7 pages.;;Search Report and opinion received for Danish Patent Application No. PA201670608, dated Jan. 3, 2017, 15 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201670609, dated Feb. 1, 2017, 11 pages.;;Summons to Attend Oral Proceeding received for European Patent Application No. 10172417.7, Jan. 28, 2013, 6 pages, Jan. 28, 2013, 6 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 11, 2015, 9 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No.11178259.5, mailed on Feb. 19, 2018, 12 pages.;;Intention to Grant received for European Patent Application No. 11178259.5, dated Nov. 8, 2018, 23 pages.;;Minutes of Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Nov. 2, 2018, 8 pages.;;Office Action received for Australian Patent Application No. 2019100490, dated Jul. 26, 2019, 4 pages.;;Liao, T. Warren, “Clustering of Time Series Data—a Survey”, Pattern Recognition, vol. 38, 2005, pp. 1857-1874.;;Marwan, et al., “Generalised Recurrence Plot Analysis for Spatial Data”, Physics Letters A, vol. 360, 2007, pp. 545-551.;;“MS Excel 2013”, Jan. 29, 2013, 2 pages.;;Non Final Office Action received for U.S. Appl. No. 15/881,544, dated Jun. 7, 2018, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/281,524, dated Jun. 19, 2018, 23 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/687,384, dated Jul. 6, 2018, 19 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-132229, dated Jun. 25, 2018, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2013-140171, dated Jul. 22, 2014, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2014-259225, dated May 27, 2016, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2015-129152, dated Sep. 23, 2016, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Van Wijk, et al., “Cluster and Calendar based Visualization of Time Series Data”, IEEE Comput. Soc., 1999, 7 pages.;;Willcom, “Operation Manual for WS003SH”, Dec. 2005, pp. 4-1 to 4-7 (Official Copy only) (see attached 37 CFR § 1.98(a) (3)).;;Certificate of Examination received for Australian Patent Application No. 2019100490, dated Oct. 16, 2019, 2 pages.;;Final Office Action received for U.S. Appl. No. 16/402,057, dated Oct. 17, 2019, 23 pages.;;Office Action received for Korean Patent Application No. 10-2019-7007053, dated Sep. 26, 2019, 9 pages (4 pages of English Translation and 5 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 16/259,771, dated Nov. 18, 2019, 13 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017284958, dated Sep. 3, 2019, 3 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024790, dated Sep. 11, 2019, 18 pages.;;Office Action received for Danish Patent Application No. PA201870385, dated Aug. 23, 2019, 3 pages.;;Invitation to Pay Additional Fee received for PCT Patent Application No. PCT/US2019/024790, dated Jul. 18, 2019, 10 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018214074, dated Aug. 6, 2019, 3 pages.;;Office Action received for Canadian Patent Application No. 2,984,527, dated Jul. 25, 2019, 4 pages.;;Final Office Action received for U.S. Appl. No. 15/881,544, dated Jan. 29, 2019, 14 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 14, 2019, 7 pages.;;Partial European Search Report received for European Patent Application No. 18197554.1, dated Jan. 22, 2019, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/881,544, dated Nov. 7, 2019, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 15/713,490, dated Mar. 20, 2019, 15 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Mar. 1, 2019, 9 pages.;;Decision to Grant received for European Patent Application No. 11178259.5, dated Apr. 4, 2019, 3 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/049795, dated Apr. 4, 2019, 16 pages.;;Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Apr. 11, 2019, 7 pages.;;Office Action received for Korean Patent Application No. 10-2019-7007053, dated Mar. 18, 2019, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 15/881,544, dated Jun. 26, 2019, 6 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/713,490, dated May 1, 2019, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/259,771, dated May 8, 2019, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/402,057, dated May 23, 2019, 16 pages.;;Office Action received for Australian Patent Application No. 2018214074, dated May 9, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Jun. 3, 2019, 2 pages.;;Extended European Search Report received for European Patent Application No. 18197554.1, dated Jun. 3, 2019, 11 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated May 13, 2019, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Search Report and Opinion received for Danish Patent Application No. PA201870385, dated Nov. 16, 2018, 10 Pages.;;Supplemental Notice of Allowance received for U.S. Appl. No.15/713,490, dated May 30, 2019, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/391,269, dated Aug. 22, 2019, 44 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated Sep. 4, 2019, 26 pages (15 pages of English Translation and 11 pages of Official Copy).;;Extended European Search Report received for European Patent Application No. 17813778.2, dated Jan. 10, 2020, 12 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Dec. 19, 2019, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Mar. 12, 2020, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Mar. 25, 2020, 8 pages.;;Office Action received for Korean Patent Application No. 10-2019-7005369, dated Mar. 13, 2020, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Applicant-Initiated Interview Summary for U.S. Appl. No. 16/402,057, dated Mar. 16, 2020, 3 pages.;;Extended European Search Report received for European Patent Application No. 19212057.4, dated Feb. 27, 2020, 8 pages.;;Advisory Action received for U.S. Appl. No. 16/259,771, dated Feb. 26, 2020, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Mar. 4, 2020, 50 pages.;;Office Action received for Australian Patent Application No. 2017330212, dated Feb. 21, 2020, 2 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated Jan. 27, 2020, 7 pages (3 pages of English Translation and 4 pages of Official Copy).;;Intention to Grant received for Danish Patent Application No. PA201870385, dated Jan. 24, 2020, 2 pages.;;Office Action received for Indian Patent Application No. 9044/CHENP/2014, dated Jan. 24, 2020, 6 pages.;;Decision to Grant received for Danish Patent Application No. PA201870385, dated Mar. 26, 2020, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-511767, dated Mar. 30, 2020, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2020-7005314, dated Mar. 23, 2020, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 15/281,524, dated Dec. 27, 2018, 6 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035322, dated Dec. 27, 2018, 13 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2018-7034875, dated Dec. 12, 2018, 4 pages (1 pages of English Translation and 3 pages of Official Copy);;Notice of Allowance received for U.S. Appl. No. 15/687,384, dated Jan. 8, 2019, 8 pages.;;Office Action received for Australian Patent Application No. 2017284958, dated Dec. 13, 2018, 3 pages.;;Hughes, Neil, “Apple Explores Merging Cloud Content with Locally Stored Media Library”, available at http://appleinsider.com/articles/11/02/10/apple_explores_merging_cloud_content_with_locally_stored_media_library.html, Feb. 10, 2011, 2 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 4, 2020, 7 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated May 7, 2020, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Advisory Action received for U.S. Appl. No. 16/259,771, dated Jul. 14, 2020, 6 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/259,771, dated May 5, 2020, 10 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Jun. 29, 2020, 5 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Jul. 6, 2020, 2 pages.;;Extended European Search Report received for European Patent Application No. 17853657.9, dated May 28, 2020, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/450,531, dated Jun. 10, 2020, 10 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017330212, dated Apr. 28, 2020, 3 pages.;;Notice of Allowance received for Canadian Patent Application No. 2,984,527, dated Apr. 30, 2020, 1 page.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jul. 3, 2020, 15 pages (9 pages of English Translation and 6 pages of Official Copy).;;Office Action received for European Patent Application No. 18197554.1, dated Jun. 15, 2020, 4 pages.;;Office Action received for European Patent Application No. 19724963.4, dated Jul. 28, 2020, 6 pages.;;Office Action received for Japanese Patent Application No. 2019-215503, dated Jul. 3, 2020, 12 pages (6 pages of English Translation and 6 pages of Official Copy).;;Notice of Allowance received for Chinese Patent Application No. 201811616429.8, dated Aug. 5, 2020, 3 pages (2 pages of English Translation and 1 page of Official Copy).;;Office Action received for Korean Patent Application No. 10-2020-7018255, dated Sep. 10, 2020, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2019-123115, dated Aug. 31, 2020, 9 pages (4 pages of English Translation and 5 pages of Official Copy).",ACTIVE
137,US,A1,US 2008/0058816 A1,043-488-145-089-037,2008-03-06,2008,US 83972107 A,2007-08-16,US 83972107 A;;US 82457306 P,2006-09-05,Anchor Delivery System,"The present disclosure relates to an anchor delivery system. The system includes a guide and an anchor delivery tool disposed within the guide. The tool includes a shaft and a handle coupled to a proximal portion of the shaft. The handle includes a hub and a nose cone coupled to the hub. In an embodiment, the tool further includes a knob coupled to the hub and located between the handle and the nose cone. In an embodiment, the system further includes an anchor, such as a suture anchor, coupled to a distal portion of the shaft. An anchor delivery tool and a method of repairing soft tissue are also disclosed.",PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M,PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M,SMITH & NEPHEW INC (2007-09-04);;UNIVERSITY OF WASHINGTON (2010-05-12),https://lens.org/043-488-145-089-037,Patent Application,yes,17,82,12,12,0,A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B2090/034;;A61B2090/062;;A61B17/0401;;A61B2090/034;;A61B2090/062;;A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B17/0401;;A61B2017/044;;A61B2017/0445;;A61B2017/0464;;A61B17/8888;;A61B2017/0411,A61B17/56,606/72,0,0,,,,ACTIVE
138,US,B2,US 9572564 B2,192-117-881-940-045,2017-02-21,2017,US 201414274977 A,2014-05-12,US 201414274977 A;;US 83972107 A;;US 82457306 P,2006-09-05,Anchor delivery system,"An anchor delivery system is described. The system includes a guide and an anchor delivery tool disposed within the guide. The tool includes a shaft and a handle coupled to a proximal portion of the shaft. The handle includes a hub and a nose cone coupled to the hub. In an embodiment, the tool further includes a knob coupled to the hub and located between the handle and the nose cone. In an embodiment, the system further includes an anchor, such as a suture anchor, coupled to a distal portion of the shaft. An anchor delivery tool and a method of repairing soft tissue are also described.",SMITH & NEPHEW INC,PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M,,https://lens.org/192-117-881-940-045,Granted Patent,yes,21,0,12,12,0,A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B2090/034;;A61B2090/062;;A61B17/0401;;A61B2090/034;;A61B2090/062;;A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B17/0401;;A61B2017/044;;A61B2017/0445;;A61B2017/0464;;A61B17/8888;;A61B2017/0411,A61B17/04;;A61B17/06;;A61B17/16;;A61B17/17,,3,0,,,"Office Action for corresponding Australian patent application No. 2007357651 mailed Jul. 24, 2014.;;International Search Report and Written Opinion for PCT/2007/079027 dated Jul. 21, 2008.;;Office action received in corresponding European patent application No. 07 871 085.2 mailed Mar. 31, 2015.",ACTIVE
139,US,A1,US 2014/0249578 A1,066-753-619-927-610,2014-09-04,2014,US 201414274977 A,2014-05-12,US 201414274977 A;;US 83972107 A;;US 82457306 P,2006-09-05,ANCHOR DELIVERY SYSTEM,"The present disclosure relates to an anchor delivery system. The system includes a guide and an anchor delivery tool disposed within the guide. The tool includes a shaft and a handle coupled to a proximal portion of the shaft. The handle includes a hub and a nose cone coupled to the hub. In an embodiment, the tool further includes a knob coupled to the hub and located between the handle and the nose cone. In an embodiment, the system further includes an anchor, such as a suture anchor, coupled to a distal portion of the shaft. An anchor delivery tool and a method of repairing soft tissue are also disclosed.",SMITH & NEPHEW INC,PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPSCHITZ JOHN M,,https://lens.org/066-753-619-927-610,Patent Application,yes,7,0,12,12,0,A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B2090/034;;A61B2090/062;;A61B17/0401;;A61B2090/034;;A61B2090/062;;A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B17/0401;;A61B2017/044;;A61B2017/0445;;A61B2017/0464;;A61B17/8888;;A61B2017/0411,A61B17/04,606/232,0,0,,,,ACTIVE
140,US,B2,US 8758367 B2,050-437-305-540-784,2014-06-24,2014,US 83972107 A,2007-08-16,US 83972107 A;;US 82457306 P,2006-09-05,Anchor delivery system,"The present disclosure relates to an anchor delivery system. The system includes a guide and an anchor delivery tool disposed within the guide. The tool includes a shaft and a handle coupled to a proximal portion of the shaft. The handle includes a hub and a nose cone coupled to the hub. In an embodiment, the tool further includes a knob coupled to the hub and located between the handle and the nose cone. In an embodiment, the system further includes an anchor, such as a suture anchor, coupled to a distal portion of the shaft. An anchor delivery tool and a method of repairing soft tissue are also disclosed.",PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M;;SMITH & NEPHEW INC,PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M,SMITH & NEPHEW INC (2007-09-04);;UNIVERSITY OF WASHINGTON (2010-05-12),https://lens.org/050-437-305-540-784,Granted Patent,yes,19,26,12,12,0,A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B2090/034;;A61B2090/062;;A61B17/0401;;A61B2090/034;;A61B2090/062;;A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B17/0401;;A61B2017/044;;A61B2017/0445;;A61B2017/0464;;A61B17/8888;;A61B2017/0411,A61B17/10,606/139;;606/144;;606/232,3,0,,,"International Search Report and Written Opinion for PCT/2007/079027 dated Jul. 21, 2008.;;Office Action for European Patent Application EP07 871 05.2-2310 mailed Sep. 19, 2011.;;Office Action for corresponding AU patent application No. 2007357651 mailed Jan. 9, 2013.",ACTIVE
141,US,A1,US 2017/0151007 A1,046-087-815-220-914,2017-06-01,2017,US 201715429477 A,2017-02-10,US 201715429477 A;;US 201414274977 A;;US 83972107 A;;US 82457306 P,2006-09-05,Anchor Delivery System,"The present disclosure relates to an anchor delivery system. The system includes a guide and an anchor delivery tool disposed within the guide. The tool includes a shaft and a handle coupled to a proximal portion of the shaft. The handle includes a hub and a nose cone coupled to the hub. In an embodiment, the tool further includes a knob coupled to the hub and located between the handle and the nose cone. In an embodiment, the system further includes an anchor, such as a suture anchor, coupled to a distal portion of the shaft. An anchor delivery tool and a method of repairing soft tissue are also disclosed.",SMITH & NEPHEW INC,PHILIPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M,,https://lens.org/046-087-815-220-914,Patent Application,yes,10,2,12,12,0,A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B2090/034;;A61B2090/062;;A61B17/0401;;A61B2090/034;;A61B2090/062;;A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B17/0401;;A61B2017/044;;A61B2017/0445;;A61B2017/0464;;A61B17/8888;;A61B2017/0411,A61B17/88;;A61B17/04,,0,0,,,,ACTIVE
142,US,B2,US 9931150 B2,199-916-505-810-795,2018-04-03,2018,US 201715429477 A,2017-02-10,US 201715429477 A;;US 201414274977 A;;US 83972107 A;;US 82457306 P,2006-09-05,Anchor delivery system,"An anchor delivery tool is described. The tool includes a shaft and a handle coupled to a proximal portion of the shaft. The handle includes a hub, with a knob and a nose cone coupled to the hub. The knob and nose cone may be spring loaded so as to selectively retain a length of suture disposed therebetween. The tool further includes an anchor, such as a suture anchor, coupled to a distal portion of the shaft.",SMITH & NEPHEW INC,PHILIPPON MARC JOSEPH;;MURPHY KEVIN;;BLOUGH REBECCA A;;TORRIE PAUL ALEXANDER;;PUNIELLO PAUL A;;VINCUILLA PAUL S;;MCCABE PAUL;;VARIO GARY R;;FERRAGAMO MICHAEL C;;DYE JUSTIN;;LIPCHITZ JOHN M,,https://lens.org/199-916-505-810-795,Granted Patent,yes,10,8,12,12,0,A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B2090/034;;A61B2090/062;;A61B17/0401;;A61B2090/034;;A61B2090/062;;A61B17/1615;;A61B17/1714;;A61B2017/0409;;A61B2017/0412;;A61B2017/0414;;A61B2017/0427;;A61B2017/0496;;A61B17/0401;;A61B2017/044;;A61B2017/0445;;A61B2017/0464;;A61B17/8888;;A61B2017/0411,A61B17/04;;A61B17/60;;A61B17/88,,0,0,,,,ACTIVE
143,US,A1,US 2022/0276750 A1,178-540-483-472-494,2022-09-01,2022,US 202217744499 A,2022-05-13,US 202217744499 A;;US 202017125744 A;;US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S;;BUTCHER GARY IAN;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;WILSON CHRISTOPHER,,https://lens.org/178-540-483-472-494,Patent Application,yes,28,6,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0481;;G06F3/0354;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/178;;G06F16/435;;G06F16/438;;G06F16/44,,0,0,,,,ACTIVE
144,US,B2,US 11681408 B2,069-916-253-126-079,2023-06-20,2023,US 202217744499 A,2022-05-13,US 202217744499 A;;US 202017125744 A;;US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S;;BUTCHER GARY IAN;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;WILSON CHRISTOPHER,,https://lens.org/069-916-253-126-079,Granted Patent,yes,571,0,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0481;;G06F3/0354;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/178;;G06F16/435;;G06F16/438;;G06F16/44;;G06T1/00,,328,9,027-954-411-824-598;;015-170-949-710-284;;052-835-691-615-436;;087-439-027-914-345;;044-447-761-889-885;;015-071-346-705-597;;051-775-327-653-999;;160-334-930-313-946;;105-254-432-716-73X,10.1145/1645953.1646021;;10.1145/1386352.1386397;;10.1145/1459359.1459458;;10.1145/1054972.1055001;;10.1016/j.patcog.2005.01.025;;10.1016/j.physleta.2006.08.058;;10.1109/infvis.1999.801851;;10.1109/icme.2006.262778;;10.1145/1054972.1054994,"US 2002/0018582 A1, 02/2002, Hagiwara et al. (withdrawn);;Notice of Allowance received for Korean Patent Application No. 10-2020-7018255, dated Feb. 24, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2020-7018255, dated Sep. 10, 2020, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Hughes Neil, “Apple Explores Merging Cloud Content with Locally Stored Media Library”, Available at <http://appleinsider.com/articles/11/02/10/apple_explores_merging_cloud_content_with_locally_stored_media_library.html>, XP55040717, Feb. 10, 2011, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/259,771, dated Apr. 18, 2022, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/153,703, dated May 11, 2022, 4 pages.;;Decision on Appeal received for Korean Patent Application No. 10-2021-7002582, mailed on May 13, 2022, 29 pages (2 pages of English Translation and 27 pages of Official Copy).;;Decision to Grant received for European Patent Application No. 19724963.4, dated Feb. 3, 2022, 2 pages.;;Extended European Search Report received for European Patent Application No. 22152524.9, dated May 2, 2022, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/259,771, dated Jan. 25, 2022, 20 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/153,703, dated Mar. 30, 2022, 10 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020294208, dated Mar. 2, 2022, 3 pages.;;Notice of acceptance received for Australian Patent Application No. 2021202225, dated Jun. 20, 2022, 3 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2021-7036310, dated Apr. 26, 2022, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2021202225, dated Apr. 7, 2022, 3 pages.;;Office Action received for Australian Patent Application No. 2022201561, dated May 2, 2022, 3 pages.;;Office Action received for German Patent Application No. 112007000067.8, dated Apr. 23, 2009, 15 pages (7 pages of English Translation and 8 pages of Official Copy).;;Office Action received for German Patent Application No. 112007000067.8, dated Sep. 14, 2010, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-079486, dated Mar. 11, 2022, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2021-092483, dated Apr. 1, 2022, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2021-566100, dated May 27, 2022, 7 pages (3 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2021-7036310, dated Feb. 23, 2022, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2022-7003364, dated Apr. 22, 2022, 14 pages (6 pages of English Translation and 8 pages of Official Copy).;;Summons to Attend Oral Proceedings received for European Patent Application No. 18197554.1, dated Mar. 23, 2022, 7 pages.;;T&GG Channel, “Canon IXUS 700 / Screenshots of deleting an image”, Online available at: https://www.youtube.com/watch?v=8BL_L5hKZUM, May 2015, 2 pages.;;Final Office Action received for U.S. Appl. No. 16/259,771, dated Aug. 12, 2022, 25 pages.;;Notice of Allowance received for Chinese Patent Application No. 201910315328.5, dated Aug. 24, 2022, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 17/153,703, dated Aug. 30, 2022, 8 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/153,703, dated Nov. 10, 2022, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 17/408,220, dated Nov. 15, 2022, 11 pages.;;Advisory Action received for U.S. Appl. No. 14/253,783, dated Feb. 15, 2017, 6 pages.;;Advisory Action received for U.S. Appl. No. 16/145,033, dated Nov. 2, 2021, 5 pages.;;Advisory Action received for U.S. Appl. No. 16/259,771, dated Feb. 26, 2020, 3 pages.;;Advisory Action received for U.S. Appl. No. 16/259,771, dated Jul. 14, 2020, 6 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/109,487, dated Apr. 21, 2020, 5 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/259,771, dated May 5, 2020, 10 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/584,783, dated May 4, 2020, 3 pages.;;Applicant-Initiated Interview Summary for U.S. Appl. No. 16/402,057, dated Mar. 16, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Apr. 30, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Jun. 29, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Nov. 24, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Oct. 7, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/450,531, dated Aug. 11, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,776, dated May 13, 2020, 9 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,776, dated Nov. 25, 2020, 5 pages.;;Brief Communication Regarding Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Jun. 22, 2021, 2 pages.;;Certificate of Examination received for Australian Patent Application No. 2019100490, mailed on Oct. 16, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Aug. 11, 2016, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Jun. 3, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/713,490, dated May 1, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Jul. 6, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Nov. 12, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Oct. 30, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Mar. 31, 2021, 6 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Dec. 8, 2021, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Dec. 24, 2021, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Mar. 10, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Mar. 30, 2022, 2 pages.;;Decision on Appeal received for U.S. Appl. No. 16/259,771, mailed on Aug. 19, 2021, 12 pages.;;Decision on Appeal received for U.S. Appl. No. 16/584,783, mailed on Oct. 14, 2021,12 pages.;;Decision to Grant received for Danish Patent Application No. PA201870385, dated Mar. 26, 2020, 2 pages.;;Decision to Grant received for European Patent Application No. 11178259.5, dated Apr. 4, 2019, 3 pages.;;Decision to Refuse received for European Patent Application No. 17813778.2, dated Jan. 24, 2022, 17 pages.;;European Search Report received for the European Patent Application No. 10172417.7, dated Jan. 7, 2011, 4 pages.;;Examiner's Answer to Appeal Brief received for U.S. Appl. No. 16/259,771, mailed on Oct. 23, 2020, 15 pages.;;Examiner's Answer to Appeal Brief received for U.S. Appl. No. 16/584,783, mailed on Feb. 17, 2021, 9 pages.;;Examiner's Pre-Review Report received for Japanese Patent Application No. 2018-138559, dated Jul. 29, 2020, 6 pages.;;Examiner's Pre-Review Report received for Japanese Patent Application No. 2019-215503, dated Aug. 20, 2021, 15 pages.;;Extended European Search Report received for European Patent Application No. 17813778.2, dated Jan. 10, 2020, 12 pages.;;Extended European Search Report received for European Patent Application No. 17853657.9, dated May 28, 2020, 9 pages.;;Extended European Search Report received for European Patent Application No. 18197554.1, dated Jun. 3, 2019, 11 pages.;;Extended European Search Report received for European Patent Application No. 19212057.4, dated Feb. 27, 2020, 8 pages.;;Final Office Action received for U.S. Appl. No. 15/281,524, dated Dec. 27, 2018, 6 pages.;;Final Office Action received for U.S. Appl. No. 15/881,544, dated Jan. 29, 2019, 14 pages.;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Jul. 6, 2021, 113 pages.;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Sep. 22, 2020, 49 pages.;;Final Office Action received for U.S. Appl. No. 16/259,771, dated Nov. 18, 2019, 13 pages.;;Final Office Action received for U.S. Appl. No. 16/402,057, dated Oct. 17, 2019, 23 pages.;;Final Office Action received for U.S. Appl. No. 16/584,783, dated May 19, 2020, 19 pages.;;Final Office Action received for U.S. Appl. No. 14/253,783, dated Sep. 30, 2016, 18 pages.;;Intention to Grant received for Danish Patent Application No. PA201870385, dated Jan. 24, 2020, 2 pages.;;Intention to Grant received for European Patent Application No. 11178259.5, dated Nov. 8, 2018, 16 pages.;;Intention to Grant received for European Patent Application No. 19724963.4, dated Sep. 20, 2021, 7 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2016/035090, dated Dec. 14, 2017, 14 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035322, dated Dec. 27, 2018, 13 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/049795, dated Apr. 4, 2019, 16 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2019/024790, dated Nov. 19, 2020, 11 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2020/031442, dated Nov. 18, 2021, 21 pages.;;International Search Report and Written Opinion received for PCT Application No. PCT/US2017/049795, dated Dec. 27, 2017, 26 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/048169, dated Oct. 21, 2011, 9 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/035090, dated Oct. 4, 2016, 17 pages.;;International Search Report and Written Opinion Received for PCT Patent Application No. PCT/US2017/035322, dated Oct. 5, 2017, 18 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024790, dated Sep. 11, 2019, 18 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/031442, dated Oct. 30, 2020, 28 pages.;;Invitation to Pay Additional Fee received for PCT Patent Application No. PCT/US2019/024790, dated Jul. 18, 2019, 10 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2016/035090, dated Jul. 15, 2016, 2 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035322, dated Aug. 7, 2017, 4 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/049795, dated Nov. 3, 2017, 3 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2020/031442, dated Aug. 25, 2020, 22 pages.;;Minutes of Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Nov. 2, 2018, 9 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 17813778.2, mailed on Jan. 21, 2022, 7 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Sep. 3, 2021,6 pages.;;MS Excel 2013, Jan. 29, 2013, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/881,544, dated Jun. 7, 2018, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,889, dated Mar. 7, 2017, 26 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Dec. 23, 2016, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Nov. 3, 2017, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/281,524, dated Jun. 19, 2018, 23 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/391,269, dated Aug. 22, 2019, 44 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/687,384, dated Jul. 6, 2018, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/109,487, dated Feb. 5, 2020, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Feb. 9, 2021, 55 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Mar. 4, 2020, 50 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/259,771, dated May 8, 2019, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/402,057, dated May 23, 2019, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/450,531, dated Jun. 10, 2020, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,776, dated Aug. 18, 2020, 36 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,776, dated Feb. 13, 2020, 31 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,783, dated Jan. 30, 2020, 18 pages.;;Notice of Acceptance received for Australian Patent Application No. 2015201028, dated Mar. 21, 2017, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017201548, dated Sep. 3, 2018, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017330212, dated Apr. 28, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018214074, dated Aug. 6, 2019, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019264623, dated Jan. 4, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019266054, dated Nov. 25, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019271873, dated Nov. 30, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020213402, dated Sep. 21, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020267310, dated Feb. 23, 2022, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020267396, dated Dec. 7, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017284958, dated Sep. 3, 2019, 3 pages.;;Notice of Allowance received for Canadian Patent Application No. 2,935,875, dated May 3, 2017, 1 page.;;Notice of Allowance received for Canadian Patent Application No. 2,984,527, dated Apr. 30, 2020, 1 page.;;Notice of Allowance received for Chinese Patent Application No. 201811136445.7, dated Aug. 11, 2021, 2 pages.;;Notice of Allowance received for Chinese Patent Application No. 201811616429.8, dated Aug. 5, 2020, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2014-259225, dated Feb. 27, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2015-129152, dated May 8, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-057997, dated Apr. 23, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-132229, dated Jun. 25, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-138559, dated Dec. 3, 2021, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-123115, dated Nov. 30, 2020, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-511767, dated Mar. 30, 2020, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2021-000224, dated May 7, 2021, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2021-094529, dated Sep. 6, 2021, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2018-7034875, dated Dec. 12, 2018, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7005369, dated Oct. 26, 2020, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Dec. 19, 2019, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Mar. 12, 2020, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2020-7005314, dated Mar. 23, 2020, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 2, 2016, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Apr. 14, 2017, 12 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Jul. 12, 2017, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Sep. 5, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,889, dated Oct. 30, 2017, 16 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 6, 2018, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 30, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Apr. 11, 2019, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/687,384, dated Jan. 8, 2019, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/713,490, dated Mar. 20, 2019, 15 pages.;;Notice of Allowance received for U.S. Appl. No. 15/881,544, dated Jun. 26, 2019, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 15/881,544, dated Nov. 7, 2019, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Aug. 18, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated May 12, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Nov. 23, 2020, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Mar. 25, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/450,531 dated Sep. 25, 2020, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 16/584,776, dated Feb. 1, 2021, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/584,783, dated Dec. 20, 2021, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Jul. 26, 2021, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Mar. 18, 2021, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Feb. 7, 2022, 10 pages.;;Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Oct. 21, 2021, 11 pages.;;Office Action received for Australian Patent Application No. 2017201548, dated Feb. 26, 2018, 2 pages.;;Office Action received for Australian Patent Application No. 2017330212, dated Feb. 21, 2020, 2 pages.;;Office Action received for Australian Patent Application No. 2018214074, dated May 9, 2019, 2 pages.;;Office Action received for Australian Patent Application No. 2019100490, dated Jul. 26, 2019, 4 pages.;;Office Action received for Australian Patent Application No. 2019264623, dated Sep. 14, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2019266054, dated Aug. 23, 2021, 4 pages.;;Office Action received for Australian Patent Application No. 2019266054, dated Jun. 29, 2021, 3 pages.;;Office Action received for Australian Patent Application No. 2019271873, dated Oct. 5, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2020267310, dated Nov. 4, 2021, 2 pages.;;Office Action received for Australian Patent Application No. 2020294208, dated Dec. 17, 2021, 2 pages.;;Office Action received for Australian Patent Application No. 2017284958, dated Dec. 13, 2018, 3 pages.;;Office Action received for Canadian Patent Application No. 2,984,527 dated Sep. 11, 2018, 5 pages.;;Office Action received for Canadian Patent Application No. 2,984,527, dated Jul. 25, 2019, 4 pages.;;Office Action received for Chinese Patent Application No. 201811136445.7, dated Apr. 14, 2021, 7 pages.;;Office Action received for Chinese Patent Application No. 201811136445.7, dated Oct. 28, 2020, 17 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated May 7, 2020, 8 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated Sep. 4, 2019, 26 pages.;;Office Action received for Chinese Patent Application No. 201910315328.5, dated Nov. 30, 2021, 21 pages.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jan. 20, 2021, 19 pages.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jul. 3, 2020, 15 pages.;;Office Action received for Chinese Patent Application No. 201911199054.4, dated Jun. 10, 2021, 13 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 14, 2019, 7 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 23, 2018, 10 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Jan. 26, 2018, 8 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Mar. 1, 2019, 9 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 4, 2020, 7 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 7, 2018, 4 pages.;;Office Action received for Danish Patent Application No. PA201870385, dated Aug. 23, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201970535, dated May 20, 2020, 3 pages.;;Office Action received for Danish Patent Application No. PA201970535, dated Oct. 27, 2020, 6 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Nov. 10, 2015, 4 pages.;;Office Action received for European Patent Application No. 17813778.2, dated Nov. 26, 2020, 10 pages.;;Office Action received for European Patent Application No. 17853657.9, dated Apr. 1, 2021, 6 pages.;;Office Action received for European Patent Application No. 18197554.1, dated Jun. 15, 2020, 4 pages.;;Office Action received for European Patent Application No. 19212057.4, dated Mar. 9, 2021, 6 pages.;;Office Action received for European Patent Application No. 19724963.4, dated Jul. 28, 2020, 6 pages.;;Office Action received for Indian Patent Application No. 9044/CHENP/2014, dated Jan. 24, 2020, 6 pages.;;Office Action received for Japanese Patent Application No. 2014-259225, dated May 27, 2016, 4 pages.;;Office Action received for Japanese Patent Application No. 2015-129152, dated Sep. 23, 2016, 3 pages.;;Office Action received for Japanese Patent Application No. 2017-057997, dated Jan. 9, 2018, 6 pages.;;Office Action received for Japanese Patent Application No. 2017-132229, dated Mar. 16, 2018, 7 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated Apr. 9, 2021, 30 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated Jan. 27, 2020, 7 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated Jul. 26, 2021, 37 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated May 13, 2019, 10 pages.;;Office Action received for Japanese Patent Application No. 2019-123115, dated Aug. 31, 2020, 9 pages.;;Office Action received for Japanese Patent Application No. 2019-215503, dated Feb. 5, 2021, 12 pages.;;Office Action received for Japanese Patent Application No. 2019-215503, dated Jul. 3, 2020, 12 pages.;;Office Action received for Japanese Patent Application No. 2020-079486, dated Jul. 16, 2021, 10 pages.;;Office Action received for Korean Patent Application No. 10-2019-7005369, dated Mar. 13, 2020, 12 pages.;;Office Action received for Korean Patent Application No. 10-2019-7007053, dated Mar. 18, 2019, 12 pages.;;Office Action received for Korean Patent Application No. 10-2019-7007053, dated Sep. 26, 2019, 9 pages.;;Office Action received for Korean Patent Application No. 10-2021-7002582, dated Apr. 16, 2021, 13 pages.;;Office Action received for Korean Patent Application No. 10-2021-7002582, dated Oct. 29, 2021, 6 pages.;;Partial European Search Report received for European Patent Application No. 18197554.1, dated Jan. 22, 2019, 8 pages.;;Record of Oral Hearing received for U.S. Appl. No. 16/259,771, mailed on Aug. 4, 2021, 15 pages.;;Result of Consultation received for European Patent Application No. 17813778.2, mailed on Dec. 6, 2021, 17 pages.;;Result of Consultation received for European Patent Application No. 19724963.4, mailed on Jul. 8, 2021,3 pages.;;Result of Consultation received for European Patent Application No. 19724963.4, mailed on May 31, 2021, 3 pages.;;Search Report and opinion received for Danish Patent Application No. PA201670608, dated Jan. 3, 2017, 15 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201670609, dated Feb. 1, 2017, 11 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201870385, dated Nov. 16, 2018, 10 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201970535, dated Nov. 5, 2019, 10 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 19, 2018, 12 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 17813778.2, mailed on Aug. 13, 2021, 13 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Dec. 23, 2020, 8 pages.;;Summons to Oral Proceedings received for German Patent Application No. 112007000067.8, mailed on Dec. 8, 2021, 11 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/713,490, dated May 30, 2019, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/584,776, dated Feb. 18, 2021, 3 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/584,776, dated May 13, 2021, 4 pages.;;Decision to Grant received for the European Patent Application No. 07814633.9, dated Sep. 2, 2010, 3 pages.;;Intention to Grant received for the European Patent Application No. 07814633.9, dated Mar. 19, 2010, 4 pages.;;Office Action received for European Patent Application No. 07814633.9, dated Aug. 10, 2009, 3 pages.;;Decision to Grant received for the European Patent Application No. 10172417.7, dated Nov. 14, 2013, 3 pages.;;Intention to Grant received for European Patent Application No. 10172417.7, dated Jul. 9, 2013, 10 pages.;;Office Action received for European Patent Application No. 10172417.7, dated Oct. 31, 2011,6 pages.;;Summons to Attend Oral Proceeding received for European Patent Application No. 10172417.7, Jan. 28, 2013, 6 pages.;;Non-Final Office Action received for U.S. Appl. No. 11/848,210, dated Jun. 30, 2011, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 11/848,210, dated Dec. 20, 2011, 5 pages.;;Decision to Grant received for the European Patent Application No. 11178257.9, dated Jun. 20, 2013, 3 pages.;;Extended European Search Report received for European Patent Application No. 11178257.9, dated Oct. 31, 2011, 5 pages.;;Intention to Grant received for European Patent Application No. 11178257.9, dated Jan. 30, 2013, 9 pages.;;European Search Report received for the European Application No. 11178259.5, dated Oct. 31, 2011, 8 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Jan. 4, 2013, 8 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 11, 2015, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/789,441, dated Jan. 17, 2013, 24 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Dec. 6, 2013, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Aug. 20, 2013, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/361,912, dated Mar. 22, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 13/361,912, dated Jul. 2, 2012, 7 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/666,943, dated Oct. 26, 2015, 12 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 17, 2015, 7 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/253,783, dated Feb. 23, 2016, 18 pages.;;Notice of Allowance received for the Canadian Patent Application No. 2,853,273, dated Jan. 12, 2016, 1 page.;;Office Action received for Canadian Patent Application No. 2,853,273, dated Feb. 23, 2015, 5 pages.;;Board Opinion received for Chinese Reexamination Patent Application No. 200780001142.8, dated Oct. 21, 2014, 13 pages.;;Decision to Grant received for Japanese Patent Application No. 2009-526943, dated Dec. 2, 2011, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2011265412, dated Nov. 12, 2014, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2013-140171, dated May 29, 2015, 4 pages.;;Office Action received for Japanese Patent Application No. 2013-140171, dated Jul. 22, 2014, 4 pages.;;Office Action Received for Japanese Patent Application No. 2014-259225, dated Nov. 20, 2015, 2 pages.;;Office Action received for Australian Patent Application No. 2015201028, dated Mar. 15, 2016, 2 pages.;;Office action received for Indian Patent Application No. 2797CHENP2008, dated Jan. 29, 2014, 3 pages.;;Applivgames, “Super Mario Run” Stickers for iMessage: Free Delivery Started!, Available online at: <https://games.app-liv.jp/archives/178627>, Sep. 13, 2016, 3 pages.;;Chen et al., “Event Detection from Flickr Data through Wavelet-based Spatial Analysis”, Proceeding of the 18th ACM Conference on Information and Knowledge Management, CIKM, Jan. 1, 2009, pp. 523-532.;;Contents Pocket, “Line Stamp Information”, Available online at: <https://web.archive.org/web/20150404080541/http://contents-pocket.net/linestamp.html>, Apr. 2015, 2 pages.;;Cyr Jim, “Apple Watch—Customize Modular Watch Face”, available online at: https://www.youtube.com/watch?v=02W93HbKIK8, May 13, 2015, 2 pages.;;Das et al., “Event Classification in Personal Image Collections”, IEEE Intl. Workshop on Media Information Analysis for Personal and Social Applications at ICME, 2009, 2009, pp. 1660-1663.;;Das et al., “Event-based Location Matching for Consumer Image Collections”, CIVR, 2008, Proc. of the ACM Int. Conf, on Image and Video Retrieval, 2008, 5 pages.;;Gallagher et al., “Image Annotation Using Personal Calendars as Context”, ACM Intl. Conf. on Multimedia, 2008, 4 pages.;;Geek, “How to Put the Day of the Week into the Windows Taskbar Clock”, available online at: https://www.howtogeek.com/194103/how-to-put-the-day-of-the-week-into-the-windows-taskbar-clock/, 2014, 3 pages.;;Han et al., “Density-Based Methods”, Data Mining Concepts and Techniques, Elsevier, 2006, pp. 418-420.;;Hinckley et al., “Sensing Techniques for Mobile Interaction”, Symposium on User Interface Software and Technology, CHI Letters, vol. 2, No. 2, Nov. 2000, pp. 91-100.;;Jobs Steve, “iPhone Introduction in 2007 (Complete)”, available at <https://www.youtube.com/watch?v=9hUlxyE2Ns8>, Jan. 10, 2013, 3 pages.;;Karlson et al., “AppLens and LaunchTile: Two Designs for One-Handed Thumb Use on Small Devices”, CHI 2005, Papers: Small Devices 1, Apr. 2-7, 2005, pp. 201-210.;;Way to Use a Camera, JP, Nov. 18, 2005, pp. 206-212.;;Liao, T.W., “Clustering of Time Series Data-a Survey”, Pattern Recognition, vol. 38, 2005, pp. 1857-1874.;;Marwan et al., “Generalized Recurrence Plot Analysis for Spatial Data”, Physics Letters A, vol. 360, 2007, pp. 545-551.;;Mozilla Developer Network, “Mouse Gesture Events”, Available online at <https://developer.mozilla.org/en-us/docs/Web/Guide/Events/Mouse_gesture_events>, May 14, 2009, 3 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2007/077441, dated Mar. 10, 2009, 9 pages.;;International Search Report and Written Opinion, received for PCT Patent Application No. PCT/US2007/077441, dated May 8, 2008, 13 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2007/077441, dated Jan. 28, 2008, dated Jan. 28, 2008, 5 pages. et al.",ACTIVE
145,AU,A4,AU 2017/100670 A4,061-523-572-217-527,2017-07-06,2017,AU 2017/100670 A,2017-05-31,US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance. Ct fl -n LI C>",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOULANT BRENDAN J;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/061-523-572-217-527,Limited Patent,no,0,1,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0488,,0,0,,,,INACTIVE
146,AU,C4,AU 2017/100670 C4,129-630-654-058-717,2019-11-21,2019,AU 2017/100670 A,2017-05-31,US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOULANT BRENDAN J;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/129-630-654-058-717,Amended Patent,no,1,0,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0488,,0,0,,,,INACTIVE
147,AU,B4,AU 2017/100670 B4,162-124-042-376-76X,2017-09-14,2017,AU 2017/100670 A,2017-05-31,US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOULANT BRENDAN J;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/162-124-042-376-76X,Limited Patent,no,1,0,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0488,,0,0,,,,INACTIVE
148,US,A1,US 2023/0297206 A1,024-568-295-051-596,2023-09-21,2023,US 202318137353 A,2023-04-20,US 202318137353 A;;US 202217744499 A;;US 202017125744 A;;US 201816109487 A;;US 201615275294 A;;US 201662349109 P,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LANGOULANT BRENDAN J;;LEMAY STEPHEN O;;TITI JUSTIN S;;BUTCHER GARY IAN;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;WILSON CHRISTOPHER,,https://lens.org/024-568-295-051-596,Patent Application,yes,31,1,8,52,0,G06F3/0484;;G06F3/0488;;G06F16/44;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/435;;G06F16/44;;G06F16/583;;G06F2203/04105;;G06F3/04883;;G06F16/23;;G06F2203/04803;;G06F2203/04806;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/178;;G06F3/03547;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F2203/04105;;G06T1/0007;;G06T2200/24,G06F3/0354;;G06F3/0481;;G06F3/04817;;G06F3/04842;;G06F3/04883;;G06F3/04886;;G06F16/178;;G06F16/435;;G06F16/438;;G06F16/44,,0,0,,,,PENDING
149,US,A1,US 2016/0360116 A1,144-824-229-429-029,2016-12-08,2016,US 201514863432 A,2015-09-23,US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;MANZARI BEHKISH J;;MEZAK CHARLES A;;TITI JUSTIN S;;WILSON CHRISTOPHER I,APPLE INC (2016-01-20),https://lens.org/144-824-229-429-029,Patent Application,yes,0,216,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06V10/10;;G06V20/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
150,KR,A,KR 20180133531 A,006-021-791-493-471,2018-12-14,2018,KR 20187034875 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,정황상 관련있는 미디어 콘텐츠를 검색하기 위한 사용자 인터페이스들,"본 발명은, 일반적으로, 정황상 관련있는 미디어 콘텐츠를 검색 및 디스플레이하는 것에 관한 것이다. 일부 실시예들에서, 디바이스는 정황상 관련있는 미디어를 디스플레이하라는 요청을 수신하고, 이에 응답하여, 디바이스의 정황과 관련있는 미디어 아이템들의 컬렉션의 표현을 디스플레이한다. 일부 실시예들에서, 디바이스는 아이템들의 시퀀스의 시각적 미디어 아이템을 디스플레이하고, 스와이프 제스처를 수신한 것에 응답하여, 미디어 아이템에 대한 관련 콘텐츠를 포함하는 세부 사용자 인터페이스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 제1 세부 사용자 인터페이스를 디스플레이하는 동안, 선택 시, 개인들이 참석한 복수의 이벤트들에 대응하는 시각적 미디어의 디스플레이를 야기하는 제1 이벤트에 참석했던 것으로 식별된 복수의 개인들에 대응하는 어포던스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 사용자 입력에 응답하여, 시각적 미디어의 자동으로 생성된 컬렉션을 획득하고, 대응하는 어포던스를 디스플레이한다.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/006-021-791-493-471,Patent Application,no,3,2,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0488,,1,0,,,"Neil Hughes, Apple explores merging cloud content with locally stored media library, (2011. 02)",ACTIVE
151,AU,A1,AU 2017/284958 A1,036-165-087-954-984,2018-12-20,2018,AU 2017/284958 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually- relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/036-165-087-954-984,Patent Application,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F17/30,,0,0,,,,ACTIVE
152,AU,A1,AU 2021/201130 A1,085-861-807-933-863,2021-03-11,2021,AU 2021/201130 A,2021-02-22,AU 2021/201130 A;;AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/085-861-807-933-863,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
153,CN,A,CN 108133742 A,134-026-676-506-701,2018-06-08,2018,CN 201810105846 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;CN 201580037927 A,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) fordisplaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a secondtype based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representationof an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/134-026-676-506-701,Patent Application,no,6,5,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;G16H40/63,,0,0,,,,ACTIVE
154,US,A1,US 2018/0206766 A1,145-850-986-091-745,2018-07-26,2018,US 201815925652 A,2018-03-19,US 201815925652 A;;US 201514839922 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/145-850-986-091-745,Patent Application,yes,6,43,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30,,0,0,,,,ACTIVE
155,JP,A,JP 2020184364 A,005-307-807-090-819,2020-11-12,2020,JP 2020115940 A,2020-07-03,JP 2018014096 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"To provide devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and user interfaces (e.g., an activity indicator) for displaying the same.SOLUTION: A device provided herein determines whether a physical activity corresponds to a first type based on a first set of criteria, and whether a physical activity corresponds to a second type based on a second set of criteria. The device controls an inactivity timer that measures user's inactivity. The device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type of physical activity. The device displays a third visual representation of an attribute or amount of a third type of activity. The third visual representation corresponds to user's inactivity.SELECTED DRAWING: Figure 24",APPLE INC,JAY BLAHNIK;;GARY IAN BUTCHER;;KEVIN WILL CHEN;;DAVID CHANCE GRAHAM;;DANIEL S KEEN;;JUSTIN SHANE RUSHING;;SHORTLIDGE T ALLAN;;ANTON M DAVYDOV;;ALAN C DYE;;JONATHAN P IVE;;ZACHERY KENNEDY;;ZACHURY MINJACK;;DENNIS S PARK;;BRIAN SCHMITT,,https://lens.org/005-307-807-090-819,Patent Application,no,8,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F3/0482;;A63B69/00;;A63B71/06;;G16H20/30,,0,0,,,,ACTIVE
156,US,B2,US 11424018 B2,021-458-243-338-919,2022-08-23,2022,US 202117192161 A,2021-03-04,US 202117192161 A;;US 201815925652 A;;US 201514839922 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/021-458-243-338-919,Granted Patent,yes,628,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/103;;A61B5/11;;A63B24/00;;G06F3/048;;G06F3/04817;;G06F3/0482;;G16H20/40,,527,1,051-162-261-989-155,10.1371/journal.pone.0037062;;pmc3353905;;22615890,"Advisory Action received for U.S. Appl. No. 16/377,892, dated Apr. 9, 2021, 4 pages.;;Advisory Action received for U.S. Appl. No. 16/378,136, dated Apr. 12, 2021, 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Apr. 13, 2021, 4 pages.;;Notice of Acceptance received for Australian Patent Application No. 2021200787, dated Mar. 19, 2021, 3 pages.;;Office Action received for Japanese Patent Application No. 2018-184532, dated Mar. 1, 2021, 11 pages (6 pages of English Translation and 5 pages of Official Copy).;;Applicant-Initiated interview Summary received for U.S. Appl. No. 16/377,892, dated Mar. 26, 2021, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/378,136, dated Mar. 26, 2021, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/418,786, dated Mar. 30, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/820,383, dated Mar. 11, 2021, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,859, dated Feb. 26, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,874, dated Feb. 26, 2021, 4 pages.;;Decision on Appeal received for Korean Patent Application No. 10-2019-7025538, mailed on Feb. 24, 2021, 20 pages (4 pages of English Translation and 16 pages of Official Copy).;;Decision to Refuse received for European Patent Application No. 18154145.9, mailed on Feb. 17, 2021, 20 pages.;;Final Office Action received for U.S. Appl. No. 16/894,309, dated Feb. 24, 2021, 30 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 18154145.9, mailed on Feb. 12, 2021, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Feb. 12, 2021, 14 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/888,629, dated Mar. 31, 2021, 14 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017277971, vFeb. 17, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019250251, dated Feb. 18, 2021, 3 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7025538, dated Mar. 10, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/144,753, dated Feb. 10, 2021, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Feb. 9, 2021, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Mar. 12, 2021, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Mar. 30, 2021, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/820,383, dated Mar. 31, 2021, 11 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jan. 5, 2021, 16 pages (7 pages of English Translation and 9 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Feb. 1, 2021, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 202010606407.4, dated Jan. 27, 2021, 16 pages (7 pages of English Translation and 9 pages of Official Copy).;;Office Action received for European Patent Application No. 18727543.3, dated Mar. 26, 2021, 7 pages.;;Office Action received for Japanese Patent Application No. 2019-563407, dated Feb. 5, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2020-7026035, dated Feb. 19, 2021, 13 pages (6 pages of English Translation and 7 pages of Official Copy).;;Search Report and Opinion received for Danish Patent Application No. PA202070815, dated Mar. 16, 2021, 8 pages.;;CBS This Morning, “This smart mirror puts a personal trainer in your reflection”, Available on: https://www.youtube.com/watch?v=nSmTTZcpVGg, Oct. 13, 2018, 4 pages.;;Intention to Grant received for Danish Patent Application No. PA201570668, dated Mar. 27, 2017, 2 pages.;;Intention to Grant received for Danish Patent Application No. PA201670656, dated Jan. 18, 2021, 2 pages.;;Notice of Allowance received for Danish Patent Application No. PA201570666, dated Sep. 15, 2016, 1 page.;;Notice of Allowance received for Danish Patent Application No. PA201570668, dated Oct. 30, 2017, 2 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated Nov. 3, 2016, 8 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Jun. 27, 2016, 4 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Sep. 9, 2016, 3 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated Jul. 1, 2020, 4 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated Jun. 14, 2017, 3 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated May 2, 2019, 4 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated May 30, 2018, 5 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Jan. 25, 2018, 3 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Nov. 21, 2018, 4 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Oct. 25, 2019, 4 pages.;;Search report and opinion received for Danish Patent Application No. PA201770191, dated Jun. 30, 2017, 9 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Feb. 2, 2016, 9 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Apr. 8, 2016, 8 pages.;;Advisory Action received for U. S. U.S. Appl. No. 16/144,864, dated Jul. 29, 2019, 6 pages.;;Adeniyi Samuel, “How to connect a second PS4 controller to a PlayStation 4 console”, Online available on:—https://www.youtube.com/watch?v=mOZX_SrNISE, May 28, 2017, 2 pages.;;Advisory Action received for U.S. Appl. No. 14/732,773, dated Aug. 23, 2019, 6 pages.;;Advisory Action received for U.S. Appl. No. 14/732,773, dated Nov. 9, 2018, 6 pages.;;Advisory Action received for U.S. Appl. No. 14/839,922, dated Mar. 24, 2017, 4 pages.;;Advisory Action received for U.S. Appl. No. 16/144,849, dated Aug. 12, 2019, 5 pages.;;Advisory Action received for U.S. Appl. No. 16/144,864, dated Jul. 6, 2020, 6 pages.;;Allison Conor, “Working out with Fiit's wearable-powered boutique fitness classes”, Online available at:—<https://www.wareable.com/wearable-tech/filt-fitness-classes-review-3849>, May 14, 2018, 8 pages.;;Apple Inc., “iPhone User Guide For iOS 7.1 Software”, available online at <https://manuals.info.apple.com/MANUALS/1000/MA1681/en_US/iphone_ios7_user_guide.pdf>, Mar. 10, 2014, pp. 1-162.;;Apple, “iPhone User's Guide”, Available at <http://mesnotices.20minutes.fr/manuel-notice-mode-emploi/APPLE/IPHONE%2D%5FE#>, Retrieved on Mar. 27, 2008, Jun. 2007, 137 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated May 12, 2020, 5 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Oct. 26, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/627,069, dated Nov. 4, 2019, 6 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,735, dated Jun. 18, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,753, dated Jun. 18, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,849, dated Jan. 21, 2020, 6 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,864, dated Apr. 29, 2020, 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/894,309, dated Jan. 26, 2021, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/600,243, dated Nov. 1, 2019, 6 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Nov. 1, 2019, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/627,069, dated Jan. 22, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/627,069, dated Jul. 20, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/705,849, dated Feb. 14, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/705,849, dated Jun. 29, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/925,652, dated Nov. 3, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/138,809, dated Dec. 16, 2020, 7 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/138,809, dated Jun. 9, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/144,753, dated Nov. 4, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/144,864, dated Jun. 22, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/377,892, dated Oct. 13, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/378,136, dated Oct. 13, 2020, 4 pages.;;Bagala et al., “Evaluation of Accelerometer-Based Fall Detection Algorithms on Real-World Falls”, PloS ONE, vol. 7, No. 5, May 16, 2012, 9 pages.;;Board Decision received for Chinese Patent Application No. 201380081349.6, dated Nov. 23, 2020, 2 pages.;;Certificate of Examination received for Australian Patent Application No. 2018101855, dated Aug. 6, 2019, 2 pages.;;Certification of Examination received for Australian Patent Application No. 2018100158, dated Oct. 23, 2018, 2 pages.;;Cho H.S., Satisfactory Innovative Smart-watch.;;CNET, “Google Fit's automatic activity tracking is getting smarter on Android Wear”, Available online at: https://www.youtube.com/watch?v=IttzlCid_d8, May 18, 2016, 1 page.;;Codrington Simon, “Intuitive Scrolling Interfaces with CSS Scroll Snap Points”, Online Available at: https://www.sitepoint.com/intuitive-scrolling-interfaces-with-css-scroll-snap-points/, Dec. 8, 2015, 14 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Feb. 10, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Mar. 24, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Feb. 25, 2019, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Mar. 27, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Feb. 5, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Mar. 13, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Mar. 31, 2020, 5 pages.;;Cyclespeed Tours, “The Most Useful Data Fields to Display on Your Garmin”, Online Available at: https://www.youtube.com/watch?v=AN0Eo50yxdg, Nov. 16, 2016, 3 pages.;;DC Rainmaker, “Garmin Fenix3 New Auto Climb Functionality”, Available online at: https://www.youtube.com/watch?v=iuavOSNpVRc, Feb. 19, 2015, 1 page.;;Decision to Grant received for Danish Patent Application No. PA201870379, dated Jul. 5, 2019, 2 pages.;;Decision to Refuse received for European Patent Application No. 13811085.3, dated Sep. 11, 2018, 21 pages.;;Decision to Refuse received for European Patent Application No. 15771747.1, dated Aug. 10, 2018, 22 pages.;;Decision to Refuse received for European Patent Application No. 17810749.6, dated Jan. 29, 2021, 24 pages.;;DwProgressBar v2: Stepping and Events, davidwalsh.name/dwprogressbar-2-stepping-events-mootools-progress-bar, retrieved from the Wayback Machine, Aug. 31, 2008, 4 pages.;;European Search Report received for European Patent Application No. 20182116.2, dated Oct. 21, 2020, 4 pages.;;Evergreen et al., “Bar Chart”, Better Evaluation, Available Online at https://www.betterevaluation.org/en/evaluation-options/BarChart, Oct. 31, 2014, 8 pages.;;Extended European Search Report received for European Patent Application No. 16837432.0, dated Mar. 11, 2019, 10 pages.;;Extended European Search Report received for European Patent Application No. 18154145.9, dated Mar. 2, 2018, 8 pages.;;Extended European Search Report received for European Patent Application No. 20203526.7, dated Jan. 29, 2021, 13 pages.;;Final Office Action received for U.S. Appl. No. 12/205,847, dated Apr. 25, 2012, 42 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated May 19, 2017, 24 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 8, 2015, 20 pages.;;Final Office Action received for U.S. Appl. No. 14/732,773, dated Jul. 13, 2018, 48 pages.;;Final Office Action received for U.S. Appl. No. 14/732,773, dated Jun. 21, 2019, 32 pages.;;Final Office Action received for U.S. Appl. No. 14/839,922, dated Dec. 14, 2016, 22 pages.;;Final Office Action received for U.S. Appl. No. 15/608,848, dated Aug. 21, 2020, 15 pages.;;Final Office Action received for U.S. Appl. No. 15/608,848, dated Jun. 26, 2019, 27 pages.;;Final Office Action received for U.S. Appl. No. 15/627,069, dated Mar. 2, 2020, 22 pages.;;Final Office Action received for U.S. Appl. No. 15/627,069, dated Oct. 20, 2020, 25 pages.;;Final Office Action received for U.S. Appl. No. 15/705,849, dated May 1, 2020, 17 pages.;;Final Office Action received for U.S. Appl. No. 15/925,652, dated Aug. 1, 2019, 30 pages.;;Final Office Action received for U.S. Appl. No. 16/138,809, dated Aug. 27, 2020, 24 pages.;;Final Office Action received for U.S. Appl. No. 16/144,735, dated May 4, 2020, 12 pages.;;Final Office Action received for U.S. Appl. No. 16/144,753, dated Sep. 22, 2020, 9 pages.;;Final Office Action received for U.S. Appl. No. 16/144,849, dated Jun. 7, 2019, 29 pages.;;Final Office Action received for U.S. Appl. No. 16/144,864, dated May 17, 2019, 24 pages.;;Final Office Action received for U.S. Appl. No. 16/144,864, dated May 28, 2020, 29 pages.;;Final Office Action received for U.S. Appl. No. 16/377,892, vJan. 28, 2021, 11 pages.;;Final Office Action received for U.S. Appl. No. 16/378,136, dated Jan. 28, 2021, 9 pages.;;Final Office Action received for U.S. Appl. No. 16/418,786, dated Jan. 13, 2021, 14 pages.;;Fitbit App, Available online at: <http://web.archive.org/web/20180114083150/https://www.fitbit.com/au/app>, Jan. 14, 2018, 8 pages.;;Garmin, “Fenix 5x Owner's Manual”, Online Available at:—https://web.archive.org/web/20180127170640/https://static.garmin.com/pumac/fenix5x_OM_EN.pdf, Jan. 27, 2018, 42 pages.;;Graphs and Charts, Online available at: <https://www.teachervision.com/lesson-planning/graph-chart-teacher-resources, retrieved on Dec. 12, 2018, 4 pages.;;Hamilton Jim, “Peloton Tips”, Online available on:—<https://www.youtube.com/watch?app=desktop&v=OneXtB0kaD4>, Oct. 23, 2015, 3 pages.;;Intention to Grant received for Danish Patent Application No. PA201870379, dated May 2, 2019, 2 pages.;;International Preliminary Report on Patentability received for PCT Application No. PCT/US2016/037686, dated Mar. 1, 2018, 12 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 16, 2016, 10 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/032474, dated Dec. 15, 2016, 7 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/047282, dated Mar. 16, 2017, 26 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035554, dated Dec. 20, 2018, 39 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2018/031662, dated Nov. 28, 2019,12 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2019/024570, dated Nov. 19, 2020, 10 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/032474, dated Aug. 19, 2015, 8 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/047282, dated May 9, 2016, 33 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/037686, dated Sep. 9, 2016, 19 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2017/035554, dated Sep. 22, 2017, 42 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2018/031662, dated Sep. 27, 2018, 17 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024570, dated Aug. 8, 2019, 18 pages.;;International Search Report and written Opinion received for PCT Patent Application No. PCT/US2020/025997, dated Jul. 1, 2020, 16 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/025997, dated Jul. 14, 2020, 15 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/035199, dated Oct. 30, 2020, 20 pages.;;International Search Report received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 3 pages.;;International Written Opinion received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 8 pages.;;Invitation to Pay Addition Fees and Partial International Search Report received for PCT Patent Application No. PCT/US2018/031662, dated Jul. 16, 2018, 13 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2015/047282, dated Dec. 22, 2015, 7 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035554, dated Jul. 20, 2017, 2 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2020/035199, dated Sep. 8, 2020, 12 pages.;;Jenbsjourney, “Wondering About a Fitbit?”, Available at: https://jenbsjourney.blogspot.kr/2013/08/wondering-about-fitbit.html, Aug. 6, 2013, 12 pages.;;Kamijo Noboru, “Next Generation Mobile System—WatchPad1.5”, Available at <http://researcher.ibm.com/researcher/view_group_subpage.php?id=5617>, retrieved on Jul. 4, 2015, 2 pages.;;Minutes of Oral Proceedings received for European Patent Application No. 13811085.3, mailed on Sep. 11, 2018, 3 pages.;;Minutes of Oral Proceedings received for European Patent Application No. 15771747.1, mailed on Aug. 10, 2018, 11 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 17810749.6, mailed on Jan. 26, 2021, 8 pages.;;Mugs, Online Available at: https://web.archive.org/web/20151029034349/http://le-mugs.com/, Oct. 29, 2015, 14 pages.;;Multi-Set Bar Chart, The Data Visualization Catalogue, Available Online at: https://datavizcatalogue.com/methods/multiset_barchart.html, Feb. 8, 2014, 3 pages.;;My CalStep, http://www.surprisesoftware.com/mycalstep/, retrieved from the Wayback Machine, May 9, 2007, 2 pages.;;Non-Final Office Action Received for U.S. Appl. No. 16/144,864, dated Dec. 18, 2018, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/205,847, dated Oct. 3, 2011, 59 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/503,372, dated Dec. 5, 2014, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Mar. 17, 2015, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 26, 2016, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/732,773, dated Feb. 8, 2019, 32 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/732,773, dated Jan. 19, 2018, 45 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,916, dated Feb. 4, 2016, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,916, dated May 1, 2017, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,922, dated Aug. 17, 2016, 25 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,922, dated Feb. 25, 2016, 20 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/183,663, dated Jul. 9, 2018, 13 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/600,243, dated Jun. 27, 2019, 17 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Feb. 6, 2020, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Nov. 2, 2018, 21 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/627,069, dated Jun. 21, 2019, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/627,069, dated May 26, 2020, 25 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/705,849, dated Nov. 12, 2019, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/925,652, dated Apr. 5, 2019, 28 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/925,652, dated Aug. 7, 2020, 39 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/138,809, dated Feb. 28, 2020, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,735, dated Feb. 19, 2020, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,753, dated Mar. 5, 2020, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,849, dated Dec. 31, 2018, 28 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,849, dated Sep. 17, 2019, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,864, dated Jan. 31, 2020, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/377,892, dated May 21, 2020, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/378,136, dated Jun. 2, 2020, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/418,786, dated Apr. 24, 2020, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/820,383, dated Dec. 14, 2020, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/894,309, dated Oct. 15, 2020, 24 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,859, dated Dec. 15, 2020, 13 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,874, dated Dec. 28, 2020, 14 pages.;;Notice of Acceptance received for Australian Patent Application No. 2015312215, dated Oct. 9, 2017, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018268972, dated Dec. 18, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019201583, dated Jul. 15, 2019, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019222943, dated May 5, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020204153, dated Jul. 6, 2020, 3 pages.;;Notice of Allowance received for Chinese Patent Application No. 201520358505.5, dated Jan. 13, 2016, 3 pages.;;Notice of Allowance received for Chinese Patent Application No. 201580037927.5, dated Oct. 17, 2019, 3 pages.;;Notice of Allowance received for Chinese Patent Application No. 201710439448.7, dated Jan. 26, 2021, 2 pages.;;Notice of Allowance received for Chinese Patent Application No. 201810105846.X, dated Feb. 18, 2020, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2016-535045, dated Mar. 2, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2016-557650, dated Apr. 9, 2019, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-014096, dated Jan. 5, 2021, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-068846, dated Dec. 9, 2019, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2020-104679, dated Jan. 4, 2021, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7014577, dated May 30, 2019, 5 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7033638, dated May 31, 2017, 5 pages.;;Notice of Allowance received for Taiwanese Patent Application No. 104117509, dated Mar. 31, 2017, 3 pages.;;Notice of Allowance received for Taiwanese Patent Application No. 104128685, dated May 3, 2017, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 12/205,847, dated Aug. 20, 2012, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Dec. 18, 2019, 21 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Aug. 31, 2016, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Jan. 10, 2018, 19 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jan. 26, 2018, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jul. 6, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Nov. 2, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Jan. 17, 2019, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Dec. 12, 2019, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/616,480, dated Jan. 3, 2019, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/705,849, dated Jul. 28, 2020, 10 pages.;;Notice of Allowance received for U.S. Appl. No. 15/705,849, dated Oct. 16, 2020, 14 pages.;;Notice of Allowance received for U.S. Appl. No. 15/925,652, dated Mar. 9, 2021, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 15/925,652, dated Nov. 20, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,671, dated Feb. 10, 2020, 17 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,735, dated Jul. 21, 2020, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,735, dated Oct. 28, 2020, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,753, dated Dec. 4, 2020, 22 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Apr. 17, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Mar. 6, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Jul. 28, 2020, 27 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 10, 2020, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 16, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 29, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/556,023, dated Jan. 13, 2021, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/556,023, dated Oct. 15, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Feb. 10, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/588,950, dated May 5, 2020, 9 pages.;;Office Action received for Australian Patent Application No. 2015100734, dated Jul. 29, 2015, 5 pages.;;Office Action received for Australian Patent Application No. 2015267240, dated Apr. 10, 2017, 5 pages.;;Office Action received for Australian Patent Application No. 2015312215, dated Oct. 13, 2016, 3 pages.;;Office Action received for Australian Patent Application No. 2017100667, dated Aug. 3, 2017, 9 pages.;;Office Action received for Australian Patent Application No. 2017277971, dated Aug. 12, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2017277971, dated Jun. 3, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2018100158, dated Apr. 23, 2018, 5 pages.;;Office Action received for Australian Patent Application No. 2018101855, dated Feb. 22, 2019, 4 pages.;;Office Action received for Australian Patent Application No. 2018200428, dated Mar. 7, 2018, 4 pages.;;Office Action received for Australian Patent Application No. 2018200428, dated Nov. 15, 2018, 4 pages.;;Office Action received for Australian Patent Application No. 2018268972, dated Jul. 9, 2020, 4 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Mar. 6, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Mar. 16, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Sep. 17, 2019, 7 pages.;;Office Action received for Australian Patent Application No. 2019222943, dated Oct. 3, 2019, 3 pages.;;Office Action received for Australian Patent Application No. 2019250251, dated Aug. 6, 2020, 3 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Feb. 26, 2019, 12 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jan. 16, 2020, 11 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jul. 15, 2019, 10 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jul. 15, 2020, 9 pages.;;Office Action received for Chinese Patent Application No. 201580037927.5, dated Apr. 22, 2019, 9 pages.;;Office Action received for Chinese Patent Application No. 201580037927.5, dated Jul. 20, 2018, 21 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated ul. 1, 2020, 6 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Mar. 18, 2019, 18 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Nov. 28, 2019, 9 pages.;;Office Action received for Chinese Patent Application No. 201710439448.7, dated Mar. 27, 2020, 13 pages.;;Office Action received for Chinese Patent Application No. 201710439448.7, dated Oct. 10, 2020, 19 pages.;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Aug. 27, 2019, 12 pages.;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Feb. 25, 2019, 10 pages.;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Nov. 28, 2019, 9 pages.;;Office Action received for Chinese Patent Application No. 201910858933.7, dated Aug. 18, 2020, 14 pages.;;Office Action received for Danish Patent Application No. PA201770423, dated Jun. 12, 2018, 7 pages.;;Office Action received for Danish Patent Application No. PA201770423, dated Mar. 29, 2019, 6 pages.;;Office Action received for Danish Patent Application No. PA201870378, dated Feb. 25, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201870378, dated Jan. 6, 2020, 3 pages.;;Office Action received for Danish Patent Application No. PA201870379, dated Feb. 28, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Mar. 5, 2020, 2 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Mar. 27, 2019, 4 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Sep. 11, 2018, 9 pages.;;Office Action received for Danish Patent Application No. PA201970532, dated May 29, 2020, 3 pages.;;Office Action received for European Patent Application No. 13811085.3, dated Apr. 20, 2018, 15 pages.;;Office Action received for European Patent Application No. 15730890.9, dated Aug. 3, 2017, 4 pages.;;Office Action received for European Patent Application No. 16837432.0, dated Jan. 10, 2020, 7 pages.;;Office Action received for European Patent Application No. 16837432.0, dated Jan. 27, 2021, 7 pages.;;Office Action received for European Patent Application No. 17810749.6, dated Aug. 20, 2019, 9 pages.;;Office Action received for European Patent Application No. 18154145.9, dated Apr. 3, 2018, 6 pages.;;Office Action received for European Patent Application No. 19721883.7, dated Jan. 10, 2020, 4 pages.;;Office Action received for European Patent Application No. 19721883.7, dated May 28, 2020, 11 pages.;;Office Action received for European Patent Application No. 20182116.2, dated Nov. 6, 2020, 9 pages.;;Office Action received for European Patent Application No. 15771747.1, dated Oct. 31, 2017, 7 pages.;;Office Action received for German Patent Application No. 112015002326.7, dated Feb. 20, 2019, 7 pages.;;Office Action received for Japanese Patent Application No. 2016-535045, dated May 12, 2017, 10 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Apr. 13, 2018, 9 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Aug. 10, 2017, 10 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Nov. 9, 2018, 6 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated Aug. 28, 2020, 4 pages. et al.",ACTIVE
157,EP,A4,EP 3472731 A4,050-811-350-043-995,2020-02-12,2020,EP 17813778 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,,APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/050-811-350-043-995,Search Report,no,3,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/00;;G06F3/0354;;G06F3/0481;;G06F3/0484;;G06F3/0488;;G06F16/435;;G06F16/44;;G06F16/583,,1,0,,,See also references of WO 2017218194A1,DISCONTINUED
158,AU,A1,AU 2019/201583 A1,094-577-979-874-968,2019-03-28,2019,AU 2019/201583 A,2019-03-07,AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/094-577-979-874-968,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F17/00;;G16H20/30,,0,0,,,,ACTIVE
159,DK,A9,DK 201570666 A9,162-870-539-459-434,2020-08-31,2020,DK PA201570666 A,2015-10-16,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user’s physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user’s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user’s inactivity.",APPLE INC,KEVIN WILL CHEN;;GARY IAN BUTCHER;;ANTON M DAVYDOV;;DANIEL S KEEN;;ALLAN T SHORTLIDGE;;ZACHERY KENNEDY;;DENNIS S PARK;;ALAN C DYE;;JONATHAN P IVE;;BRIAN SCHMITT;;DAVID CHANCE GRAHAM;;JAY BLAHNIK;;JUSTIN SHANE RUSHING;;ZACHURY MINJACK,,https://lens.org/162-870-539-459-434,Unknown,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/103,,0,0,,,,ACTIVE
160,US,A1,US 2016/0058336 A1,197-806-517-943-739,2016-03-03,2016,US 201514839916 A,2015-08-28,US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,APPLE INC (2015-03-23),https://lens.org/197-806-517-943-739,Patent Application,yes,4,197,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30,,0,0,,,,ACTIVE
161,AU,B2,AU 2021/201130 B2,191-273-406-461-676,2022-04-07,2022,AU 2021/201130 A,2021-02-22,AU 2021/201130 A;;AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/191-273-406-461-676,Granted Patent,no,1,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F15/00;;G16H20/30,,0,0,,,,ACTIVE
162,KR,A,KR 20170003608 A,040-577-672-948-898,2017-01-09,2017,KR 20167033638 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"본 개시내용은 사용자의 신체적 활동(예컨대, 운동) 또는 비활동의 속성들을 모니터하기 위한 디바이스 및 프로세스, 및 그것들을 표시하기 위한 사용자 인터페이스(예컨대, 활동 표시자)에 관한 것이다. 일부 예들에서, 디바이스는 신체적 활동이 제1 세트의 기준에 기초하여 제1 유형에 대응하는지 여부, 및 신체적 활동이 제2 세트의 기준에 기초하여 제2 유형에 대응하는지 여부를 결정한다. 일부 예들에서, 디바이스는 사용자의 비활동을 측정하는 비활동 타이머를 제어한다. 일부 예들에서, 디바이스는 제1 유형의 신체적 활동의 속성 또는 양에 대한 제1 시각적 표현, 및 제2 유형의 속성 또는 양에 대한 제2 시각적 표현을 표시한다. 일부 예들에서, 디바이스는 제3 유형의 활동의 속성 또는 양에 대한 제3 시각적 표현을 표시한다. 일부 예들에서, 제3 시각적 표현은 사용자의 비활동에 대응한다.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/040-577-672-948-898,Patent Application,no,0,55,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/00;;A61B5/11;;G16H20/30,,0,0,,,,ACTIVE
163,CN,A,CN 111180039 A,048-307-512-601-933,2020-05-19,2020,CN 201911396744 A,2015-08-27,CN 201911396744 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) fordisplaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a secondtype based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representationof an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/048-307-512-601-933,Patent Application,no,11,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,0,0,,,,ACTIVE
164,DK,A1,DK 201570666 A1,154-448-710-521-899,2016-07-25,2016,DK PA201570666 A,2015-10-16,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user¿s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BUTCHER GARY IAN;;BLAHNIK JAY;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN;;SHORTLIDGE T ALLAN,,https://lens.org/154-448-710-521-899,Unknown,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/103,,0,0,,,,ACTIVE
165,US,A1,US 2021/0007632 A1,194-043-822-711-879,2021-01-14,2021,US 202017031859 A,2020-09-24,US 202017031859 A;;US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/194-043-822-711-879,Patent Application,yes,1,38,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30;;G16H20/40,,5,0,,,"Author: VenusiVenus Title: Nike Training Club Date: March 28, 2011 Pages: 1-6 (Year: 2011);;Author: Peter Heinrich Title: More Player Engagement Potential: GameCircle Now Rewards Player Experience across Games Date: April 11, 2014 Pages: 1-9 (Year: 2014);;Author: Ray Allen Title: Join the Nike Training Club and let your iPhone be your fitness instructor Date: April 19, 2011 Pages: 1-26 (Year: 2011);;Author: GPSCity Title: Garmin Connect Mobile App iOS Overview with GPS City Date: Feb 28, 2014 Pages: 1-9 (https://www.youtube.com/watch?v=rD-KPOJpmOA) (Year: 2014);;Author: GPSCity Title: Garmin Connect 2.0 Overview with GPS City (https://www.youtube.com/watch?v=EJ6U10y_8y0) Date: Feb 28, 2014 Pages: 1-7 (Year: 2014)",PENDING
166,CN,A,CN 111180040 A,050-014-188-951-474,2020-05-19,2020,CN 201911396876 A,2015-08-27,CN 201911396876 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The invention relates to a physical activity and workout monitor. The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first setof criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. Insome examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE ALLAN T;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/050-014-188-951-474,Patent Application,no,16,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,1,0,,,"史成城;谢丽蓉;张丹;: ""运动控制系统实验软件开发平台"", 实验技术与管理, no. 01",ACTIVE
167,EP,A1,EP 3472731 A1,124-691-142-047-317,2019-04-24,2019,EP 17813778 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,,APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/124-691-142-047-317,Patent Application,yes,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F17/30,,0,0,,,,DISCONTINUED
168,WO,A4,WO 2016/036582 A4,126-460-659-695-354,2016-09-01,2016,US 2015/0047282 W,2015-08-27,US 201462044990 P;;US 201562129828 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/126-460-659-695-354,Patent Application,yes,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,PENDING
169,AU,B2,AU 2015/312215 B2,141-716-556-478-55X,2017-10-19,2017,AU 2015/312215 A,2015-08-27,US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/141-716-556-478-55X,Granted Patent,no,2,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
170,AU,A1,AU 2022/201761 A1,147-318-385-528-341,2022-04-07,2022,AU 2022/201761 A,2022-03-15,AU 2022/201761 A;;AU 2021/201130 A;;AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/147-318-385-528-341,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/00;;G16H20/30,,0,0,,,,ACTIVE
171,US,A1,US 2016/0058337 A1,166-744-807-371-091,2016-03-03,2016,US 201514839922 A,2015-08-29,US 201514839922 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,APPLE INC (2015-03-23),https://lens.org/166-744-807-371-091,Patent Application,yes,2,186,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30,,0,0,,,,ACTIVE
172,AU,B2,AU 2019/271873 B2,162-544-403-876-083,2020-12-10,2020,AU 2019/271873 A,2019-11-25,AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/162-544-403-876-083,Granted Patent,no,2,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
173,US,B2,US 10073584 B2,122-073-217-045-869,2018-09-11,2018,US 201615275294 A,2016-09-23,US 201615275294 A;;US 201662349109 P,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC M G;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOULANT BRENDAN J;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,APPLE INC (2017-01-16),https://lens.org/122-073-217-045-869,Granted Patent,yes,261,13,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0481;;G06F3/0354;;G06F3/0484;;G06F3/0488;;G06F17/30;;G06T1/00,,83,4,027-954-411-824-598;;015-170-949-710-284;;052-835-691-615-436;;087-439-027-914-345,10.1145/1645953.1646021;;10.1145/1386352.1386397;;10.1145/1459359.1459458;;10.1145/1054972.1055001,"US 2002/0018582 A1, 02/2002, Hagiwara et al. (withdrawn);;Han, et al., “Data Mining Concepts and Techniques”, Elsevier, 2006, pp. 418-420.;;Chen, et al., “Event Detection from Flickr Data through Wavelet-based Spatial Analysis”, Proceeding of the 18th ACM Conference on Information and Knowledge Management, CIKM, 2009, pp. 523-532.;;Das, et al., “Event Classification in Personal Image Collections”, IEEE Intl. Workshop on Media Information Analysis for Personal and Social Applications at ICME, 2009, pp. 1660-1663.;;Das, et al., “Event-based Location Matching for Consumer Image Collections”, Proc. of the ACM Int. Conf. on Image and Video Retrieval, CIVR, 2008, 5 pages.;;Gallagher, et al., “Image Annotation Using Personal Calendars as Context”, ACM Intl. Conf. on Multimedia, 2008, 4 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/048169, dated Oct. 21, 2011, 11 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 3, 2017, 15 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Feb. 1, 2017, 11 pages.;;Advisory Action received for U.S. Appl. No. 14/253,783, dated Feb. 15, 2017, 6 Pages.;;Board Opinion received for Chinese Reexamination Patent Application No. 200780001142.8, dated Oct. 21, 2014, 19 pages (7 pages of English Translation and 12 pages of Official copy).;;Communication Regarding Intention to Grant received for the European Patent Application No. 07814633.9, dated Mar. 19, 2010, 4 pages.;;Cyr, Jim, “Apple Watch—Customize Modular Watch Face”, available online at: https://www.youtube.com/watch?v=02W93HbKIK8, May 13, 2015, 2 pages.;;Decision to Grant received for Japanese Patent Application No. 2009-526943, dated Dec. 2, 2011, 3 pages. (Official Copy only) (See Communication under 37 CFR § 1.98(a) (3)).;;Decision to Grant received for the European Patent Application No. 07814633.9, dated Sep. 2, 2010, 3 pages.;;Decision to Grant received for the European Patent Application No. 10172417.7, dated Nov. 14, 2013, 3 pages.;;Decision to Grant received for the European Patent Application No. 11178257.9, dated Jun. 20, 2013, 3 pages.;;European Search Report received for the European Patent Application No. 10172417.7, dated Jan. 7, 2011, 4 pages.;;European Search Report received for the European Application No. 11178259.5, dated Oct. 31, 2011, 8 pages.;;European Search Report received for the European Patent Application No. 11178257.9, dated Oct. 31, 2011, 5 pages.;;Final Office Action received for the U.S. Appl. No. 14/253,783, dated Sep. 30, 2016, 18 pages.;;Geek, “How to Put the Day of the Week into the Windows Taskbar Clock”, available online at: <https://www.howtogeek.com/194103/how-to-put-the-day-of-the-week-into-the-windows-taskbar-clock/>, 2014, 4 pages.;;Hinckley et al., “Sensing Techniques for Mobile Interaction”, Symposium on User Interface Software and Technology, CHI Letters, vol. 2, No. 2, Nov. 2000, pp. 91-100.;;Intention to Grant received for the European Patent Application No. 10172417.7, dated Jul. 9, 2013, 10 pages.;;Intention to Grant received for the European Patent Application No. 11178257.9, dated Jan. 30, 2013, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2007/077441, dated Mar. 10, 2009, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2011/020403, dated Jul. 19, 2012, 10 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/020403, dated May 26, 2011, 14 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/035090, dated Oct. 4, 2016, 17 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2007/077441, dated May 8, 2008, 13 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2007/077441, mailed on Jan. 28, 2008.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2016/035090, mailed on Jul. 15, 2016, 2 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035322, mailed on Aug. 7, 2017, 4 pages.;;Karlson et al., “AppLens and LaunchTile: Two Designs for One-Handed Thumb Use on Small Devices”, CHI 2005, Papers: Small Devices 1, Apr. 2-7, 2005, pp. 201-210.;;Kyocera WX300K, “Way to Use a Camera”, JP, Nov. 18, 2005, pp. 206-212. (Official Copy Only) (See Communication under 37 CFR § 1.98(a) (3)).;;Mozilla Developer Network, “Mouse Gesture Events”, Available online at <https://developer. mozilla.org/en-US/docs/Web/Guide/Events/Mouse_gesture_events>, May 14, 2009, 3 pages.;;Non Final Office Action received for U.S. Appl. No. 12/789,441, dated Jan. 17, 2013, 24 pages.;;Non Final Office Action received for U.S. Appl. No. 14/253,783, dated Feb. 23, 2016, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 11/848,210, dated Jun. 30, 2011, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/361,912, dated Mar. 22, 2012, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,889, dated Mar. 7, 2017, 26 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/666,943, dated Oct. 26, 2015, 12 Pages.;;Notice of Acceptance received for Australian Patent Application No. 2011265412, dated Nov. 12, 2014, 2 pages.;;Notice of Allowance received for Australian Patent Application No. 2015201028, dated Mar. 21, 2017, 3 pages.;;Notice of Allowance received for Canadian Patent Application No. 2,935,875, dated May 3, 2017, 1 page.;;Notice of Allowance received for Japanese Patent Application No. 2013-140171, dated May 29, 2015, 4 pages (Official Copy only) (See Communication under 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for Japanese Patent Application No. 2014-259225, dated Feb. 27, 2017, 3 pages (Official Copy Only) (See Communication under 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for Japanese Patent Application No. 2015-129152, dated May 8, 2017, 3 pages (Official Copy only) (See Communication under 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for the Canadian Patent Application No. 2,853,273, dated Jan. 12, 2016, 1 page.;;Notice of Allowance received for U.S. Appl. No. 11/848,210, dated Dec. 20, 2011, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Dec. 6, 2013, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 13/361,912, dated Jul. 2, 2012, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Aug. 11, 2016, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 2, 2016, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 17, 2015, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Apr. 14, 2017, 12 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Jul. 12, 2017, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Sep. 5, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Aug. 20, 2013, 9 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Jan. 4, 2013, 8 pages.;;Office Action received for Australian Patent Application No. 2015201028, dated Mar. 15, 2016, 2 pages.;;Office Action received for Canadian Patent Application No. 2,853,273, dated Feb. 23, 2015, 5 pages.;;Office Action received for European Patent Application No. 07814633.9, dated Aug. 10, 2009, 3 pages.;;Office Action received for European Patent Application No. 10172417.7, dated Oct. 31, 2011, 6 pages.;;Office Action received for European Patent Application No. 11178259.5, dated Nov. 10, 2015, 4 pages.;;Office Action received for Japanese Patent Application No. 2014-259225, dated Nov. 20, 2015, 2 pages (Official copy only). (See Communication under 37 CFR § 1.98(a) (3)).;;Office action received for Indian Patent Application No. 2797CHENP2008, dated Jan. 29, 2014, 3 pages.;;Summons to Attend Oral Proceeding received for European Patent Application No. 10172417.7, Jan. 28, 2013, 6 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 11, 2015, 9 pages.;;YouTube, Steve Jobs—Presenting the iPhone, Jan. 9, 2007, (iPhone Introduction in 2007), available at <https://www.youtube.com/watch?v=9hUlxyE2Ns8>, retrieved on Apr. 23, 2015, 3 pages.;;Office Action received for Japanese Patent Application No. 2017-132229, dated Mar. 16, 2018, 7 pages (3 pages of English Translation and 4 pages of Official Copy).;;International Search Report and Written Opinion Received for PCT Patent Application No. PCT/US2017/035322, dated Oct. 5, 2017, 18 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,889, dated Oct. 30, 2017, 16 pages.;;Office Action received for Danish Patent Application No. PA201670608, dated Jan. 23, 2018. 10 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated Jan. 26, 2018, 8 pages.;;Office Action received for Japanese Patent Application No. 2017-057997, dated Jan. 9, 2018, 6 pages (3 pages of English translation and 3 pages of official copy.;;Notice of Allowance received for Japanese Patent Application No. 2017-057997, dated Apr. 23, 2018, 4 pages (1 page of English Translation and 3 pages of Official copy).;;Office Action received for Danish Patent Application No. PA201670609, dated May 7, 2018, 4 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2016/035090, dated Dec. 14, 2017, 14 pages.;;International Search Report and Written Opinion received for PCT Application No. PCT/US2017/049795, dated Dec. 27, 2017, 26 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/049795, mailed on Nov. 3, 2017, 3 pages.;;Office Action received for Australian Patent Application No. 2017201548, dated Feb. 26, 2018, 2 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Feb. 19, 2018, 12 pages.",ACTIVE
174,EP,A2,EP 3129907 A2,152-978-639-471-969,2017-02-15,2017,EP 15771747 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,,APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,APPLE INC. (2018-08-01),https://lens.org/152-978-639-471-969,Patent Application,yes,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,DISCONTINUED
175,CN,A,CN 106537397 A,177-708-217-224-279,2017-03-22,2017,CN 201580037927 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/177-708-217-224-279,Patent Application,no,4,64,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
176,AU,A1,AU 2022/263576 A1,113-072-840-741-080,2022-12-08,2022,AU 2022/263576 A,2022-11-04,AU 2022/263576 A;;AU 2022/201561 A;;AU 2020/267310 A;;AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/113-072-840-741-080,Patent Application,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
177,US,A1,US 2021/0350900 A1,147-484-873-622-496,2021-11-11,2021,US 202117381570 A,2021-07-21,US 202117381570 A;;US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR WITH A PROGRESS INDICATOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/147-484-873-622-496,Patent Application,yes,6,19,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,1,0,,,"Author: GPS City Title: Garmin Connect 2.0 Overview with GPS City Date: Feb 28, 2014 Pages: 1-8 (Year: 2014)",ACTIVE
178,CN,A,CN 111035394 A,011-507-191-605-055,2020-04-21,2020,CN 201911401161 A,2015-08-27,CN 201911401161 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) fordisplaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a secondtype based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representationof an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/011-507-191-605-055,Patent Application,no,43,1,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30;;G16H20/40,,1,0,,,"张丽玉等: ""健身运动处方对大学生身体成分的影响"", 《中国临床康复》",ACTIVE
179,AU,A1,AU 2019/250251 A1,047-726-153-105-734,2019-11-07,2019,AU 2019/250251 A,2019-10-18,AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/047-726-153-105-734,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F17/00;;G16H20/30,,0,0,,,,ACTIVE
180,US,A1,US 2023/0013932 A1,126-442-315-691-350,2023-01-19,2023,US 202217952075 A,2022-09-23,US 202217952075 A;;US 202017031854 A;;US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/126-442-315-691-350,Patent Application,yes,11,8,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G06F3/04817;;G06F3/0482;;G16H20/40,,0,0,,,,PENDING
181,DK,B9,DK 178771 B9,119-701-881-106-312,2020-08-31,2020,DK PA201570666 A,2015-10-16,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Fysisk aktivitet og workoutmonitor,"The present disclosure relates to devices and processes for monitoring attributes of a user’s physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user’s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user’s inactivity.",APPLE INC,GARY IAN BUTCHER;;ANTON M DAVYDOV;;DANIEL S KEEN;;ALLAN T SHORTLIDGE;;ZACHERY KENNEDY;;DENNIS S PARK;;ALAN C DYE;;JONATHAN P IVE;;KEVIN WILL CHEN;;BRIAN SCHMITT;;DAVID CHANCE GRAHAM;;JAY BLAHNIK;;JUSTIN SHANE RUSHING;;ZACHURY MINJACK,,https://lens.org/119-701-881-106-312,Amended Patent,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,ACTIVE
182,CN,A,CN 111128339 A,137-162-800-778-276,2020-05-08,2020,CN 201911401375 A,2015-08-27,CN 201911401375 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Physical activity and fitness monitor,"The disclosure relates to physical activity and fitness monitor. The present disclosure relates to a device and process for monitoring an attribute of physical activity (e.g., fitness) or inactivity of a user, and to a user interface (e.g., an activity indicator) for displaying the attribute. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria and determines whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer for measuring inactivity of the user. In some examples, the device displays a first visual representation of an attribute or quantity of a first type of physical activity and a second visual representation of an attribute or quantity of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to inactivity of the user.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/137-162-800-778-276,Patent Application,no,13,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,0,0,,,,ACTIVE
183,CN,A,CN 117038008 A,171-389-145-062-421,2023-11-10,2023,CN 202310976891 A,2015-08-27,US 201562129828 P;;CN 201580037927 A;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and fitness monitor,"The present disclosure relates to a device and process for monitoring attributes of physical activity (e.g., fitness) or inactivity of a user, and to a user interface (e.g., an activity indicator) for displaying the attributes. In some examples, the device determines whether the physical activity corresponds to a first type based on a first set of criteria and determines whether the physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer for measuring inactivity of a user. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to an inactivity of the user.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;ALAN C DYE;;JONATHAN P IVE;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/171-389-145-062-421,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,0,0,,,,PENDING
184,WO,A3,WO 2016/036582 A3,050-314-435-054-100,2016-06-30,2016,US 2015/0047282 W,2015-08-27,US 201462044990 P;;US 201562129828 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/050-314-435-054-100,Search Report,yes,9,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,PENDING
185,EP,A1,EP 4064064 A1,004-176-891-214-840,2022-09-28,2022,EP 22164099 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;EP 17813778 A;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.
",APPLE INC,MUIRA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/004-176-891-214-840,Patent Application,yes,32,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/00;;G06F3/0354;;G06F3/0481;;G06F3/04817;;G06F3/0484;;G06F3/04842;;G06F3/0488;;G06F3/04883;;G06F3/04886;;G06F16/44,,0,0,,,,PENDING
186,US,B2,US 9974467 B2,026-345-015-492-747,2018-05-22,2018,US 201514839916 A,2015-08-28,US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,APPLE INC (2015-03-23),https://lens.org/026-345-015-492-747,Granted Patent,yes,111,22,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G06F3/048;;G16H20/30,,49,0,,,"“i Phone User Guide for iOS 7.1 Software”, available online at <https://manuals.info.apple.com/MANUALS/1000/MA1681/en_US/iphone_ios7_user_guide.pdf> retrieved on Aug. 10, 2015, 162 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, mailed on Oct. 8, 2015, 20 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, mailed on Mar. 17, 2015, 16 pages.;;Non Final Office Action received for U.S. Appl. No. 14/839,922, mailed on Feb. 25, 2016, 20 pages.;;Office Action received for Australian Patent Application No. 2015100734, issued on Jul. 29, 2015, 5 pages.;;Notice of Allowance received for Chinese Patent Application No. 201520358505.5, mailed on Jan. 13, 2016, 3 pages (2 pages of English Translation and 1 page of Official Copy).;;Kamijo, Noboru, “Next Generation Mobile System—WatchPad1.5”, available at <http://researcher.ibm.com/researcher/view_group_subpage.php?id=5617>, retrieved on Jul. 4, 2015, 2 pages.;;Office Action received for Danish Patent Application No. PA201570666, mailed on Feb. 2, 2016, 9 pages.;;International Search Report received for PCT Patent Application No. PCT/US2013/073195, mailed on Jun. 23, 2014, 3 pages.;;International Search Report and Written Opinion recieved for PCT Patent Application No. PCT/US2015/032474, mailed on Aug. 19, 2015, 8 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2015047282, mailed on Dec. 22, 2015, 7 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/047282, mailed on May 9, 2016, 33 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/503,372, mailed on Dec. 5, 2014, 11 pages.;;Office Action received for Danish Patent Application No. PA201570668, mailed on Apr. 8, 2016, 8 pages.;;Office Action received for Danish Patent Application No. PA201570666, mailed on Jun. 27, 2016, 4 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2013/073195, mailed on Jun. 7, 2016, 9 pages.;;Final Office Action received for U.S. Appl. No. 14/839,922, dated Dec. 14, 2016, 22 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/032474,dated Dec. 15, 2016, 7 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 26, 2016, 22 pages.;;Office Action received for Australian Patent Application No. 2015312215, dated Oct. 13, 2016, 3 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated Nov. 3, 2016, 8 pages.;;Office Action received for Korean Patent Application No. 10-2016-7033638, dated Jan. 31, 2017, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Taiwanese Patent Application No. 104128685, dated Jan. 4, 2017, 40 pages (15 pages of English Translation and 25 pages of Official Copy).;;Written Opinion received for PCT Patent Application No. PCT/U52013/073195, dated Jun. 23, 2014, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,922, dated Aug. 17, 2016, 25 pages.;;Notice of Allowance received for Danish Patent Application No. PA201570666, dated Sep. 15, 2016, 1 page.;;Office Action received for Danish Patent Application No. PA201570668, dated Sep. 9, 2016, 3 pages.;;Office Action received for Taiwanese Patent Application No. 104117509, dated Aug. 22, 2016, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for European Patent Application No. 15730890.9, dated Aug. 3, 2017, 4 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Aug. 10, 2017, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Notice of Acceptance received for Australian Patent Application No. 2015312215, dated Oct. 9, 2017, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Nov. 2, 2017, 8 pages.;;Office Action received for European Patent Application No. 15771747.1, dated Oct. 31, 2017, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jul. 6, 2017, 8 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated Jun. 14, 2017, 3 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201770191, dated Jun. 30, 2017, 9 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated May 19, 2017, 24 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7033638, dated May 31, 2017, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Taiwanese Patent Application No. 104117509, dated Mar. 31, 2017, 3 pages (Official Copy Only) (see attached 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for Taiwanese Patent Application No. 104128685, dated May 3, 2017, 3 pages (Official Copy Only) (see attached 37 CFR § 1.98(a) (3)).;;Office Action received for Australian Patent Application No. 2015267240, dated Apr. 10, 2017, 5 pages.;;Office Action received for Japanese Patent Application No. 2016535045, dated May 12, 2017, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Advisory Action received for U.S. Appl. No. 14/839,922, dated Mar. 24, 2017, 4 pages.;;Intention to Grant received for Danish Patent Application No. PA201570668, dated Mar. 27, 2017, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/047282, dated Mar. 16, 2017, 26 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/037686, dated Sep. 9, 2016, 19 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Jan. 25, 2018, 3 pages.;;Extended European Search Report received for European Patent Application No. 18154145.9, dated Mar. 2, 2018, 8 pages.;;Office Action received for Australian Patent Application No. 2018200428, dated Mar. 7, 2018, 4 pages.",ACTIVE
187,US,B2,US 11107567 B2,081-813-640-745-905,2021-08-31,2021,US 201715627069 A,2017-06-19,US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,Physical activity and workout monitor with a progress indicator,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/081-813-640-745-905,Granted Patent,yes,241,1,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/103;;A61B5/11;;A63B24/00;;G06F3/048;;G16H20/40,,186,1,051-162-261-989-155,10.1371/journal.pone.0037062;;pmc3353905;;22615890,"Office Action received for Australian Patent Application No. 2015267240, dated Mar. 21, 2018, 5 pages.;;Office Action received for Chinese Patent Application No. 201510284850.3, dated Nov. 28, 2017, 15 pages (5 pages of English Translation and 10 pages of Official Copy).;;Advisory Action received for U.S. Appl. No. 14/839,922, dated Mar. 24, 2017, 4 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated May 19, 2017, 24 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 8, 2015, 20 pages.;;Final Office Action received for U.S. Appl. No. 14/839,922, dated Dec. 14, 2016, 22 pages.;;Intention to Grant received for Danish Patent Application No. PA201570668, dated Mar. 27, 2017, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 7, 2016, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/047282, dated Mar. 16, 2017, 26 pages.;;International Preliminary Report on Patentability Received for PCT Patent Application No. PCTUS2015032474, dated Dec. 15, 2016, 7 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/032474, dated Aug. 19, 2015, 8 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/047282, dated May 9, 2016, 33 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/037686, dated Sep. 9, 2016, 19 pages.;;International Search Report received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 3 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2015047282, dated Dec. 22, 2015, 7 pages.;;“I Phone User Guide for iOS 7.1 Software”, available online at <https://manuals.info.apple.com/MANUALS/1000/MA1681/en_US/iphone_ios7_user_guide.pdf> retrieved on Aug. 10, 2015, 162 pages.;;Kamijo, Noboru, “Next Generation Mobile System—WatchPad1.5”, available at <http://researcher.ibm.com/researcher/view_group_subpage.php?id=5617>, retrieved on Jul. 4, 2015, 2 pages.;;Non Final Office Action received for U.S. Appl. No. 14/839,916, dated Feb. 4, 2016, 19 pages.;;Non Final Office Action received for U.S. Appl. No. 14/839,922, dated Feb. 25, 2016, 20 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/503,372, dated Dec. 5, 2014, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Mar. 17, 2015, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 26, 2016, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,916, dated May 1, 2017, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,922, dated Aug. 17, 2016, 25 pages.;;Notice of Allowance received for Chinese Patent Application No. 201520358505.5, dated Jan. 13, 2016, 3 pages.;;Notice of Allowance received for Danish Patent Application No. PA201570666, dated Sep. 15, 2016, 1 page.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7033638, dated May 31, 2017, 5 pages.;;Notice of Allowance received for Taiwanese Patent Application No. 104117509, dated Mar. 31, 2017, 3 pages.;;Notice of Allowance received for Taiwanese Patent Application No. 104128685, dated May 3, 2017, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Aug. 31, 2016, 11 pages.;;Office Action received for Australian Patent Application No. 2015100734, dated Jul. 29, 2015, 5 pages.;;Office Action received for Australian Patent Application No. 2015267240, dated Apr. 10, 2017, 5 pages.;;Office Action received for Australian Patent Application No. 2015312215, dated Oct. 13, 2016, 3 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated Nov. 3, 2016, 8 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Feb. 2, 2016, 9 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Jun. 27, 2016, 4 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Apr. 8, 2016, 8 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Sep. 9, 2016, 3 pages.;;Office Action received for Japanese Patent Application No. 2016535045, dated May 12, 2017, 10 pages.;;Office Action received for Korean Patent Application No. 10-2016-7033638, dated Jan. 31, 2017, 6 pages.;;Office Action received for Taiwanese Patent Application No. 104117509, dated Aug. 22, 2016, 6 pages.;;Office Action received for Taiwanese Patent Application No. 104128685, dated Jan. 4, 2017, 40 pages.;;Written Opinion received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 14/599,425, dated Dec. 19, 2018, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 14/599,424, dated Dec. 13, 2018, 6 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Nov. 21, 2018, 4 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated Nov. 6, 2018, 15 pages (7 pages of English Translation and 8 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2016-569945, dated Nov. 10, 2017, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Notice of Allowance received for Chinese Patent Application No. 201580028677.9, dated Apr. 2, 2019, 2 pages (1 pages of English Translation and 1 pages of Official Copy).;;Notice of Allowance received for Japanese Patent Application No. 2016-557650, dated Apr. 9, 2019, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Non-Final Office Action received for U.S. Appl. No. 15/925,652, dated Apr. 5, 2019, 28 pages.;;Office Action received for Australian Patent Application No. 2018206772, dated Apr. 1, 2019, 4 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Mar. 18, 2019, 18 pages (6 pages of English Translation and 12 pages of Official Copy).;;Office Action received for German Patent Application No. 112015002326.7, dated Feb. 20, 2019, 7 pages (2 pages of English Translation and 5 pages of Official Copy).;;Corrected Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Mar. 27, 2019, 2 pages.;;Extended European Search Report received for European Patent Application No. 16837432.0, dated Mar. 11, 2019, 10 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Feb. 26, 2019, 12 pages (6 pages of English Translation and 6 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Feb. 25, 2019, 10 pages (5 pages of English Translation and 5 pages of Official copy).;;Preliminary Opinion received for European Patent Application No. 15730890.9, dated Mar. 7, 2019, 4 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Feb. 25, 2019, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/732,773, dated Feb. 8, 2019, 32 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jul. 6, 2017, 8 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated Jun. 14, 2017, 3 pages.;;Search report and opinion received for Danish Patent Application No. PA201770191, dated Jun. 30, 2017, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jan. 26, 2018, 2 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Jan. 25, 2018, 3 pages.;;Summons to attend oral proceedings received for European Patent Application No. 13811085.3, dated Jan. 26, 2018, 14 pages.;;Extended European Search Report received for European Patent Application No. 18154145.9, dated Mar. 2, 2018, 8 pages.;;International Preliminary Report on Patentability received for PCT Application No. PCT/US2016/037686, dated Mar. 1, 2018, 12 pages.;;Notice of Allowance received for Japanese Patent Application No. 2016-535045, dated Mar. 2, 2018, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2018200428, dated Mar. 7, 2018, 4 pages.;;Decision to Refuse received for European Application No. 13811085.3, dated Sep. 11, 2018, 21 pages.;;Minutes of the Oral Proceedings received for European Application No. 13811085.3, mailed on Sep. 11, 2018, 3 pages.;;Office Action received for Chinese Patent Application No. 201510284850.3, dated Jul. 9, 2018, 11 pages (2 pages of English Translation and 9 pages of Official copy).;;Office Action received for Chinese Patent Application No. 201580037927.5, dated Jul. 20, 2018, 21 pages (6 pages of English Translation and 15 pages of Official copy).;;Summons to Attend Oral Proceedings received for European Patent Application No. 15730890.9, mailed on Sep. 10, 2018, 11 pages.;;Final Office Action received for U.S. Appl. No. 14/599,424, dated Jun. 28, 2018, 12 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated Jun. 12, 2018, 45 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated May 2, 2019, 4 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated May 30, 2018, 5 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Apr. 13, 2018, 9 pages (5 pages of English Translation and 4 pages of Official Copy).;;Summons to Attend Oral Proceedings received for European Patent Application No. 15771747.1, mailed on May 25, 2018, 17 pages.;;Final Office Action received for U.S. Appl. No. 14/732,773, dated Jul. 13, 2018, 48 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/183,663, dated Jul. 9, 2018, 13 pages.;;Office Action received for Chinese Patent Application No. 201580028677.9, dated May 25, 2018, 14 pages (6 pages of English Translation and 8 pages of Official copy).;;Office Action received for European Patent Application No. 15730890.9, dated Aug. 3, 2017, 4 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Aug. 10, 2017, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Advisory Action received for U.S. Appl. No. 14/732,773, dated Nov. 9, 2018, 6 pages.;;Office Action received for Australian Patent Application No. 2018200428, dated Nov. 15, 2018, 4 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Nov. 9, 2018, 6 pages (3 pages of English Translation and 3 pages of Official copy).;;Office Action received for Korean Patent Application No. 10-2016-7014577, dated Oct. 31, 2018, 11 pages (5 pages of English Translation and 6 pages of Official Copy).;;Cho, H. S., “Satisfactory Innovative Smart-watch (fitbit force) review after seven days of use, such as the amount of sleep and movement (improving sleep is the object of X-Blue)”, Online Available at: < https://x -blueuv.blogspotcom/2013/12/fitbit-force.html>, Dec. 3, 2013, 6 pages (Official Copy Only) (See Communication under 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for Danish Patent Application No. PA201570668, dated Oct. 30, 2017, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,424, dated Jan. 17, 2018, 13 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Jan. 11, 2018, 42 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/732,773, dated Jan. 19, 2018, 45 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Jan. 10, 2018, 19 pages.;;Office Action received for Korean Patent Application No. 10-2016-7014577, dated Dec. 26, 2017, 14 pages (6 pages of English Translation and 8 pages of Official Copy).;;“Utilization of Galaxy S4—S Health, ChatOn and Samsung Hub”, Available at: http://seeit.kr/1263, Jun. 12, 2013, 25 pages (Official Copy only) (see attached 37 CFR § 1.98(a) (3)).;;JENBSJOURNEY, “Wondering About a Fitbit?”,Available at: https://jenbsjourney.blogspot.kr/2013/08/wondering-about-fitbit.html, Aug. 6, 2013, 12 pages.;;Notice of Acceptance received for Australian Patent Application No. 2015312215, dated Oct. 9, 2017, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Nov. 2, 2017, 8 pages.;;Office Action received for European Patent Application No. 15771747.1, dated Oct. 31, 2017, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Jan. 17, 2019, 6 pages.;;Office Action received for Japanese Patent Application No. 2018-068846, dated Jan. 8, 2019, 6 pages (3 pages of English Translation and 3 pages of Official copy).;;Decision to Refuse received for European Patent Application No. 15771747.1, dated Aug. 10, 2018, 12 pages.;;Minutes of Oral proceedings received for European Patent Application No. 15771747.1, mailed on Aug. 10, 2018, 11 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated Jun. 29, 2018, 20 pages (11 pages of English Translation and 9 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2016-569945, dated Sep. 10, 2018, 11 pages (6 pages of English Translation and 5 pages of Official Copy).;;Notice of Acceptance received for Australian Patent Application No. 2015267240, dated Apr. 10, 2018, 3 pages.;;Office Action received for European Patent Application No. 13811085.3, dated Apr. 20, 2018, 15 pages.;;Office Action received for European Patent Application No. 18154145.9, dated Apr. 3, 2018, 6 pages.;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Nov. 28, 2019, 9 pages (5 pages of English Translation and 4 pages of Official Copy).;;Notice of Allowance received for Japanese Patent Application No. 2018-068846, dated Dec. 9, 2019, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Dec. 18, 2019, 21 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Nov. 28, 2019, 9 pages (4 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025781, dated Nov. 26, 2019, 10 pages (4 pages of English Translation and 6 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 15/925,652, dated Aug. 1, 2019, 30 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jul. 15, 2019, 10 pages (5 pages of English Translation and 5 pages of Official copy).;;Final Office Action received for U.S. Appl. No. 14/732,773, dated Jun. 21, 2019, 32 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7014577, dated May 30, 2019, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Advisory Action received for U.S. Appl. No. 14/732,773, dated Aug. 23, 2019, 6 pages.;;Office Action received for Japanese Patent Application No. 2016-569945, dated Jul. 29, 2019, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Chinese Patent Application No. 201580037927.5, dated Oct. 17, 2019, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201770191, dated Oct. 25, 2019, 4 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019201583, dated Jul. 15, 2019, 3 pages.;;Office Action received for Chinese Patent Application No. 201510284850.3, dated Jun. 21, 2019, 10 pages (4 pages of English Translation and 6 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201580037927.5, dated Apr. 22, 2019, 9 pages(4 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Aug. 27, 2019, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2018206772, dated Nov. 6, 2019, 4 pages.;;Extended European Search Report received for European Patent Application No. 19163212.4, dated Jun. 25, 2019, 11 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated May 8, 2019, 14 pages (7 pages of English Translation and 7 pages of Official Copy).;;Wikipedia, “Enhanced Multi-Level Precedence and Pre-emption Service”, Available online at: https://de.wikipedia.org/w/index.php?%20title=Enhanced%20Multi%E3%83%BCLevel_Precedence_And_Pre-emption_Service&oldid=123047429, Oct. 2013, 2 pages. (Official copy only) {See Communication under 37 CFR § 1.98(a) (3)}.;;Notice of Allowance received for Japanese Patent Application No. 2016-569945, dated Jan. 7, 2020, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Office Action received for European Patent Application No. 16837432.0, dated Jan. 10, 2020, 7 pages.;;Notice of Allowance received for Chinese Patent Application No. 201810105846.X, dated Feb. 18, 2020, 2 pages (1 page of English Translation and 1 page of Official Copy).;;Office Action received for Japanese Patent Application No. 2018-014096, dated Jan. 6, 2020, 17 pages (8 pages of English Translation and 9 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jul. 15, 2020, 9 pages (4 pages of English Translation and 5 pages of Official Copy).;;Result of Consultation received for European Patent Application No. 18154145.9, dated Sep. 4, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Feb. 10, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Mar. 24, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018206772, dated Mar. 17, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2018206772, dated Feb. 6, 2020, 4 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jan. 16, 2020, 11 pages (6 pages of English Translation and 5 pages of Official Copy).;;Office Action Received for Danish Patent Application No. PA201670656, dated Jul. 1, 2020, 4 pages.;;Office Action received for Japanese Patent Application No. 2019-044107, dated May 29, 2020, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Non-Final Office Action received for U.S. Appl. No. 15/925,652, dated Aug. 7, 2020, 39 pages.;;Office Action received for Australian Patent Application No. 2019250251, dated Aug. 6, 2020, 3 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Jul. 1, 2020, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2018-014096, dated Aug. 28, 2020, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Summons to Attend Oral Proceedings received for European Patent Application No. 18154145.9, dated Sep. 17, 2020, 11 pages.;;Result of Consultation received for European Patent Application No. 18154145.9, dated Nov. 30, 2020, 17 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,859, dated Feb. 26, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,874, dated Feb. 26, 2021, 4 pages.;;Decision to Refuse received for European Patent Application No. 18154145.9, dated Feb. 17, 2021, 20 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 18154145.9, dated Feb. 12, 2021, 8 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jan. 5, 2021, 16 pages (7 pages of English Translation and 9 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Feb. 1, 2021, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/925,652, dated Feb. 17, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019250251, dated Feb. 18, 2021, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 15/925,652, dated Mar. 9, 2021, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/192,161, dated May 13, 2021, 28 pages.;;Notice of Allowance received for Chinese Patent Application No. 201680047983.1, dated Apr. 28, 2021, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Summons to Oral Proceedings received for European Patent Application No. 15771747.1, mailed on Apr. 29, 2021, 8 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/925,652, dated Nov. 3, 2020, 4 pages.;;Bagala et al., “Evaluation of Accelerometer-Based Fall Detection Algorithms on Real-World Falls”, PloS One, vol. 7, No. 5, May 16, 2012, 9 pages.;;Board Decision received for Chinese Patent Application No. 201380081349.6, dated Nov. 23, 2020, 2 pages (1 page of English Translation and 1 page of Official Copy).;;Intention to Grant received for Danish Patent Application No. PA201670656, dated Jan. 18, 2021, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,859, dated Dec. 15, 2020, 13 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,874, dated Dec. 28, 2020, 14 pages.;;Notice of Allowance received for U.S. Appl. No. 15/925,652, Nov. 20, 2020, 9 pages.;;Office Action received for Australian Patent Application No. 2020204259, dated Nov. 30, 2020, 8 pages.;;Office Action received for European Patent Application No. 16837432.0, dated Jan. 27, 2021, 7 pages.;;Office Action received for European Patent Application No. 19163212.4, dated Oct. 12, 2020, 4 pages.;;Office Action received for Japanese Patent Application No. 2020-000492, dated Dec. 11, 2020, 6 pages (3 pages English Translation and 3 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-010239, dated Jan. 4, 2021, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025781, dated Oct. 30, 2020, 10 pages (4 pages of English Translation and 6 pages of Official Copy).;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/925,652, dated Jan. 6, 2021, 3 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/925,652, dated Jan. 26, 2021, 3 pages.;;Final Office Action received for U.S. Appl. No. 17/031,859, dated Apr. 16, 2021, 14 pages.;;Final Office Action received for U.S. Appl. No. 17/031,874, dated Apr. 16, 2021, 17 pages.;;Office Action received for Danish Patent Application No. PA202170113, dated Apr. 15, 2021, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-014096, dated Jan. 5, 2021, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Decision to Grant received for Danish Patent Application No. PA201670656, dated Jun. 21, 2021, 2 pages.;;Decision to Grant received for German Patent Application No. 112015002326.7, dated Jun. 15, 2021, 10 pages (1 page of English Translation and 9 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-115940, dated May 7, 2021, 3 pages (1 page of English Translation and 2 pages of Official Copy).",ACTIVE
188,DK,B1,DK 178771 B1,148-037-264-616-025,2017-01-09,2017,DK PA201570666 A,2015-10-16,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Fysisk aktivitet og workoutmonitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user´s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BUTCHER GARY IAN;;BLAHNIK JAY;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN;;SHORTLIDGE T ALLAN,,https://lens.org/148-037-264-616-025,Granted Patent,no,7,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,ACTIVE
189,AU,A1,AU 2023/237090 A1,187-201-862-224-300,2023-10-12,2023,AU 2023/237090 A,2023-09-27,AU 2023/237090 A;;AU 2022/201761 A;;AU 2021/201130 A;;AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 2015/0047282 W;;US 201462044990 P,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/187-201-862-224-300,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,,,0,0,,,,PENDING
190,US,A1,US 2021/0007633 A1,082-058-574-201-730,2021-01-14,2021,US 202017031874 A,2020-09-24,US 202017031874 A;;US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/082-058-574-201-730,Patent Application,yes,3,28,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30;;G16H20/40,,1,0,,,"Author: AndroidAndyUK Title: Endomondo Android App Review Date: Jan 9, 2013 Pages: 1-17 (Year: 2013)",DISCONTINUED
191,US,B2,US 11798672 B2,109-630-998-400-664,2023-10-24,2023,US 202117381570 A,2021-07-21,US 202117381570 A;;US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,Physical activity and workout monitor with a progress indicator,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/109-630-998-400-664,Granted Patent,yes,883,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G06F3/048;;G06F3/04817;;G06F3/0482;;G16H20/40,,794,1,051-162-261-989-155,10.1371/journal.pone.0037062;;pmc3353905;;22615890,"Author: GPS City Title: Garmin Connect 2.0 Overview with GPS City Date: Feb. 28, 2014 pp. 1-8 (Year: 2014).;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/192, 161, dated Dec. 24, 2021, 4 pages.;;Decision of Appeal received for European Patent Application No. 15771747.1, T.Dec. 14, 2021, 21 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2020/035199, dated Dec. 16, 2021, 14 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,859, dated Dec. 24, 2021, 16 pages.;;Notice of Allowance received for Chinese Patent Application No. 201380081349.6, dated Dec. 17, 2021, 2 pages (1 page of English Translation and 1 page of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2021-7038005, dated Dec. 14, 2021, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 202010606407.4, dated Nov. 18, 2021, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 202110363565.6, dated Nov. 16, 2021, 16 pages (9 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Indian Patent Application No. 202014041571, dated Dec. 17, 2021, 5 pages.;;Office Action received for Japanese Patent Application No. 2020-160052, dated Dec. 17, 2021, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Search Report and Opinion received for Danish Patent Application No. PA202170113, dated Nov. 30, 2021, 9 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 20182116.2, dated Dec. 21, 2021, 7 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/894,309, dated Dec. 24, 2021, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2020/025997, dated Nov. 18, 2021, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/987,275, dated Nov. 23, 2021, 17 pages.;;Notice of Allowance received for U.S. Appl. No. 16/888,629, dated Nov. 9, 2021, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 16/894,309, dated Nov. 5, 2021, 12 pages.;;Office Action received for Danish Patent Application No. PA202070615, dated Nov. 16, 2021, 4 pages.;;Office Action received for European Patent Application No. 20721342.2, dated Nov. 4, 2021, 9 pages.;;Final Office Action received for U.S. Appl. No. 16/994,352, dated Dec. 6, 2021, 14 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 15771747.1, dated Dec. 1, 2021, 4 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/157,728, dated Nov. 26, 2021, 18 pages.;;Notice of Allowance received for U.S. Appl. No. 16/418,786, dated Dec. 9, 2021, 9 pages.;;Office Action received for European Patent Application No. 20203526.7, dated Nov. 23, 2021, 9 pages.;;Adeniyi Samuel, “How to connect a second PS4 controller to a PlayStation 4 console”, Online available on: https://www.youtube.com/watch?v=mOZX_SrNISE, May 28, 2017, 2 pages.;;Advisory Action received for U.S. Appl. No. 16/144,864, dated Jul. 29, 2019, 6 pages.;;Advisory Action received for U.S. Appl. No. 16/144,849, dated Aug. 12, 2019, 5 pages.;;Advisory Action received for U.S. Appl. No. 16/144,864, dated Jul. 6, 2020, 6 pages.;;Advisory Action received for U.S. Appl. No. 16/377,892, dated Apr. 9, 2021, 4 pages.;;Advisory Action received for U.S. Appl. No. 16/378,136, dated Apr. 12, 2021, 4 pages.;;Allison Conor, “Working out with Fiit's wearable-powered boutique fitness classes”, Online available at: https://www.wareable.com/wearable-tech/fiit-fitness-classes-review-3849, May 14, 2018, 8 pages.;;Apple, “iPhone User's Guide”, Available at: http://mesnotices.20minutes.fr/manuel-notice-mode-emploi/APPLE/IPHONE%2D%5FE#, Retrieved on Mar. 27, 2008, Jun. 2007, 137 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Apr. 13, 2021 , 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated May 12, 2020, 5 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Oct. 26, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,735, dated Jun. 18, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,753, dated Jun. 18, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,849, dated Jan. 21, 2020, 6 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,864, dated Apr. 29, 2020, 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/894,309, dated Jan. 26, 2021, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/600,243, dated Nov. 1, 2019, 6 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Nov. 1, 2019, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/705,849, dated Feb. 14, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/705,849, dated Jun. 29, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/138,809, dated Dec. 16, 2020, 7 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/138,809, dated Jun. 9, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/144,753, dated Nov. 4, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/144,864, dated Jun. 22, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/377,892, dated Mar. 26, 2021, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/377,892, dated Oct. 13, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/378,136, dated Mar. 26, 2021, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/378,136, dated Oct. 13, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/418,786, dated Mar. 30, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/820,383, dated Mar. 11, 2021, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/888,629, dated Aug. 4, 2021, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/894,309, dated Jun. 25, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,859, dated Jun. 30, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,874, dated Jun. 30, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/192,161, dated Jun. 29, 2021, 4 pages.;;Board Opinion received for Chinese Patent Application No. 201510284850.3, dated Jul. 2, 2021, 13 pages (3 pages of English Translation and 10 pages of Official Copy).;;CBS This Morning, “This smart mirror puts a personal trainer in your reflection”, Available on: https://www.youtube.com/watch?v=nSmTTZcpVGg, Oct. 13, 2018, 4 pages.;;Certificate of Examination received for Australian Patent Application No. 2018101855, dated Aug. 6, 2019, 2 pages.;;Certification of Examination received for Australian Patent Application No. 2018100158, datetd Oct. 23, 2018, 2 pages.;;CNET, “Google Fit's automatic activity tracking is getting smarter on Android Wear”, Available online at: https://www.youtube.com/watch?v=IttzlCid_d8, May 18, 2016, 1 pages.;;Codrington Simon, “Intuitive Scrolling Interfaces with CSS Scroll Snap Points”, Online Available at: https://www.sitepoint.com/intuitive-scrolling-interfaces-with-css-scroll-snap-points/, Dec. 8, 2015, 14 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Feb. 5, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Mar. 13, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Mar. 31, 2020, 5 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/377,892, dated Aug. 11, 2021, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/378,136, dated Aug. 11, 2021, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/378,136, dated Jun. 11, 2021, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/820,383, dated Aug. 13, 2021, 2 pages.;;Cyclespeed Tours, “The Most Useful Data Fields to Display on Your Garmin”, Online Available at: https://www.youtube.com/watch?v=AN0Eo50yxdg, Nov. 16, 2016, 3 pages.;;DC Rainmaker, “Garmin Fenix3 New Auto Climb Functionality”, Available online at: https://www.youtube.com/watch?v=ivavOSNpVRc, Feb. 19, 2015, 1 page.;;Decision on Appeal received for Korean Patent Application No. 10-2019-7025538, dated Feb. 24, 2021, 20 pages. (4 pages. f English Translation and 16 pages of Official Copy).;;Decision to Grant received for Danish Patent Application No. PA201870379, dated Jul. 5, 2019, 2 pages.;;Decision to Refuse received for European Patent Application No. 17810749.6, dated Jan. 29, 2021, 24 pages.;;DwProgressBar v2: Stepping and Events, davidwalsh.name/dwprogressbar-2-stepping-events-mootools-progress-bar, retrieved from the way back Machine, Aug. 31, 2008, 4 pages.;;European Search Report received for European Patent Application No. 20182116.2, dated Oct. 21, 2020, 4 pages.;;European Search Report received for European Patent Application No. 21165295.3, dated Jun. 18, 2021, 4 pages.;;European Search Report received for European Patent Application No. 21168916.1, dated Jul. 14, 2021, 5 pages.;;Evergreen et al., “Bar Chart”, Better Evaluation, Available Online at: https://www.betterevaluation.org/en/evaluation-options/BarChart, Oct. 31, 2014, 8 pages.;;Extended European Search Report received for European Patent Application No. 20203526.7, dated Jan. 29, 2021, 13 pages.;;Final Office Action received for U.S. Appl. No. 12/205,847, dated Apr. 25, 2012, 42 pages.;;Final Office Action received for U.S. Appl. No. 15/608,848, dated Aug. 21, 2020, 15 pages.;;Final Office Action received for U.S. Appl. No. 15/608,848, dated Jun. 26, 2019, 27 pages.;;Final Office Action received for U.S. Appl. No. 15/705,849, dated May 1, 2020, 17 pages.;;Final Office Action received for U.S. Appl. No. 16/138,809, dated Aug. 27, 2020, 24 pages.;;Final Office Action received for U.S. Appl. No. 16/144,735, dated May 4, 2020, 12 pages.;;Final Office Action received for U.S. Appl. No. 16/144,753, dated Sep. 22, 2020, 9 pages.;;Final Office Action received for U.S. Appl. No. 16/144,849, dated Jun. 7, 2019, 29 pages.;;Final Office Action received for U.S. Appl. No. 16/144,864, dated May 17, 2019, 24 pages.;;Final Office Action received for U.S. Appl. No. 16/144,864, dated May 28, 2020, 29 pages.;;Final Office Action received for U.S. Appl. No. 16/377,892, dated Jan. 28, 2021, 11 pages.;;Final Office Action received for U.S. Appl. No. 16/378,136, dated Jan. 28, 2021, 9 pages.;;Final Office Action received for U.S. Appl. No. 16/418,786, dated Jan. 13, 2021, 14 pages.;;Final Office Action received for U.S. Appl. No. 16/894,309, dated Feb. 24, 2021, 30 pages.;;Final Office Action received for U.S. Appl. No. 17/192,161, dated Aug. 16, 2021, 22 pages.;;Fitbit App, Available online at: http://web.archive.org/web/20180114083150/https://www.fitbit.com/au/app, Jan. 14, 2018, 8 pages.;;Garmin, “Fenix 5x Owner's Manual”, Online Available at: https://web.archive.org/web/20180127170640/https://static.garmin.com/pumac/fenix5x_OM_EN.pdf, Jan. 27, 2018, 42 pages.;;Graphs and Charts, Online available at: https://www.teachervision.com/lesson-planning/graph-chart-teacher-resources, retrieved on Dec. 12, 2018, 4 pages.;;Hamilton Jim, “Peloton Tips”, Online available: https://www.youtube.com/watch?app=desktop&v=OneXtBOkaD4, Oct. 22, 2015, 3 pages.;;Intention to Grant received for Danish Patent Application No. PA201870379, dated May 2, 2019, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035554, dated Dec. 20, 2018, 39 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2018/031662, dated Nov. 28, 2019, 12 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2019/024570, dated Nov. 19, 2020, 10 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2017/035554, dated Sep. 22, 2017, 42 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2018/031662, dated Sep. 27, 2018, 17 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024570, dated Aug. 8, 2019, 18 pages.;;International Search Report and written Opinion received for PCT Patent Application No. PCT/US2020/025997, dated Jul. 1, 2020, 16 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/025997, dated Jul. 14, 2020, 15 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/035199, dated Oct. 30, 2020, 20 pages.;;Invitation to Pay Addition Fees and Partial International Search Report received for PCT Patent Application No. PCT/US2018/031662, dated Jul. 16, 2018, 13 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035554, dated Jul. 20, 2017, 2 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2020/035199, dated Sep. 8, 2020, 12 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 17810749.6, dated Jan. 26, 2021, 8 pages.;;Mugs, Online Available at: https://web.archive.org/web/20151029034349/http://le-mugs.com/, Oct. 29, 2015, 14 pages.;;Multi-Set Bar Chart, The Data Visualization Catalogue, Available Online at: https://datavizcatalogue.com/methods/multiset_barchart.html, Feb. 8, 2014, 3 pages.;;My Calstep, http://www.surprisesoftware.com/mycalstept, retrieved from the wayback Machine, May 9, 2007, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/994,352, dated Jul. 30, 2021, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/205,847, dated Oct. 3, 2011, 59 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/600,243, dated Jun. 27, 2019, 17 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Feb. 6, 2020, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Feb. 12, 2021, 14 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Nov. 2, 2018, 21 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/705,849, dated Nov. 12, 2019, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/138,809, dated Feb. 28, 2020, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,735, dated Feb. 19, 2020, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,753, dated Mar. 5, 2020, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,849, dated Dec. 31, 2018, 28 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,849, dated Sep. 17, 2019, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,864, dated Dec. 18, 2018, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,864, dated Jan. 31, 2020, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/377,892, dated May 21, 2020, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/378,136, dated Jun. 2, 2020, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/418,786, dated Apr. 24, 2020, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/820,383, dated Dec. 14, 2020, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/888,629, dated Mar. 31, 2021, 14 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/894,309, dated Oct. 15, 2020, 24 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017277971, dated Feb. 17, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018268972, dated Dec. 18, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019222943, dated May 5, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020204153, dated Jul. 6, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020256383, dated Aug. 3, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2021200787, dated Mar. 19, 2021, 3 pages.;;Notice of Allowance received for Chinese Patent Application No. 201710439448.7, dated Jan. 26, 2021, 2 pages. (1 page of English Translation and 1 page of Official Copy).;;Notice of Allowance received for Japanese Patent Application No. 2019-162293, dated Apr. 9, 2021, 4 pages. (1 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Japanese Patent Application No. 2020-000492, dated Jul. 16, 2021, 4 pages. (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Japanese Patent Application No. 2020-104679, dated Jan. 4, 2021, 4 pages. (1 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2019-7025538, dated Mar. 10, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2019-7025781, dated Jun. 29, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2019-7033834, dated Jul. 3, 2021, 4 pages (2 page of English Translation and 2 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 12/205,847, dated Aug. 20, 2012, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Dec. 12, 2019, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/616,480, dated Jan. 3, 2019, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/705,849, dated Jul. 28, 2020, 10 pages.;;Notice of Allowance received for U.S. Appl. No. 15/705,849, dated Oct. 16, 2020, 14 pages.;;Notice of Allowance received for U.S. Appl. No. 16/138,809, dated Apr. 16, 2021, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 16/138,809, dated Jul. 20, 2021, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,671, dated Feb. 10, 2020, 17 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,735, dated Jul. 21, 2020, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,735, dated Oct. 28, 2020, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,753, dated Dec. 4, 2020, 22 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,753, dated Feb. 10, 2021, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Apr. 17, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Mar. 6, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Feb. 9, 2021, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Jul. 28, 2020, 27 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Mar. 12, 2021, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Mar. 30, 2021, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 10, 2020, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 16, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 29, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/377,892, dated May 24, 2021, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/378,136, dated Jun. 3, 2021, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 16/556,023, dated Jan. 13, 2021, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/556,023, dated Oct. 15, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Feb. 10, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/588,950, dated May 5, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/820,383, dated Jul. 21, 2021, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 16/820,383, dated Mar. 31, 2021, 11 pages.;;Office Action received for Australian Patent Application No. 2017100667, dated Aug. 3, 2017, 9 pages.;;Office Action received for Australian Patent Application No. 2017277971, dated Aug. 12, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2017277971, dated Jun. 3, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2018100158, dated Apr. 23, 2018, 5 pages.;;Office Action received for Australian Patent Application No. 2018101855, dated Feb. 22, 2019, 4 pages.;;Office Action received for Australian Patent Application No. 2018268972, dated Jul. 9, 2020, 4 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Mar. 6, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Mar. 16, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Sep. 17, 2019, 7 pages.;;Office Action received for Australian Patent Application No. 2019222943, dated Oct. 3, 2019, 3 pages.;;Office Action received for Australian Patent Application No. 2020256383, dated Jun. 4, 2021, 3 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jun. 2, 2021, 17 pages (8 pages of English Translation and 9 pages off Official Copy).;;Office Action received for Chinese Patent Application No. 201710439448.7, dated Mar. 27, 2020, 13 pages (7 pages of English Translation and 6 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201710439448.7, dated Oct. 10, 2020, 19 pages (8 pages of English Translation and 11 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201780034203.4, dated Jul. 14, 2021, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201910858933.7, dated Aug. 18, 2020, 14 pages (7 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201910858933.7, dated Jun. 29, 2021, 8 pages (3 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 202010606407.4, dated Jan. 27, 2021, 16 pages (7 pages of English Translation and 9 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 202010606407.4, dated Jun. 2, 2021, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201770423, dated Jun. 12, 2018, 7 pages.;;Office Action received for Danish Patent Application No. PA201770423, dated Mar. 29, 2019, 6 pages.;;Office Action received for Danish Patent Application No. PA201870378, dated Feb. 25, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201870378, dated Jan. 6, 2020, 3 pages.;;Office Action received for Danish Patent Application No. PA201870379, dated Feb. 28, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Mar. 5, 2020, 2 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Mar. 27, 2019, 4 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Sep. 11, 2018, 9 pages.;;Office Action received for Danish Patent Application No. PA201970532, dated May 29, 2020, 3 pages.;;Office Action received for European Patent Application No. 17810749.6, dated Aug. 20, 2019, 9 pages.;;Office Action received for European Patent Application No. 18727543.3, dated Mar. 26, 2021, 7 pages.;;Office Action received for European Patent Application No. 19721883.7, dated Jan. 10, 2020, 4 pages.;;Office Action received for European Patent Application No. 19721883.7, dated Jun. 15, 2021, 9 pages.;;Office Action received for European Patent Application No. 19721883.7, dated May 28, 2020, 11 pages.;;Office Action received for European Patent Application No. 20182116.2, dated May 25, 2021, 9 pages.;;Office Action received for European Patent Application No. 20182116.2, dated Nov. 6, 2020, 9 pages.;;Office Action received for European Patent Application No. 21165295.3, dated Jul. 1, 2021, 10 pages.;;Office Action received for Japanese Patent Application No. 2018-184532, dated Mar. 1, 2021, 11 pages (6 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2019-162293, dated Jan. 31, 2020, 8 pages. (4 pages off English Translation and 4 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2019-162293, dated Jul. 27, 2020, 9 pages (5 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2019-563407, dated Feb. 5, 2021, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-104679, dated Sep. 18, 2020, 13 pages (7 pages of English Translation and 6 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025538, dated Aug. 15, 2020, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025538, dated Feb. 17, 2020, 12 pages (6 pages of English Translation and 6 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7033834, dated Jan. 22, 2021, 13 pages (6 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2020-7026035, dated Feb. 19, 2021, 13 pages (6 pages of English Translation and 7 pages of Official Copy).;;Partial Supplementary European Search Report received for European Patent Application No. 17810749.6, dated Apr. 25, 2019, 8 pages.;;Razykdreviews, “In Depth Review of Apple Watch Activity and Workout App”, available at: https://www.youtube.com/watch?v=GkKI3qIK0ow, Category : X Claims: 1-5 Category: L Reason: Internet citation/video, May 11, 2015, 1 page.;;Result of Consultation received for European Patent Application No. 17810749.6, dated Dec. 15, 2020, 3 pages.;;Result of Consultation received for European Patent Application No. 17810749.6, dated Jan. 18, 2021, 3 pages.;;Result of Consultation received for European Patent Application No. 17810749.6, dated Jan. 21, 2021, 18 pages.;;Result of Consultation received for European Patent Application No. 19721883.7, dated Oct. 7, 2020, 3 pages.;;Rizknows, “Garmin Connect Mobile App—Review#2”, https://www.youtube.com/watch?v=7my3wMpeRbE, Category: X Claims: 1-5 Category: L Reason: Internet citation/video, Oct. 22, 2015, 1 page.;;Rizknows, “TomTom Multisport Cardio Review”, Online available at: https://www.youtube.com/watch?v=WoVCzLrSN9A, Sep. 4, 2015, 1 page.;;Search Report and Opinion received for Danish Patent Application No. PA201770423, dated Oct. 4, 2017, 10 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201870378, dated Sep. 10, 2018, 9 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201870379, dated Sep. 14, 2018, 9 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201970532, dated Nov. 8, 2019, 9 pages.;;Search Report and Opinion received for Danish Patent Application No. PA202070614, dated Jan. 14, 2021, 9 pages.;;Search Report and Opinion received for Danish Patent Application No. PA202070815, dated Mar. 16, 2021, 8 pages.;;Smith, “Garmin Fenix 5 Activity/Smart Watch Review”, Online Available at: https://www.youtube.com/watch?v=6PkQxXQxpoU, Sep. 2, 2017, 1 pages.;;Sportstechguides, “Garmin Fenix 5: How to Add Power Data Fields”, Online Available at: https://www.youtube.com/watch?v=ZkPptnnXEiQ, Apr. 29, 2017, 2 pages.;;Sportstechguides, “Garmin Fenix 5: How to Set Up Run Alerts”, Online Available at: https://www.youtube.com/watch?v=gSMwv8vIhB4, May 13, 2017, 2 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 17810749.6, dated Aug. 12, 2020, 11 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/616,480, dated Mar. 28, 2019, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Mar. 31, 2020, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/556,023, dated Feb. 3, 2021, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Apr. 1, 2020, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Jul. 29, 2020, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Jun. 18, 2020, 2 pages.;;Supplementary European Search Report received for European Patent Application No. 17810749.6, dated Aug. 6, 2019, 6 pages.;;Suunto Spartan Trainer Wrist HR 1.12, Online Available at: https://web.archive.org/web/20180127155200/https://ns.suunto.com/Manuals/Spartan_Trainer_WristHR/Userguides/Suunto_Spartan_Trainer_WristHR_UserGuide_EN.pdf, Jan. 17, 2018, 47 pages.;;Suunto, “Suunto Spartan-Heart Rate Zones”, Online Available at: https://www.youtube.com/watch?v=aixfoCnS0OU, Mar. 19, 2018, 2 pages.;;Teunmo, “Data field: Visual Pace Alarm”, Garmin Forum; Available online at: https://forums.garmin.com/forum/developers/connect-iq/connect-iq-showcase/115996-data-field-visual-pace-alarm, Nov. 17, 2015, 10 pages.;;Tomtom, “TomTom Runner & Multi-Sport Reference Guide”, Online available at :-https://web.archive.org/web/20150908075934/http://download.tomtom.com/open/manuals/Runner_Multi-Sport/refman/TomTom-Runner-Multi-Sport-RG-en-GB.pdf, Sep. 8, 2015, 44 pages.;;Vicky's Blog, “How to Log In to PS4 Automatically with Particular User?”, Online available on :-https://www.youtube.com/watch?v=kqdlzXAvOkY, May 30, 2018, 3 pages.;;“Visual pace alarm app”, Available Online at: https://apps.garmin.com/en-US/apps/3940f3a2-4847-4078-a911-d77422966c82, Oct. 19, 2016, 1 page.;;Wesley, “Apple Watch Series 1”, online available at :-http://tool-box.info/blog/archives/1737-unknown.html, May 28, 2015, 5 pages (Official copy only) See Communication under 37 CFR § 1.98(a) (3).;;Youtube, “Apple Watch Series 3”, Online available at :-https://www.youtube.com/watch?v=iBPr9gEfkK8, Nov. 21, 2017, 15 pages (Official copy only) See Communication under 37 CFR § 1.98(a) (3).;;Yoyodavid, “How To Use Multiple Accounts on the play station 4”, Online available at :-https://www.youtube.com/watch?v=5V21obRMeKE, Jan. 9, 2014, 3 pages.;;Zlelik, “Garmin Fenix 5 Open Water Swimming Activity Demo”, Online Available at: https://www.youtube.com/watch?v=iSVhdvw2dcs, Jun. 9, 2017, 1 page.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/820,383, dated Oct. 5, 2021, 2 pages.;;Final Office Action received for U.S. Appl. No. 17/192,161, dated Oct. 18, 2021, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/030,321, dated Oct. 18, 2021, 28 pages.;;Office Action received for Danish Patent Application No. PA202070613, dated Sep. 30, 2021, 4 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/418,786, dated Jan. 5, 2022, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/820,383, dated Jan. 10, 2022, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,854, dated Dec. 27, 2021, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 17/030,318, dated Jan. 5, 2022, 8 pages.;;Office Action received for Indian Patent Application No. 202014041563, dated Dec. 30, 2021, 6 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 17/030,318, dated Jul. 30, 2021, 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 17/030,321, dated Jul. 30, 2021, 2 pages.;;Communication of the Board of Appeal received for European Patent Application No. 15771747.1, dated Aug. 25, 2021, 9 pages. et al.",ACTIVE
192,AU,B2,AU 2022/201561 B2,026-533-434-032-436,2022-08-04,2022,AU 2022/201561 A,2022-03-07,AU 2022/201561 A;;AU 2020/267310 A;;AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/026-533-434-032-436,Granted Patent,no,3,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
193,AU,B2,AU 2020/267310 B2,049-044-514-684-888,2022-03-10,2022,AU 2020/267310 A,2020-11-13,AU 2020/267310 A;;AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/049-044-514-684-888,Granted Patent,no,3,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
194,JP,A,JP 2019145121 A,062-365-240-301-672,2019-08-29,2019,JP 2019044107 A,2019-03-11,US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND TRAINING MONITOR,To provide a user interface for displaying the attribute of the physical activity of a user in a device and a process for monitoring the attribute of the physical activity of the user.SOLUTION: A portable multifunction device 100 includes an optical sensor 164. The optical sensor 164 captures a still image or a video in association with an imaging module 143. A contact strength sensor 165 coupled to a strength sensor controller 159 measures the force of contact on a touch-sensitive surface. A palpable output generator 167 includes a component for converting an electrical signal into palpable output on a device. The contact strength sensor 165 receives a tactile feedback generation command from a tactile feedback module 133 and generates the palpable output which can be sensed by a user on the portable multifunction device 100.SELECTED DRAWING: Figure 1A,APPLE INC,JAY BLAHNIK;;GARY IAN BUTCHER;;KEVIN WILL CHEN;;DAVID CHANCE GRAHAM;;DANIEL S KEEN;;JUSTIN SHANE RUSHING;;SHORTLIDGE T ALLAN;;ANTON M DAVYDOV;;ALAN C DYE;;JONATHAN P IVE;;ZACHERY KENNEDY;;ZACHURY MINJACK;;DENNIS S PARK;;BRIAN SCHMITT,,https://lens.org/062-365-240-301-672,Patent Application,no,10,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/00;;A61B5/00;;A61B5/11;;A63B69/00;;A63B71/06;;G16H20/30,,0,0,,,,ACTIVE
195,AU,B9,AU 2019/201583 B9,084-545-460-984-571,2019-07-25,2019,AU 2019/201583 A,2019-03-07,AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/084-545-460-984-571,Amended Patent,no,1,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F17/00;;G16H20/30,,0,0,,,,ACTIVE
196,AU,B2,AU 2019/250251 B2,075-248-028-069-094,2021-03-04,2021,AU 2019/250251 A,2019-10-18,AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/075-248-028-069-094,Granted Patent,no,1,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F17/00;;G16H20/30,,0,0,,,,ACTIVE
197,US,A1,US 2017/0281057 A1,115-319-922-398-575,2017-10-05,2017,US 201715627069 A,2017-06-19,US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/115-319-922-398-575,Patent Application,yes,13,56,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30,,0,0,,,,ACTIVE
198,AU,B2,AU 2017/284958 B2,117-886-389-373-671,2019-09-12,2019,AU 2017/284958 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually- relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/117-886-389-373-671,Granted Patent,no,4,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
199,US,A1,US 2021/0193293 A1,165-941-249-933-008,2021-06-24,2021,US 202117192161 A,2021-03-04,US 202117192161 A;;US 201815925652 A;;US 201514839922 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/165-941-249-933-008,Patent Application,yes,0,23,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,0,0,,,,ACTIVE
200,AU,A1,AU 2018/200428 A1,174-999-525-676-756,2018-02-08,2018,AU 2018/200428 A,2018-01-18,AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity. WO 2016/036582 PCT/US2015/047282 cn .2 C0",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;PARK DENNIS S;;SCHMITT BRIAN;;MINJACK ZACHURY,,https://lens.org/174-999-525-676-756,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,DISCONTINUED
201,CN,A,CN 109313651 A,181-637-083-654-896,2019-02-05,2019,CN 201780033901 A,2017-05-31,DK PA201670608 A;;DK PA201670609 A;;US 201662349109 P;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response toreceiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended bythe individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/181-637-083-654-896,Patent Application,no,8,3,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/44,,0,0,,,,PENDING
202,DK,A1,DK 201500582 A1,013-464-167-032-555,2017-01-02,2017,DK PA201500582 A,2015-09-30,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN P;;KING NICHOLAS V;;MANZARI BEHKISH J;;MEZAK CHARLES A;;TITI JUSTIN S;;WILSON CHRISTOFFER I;;PENHA HENRIQUE D,,https://lens.org/013-464-167-032-555,Unknown,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N1/21;;G06F3/048;;G06V10/10;;G06V20/00;;H04N5/225;;H04N101/00,,0,0,,,,DISCONTINUED
203,DK,A1,DK 201670656 A1,032-766-603-248-321,2016-09-19,2016,DK PA201670656 A,2016-08-26,US 201462044990 P;;US 201562129828 P;;DK PA201570666 A,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/032-766-603-248-321,Unknown,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,ACTIVE
204,WO,A1,WO 2017/218194 A1,056-351-419-737-682,2017-12-21,2017,US 2017/0035322 W,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually- relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/056-351-419-737-682,Patent Application,yes,36,52,1,52,0,G06F16/178,G06F17/30,,1,0,,,See also references of EP 3472731A4,PENDING
205,DK,A1,DK 202170113 A1,077-898-511-920-069,2021-03-12,2021,DK PA202170113 A,2021-03-11,US 201462044990 P;;US 201562129828 P;;DK PA201670656 A,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user’s physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user’s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user’s inactivity.",APPLE INC,DAVID CHANCE GRAHAM;;ZACHERY KENNEDY;;BRIAN SCHMITT;;ZACHURY MINJACK;;JONATHAN P IVE;;GARY IAN BUTCHER;;ALAN C DYE;;KEVIN WILL CHEN;;JAY BLAHNIK;;DANIEL S KEEN;;JUSTIN SHANE RUSHING;;T ALLAN SHORTLIDGE;;ANTON M DAVYDOV;;DENNIS S PARK,,https://lens.org/077-898-511-920-069,Unknown,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,DISCONTINUED
206,DK,B1,DK 179222 B1,095-318-574-518-359,2018-02-12,2018,DK PA201570668 A,2015-10-16,US 201462044990 P;;US 201562129828 P;;DK PA201570666 A,2014-09-02,FYSISK AKTIVITETS- OG TRÆNINGSMONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user´s physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user´s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user´s inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE ALLAN T;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/095-318-574-518-359,Granted Patent,no,7,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,ACTIVE
207,US,B2,US 9918664 B2,103-042-844-759-480,2018-03-20,2018,US 201514839922 A,2015-08-29,US 201514839922 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,APPLE INC (2015-03-23),https://lens.org/103-042-844-759-480,Granted Patent,yes,104,19,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/11;;A61B5/00;;G16H20/30,,44,0,,,"“i Phone User Guide for iOS 7.1 Software”, available online at <https://manuals.info.apple.com/MANUALS/1000/MA1681/en_US/iphone_ios7_user_guide.pdf>, 162 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/503,372, dated Dec. 5, 2014, 11 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 8, 2015, 20 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Mar. 17, 2015, 16 pages.;;Office Action received for Australian Patent Application No. 2015100734, dated Jul. 29, 2015, 5 pages.;;Kamijo, Noboru; Next Generation Mobile System—WatchPad1.5″, Available at <http://researcher.ibm.com/researcher/view_group_subpage.php?id=5617>, 2 pages.;;U.S. Appl. No. 60/936,562, filed Jun. 20, 2007, titled “Portable Multifunction Device, Method, and Graphical User Interface for Playing Online Videos”, 61 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/032474, dated Aug. 19, 2015, 8 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/047282, dated May 9, 2016, 33 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Apr. 8, 2016, 8 pages.;;Non Final Office Action received for U.S. Appl. No. 14/839,916, dated Feb. 4, 2016, 19 pages.;;Notice of Allowance received for Chinese Patent Application No. 201520358505.5, dated Jan. 13, 2016, 3 pages. (2 pages of English Translation and 1 page of Official Copy).;;Office Action received for Danish Patent Application No. PA201570666, dated Feb. 2, 2016, 9 pages.;;International Search Report received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 3 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2015047282, dated Dec. 22, 2015, 7 pages.;;Notice of Allowance received for Danish Patent Application No. PA201570666, dated Sep. 15, 2016, 1 page.;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Aug. 31, 2016, 11 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Sep. 9, 2016, 3 pages.;;Office Action received for Taiwanese Patent Application No. 104117509, dated Aug. 22, 2016, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 26, 2016, 22 pages.;;Office Action received for Australian Patent Application No. 2015312215, dated Oct. 13, 2016, 3 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated Nov. 3, 2016, 8 pages.;;Written Opinion received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 8 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Jun. 27, 2016, 4 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 7, 2016, 9 pages.;;Office Action received for Korean Patent Application No. 10-2016-7033638, dated Jan. 31, 2017, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Taiwanese Patent Application No. 104128685, dated Jan. 4, 2017, 40 pages (15 pages of English Translation and 25 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 14/599,425, dated May 19, 2017, 24 pages.;;Intention to Grant received for Danish Patent Application No. PA201570668, dated Mar. 27, 2017, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/047282, dated Mar. 16, 2017, 26 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCTUS2015032474, dated Dec. 15, 2016, 7 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/037686, dated Sep. 9, 2016, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,916, dated May 1, 2017, 18 pages.;;Notice of Allowance received for Taiwanese Patent Application No. 104117509, dated Mar. 31, 2017, 3 pages (Official Copy Only) (see attached 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for Taiwanese Patent Application No. 104128685, dated May 3, 2017, 3 pages (Official Copy Only) (see attached 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for Korean Patent Application No. 10-2016-7033638, dated May 31, 2017, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2015267240, dated Apr. 10, 2017, 5 pages.;;Office Action received for Japanese Patent Application No. 2016535045, dated May 12, 2017, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201670656, dated Jun. 14, 2017, 3 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201770191, dated Jun. 30, 2017, 9 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Aug. 10, 2017, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Office Action received for European Patent Application No, 15730890.9, dated Aug. 3, 2017, 4 pages.;;Office Action received for European Patent Application No. 15771747.1, dated Oct. 31, 2017, 7 pages.;;Notice of Allowance received for Danish Patent Application No. PA201570668, dated Oct. 30, 2017, 2 pages.",ACTIVE
208,JP,A,JP 2018124998 A,086-559-225-397-908,2018-08-09,2018,JP 2018014096 A,2018-01-30,US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"PROBLEM TO BE SOLVED: To monitor attributes of a user's physical activity or inactivity, and generates user interfaces for displaying the attributes of the user's physical activity or inactivity.SOLUTION: A device determines whether physical activity corresponds to a first type on the basis of a first set of criteria, and whether physical activity corresponds to a second type on the basis of a second set of criteria. The device controls an inactivity timer that measures a user's inactivity. The device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. The device displays a third visual representation of an attribute or amount of a third type of activity. The third visual representation corresponds to a user's inactivity.SELECTED DRAWING: Figure 16",APPLE INC,JAY BLAHNIK;;GARY IAN BUTCHER;;KEVIN WILL CHEN;;DAVID CHANCE GRAHAM;;DANIEL S KEEN;;JUSTIN SHANE RUSHING;;SHORTLIDGE T ALLAN;;ANTON M DAVYDOV;;ALAN C DYE;;JONATHAN P IVE;;ZACHERY KENNEDY;;ZACHURY MINJACK;;DENNIS S PARK;;BRIAN SCHMITT,,https://lens.org/086-559-225-397-908,Patent Application,no,8,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F3/0481;;G06F3/01;;G16H20/30,,0,0,,,,ACTIVE
209,TW,B,TW I598076 B,099-559-680-344-826,2017-09-11,2017,TW 104128685 A,2015-08-31,US 201462044990 P;;US 201562129828 P,2014-09-02,Physical activity and workout monitor,,APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/099-559-680-344-826,Granted Patent,no,0,14,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
210,AU,A1,AU 2015/312215 A1,139-940-105-069-209,2016-10-06,2016,AU 2015/312215 A,2015-08-27,US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/139-940-105-069-209,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
211,US,B2,US 10978195 B2,147-096-928-600-784,2021-04-13,2021,US 201815925652 A,2018-03-19,US 201815925652 A;;US 201514839922 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/147-096-928-600-784,Granted Patent,yes,454,21,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G06F3/048;;G16H20/40,,319,1,051-162-261-989-155,10.1371/journal.pone.0037062;;pmc3353905;;22615890,"Advisory Action received for U.S. Appl. No. 14/732,773, dated Nov. 9, 2018, 6 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2018/031662, dated Sep. 27, 2018, 19 pages.;;Invitation to Pay Addition Fees and Partial International Search Report received for PCT Patent Application No. PCT/US2018/031662, dated Jul. 16, 2018, 13 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Nov. 2, 2018, 21 pages.;;Office Action received for Australian Patent Application No. 2018200428, dated Nov. 15, 2018, 4 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Nov. 9, 2018, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2016-7014577, dated Oct. 31, 2018, 11 pages (5 pages of English Translation and 6 pages of Official Copy).;;Cho, H. S., Satisfactory Innovative Smart-watch (fitbit force) . . . review after seven days of use, such as the amount of sleep and movement (improving sleep is the object of X-Blue), Online Available at: https://x-blueuv.blogspot.com/2013/12/fitbit-force.html, Dec. 3, 2013, 6 pages (Official Copy Only) (See Communication. under 37 CFR § 1.98(a) (3)).;;Final Office Action received for U.S. Appl. No. 14/732,773, dated Jul. 13, 2018, 48 pages.;;Certification of Examination received for Australian Patent Application No. 2018100158, dated Oct. 23, 2018, 2 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated Nov. 6, 2018, 15 pages (7 pages of English Translation and 8 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201770191, dated Nov. 21, 2018, 4 pages.;;“Graphs and Charts”, available at: <https://www.teachervision.com/lesson-planning/graph-chart-teacher-resources>, retrieved on Dec. 12, 2018, 4 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035554, dated Dec. 20, 2018, 39 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/732,773, dated Feb. 8, 2019, 32 pages.;;Office Action received for Japanese Patent Application No. 2018-068846, dated Jan. 8, 2019, 6 pages (3 pages of English Translation and 3 pages of Official copy).;;Non-Final Office Action received for U.S. Appl. No. 15/183,663, dated Jul. 9, 2018, 13 pages.;;Office Action received for Danish Patent Application No. PA201770423, dated Jun. 12, 2018, 7 pages.;;CNET, “Google Fit's Automatic Activity Tracking is getting Smarter on Android”, Available online at: https://www.youtube.conn/watch?v=lttzlCid_d8, May 18, 2016, 1 page.;;Garmin, “Fenix 5x Owner's Manual”, Online Available at:—https://web.archive.org/web/20180127170640/https://static.garmin.com/pumac/fenix5x_OM_EN.pdf, Jul. 2017, 42 pages.;;Rainmaker, “Garmin Fenix3 New Auto Climb Functionality”, Available online at: https://www.youtube.com/watch?v=iuavOSNpVRc, Feb. 19, 2015, 1 page.;;Rizknows, “Tom Tom Multisport Cardio Review”, Online available at:—https://www.youtube.com/watch?v=WoVCzLrSN9A, Sep. 4, 2015, 1 page.;;Smith, Ian, “Garmin Fenix 5 Activity/Smart Watch Review”, Online Available at :—https://www.youtube.com/watch?v=6PkQxXQxpoU, Sep. 2, 2017, 1 page.;;Sportstechguides, “Garmin Fenix 5: How to Add Power Data Fields”, Online Available at:—https://www.youtube.com/watch?v=ZkPptnnXEiQ, Apr. 29, 2017, 2 pages.;;Sportstechguides, “Garmin Fenix 5: How to Set Up Run Alerts”, Online Available at:—https://www.youtube.com/watch?v=gSMwv8vlhB4, May 13, 2017, 2 pages.;;Suunto, “Suunto Spartan—Heart Rate Zones”, Online Available at :—https://www.youtube.com/watch?v=aixfoCnS0OU, Mar. 19, 2018, 2 page.;;“Suunto Spartan Trainer Wrist HR 1.12”, Online Available at:—https://web.archive.org/web/20180127155200/https://ns.suunto.com/Manuals/Spartan_Trainer_WristHR/Userguides/Suunto_Spartan_Trainer_WristHR_UserGuide_EN.pdf, Jan. 17, 2018, 47 pages.;;Tomtom, “TomTom Runner & Multi-Sport Reference Guide”, Online available at:—https://web.archive.org/web/20150908075934/http://download.tomtom.com/open/manuals/Runner_Multi-Sport/refman/TomTom-Runner-Multi-Sport-RG-en-gb.pdf, Sep. 8, 2015, 44 pages.;;Zlelik, “Garmin Fenix 5 Open Water Swimming Activity Demo”, Online Available at:—https://www.youtube.com/watch?v=iSVhdvw2dcs, Jun. 9, 2017, 1 page.;;Decision to Refuse received for European Patent Application No. 15771747.1, dated Aug. 10, 2018, 22 pages.;;Minutes of Oral proceedings received for European Patent Application No. 15771747.1, dated Aug. 10, 2018, 11 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated Jun. 29, 2018, 20 pages (11 pages of English Translation and 9 pages of Official Copy).;;Corrected Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Feb. 25, 2019, 3 pages.;;Extended European Search Report received for European Patent Application No. 16837432.0, dated Mar. 11, 2019, 10 pages.;;Office Action received for Australian Patent Application No. 2018101855, dated Feb. 22, 2019, 4 pages.;;Advisory Action received for U.S. Appl. No. 14/839,922, dated Mar. 24, 2017, 4 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated May 19, 2017, 24 pages.;;Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 8, 2015, 20 pages.;;Final Office Action received for U.S. Appl. No. 14/839,922, dated Dec. 14, 2016, 22 pages.;;Intention to Grant received for Danish Patent Application No. PA201570668, dated Mar. 27, 2017, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2013/073195,dated Jun. 7, 2016, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/032474, dated Dec. 15, 2016, 7 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2015/047282, dated Mar. 16, 2017, 26 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/032474, dated Aug. 19, 2015, 8 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2015/047282, dated May 9, 2016, 33 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/037686, dated Sep. 9, 2016, 19 pages.;;International Search Report received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 3 pages.;;International Written Opinion received for PCT Patent Application No. PCT/US2013/073195, dated Jun. 23, 2014, 8 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2015/047282, dated Dec. 22, 2015, 7 pages.;;“Iphone User Guide for iOS 7.1 Software”, Mar. 10, 2014, pp. 1-162.;;Kamijo, Noboru, “Next Generation Mobile System—Watchpad1.5”, Available at <http://researcher.ibm.com/researcher/view_group_subpage.php?id=5617>, retrieved on Jul. 4, 2015, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/503,372, dated Dec. 5, 2014, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Mar. 17, 2015, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/599,425, dated Oct. 26, 2016, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,916, dated Feb. 4, 2016, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,916, dated May 1, 2017, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,922, dated Aug. 17, 2016, 25 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/839,922, dated Feb. 25, 2016, 20 pages.;;Notice of Allowance received for Chinese Patent Application No. 201520358505.5, dated Jan. 13, 2016, 3 pages (2 pages of English Translation and 1 page of Official copy).;;Notice of Allowance received for Danish Patent Application No. PA201570666, dated Sep. 15, 2016, 1 page.;;Notice of Allowance received for Danish Patent Application No. PA201570668, dated Oct. 30, 2017, 2 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7033638, dated May 31, 2017, 5 pages (2 pages of English Translation and 3 pages of Official copy).;;Notice of Allowance received for Taiwanese Patent Application No. 104117509, dated Mar. 31, 2017, 3 pages (Official copy only).;;Notice of Allowance received for Taiwanese Patent Application No. 104128685, dated May 3, 2017, 3 pages (Official copy only).;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Aug. 31, 2016, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jan. 26, 2018, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Jul. 6, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,922, dated Nov. 2, 2017, 8 pages.;;Office Action received for Australian Patent Application No. 2015100734, dated Jul. 29, 2015, 5 pages.;;Office Action received for Australian Patent Application No. 2015267240, dated Apr. 10, 2017, 5 pages.;;Office Action received for Australian Patent Application No. 2015312215, dated Oct. 13, 2016, 3 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Feb. 2, 2016, 9 pages.;;Office Action received for Danish Patent Application No. PA201570666, dated Jun. 27, 2016, 4 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Apr. 8, 2016, 8 pages.;;Office Action received for Danish Patent Application No. PA201570668, dated Sep. 9, 2016, 3 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated Jun. 14, 2017, 3 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated Nov. 3, 2016, 8 pages.;;Office Action received for European Patent Application No. 15730890.9, dated Aug. 3, 2017, 4 pages.;;Office Action received for European Patent Application no. 15771747.1, dated Oct. 31, 2017, 7 pages.;;Office Action received for Japanese Patent Application No. 2016-535045, dated May 12, 2017, 10 pages (5 pages of English Translation and 5 pages of Official copy).;;Office Action received for Japanese Patent Application No. 2016-557650, dated Aug. 10, 2017, 10 pages (5 pages of English Translation and 5 pages of Official copy).;;Office Action received for Korean Patent Application No. 10-2016-7033638, dated Jan. 31, 2017, 6 pages (2 pages of English Translation and 4 pages of Official copy).;;Office Action received for Taiwanese Patent Application No. 104117509, dated Aug. 22, 2016, 6 pages (3 pages of English Translation and 3 pages of Official copy).;;Office Action received for Taiwanese Patent Application No. 104128685, dated Jan. 4, 2017, 40 pages (15 pages of English Translation and 25 pages of Official Copy).;;Search Report and Opinion received for Danish Patent Application No. PA201770191, dated Jun. 30, 2017, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Jan. 17, 2019, 6 pages.;;Notice of Allowance received for U.S. Appl. No. 15/616,480, dated Jan. 3, 2019, 8 pages.;;Apple, “Iphone Users Guide”, Available at: http://mesnotices.20minutes.fr/manuel-notice-mode-emploi/APPLE/IPHONE%2D%5FE#, Retrieved on Mar. 27, 2008, Jun. 2007, 137 pages.;;Codrington, Simon, “Intuitive Scrolling Interfaces with Css Scroll Snap Points”, Online Available at: https://www.sitepoint.com/intuitive-scrolling-interfaces-with-css-scroll-snap-points/, Dec. 8, 2015, 14 pages.;;“Dwprogressbar V2: Stepping and Events”, Aug. 31, 2008, 4 pages.;;Extended European Search Report received for European Patent Application No. 18154145.9, dated Mar. 2, 2018, 8 pages.;;Final Office Action received for U.S. Appl. No. 12/205,847, dated Apr. 25, 2012, 42 pages.;;International Preliminary Report on Patentability received for PCT Application No. PCT/US2016/037686, dated Mar. 1, 2018, 12 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2017/035554, dated Sep. 22, 2017, 42 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035554, dated Jul. 20, 2017, 2 pages.;;Jenbsjourney, “Wondering About a Fitbit?”, Available at: https://jenbsjourney.blogspot.kr/2013/08/wondering-about-fitbit.html, Aug. 6, 2013, 12 pages.;;“Mugs”, Online Available at: https://web.archive.org/web/20151029034349/http://le-mugs.com/, Published on Oct. 29, 2015.;;“My Calstep”, Online Available at: http://www.surprisesoftware.com/mycalstep/, retireved from the Wayback Machine, Published on May 9, 2007, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/205,847, dated Oct. 3, 2011, 59 pages.;;Non-Final Office Action received for U.S. Appl. No. 14/732,773, dated Jan. 19, 2018, 45 pages.;;Notice of Acceptance received for Australian Patent Application No. 2015312215, dated Oct. 9, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2016-535045, dated Mar. 2, 2018, 4 pages (1 page of English Translation and 3 pages of Official copy).;;Notice of Allowance received for U.S. Appl. No. 12/205,847, dated Aug. 20, 2012, 13 pages.;;Notice of Allowance received for U.S. Appl. No. 14/839,916, dated Jan. 10, 2018, 19 pages.;;Office Action received for Australian Patent Application No. 2017100667, dated Aug. 3, 2017, 9 pages.;;Office Action received for Australian Patent Application No. 2018100158, dated Apr. 23, 2018, 5 pages.;;Office Action received for Australian Patent Application No. 2018200428, dated Mar. 7, 2018, 4 pages.;;Office Action received for Danish Patent Application No. PA201670656, dated May 30, 2018, 5 pages.;;Office Action received for Danish Patent Application No. PA201770191, dated Jan. 25, 2018, 3 pages.;;Office Action received for European Patent Application No. 13811085.3, dated Apr. 20, 2018, 15 pages.;;Office Action received for European Patent Application No. 18154145.9, dated Apr. 3, 2018, 6 pages.;;Office Action received for Japanese Patent Application No. 2016-557650, dated Apr. 13, 2018, 9 pages (5 pages of English Translation and 4 pages of Official copy).;;Office Action received for Korean Patent Application No. 10-2016-7014577, dated Dec. 26, 2017, 14 pages (6 pages of English Translation and 8 pages of Official copy).;;Razykdreviews, “In Depth Review of Apple Watch Activity and Workout App”, available at: URL: https://www.youtube.com/watch?v=GkKl3qlK0ow, May 11, 2015, 1 page.;;Rizknows, “Garmin Connect Mobile App—Review #2”, https://www.youtube.com/watch?v=7my3wMpeRbE, Oct. 22, 2015, 1 page.;;Search Report and Opinion received for Danish Patent Application No. PA201770423, dated Oct. 4, 2017, 10 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 13811085.3, dated Jan. 26, 2018, 14 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 15771747.1, mailed on May 25, 2018, 17 pages.;;Utilization of Galaxy S4—S Health, Chaton and Samsung Hub, Jun. 12, 2013, 25 pages (Official copy only) (See Communication under 37 CFR § 1.98(a) (3)).;;Decision to Refuse received for European Application No. 13811085.3, dated Sep. 11, 2018, 31 pages.;;Minutes of the Oral Proceedings received for European Application No. 13811085.3, mailed on Sep. 11, 2018, 3 pages.;;Office Action received for Chinese Patent Application No. 201580037927.5, dated Jul. 20, 2018, 21 pages (6 pages of English Translation and 15 pages of Official Copy).;;Corrected Notice of Allowance received for U.S. Appl. No. 15/183,663, dated Mar. 27, 2019, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2016-557650, datedd Apr. 9, 2019, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Feb. 26, 2019, 12 pages (6 pages of English Translation and 6 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Mar. 18, 2019, 18 pages (6 pages of English Translation and 12 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Feb. 25, 2019, 10 pages (5 pages of English Translation and 5 pages of Official copy).;;Office Action received for Danish Patent Application No. PA201770423, dated Mar. 29, 2019, 6 pages.;;Office Action received for Germany Patent Application No. 112015002326.7, dated Feb. 20, 2019, 7 pages (2 pages of English Translation and 5 pages of Official Copy).;;Supplemental Notice of Allowance received for U.S. Appl. No. 15/616,480, dated Mar. 28, 2019, 2 pages.;;“Visual Pace Alarm app”, Available Online at: https://apps.garmin.com/en-US/apps/3940f3a2-4847-4078-a911-d77422966c82, Oct. 19, 2016, 1 page.;;Teunmo, “Data field: Visual Pace Alarm”, Garmin Forum; Available online at: https://forunns.garmin.com/forum/developers/connect-iq/connect-iq-showcase/115996-data-field-visual-pace-alarm, Nov. 17, 2015, 10 pages.;;“Multi-Set Bar Chart”, The Data Visualization Catalogue, Available Online at: https://datavizcatalogue.com/methods/multiset_barchart.html, Feb. 8, 2014, 3 pages.;;Office Action received for Chinese Patent Application No. 201580037927.5, dated Apr. 22, 2019, 9 pages(4 pages of English Translation and 5 pages of Official Copy).;;Evergreen, et al., “Bar Chart”, Better Evaluation, Available Online at: https://www.betterevaluation.org/en/evaluation-options/BarChart, Oct. 31, 2014, 8 pages.;;Final Office Action received for U.S. Appl. No. 14/732,773, dated Jun. 21, 2019, 32 pages.;;Final Office Action received for U.S. Appl. No. 15/608,848, dated Jun. 26, 2019, 27 pages.;;Final Office Action received for U.S. Appl. No. 16/144,849, dated Jun. 7, 2019, 29 pages.;;Final Office Action received for U.S. Appl. No. 16/144,864, dated May 17, 2019, 24 pages.;;Intention to Grant received for Danish Patent Application No. PA201870379, dated May 2, 2019, 2 pages.;;Non-Final Office Action Received for U.S. Appl. No. 16/144,864, dated Dec. 18, 2018, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/627,069, dated Jun. 21, 2019, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,849, dated Dec. 31, 2018, 28 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2016-7014577, dated May 30, 2019, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201870378, dated Feb. 25, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201870379, dated Feb. 28, 2019, 3 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Mar. 27, 2019, 4 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Sep. 11, 2018, 9 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201870378, dated Sep. 10, 2018, 9 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201870379, dated Sep. 14, 2018, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/600,243, dated Jun. 27, 2019, 17 Pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated May 8, 2019, 14 pages (7 pages of English Translation and 7 pages of Official Copy).;;Office Action Received for Danish Patent Application No. PA201670656, dated May 2, 2019, 4 pages.;;Partial Supplementary European Search Report received for European Patent Application No. 17810749.6, dated Apr. 25, 2019, 8 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,849, dated Jan. 21, 2020, 6 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Feb. 5, 2020, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,864, dated Jan. 31, 2020, 29 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,735, dated Jun. 18, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,753, dated Jun. 18, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/144,864, dated Jun. 22, 2020, 3 pages.;;Office Action received for Australian Patent Application No. 2017277971, dated Jun. 3, 2020, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-068846, dated Dec. 9, 2019, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Dec. 18, 2019, 21 pages.;;Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Dec. 12, 2019, 7 pages.;;Office Action received for Chinese Patent Application No. 201680047983.1, dated Nov. 28, 2019, 9 pages (4 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025781, dated Nov. 26, 2019, 10 pages (4 pages of English Translation and 6 pages of Official Copy).;;Notice of Allowance received for Chinese Patent Application No. 201580037927.5, dated Oct. 17, 2019, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201770191, dated Oct. 25, 2019, 4 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Mar. 13, 2020, 3 pages.;;Final Office Action received for U.S. Appl. No. 15/627,069, dated Mar. 2, 2020, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/138,809, dated Feb. 28, 2020, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,753, dated Mar. 5, 2020, 9 pages.;;Notice of Allowance received for Chinese Patent Application No. 201810105846.X, dated Feb. 18, 2020, 2 pages (1 page of English Translation and 1 page of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Mar. 6, 2020, 9 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Mar. 6, 2020, 3 pages.;;Office Action received for Danish Patent Application No. PA201870380, dated Mar. 5, 2020, 2 pages.;;Office Action received for Japanese Patent Application No. 2019-162293, dated Jan. 31, 2020, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025538, dated Feb. 17, 2020, 12 pages (6 pages of English Translation and 6 pages of Official Copy).;;Wesley, “Apple Watch Series 1”, Online available at: http://tool-box.info/blog/archives/1737-unknown.html, May 28, 2015, 5 pages (Official copy only) (See Communication under 37 CFR § 1.98(a) (3)).;;Youtube, “Apple Watch Series 3”, Online available at: https://www.youtube.com/watch?v=iBPr9gEti<K8, Nov. 21, 2017, 15 pages. (Official copy only) (See Communication under 37 CFR § 1.98(a) (3)).;;Corrected Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Mar. 24, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/600,243, dated Mar. 31, 2020, 5 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Mar. 16, 2020, 3 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Mar. 31, 2020, 2 pages.;;Office Action received for Chinese Patent Application No. 20180105846.X, dated Aug. 27, 2019, 12 pages (5 pages of English Translation and 7 pagesof Official Copy).;;Notice of Acceptance received for Australian Patent Application No. 2019201583, dated Jul. 15, 2019, 3 pages.;;Advisory Action received for U.S. Appl. No. 16/144,864, dated Jul. 6, 2020, 6 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/705,849, dated Jun. 29, 2020, 3 pages.;;Office Action Received for Danish Patent Application No. PA201670656, dated Jul. 1, 2020, 4 pages.;;Office Action received for Japanese Patent Application No. 2019-044107, dated May 29, 2020, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 201810105846.X, dated Nov. 28, 2019, 9 pages (5 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201870378, dated Jan. 6, 2020, 3 pages.;;Office Action received for European Patent Application No. 16837432.0, dated Jan. 10, 2020, 7 pages.;;Office Action received for European Patent Application No. 19721883.7, dated Jan. 10, 2020, 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated May 12, 2020, 5 pages.;;Final Office Action received for U.S. Appl. No. 15/705,849, dated May 1, 2020, 17 pages.;;Final Office Action received for U.S. Appl. No. 16/144,735, dated May 4, 2020, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/377,892, dated May 21, 2020, 9 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019222943, dated May 5, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/138,809, dated Jun. 9, 2020, 7 pages.;;Final Office Action received for U.S. Appl. No. 16/144,864, dated May 28, 2020, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/627,069, dated May 26, 2020, 25 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/378,136, dated Jun. 2, 2020, 8 pages.;;Office Action received for European Patent Application No. 19721883.7, dated May 28, 2020, 11 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/144,864, dated Apr. 29, 2020, 4 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/418,786, dated Apr. 24, 2020, 16 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,849, dated Apr. 17, 2020, 2 pages.;;Office Action received for Chinese Patent Application No. 201710439448.7, dated Mar. 27, 2020, 13 pages (7 pages of English Translation and 6 pages of Official Copy).;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/705,849, dated Feb. 14, 2020, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 14/732,773, dated Feb. 10, 2020, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/608,848, dated Feb. 6, 2020, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,735, dated Feb. 19, 2020, 10 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,671, dated Feb. 10, 2020, 17 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jan. 16, 2020, 11 pages (6 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2018-014096, dated Jan. 6, 2020, 17 pages (8 pages of English Translation and 9 pages of Official Copy).;;Advisory Action received for U.S. Appl. No. 16/144,864, dated Jul. 29, 2019, 6 pages.;;Advisory Action received for U.S. Appl. No. 14/732,773, dated Aug. 23, 2019, 6 pages.;;Advisory Action received for U.S. Appl. No. 16/144,849, dated Aug. 12, 2019, 5 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/627,069, dated Nov. 4, 2019, 6 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/600,243, dated Nov. 1, 2019, 6 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Nov. 1, 2019, 3 pages.;;Certificate of Examination received for Australian Patent Application No. 2018101855, dated Aug. 6, 2019, 2 pages.;;Decision to Grant received for Danish Patent Application No. PA201870379, dated Jul. 5, 2019, 2 pages.;;“Fitbit App”, Available online at: <http://web.archive.org/web/20180114083150/https://www.fitbit.com/au/app>, Jan. 14, 2018, 8 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024570, dated Aug. 8, 2019, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/705,849, dated Nov. 12, 2019, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/144,849, dated Sep. 17, 2019, 9 pages.;;Office Action received for Australian Patent Application No. 2019100495, dated Sep. 17, 2019, 7 pages.;;Office Action received for Australian Patent Application No. 2019222943, dated Oct. 3, 2019, 3 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jul. 15, 2019, 10 pages (5 pages of English Translation and 5 pages of Official copy).;;Office Action received for European Patent Application No. 17810749.6, dated Aug. 20, 2019, 9 pages.;;Supplementary European Search Report received for European Patent Application No. 17810749.6, dated Aug. 6, 2019, 6 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2018/031662, dated Nov. 28, 2019, 12 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 15/608,848, dated Oct. 26, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/144,753, dated Nov. 4, 2020, 3 pages.;;European Search Report received for European Patent Application No. 20182116.2, dated Oct. 21, 2020, 4 pages.;;Final Office Action received for U.S. Appl. No. 15/627,069, dated Oct. 20, 2020, 25 pages.;;Notice of Allowance received for U.S. Appl. No. 15/705,849, dated Oct. 16, 2020, 14 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,735, dated Oct. 28, 2020, 13 pages.;;Office Action received for Japanese Patent Application No. 2020-104679, dated Sep. 18, 2020, 13 pages (7 pages of English Translation and 6 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 15/608,848, dated Aug. 21, 2020, 15 pages.;;Final Office Action received for U.S. Appl. No. 16/138,809, dated Aug. 27, 2020, 24 pages.;;Office Action received for Australian Patent Application No. 2017277971, dated Aug. 12, 2020, 3 pages.;;Office Action received for Chinese Patent Application No. 201380081349.6, dated Jul. 15, 2020, 9 pages (4 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2019-7025538, dated Aug. 15, 2020, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2019250251, dated Aug. 6, 2020, 3 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 17810749.6, dated Aug. 12, 2020, 11 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/377,892, dated Oct. 13, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/378,136, dated Oct. 13, 2020, 4 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/894,309, dated Oct. 15, 2020, 24 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 29, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/556,023, dated Oct. 15, 2020, 8 pages.;;Result of Consultation received for European Patent Application No. 19721883.7, dated Oct. 7, 2020, 3 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/025997, dated Jul. 1, 2020, 16 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/025997, dated Jul. 14, 2020, 15 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 10, 2020, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/144,864, dated Sep. 16, 2020, 2 pages.;;Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Feb. 10, 2020, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/588,950, dated May 5, 2020, 9 pages.;;Office Action received for Chinese Patent Application No. 201910858933.7, dated Aug. 18, 2020, 14 pages (7 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201970532, dated May 29, 2020, 3 pages.;;Office Action received for Japanese Patent Application No. 2018-014096, dated Aug. 28, 2020, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2019-162293, dated Jul. 27, 2020, 9 pages (5 pages of English Translation and 4 pages of Official Copy).;;Result of Consultation received for European Patent Application No. 18154145.9, dated Sep. 4, 2020, 3 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201970532, dated Nov. 8, 2019, 9 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Apr. 1, 2020, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/588,950, dated Jul. 29, 2020, 2 pages. et al.",ACTIVE
212,EP,A1,EP 3872814 A1,162-133-864-825-098,2021-09-01,2021,EP 21168916 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;EP 18154145 A;;EP 15771747 A;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.
",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/162-133-864-825-098,Patent Application,yes,29,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A63B71/06,,0,0,,,,PENDING
213,CN,A,CN 117038007 A,063-187-797-591-416,2023-11-10,2023,CN 202310976708 A,2015-08-27,US 201562129828 P;;CN 201580037927 A;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and fitness monitor,"The present disclosure relates to a device and process for monitoring attributes of physical activity (e.g., fitness) or inactivity of a user, and to a user interface (e.g., an activity indicator) for displaying the attributes. In some examples, the device determines whether the physical activity corresponds to a first type based on a first set of criteria and determines whether the physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer for measuring inactivity of a user. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to an inactivity of the user.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;ALAN C DYE;;JONATHAN P IVE;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/063-187-797-591-416,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,0,0,,,,PENDING
214,DK,A1,DK 201570668 A1,075-193-304-942-166,2016-07-25,2016,DK PA201570668 A,2015-10-16,US 201462044990 P;;US 201562129828 P;;DK PA201570666 A,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE ALLAN T;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/075-193-304-942-166,Unknown,no,7,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/103,,0,0,,,,ACTIVE
215,AU,B2,AU 2022/201761 B2,084-381-350-873-91X,2023-06-29,2023,AU 2022/201761 A,2022-03-15,AU 2022/201761 A;;AU 2021/201130 A;;AU 2019/250251 A;;AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/084-381-350-873-91X,Granted Patent,no,2,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/00,,0,0,,,,ACTIVE
216,AU,B2,AU 2022/263576 B2,145-534-379-065-049,2023-12-21,2023,AU 2022/263576 A,2022-11-04,AU 2022/263576 A;;AU 2022/201561 A;;AU 2020/267310 A;;AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/145-534-379-065-049,Granted Patent,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
217,US,A1,US 2017/0357382 A1,165-297-000-954-765,2017-12-14,2017,US 201615275294 A,2016-09-23,US 201615275294 A;;US 201662349109 P,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC M G;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOULANT BRENDAN J;;LOPEZ PAULO MICHAELO;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,APPLE INC (2017-01-16),https://lens.org/165-297-000-954-765,Patent Application,yes,13,79,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0481;;G06F3/0484;;G06F17/30;;G06T1/00,,0,0,,,,ACTIVE
218,KR,A,KR 20190028574 A,170-811-005-802-090,2019-03-18,2019,KR 20197007053 A,2017-05-31,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"본 발명은, 일반적으로, 정황상 관련있는 미디어 콘텐츠를 검색 및 디스플레이하는 것에 관한 것이다. 일부 실시예들에서, 디바이스는 정황상 관련있는 미디어를 디스플레이하라는 요청을 수신하고, 이에 응답하여, 디바이스의 정황과 관련있는 미디어 아이템들의 컬렉션의 표현을 디스플레이한다. 일부 실시예들에서, 디바이스는 아이템들의 시퀀스의 시각적 미디어 아이템을 디스플레이하고, 스와이프 제스처를 수신한 것에 응답하여, 미디어 아이템에 대한 관련 콘텐츠를 포함하는 세부 사용자 인터페이스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 제1 세부 사용자 인터페이스를 디스플레이하는 동안, 선택 시, 개인들이 참석한 복수의 이벤트들에 대응하는 시각적 미디어의 디스플레이를 야기하는 제1 이벤트에 참석했던 것으로 식별된 복수의 개인들에 대응하는 어포던스를 디스플레이한다. 일부 실시예들에서, 디바이스는, 사용자 입력에 응답하여, 시각적 미디어의 자동으로 생성된 컬렉션을 획득하고, 대응하는 어포던스를 디스플레이한다.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/170-811-005-802-090,Patent Application,no,6,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/23;;G06F3/0488,,1,0,,,"Neil Hughes, Apple explores merging cloud content with locally stored media library, (2011. 02)",ACTIVE
219,CN,A,CN 109684491 A,177-872-972-486-082,2019-04-26,2019,CN 201811616429 A,2017-05-31,DK PA201670608 A;;DK PA201670609 A;;US 201662349109 P;;CN 201780033901 A,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually-relevant media and,in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attterminaled a first event, that when selected, causes display of visual media corresponding to a plurality of events attterminaled by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRTERMINALAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/177-872-972-486-082,Patent Application,no,7,1,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/44;;G06F3/0482;;G06F3/0484;;G06F3/0487,,0,0,,,,ACTIVE
220,DK,A1,DK 201770191 A1,014-665-127-945-226,2017-03-27,2017,DK PA201770191 A,2017-03-17,US 201462044990 P;;US 201562129828 P;;DK PA201670656 A,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user´s physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user´s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user´s inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;DAVYDOV ANTON M;;DYE ALAN C;;GRAHAM DAVID CHANCE;;IVE JONATHAN P;;KEEN DANIEL S;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;RUSHING JUSTIN SHANE;;SCHMITT BRIAN;;SHORTLIDGE ALLAN T,,https://lens.org/014-665-127-945-226,Unknown,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,DISCONTINUED
221,AU,A1,AU 2020/267310 A1,032-921-771-599-515,2020-12-10,2020,AU 2020/267310 A,2020-11-13,AU 2020/267310 A;;AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/032-921-771-599-515,Patent Application,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
222,AU,A1,AU 2022/201561 A1,122-445-122-746-587,2022-03-31,2022,AU 2022/201561 A,2022-03-07,AU 2022/201561 A;;AU 2020/267310 A;;AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/122-445-122-746-587,Patent Application,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
223,CN,A,CN 111210891 A,124-921-281-491-398,2020-05-29,2020,CN 201911396643 A,2015-08-27,CN 201911396643 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The invention relates to a physical activity and workout monitor. The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first setof criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. Insome examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;PARK DENNIS S;;SCHMITT BRIAN;;MINJACK ZACHURY,,https://lens.org/124-921-281-491-398,Patent Application,no,13,1,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,2,0,,,"JOHN DICRISTINA;: ""健身监测设备走向无线化"", 中国电子商情(基础电子), no. 12;;白玉羚;劳奇成;: ""虚拟齿轮测量中心的运动建模研究"", 工具技术, no. 02",ACTIVE
224,TW,A,TW 201628556 A,167-287-966-970-484,2016-08-16,2016,TW 104128685 A,2015-08-31,US 201462044990 P;;US 201562129828 P,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to systems and processes for monitoring attributes of a user's physical activity or inactivity, and for generating user interfaces for displaying the same. One example user interface can include a first indicator that represents an attribute of a user's physical activity that is of a first type and a second indicator that represents an attribute of a user's physical activity that is of a second type. The first type of physical activity can be a physical activity that meets a first set of criteria and the second type of physical activity can be a physical activity that meets a second set of criteria. The user interface can further include a third indicator that represents an attribute of a user's inactivity, which can include the user not performing a specified type of physical activity or not performing a physical activity that meets a third set of criteria. The present disclosure also relates to systems and processes for monitoring a user's workout, and for generating user interfaces for displaying the same. One example process can include monitoring a user's physical activity during a workout (e.g., a session of physical activity or exercise) using activity sensors selected based on the type of workout. The process can further include generating a user interface for displaying one or more attributes of the workout. One example user interface can include a first indicator (e.g., a visual representation) that represents a first attribute of the workout and a second indicator (e.g., a visual representation) that represents a second attribute of the workout. The process can further include providing notifications during the workout to notify the user of significant events associated with the workout.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/167-287-966-970-484,Patent of Addition,no,0,1,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/11,,0,0,,,,ACTIVE
225,CN,A,CN 109599161 A,161-099-630-224-510,2019-04-09,2019,CN 201811303556 A,2015-08-27,CN 201811303556 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The invention provides a physical activity and workout monitor. The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set ofcriteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a secondtype. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/161-099-630-224-510,Patent Application,no,4,3,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
226,AU,B2,AU 2019/201583 B2,047-144-171-467-448,2019-07-18,2019,AU 2019/201583 A,2019-03-07,AU 2019/201583 A;;AU 2018/200428 A;;AU 2015/312215 A;;US 201562129828 P;;US 201462044990 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/047-144-171-467-448,Granted Patent,no,1,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G06F17/00;;G16H20/30,,0,0,,,,ACTIVE
227,EP,A1,EP 3333740 A1,050-941-521-506-479,2018-06-13,2018,EP 18154145 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;EP 15771747 A,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.
",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,APPLE INC. (2018-08-01),https://lens.org/050-941-521-506-479,Patent Application,yes,26,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,DISCONTINUED
228,AU,A1,AU 2019/271873 A1,109-660-928-303-719,2019-12-12,2019,AU 2019/271873 A,2019-11-25,AU 2019/271873 A;;AU 2017/284958 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A;;US 2017/0035322 W,2016-06-12,User interfaces for retrieving contextually relevant media content,"The present disclosure generally relates to retrieving and displaying contextually-relevant media content. In some embodiments, a device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. In some embodiments, a device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. In some embodiments, a device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, causes display of visual media corresponding to a plurality of events attended by the individuals. In some embodiments, a device, in response to user input, obtains an automatically-generated collection of visual media and displays a corresponding affordance.",APPLE INC,MIURA BRITT S;;BOVET SIMON;;BUTCHER GARY IAN;;CIRCLAEYS ERIC;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;IRANI CYRUS DANIEL;;LEMAY STEPHEN O;;LANGOLANT BRENDAN J;;LOPEZ PAULO MICHAELO;;O'ROURKE RYAN;;PENHA HENRIQUE;;TITI JUSTIN S;;WILSON CHRISTOPHER,,https://lens.org/109-660-928-303-719,Patent Application,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F16/178,,0,0,,,,ACTIVE
229,WO,A2,WO 2016/036582 A2,108-817-027-472-511,2016-03-10,2016,US 2015/0047282 W,2015-08-27,US 201462044990 P;;US 201562129828 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/108-817-027-472-511,Patent Application,yes,7,64,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,PENDING
230,US,A1,US 2021/0110908 A1,125-895-622-081-777,2021-04-15,2021,US 202017031854 A,2020-09-24,US 202017031854 A;;US 201715627069 A;;US 201514839916 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/125-895-622-081-777,Patent Application,yes,2,23,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A61B5/00;;A61B5/11;;G16H20/40,,0,0,,,,PENDING
231,CN,A,CN 111081345 A,157-586-194-396-802,2020-04-28,2020,CN 201911396819 A,2015-08-27,CN 201911396819 A;;CN 201580037927 A;;US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Physical activity and workout monitor,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) fordisplaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a secondtype based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representationof an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN,,https://lens.org/157-586-194-396-802,Patent Application,no,12,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30,,0,0,,,,ACTIVE
232,DE,T5,DE 112015002326 T5,100-341-938-857-103,2017-03-23,2017,DE 112015002326 T,2015-08-27,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Monitor für physische Aktivität und Training,"Die vorliegende Offenbarung betrifft Vorrichtungen und Prozesse zum Überwachen von Eigenschaften einer physischen Aktivität (z. B. eines Trainings) oder Inaktivität eines Benutzers sowie Benutzerschnittstellen (z. B. einen Aktivitätsanzeiger) zum Anzeigen derselben. In manchen Beispielen ermittelt eine Vorrichtung auf Grundlage eines ersten Satzes von Kriterien, ob die physische Aktivität einem ersten Typ entspricht, und auf Grundlage eines zweiten Satzes von Kriterien, ob die physische Aktivität einem zweiten Typ entspricht. In manchen Beispielen steuert die Vorrichtung einen Inaktivitätszeitgeber, der eine Inaktivität des Benutzers misst. In manchen Beispielen zeigt die Vorrichtung eine erste visuelle Darstellung einer Eigenschaft oder Menge eines ersten Typs physischer Aktivität und eine zweite visuelle Darstellung einer Eigenschaft oder Menge eines zweiten Typs an. In manchen Beispielen zeigt die Vorrichtung eine dritte visuelle Darstellung einer Eigenschaft oder Menge eines dritten Aktivitätstyps an. In manchen Beispielen entspricht die dritte visuelle Darstellung einer Inaktivität eines Benutzers.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;SHORTLIDGE ALLAN T;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN A,,https://lens.org/100-341-938-857-103,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A63B24/00;;G16H20/30,,0,0,,,,ACTIVE
233,JP,A,JP 2019215874 A,070-003-712-271-582,2019-12-19,2019,JP 2019123115 A,2019-07-01,US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A,2016-06-12,USER INTERFACE FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"To provide an interface in which retrieval and presentation of contextually-relevant media content is made easy, and is improved for engaging media content.SOLUTION: A device receives a request to display contextually-relevant media and displays representation of collection of media items relevant to context of the device. The device displays a visual media item of a sequence of items and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. The device, while displaying a first detail user interface, displays an affordance corresponding to a plurality of individuals identified as having attended a first event, that when selected, displays visual media corresponding to a plurality of events attended by the individuals. The device, in response to user input, obtains automatically-generated collection of visual media, and displays a corresponding affordance.SELECTED DRAWING: Figure 7A",APPLE INC,BRITT S MIURA;;SIMON BOVET;;GARY IAN BUTCHER;;ERIC M G CIRCLAEYS;;ALAN C DYE;;DANIEL E GOBERA RUBALCAVA;;CYRUS DANIEL IRANI;;STEPHEN O LEMAY;;BRENDAN J LANGOLANT;;PAULO MICHAELO LOPEZ;;RYAN O'ROURKE;;HENRIQUE PENHA;;JUSTIN S TITI;;CHRISTOPHER WILSON,,https://lens.org/070-003-712-271-582,Patent Application,no,5,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0482;;G06F16/904;;H04N21/482,,0,0,,,,ACTIVE
234,JP,A,JP 2023098880 A,059-647-641-531-353,2023-07-11,2023,JP 2023041035 A,2023-03-15,JP 2021188824 A;;US 201562129828 P;;US 201462044990 P,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"To provide a device and a process for monitoring the attributes of a user's physical activity or inactivity, and a user interface for displaying the attributes of the user's physical activity or inactivity.SOLUTION: A device determines whether or not a physical activity corresponds to a first type on the basis of a first set of criteria, and whether or not the physical activity corresponds to a second type based on a second set of criteria. The device controls an inactivity timer that measures a user's inactivity. The device displays a first visual representation of an attribute or amount of a first type of physical activity and a second visual representation of an attribute or amount of a second type. The device displays a third visual representation of an attribute or amount of a third type of activity. The third visual representation corresponds to the user's inactivity.SELECTED DRAWING: Figure 1A",APPLE INC,JAY BLAHNIK;;GARY IAN BUTCHER;;KEVIN WILL CHEN;;DAVID CHANCE GRAHAM;;DANIEL S KEEN;;JUSTIN SHANE RUSHING;;SHORTLIDGE T ALLAN;;ANTON M DAVYDOV;;ALAN C DYE;;JONATHAN P IVE;;ZACHERY KENNEDY;;ZACHURY MINJACK;;DENNIS S PARK;;BRIAN SCHMITT;;KEVIN LYNCH,,https://lens.org/059-647-641-531-353,Patent Application,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A63B71/06;;A63B69/00;;G06F3/01;;G06F3/0481;;G16H10/60;;G16H20/00,,0,0,,,,PENDING
235,DE,B4,DE 112015002326 B4,024-932-174-968-291,2021-09-23,2021,DE 112015002326 T,2015-08-27,US 201462044990 P;;US 201562129828 P;;US 2015/0047282 W,2014-09-02,Monitor für physische Aktivität und Training,"Die vorliegende Offenbarung betrifft Vorrichtungen und Prozesse zum Überwachen von Eigenschaften einer physischen Aktivität (z. B. eines Trainings) oder Inaktivität eines Benutzers sowie Benutzerschnittstellen (z. B. einen Aktivitätsanzeiger) zum Anzeigen derselben. In manchen Beispielen ermittelt eine Vorrichtung auf Grundlage eines ersten Satzes von Kriterien, ob die physische Aktivität einem ersten Typ entspricht, und auf Grundlage eines zweiten Satzes von Kriterien, ob die physische Aktivität einem zweiten Typ entspricht. In manchen Beispielen steuert die Vorrichtung einen Inaktivitätszeitgeber, der eine Inaktivität des Benutzers misst. In manchen Beispielen zeigt die Vorrichtung eine erste visuelle Darstellung einer Eigenschaft oder Menge eines ersten Typs physischer Aktivität und eine zweite visuelle Darstellung einer Eigenschaft oder Menge eines zweiten Typs an. In manchen Beispielen zeigt die Vorrichtung eine dritte visuelle Darstellung einer Eigenschaft oder Menge eines dritten Aktivitätstyps an. In manchen Beispielen entspricht die dritte visuelle Darstellung einer Inaktivität eines Benutzers.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN;;LYNCH KEVIN,,https://lens.org/024-932-174-968-291,Granted Patent,no,18,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16H20/30;;A63B24/00;;G16Z99/00,,0,0,,,,ACTIVE
236,JP,A,JP 2021073559 A,156-899-008-898-392,2021-05-13,2021,JP 2021000224 A,2021-01-04,JP 2019123115 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A,2016-06-12,USER INTERFACE FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"To provide a faster and more efficient method for retrieving and viewing contextually relevant content.SOLUTION: A device includes a display, and displays a first detail user interface that includes a representation of first visual media corresponding to a first event and an affordance corresponding to a plurality of individuals identified as having attended the first event. A user input corresponding to selection of the affordance is received, and in response to the user input, a second detail user interface that includes a representation of second visual media is displayed. The representation of the second visual media includes a first plurality of media items and a second plurality of media items. The first plurality of media items correspond to a second event identified as having been attended by fewer than all of the individuals of the plurality of individuals. The second plurality of media items correspond to a third event identified as having been attended by the plurality of individuals and different from the second event.SELECTED DRAWING: Figure 13A",APPLE INC,BRITT S MIURA;;SIMON BOVET;;GARY IAN BUTCHER;;ERIC M G CIRCLAEYS;;ALAN C DYE;;DANIEL E GOBERA RUBALCAVA;;CYRUS DANIEL IRANI;;STEPHEN O LEMAY;;BRENDAN J LANGOLANT;;PAULO MICHAELO LOPEZ;;RYAN O'ROURKE;;HENRIQUE PENHA;;JUSTIN S TITI;;CHRISTOPHER WILSON,,https://lens.org/156-899-008-898-392,Patent Application,no,6,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0484;;G06F3/0481,,0,0,,,,ACTIVE
237,DK,B1,DK 180630 B1,068-952-850-141-180,2021-11-04,2021,DK PA201670656 A,2016-08-26,US 201462044990 P;;US 201562129828 P;;DK PA201570666 A,2014-09-02,Fysisk aktivitet og træningsmonitor,"The present disclosure relates to devices and processes for monitoring attributes of a user’s physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user’s inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user’s inactivity.",APPLE INC,GARY IAN BUTCHER;;ANTON M DAVYDOV;;DANIEL S KEEN;;ALLAN T SHORTLIDGE;;ZACHERY KENNEDY;;DENNIS S PARK;;ALAN C DYE;;JONATHAN P IVE;;KEVIN WILL CHEN;;BRIAN SCHMITT;;DAVID CHANCE GRAHAM;;JAY BLAHNIK;;JUSTIN SHANE RUSHING;;ZACHURY MINJACK;;KEVIN LYNCH,,https://lens.org/068-952-850-141-180,Granted Patent,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A61B5/103;;G16H20/30,,0,0,,,,ACTIVE
238,DE,B4,DE 112015007285 B4,089-955-289-194-484,2023-11-02,2023,DE 112015007285 T,2015-08-27,US 201462044990 P;;US 201562129828 P,2014-09-02,MONITOR FÜR PHYSISCHE AKTIVITÄT UND TRAINING,"Computerimplementiertes Verfahren (1500), umfassend:an einem oder mehreren Prozessoren eines elektronischen Geräts (10000):Anzeigen (1502) eines Aktivitätsanzeigers (4101), wobei der Aktivitätsanzeiger (4101) umfasst:einen ersten Anzeiger (4102), der für eine Gesamtmenge einer ersten Art von körperlicher Aktivität repräsentativ ist, die durch einen Sensor des elektronischen Geräts (10000) erfassbar ist und von einem Benutzer über eine Zeitspanne ausgeführt wird, wobei eine Startposition des ersten Anzeigers (4102) an eine erste Zielposition der ersten Art von körperlicher Aktivität angrenzt, so dass der erste Anzeiger (4102) einen Ring bildet;einen zweiten Anzeiger (4104), der für eine Gesamtmenge einer zweiten Art von körperlicher Aktivität repräsentativ ist, die vom Benutzer über die Zeitspanne ausgeführt wird, wobei eine Startposition des zweiten Anzeigers (4104) an eine zweite Zielposition der zweiten Art der körperlichen Aktivität angrenzt, so dass der zweite Anzeiger (4104) einen Ring bildet, und wobei die zweite Art der körperlichen Aktivität eine körperliche Aktivität repräsentiert, die eine Intensität aufweist, die gleich oder größer als ein Schwellenwert ist; undeinen dritten Anzeiger (4106), der für eine Anzahl von vorbestimmten Zeitsegmenten repräsentativ ist, während derer der Benutzer einen Schwellenbetrag einer dritten Art von körperlicher Aktivität ausführt, wobei eine Startposition des dritten Anzeigers (4106) an einer dritten Zielposition der dritten Art von körperlicher Aktivität angrenzt, so dass der dritte Anzeiger (4106) einen Ring bildet;Empfangen (1504) von einem Sensor (168, 359, 520) des elektronischen Geräts (10000) von Aktivitätsdaten, die von dem Sensor (168, 359, 520) erfasst wurden; undAktualisieren (1510) der Gesamtmenge der ersten Art von körperlicher Aktivität, der Gesamtmenge der zweiten Art von körperlicher Aktivität und der Anzahl von vorbestimmten Zeitsegmenten basierend auf den Aktivitätsdaten,wobei beim Anzeigen des Aktivitätsanzeigers (4101) die Gesamtmenge der ersten Art von körperlicher Aktivität durch eine Maßeinheit repräsentiert wird, die sich von der Maßeinheit zum Repräsentieren der Gesamtmenge der zweiten Art von körperlicher Aktivität unterscheidet, undwobei für jeden von dem ersten (4102), dem zweiten (4104) und dem dritten Anzeiger (4106):eine führende Position eines abgeschlossenen Abschnitts eines jeden Anzeigers (4102a, 4104a, 4106a) unterscheidbar von einem hinteren Teil des abgeschlossenen Abschnitts eines jeden Anzeigers (4102b, 4104b, 4106b) angezeigt wird; undwenn ein aktueller Wert eines jeden Anzeigers einen entsprechenden Zielwert überschreitet, durchquert die führende Position des abgeschlossenen Abschnitts eines jeden Anzeigers die entsprechende Zielposition, um einen zuvor abgeschlossenen Abschnitt eines jeden Anzeigers zu überlappen.",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN;;LYNCH KEVIN,,https://lens.org/089-955-289-194-484,Granted Patent,no,0,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,G16Z99/00;;A63B24/00,,0,0,,,,ACTIVE
239,JP,A,JP 2021144739 A,173-947-311-899-216,2021-09-24,2021,JP 2021094529 A,2021-06-04,JP 2021000224 A;;US 201662349109 P;;DK PA201670608 A;;DK PA201670609 A,2016-06-12,USER INTERFACES FOR RETRIEVING CONTEXTUALLY RELEVANT MEDIA CONTENT,"To provide a method for retrieving contextually relevant media content.SOLUTION: A personal electronic device receives a request to display contextually relevant media and, in response, displays a representation of a collection of media items relevant to a context of the device. The device displays a visual media item of a sequence item and, in response to receiving a swipe gesture, displays a detail user interface comprising related content for the media item. The device displays an affordance corresponding to a plurality of individuals identified as having attended a first event while displaying a first detail user interface, and displays a visual media corresponding to a plurality of events attended by the individuals when selected. The device acquires an automatically generated collection of visual media in response to user input and displays a corresponding affordance.SELECTED DRAWING: Figure 7A",APPLE INC,BRITT S MIURA;;SIMON BOVET;;GARY IAN BUTCHER;;ERIC M G CIRCLAEYS;;ALAN C DYE;;DANIEL E GOBERA RUBALCAVA;;CYRUS DANIEL IRANI;;STEPHEN O LEMAY;;BRENDAN J LANGOLANT;;PAULO MICHAELO LOPEZ;;RYAN O'ROURKE;;HENRIQUE PENHA;;JUSTIN S TITI;;CHRISTOPHER WILSON,,https://lens.org/173-947-311-899-216,Patent Application,no,0,0,39,52,0,G06F16/44;;G06F3/0488;;G06F3/0484;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F3/0481;;G06F3/04842;;G06F16/447;;G06F16/23;;G06F3/04883;;G06F2203/04803;;G06F2203/04806;;G06F16/44;;G06F16/435;;G06F16/438;;G06F2203/04105;;G06F3/04883;;G06F3/04886;;G06F3/04817;;G06F3/03547;;G06F16/178;;G06F3/0481;;G06F3/04842;;G06T1/0007;;G06T2200/24,G06F3/0484,,0,0,,,,ACTIVE
240,EP,A2,EP 4316615 A2,049-020-251-864-564,2024-02-07,2024,EP 23217005 A,2015-08-27,US 201462044990 P;;US 201562129828 P;;EP 21168916 A;;EP 18154145 A;;EP 15771747 A;;US 2015/0047282 W,2014-09-02,PHYSICAL ACTIVITY AND WORKOUT MONITOR,"The present disclosure relates to devices and processes for monitoring attributes of a user's physical activity (e.g., workout) or inactivity, and to user interfaces (e.g., an activity indicator) for displaying the same. In some examples, a device determines whether physical activity corresponds to a first type based on a first set of criteria, and whether physical activity corresponds to a second type based on a second set of criteria. In some examples, the device controls an inactivity timer that measures user's inactivity. In some examples, the device displays a first visual representation of an attribute or amount of a first type of physical activity, and a second visual representation of an attribute or amount of a second type. In some examples, the device displays a third visual representation of an attribute or amount of a third type of activity. In some examples, the third visual representation corresponds to user's inactivity.
",APPLE INC,BLAHNIK JAY;;BUTCHER GARY IAN;;CHEN KEVIN WILL;;GRAHAM DAVID CHANCE;;KEEN DANIEL S;;RUSHING JUSTIN SHANE;;SHORTLIDGE T ALLAN;;DAVYDOV ANTON M;;DYE ALAN C;;IVE JONATHAN P;;KENNEDY ZACHERY;;MINJACK ZACHURY;;PARK DENNIS S;;SCHMITT BRIAN;;LYNCH KEVIN,,https://lens.org/049-020-251-864-564,Patent Application,yes,26,0,87,1267,0,A61B5/103;;G16H20/30;;G16H40/67;;G16H20/30;;A61B5/1112;;A61B5/1116;;A61B5/1118;;A61B5/1123;;A61B5/6801;;A61B5/7435;;A61B2503/10;;A61B5/1118;;A61B5/1123;;A61B5/7435;;A61B2503/10;;G06F3/048;;G06F3/0482;;G06F3/04817;;A61B5/1112;;A61B5/1116;;A61B5/6801;;G16H20/40;;G16H20/30,A63B71/06,,0,0,,,,PENDING
241,US,B2,US 9860451 B2,148-328-007-098-044,2018-01-02,2018,US 201514863432 A,2015-09-23,US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;MANZARI BEHKISH J;;MEZAK CHARLES A;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE,APPLE INC (2016-01-20),https://lens.org/148-328-007-098-044,Granted Patent,yes,1132,3,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0487;;G06F3/0488;;G06V10/10;;G06V20/00;;G11B27/031;;G11B27/34;;H04N1/00;;H04N1/21;;H04N5/235;;H04N101/00,,575,5,021-411-866-534-301;;025-388-407-138-206;;102-140-305-428-255;;172-005-321-198-602;;115-594-732-723-118,10.1145/1449715.1449730;;10.1145/1056808.1056920;;10.1145/1738826.1738856;;10.1145/964696.964719;;10.1016/j.jss.2007.04.045,"Agarwal, “How to Copy and Paste Text on Windows Phone 8,” Guiding Tech, http://web.archive.org/web20130709204246/http://www.guidingtech.com/20280/copy-paste-text-windows-phone-8/, Jul. 9, 2013, 10 pages.;;Alzona, “Full Screen Maximization with RightZoom,” http://www.brighhub.com/computing/mac-platform/articles/31024.aspx>, Mar. 31, 2009, 6 pages.;;Apple Inc., “iPhone User Guide for iPhone and iPhone 3G,” http://manuals.info.apple.com/en—US/iPhone—User—Guide.pdf, Jul. 11, 2008, 154 pages.;;Ask.MetaFilter, “Enable Screen Resize?” ask. Metafilter.com, Jan. 29, 2006, http://ask.metafilter.com/31720/Enable-screen-resize, 4 pages.;;Awduche et al., “Synchronized Broadcast in Cellular Networks,” 2nd Telecommunications R&D Conference in Massachusetts, Mar. 1996, 12 pages.;;Azundris, “A Fire in the Sky,” http://web.archive.org/web/20140722062639/http://blog.azundrix.com/archives/168-A-fire-in-the-sky.html, Jul. 22, 2014, 8 pages.;;Bautista, “Microsoft Mathematics Tutorial 7—The Ink Input”, <URL:http://mathandmultimedia.com/2012/05/23/microsoft-math-tutorial-7-ink>, May 23, 2012, 3 pages.;;CrackBerry Forums, Windows 8 Bezel Control and Gestures, http://wwwforums.crackberry.com/blackberry-playbook-f222/windows-8-bezel-control-gestures-705129/, Mar. 1, 2012, 8 pages.;;Crook, “Microsoft Patenting Multi-Screen, Milti-Touch Gesures,” http://techcrunch.com/2011/08/25/microsoft-awarded-patents-for-multi-screen-multi-touch-gestures/, Aug. 25, 2011, 8 pages.;;Cvil.ly—a design blog, Interesting Touch Interactions on Windows 8, http://cvil.ly/2011/06/04/interesting-touch-interactions-on-windows-8/, Jun. 4, 2011, 3 pages.;;Davidson, et al., “Extending 2D Object Arrangement with Pressure-Sensitive Layering Cues”, Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology, Oct. 19, 2008, 4 pages.;;Deeter, “DigiStamp Signs Strategic Partnership with European Trust Center EuroSignCard to Safeguard Monetary Transactions in Financial Sector,” http://proquest.umi.com/, Mar. 14, 2001, 2 pages.;;Dilger, “Inside Apple's iPad: Multitasking,” Appleinsider.com, <http://www.appleinsider.com/articles/10/02/18/inside—apples—ipad—multitasking.html>, Feb. 17, 2010, 3 pages.;;Dinwiddie, et al., “Combined-User Interface for Computers, Television, Video Recorders, and Telephone, ETC”, IP.COM Journal, Aug. 1, 1990, 3 Pages.;;Fahey, “The iPad Blows Up iPhone Apps Read Good,” Kotaku http://kotaku.com/5458316/the-ipad-blows-up-iphone-apps-rel-good, Jan. 27, 2010, 3 pages.;;Fehily, “Visual QuickStart Guide: Microsoft Windows 7,” Peachpit Press, 9 pages.;;Fenlon, “The Case for Bezel Touch Gestures on Apple's iPad,” http://www.tested.com/tech/tablets/3104-the case-for-bezel-touch-gestures-on-apples-ipad/, Nov. 2, 2011, 6 pages.;;Flowplayer, “Slowmotion: Flowplayer,” https://web.archive.org/web/20150226191526/http://flash.flowplayer.org/plugins/streaming/slowmotion.html, Feb. 26, 2015, 4 pages.;;Forlines, et al., “Glimpse: a Novel Input Model for Multi-level Devices”, Chi '05 Extended Abstracts on Human Factors in Computing Systems, Apr. 2, 2005, 4 pages.;;Gorman, “Hands-On With Immersion HD Integrator Hi-Fi Haptics,” http://www.engadget.com/2012/02/23/hands-on-with-immersion-hd-integrator-hi-fi-haptics/?utm—medium=referral&utm—source=pulsenews, Feb. 23, 2012, 10 pages.;;Harris, “Windows 8 Consumer Preview: Product Demo,” https://www.youtube.com/watch?feature=[;auer-embedded&v=jDYAQmQ-phX8, Feb. 28, 2012, 3 pages.;;Harrison, “Stylus-Based Interface with Full Mouse Emulation”, IBM Technical Disclosure Bulletin, vol. 34, No. 10B, Mar. 1, 1992, 3 pages.;;HTC, “HTC One (M7),” Wikipedia, the free encyclopedia, https://en.wikipedia.org/wiki/HTC—One—(M7), Mar. 2013, 20 pages.;;HTC, “User Manual—PDA Phone—HTC—P3050 Touch,” http://web.archive.org/web/20101228223033/http://www.comparecellular.com, Nov. 2, 2007, 154 pages.;;iCIMS Recruiting Software, “Blackberry Playbook Review,” http://www.tested.com/tech.tablets/5749-blackberry-playbook-review/, 2015, 11 pages.;;Jade et al., “Apple's iPhone 4.0 to Support Multitasking via Expose-like Interface,” AppleInsider.com, Mar. 31, 2010, 4 pages.;;Jade et al., “Apple's iPhone 4.0 Software to Deliver Multitasking Support,” AppleSider.com, Mar. 11, 2010, 3 pages.;;Kishore, “Make the OS X Maximize Button Work like Windows,” http://www.switchingtomac.com/making-the-switch/make-the-os-x-maximize-buttom-work-like-windows/, May 5, 2009, 11 pages.;;MacRumors, “Fit to Screen Button Poll for Mac / Windows Users,” http://forums.macrumors.com/showthread.php?t=615215>, Dec. 11, 2008, 15 pages.;;MacRumors, “Window, Fit to Screen?,” http://forums.macrumors.com/showthread.php?t=439783>, Feb. 22, 2008, 5 pages.;;McRitchie, “Internet Explorer Right-Click Menus,” http://web.archive.org/web-201405020/http:/dmcritchie.mvps.org/ie/rightie6.htm, May 2, 2014, 10 pages.;;MetaFilter Network Inc., “Enable Screen Resize?”, http://ask.metafilter.com/31720/Enable-screen-resize>, Jan. 29, 2006, 4 pages.;;Mick, “iPhone OS 4.0 Will Bring True Multitasking This Summer”, Daily Tech, http:///www.dailytech.com/report+iphone+os+40+will+bring+true+multitasking+this+summer/article 17878.htm>, Mar. 11, 2010, 3 pages.;;Minsky, “Computational Haptics the Sandpaper System for Synthesizing Texture for a Force-Feedback Display,” Massachusetts Institute of Technology, Jun. 1978, 217 pages.;;Moth, “Share Code—Write Code Once for Both Mobile and Desktop Apps,” MSDN Magazine, Jul. 2007, http://msdn.microsoft.com/en-us/magazine/cc163387.aspx, 8 pages.;;Newman, “Sprint's HTC EVO 4G: 5 Killer Features,” pcworld, http://www.pcworld.com/article/192286/sprints—htc—evo—4g—5—killer—features.html, Mar. 24, 2010, 3 pages.;;Nickinson, “Review: The New HTC Sense Interface on Android Phones,” Android Central, Feb. 22, 2010, http://www.androidcentral.com/review-new-htc-sense-android-phone, 10 pages.;;Nilsson, “Design Guidelines for Mobile Applications,” SINTEF ICT, Jun. 2008, 73 pages.;;Nilsson et al., “Design Patterns for User Interface for Mobile Applications,” Advances in Engineering Software, Elsevier Science, Oxford, GB vol. 40, No. 12, Dec. 1, 2009, 11 pages.;;O'Hara, et al., “Pressure-Sensitive Icons”, IP.COM Journal, Jun. 1, 1990, 2 Pages.;;Pallenberg, “Wow, the new iPad had gestures.” https://plus.google.com/+SaschaPallenberg/posts/aaJtJogu8ac, Mar. 7, 2012, 2 pages.;;Pradeep, “Android App Development—Microsoft Awarded With Patents on Gestures Supported on Windows 8,” http://mspoweruser.com/microsoft-awarded-with-patents-on-gestures-supported-on-windows-8/, Aug. 25, 2011, 16 pages.;;Quinn, et al., “Zoofing! Faster List Selections with Pressure-Zoom-Flick-Scrolling”, Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group on Design, Nov. 23, 2009, ACM Press, vol. 411, 8 pages.;;Reiger, “Effective Design for Multiple Screen Sizes,” mobiForge, http://mobiforge.com/designing/story/effective-design-multiple-screen-sizes, Jan. 2009, 12 pages.;;Rekimoto, et al., “PreSense: Interaction Techniques for Finger Sensing Input Devices”, Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology, Nov. 30, 2003, 10 pages.;;Rekimoto, et al., “PreSensell: Bi-directional Touch and Pressure Sensing Interactions with Tactile Feedback”, Conference on Human Factors in Computing Systems Archive, ACM, Apr. 22, 2006, 6 pages.;;Robertson et al., “The Task Gallery: A 3D Window Manager,” Redmond, WA, Sep. 12, 1999, 8 pages.;;Savoy, “HTC Enhances Sense with Leap and Friend Stream (updated with video),” Engadget, http://www.engadget.com/2010/02/16/htc-enhances-sense-with-leap-and-friend-stream/, Feb. 16, 2010, 4 pages.;;Seffah et al., Multi-devices “Multiple” User Interfaces: Development Models and Research Opportunities, The Journal of Systems Software, www.sciencedirect.com, Dec. 25, 2003, 14 pages.;;Siracusa, “Antacid Tablet,” http://arstechnica.com/staff/2010/01/antacid-tablet/>, Jan. 1, 2010, 3 pages.;;Song, et al., “Grips and Gestures on a Multi-Touch Pen,” The ACM CHI Conference on Human Factors in Computing Systems, <URL:research.microsoft.com/pubs/.../gripsandgenstures%20mtpen-chi201>, May 7-12, 2011,10 pages.;;Sony, “Sony Xperia Z1”, Wikipedia, the free encyclopedia, https://en.wikipedia.org/wiki/Sony—Xperia—Z1, Sep. 2013, 10 pages.;;Tidwell, “Designing Interfaces,” O'Reilly Media, Inc., USA, Nov. 2005, 348 pages.;;Viana et al., “Xmobile: A MB-UID Environment for Semi-Automatic Generation of Adaptive Applications for Mobile Devices,” The Journal of Systems and Software, www.sciencedirect.com, Jun. 9, 2007, 13 pages.;;Windows, “Stupid Geek Tricks: Tile or Cascade Multiple Windows in Windows 7,” How to Geek, Feb. 18, 2010, 3 pages.;;YouTube, “Blackberry Playbook bezel interation,” https://www.youtube.com/watch?v=YGkzFqnOwXI, Jan. 10, 2011, 2 pages.;;Office Action, dated May 22, 2012, received in U.S. Appl. No. 12/888,381, 18 pages.;;Final Office Action, dated Nov. 19, 2012, received in U.S. Appl. No. 12/888,381, 14 pages.;;Office Action, dated Dec. 10, 2013, received in U.S. Appl. No. 12/888,381, 13 pages.;;Notice of Allowance, dated Oct. 21, 2014, received in U.S. Appl. No. 12/888,381, 8 pages.;;Notice of Allowance, dated Feb. 17, 2015, received in U.S. Appl. No. 12/888,381, 5 pages.;;Notice of Allowance (corrected), dated Apr. 9, 2015, received in U.S. Appl. No. 12/888,381, 2 pages.;;Office Action, dated Aug. 8, 2013, received in Australian Patent Application No. 2010350740, 3 pages.;;Office Action, dated Aug. 28, 2012, received in Chinese Patent Application No. 201010602688.2, which corresponds with U.S. Appl. No. 12/888,381, 6 pages.;;Office Action, dated May 24, 2013, received in Chinese Patent Application No. 201010602688.2, which corresponds with U.S. Appl. No. 12/888,381, 7 pages.;;Office Action, dated Aug. 6, 2013, received in European Patent Application No. 10760867.1, which corresponds with U.S. Appl. No. 12/888,381, 4 pages.;;Office Action, dated Dec. 6, 2013, received in Japanese Patent Application No. 2013-503722, which corresponds with U.S. Appl. No. 12/888,381, 2 pages.;;Office Action, dated Nov. 29, 2013, received in Korean Patent Application No. 2012-7029281, which corresponds with U.S. Appl. No. 12/888,381, 4 pages.;;Office Action, dated May 10, 2012, received in U.S. Appl. No. 12/888,382, 9 pages.;;Final Office Action, dated Nov. 15, 2012, received in U.S. Appl. No. 12/888,382, 11 pages.;;Office Action, dated Dec. 10, 2013, received in U.S. Appl. No. 12/888,382, 12 pages.;;Notice of Allowance, dated Oct. 31, 2014, received in U.S. Appl. No. 12/888,382, 5 pages.;;Notice of Allowance, dated Feb. 13, 2015, received in U.S. Appl. No. 12/888,382, 6 pages.;;Office Action, dated May 17, 2012, received in U.S. Appl. No. 12/888,384, 15 pages.;;Final Office Action, dated Nov. 7, 2012, received in U.S. Appl. No. 12/888,384, 14 pages.;;Office Action, dated May 16, 2012, received in U.S. Appl. No. 12/888,386, 12 pages.;;Final Office Action, dated Nov. 8, 2012, received in U.S. Appl. No. 12/888,386, 13 pages.;;Office Action, dated Jan. 23, 2013, received in U.S. Appl. No. 12/888,389, 11 pages.;;Final Office Action, dated Sep. 12, 2013, received in U.S. Appl. No. 12/888,389, 10 pages.;;Notice of Allowance, dated Sep. 8, 2014, received in U.S. Appl. No. 12/888,389, 13 pages.;;Notice of Allowance, dated Feb. 11, 2015, received in U.S. Appl. No. 12/888,389, 13 pages.;;Notice of Allowance, dated Jun. 15, 2012, received in U.S. Appl. No. 12/888,391, 23 pages.;;Office Action, dated Jun. 28, 2013, received in U.S. Appl. No. 13/077,524, 17 pages.;;Office Action, dated Apr. 4, 2013, received in U.S. Appl. No. 12/789,426, 8 pages.;;Office Action, dated Feb. 12, 2014, received in U.S. Appl. No. 13/077,524, 13 pages.;;Notice of Allowance, dated May 27, 2015, received in U.S. Appl. No. 13/077,524, 9 pages.;;Notice of Allowance, dated Sep. 15, 2015, received in U.S. Appl. No. 13/077,524, 9 pages.;;Office Action, dated Mar. 19, 2013, received in U.S. Appl. No. 13/333,909, 18 pages.;;Final Office Action, dated Dec. 5, 2013, received in U.S. Appl. No. 13/333,909, 24 pages.;;Notice of Allowance, dated Mar. 31, 2014, received in U.S. Appl. No. 13/333,909. 20 pages.;;Office Action, dated Dec. 18, 2015, received in Australian Patent Application No. 2013368440, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Apr. 5, 2016, received in Korean Patent Application No. 102015-7018851, which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;Office Action, dated Dec. 17, 2015, received in U.S. Appl. No. 14/536,426, 28 pages.;;Office Action, dated Jul. 15, 2015, received in Australian Patent Application No. 2013259606, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 18, 2015, received in Australian Patent Application No. 2015101231, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Mar. 4, 2016, received in Japanese Patent Application No. 2015-511644, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Feb. 1, 2016, received in Australian Patent Application No. 2013368441, which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Notice of Allowance, dated Mar. 30, 2016, received in Australian Patent Application No. 2013368441, which corresponds with U.S. Appl. No. 14/608,926, 1 page.;;Office Action, dated Mar. 14, 2016, received in Japanese Patent Application No. 2015-549392, which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Office Action, dated Jul. 17, 2015, received in Australian Patent Application No. 2013259613, which corresponds with U.S. Appl. No. 14/536,646, 5 pages.;;Office Action, dated Nov. 12, 2015, received in European Patent Application No. 13724102.2, which corresponds with U.S. Appl. No. 14/536,646, 6 pages.;;Office Action, dated Feb. 29, 2016, received in Japanese Patent Application No. 2015-511645, which corresponds with U.S. Appl. No. 14/536,646, 5 pages.;;Office Action, dated Aug. 27, 2015, received in Australian Patent Application No. 2013259614, which corresponds with U.S. Appl. No. 14/536,141, 4 pages.;;Office Action, dated Jan. 7, 2016, received in European Patent Application No. 13726053.5, which corresponds with U.S. Appl. No. 14/536,141, 10 pages.;;Office Action, dated Feb. 29, 2016, received in Japanese Patent Application No. 2015-511646, which corresponds with U.S. Appl. No. 14/536,141, 3 pages.;;Office Action, dated Jan. 29, 2016, received in Australian Patent Application No. 2013368443, which corresponds with U.S. Appl. No. 14/536,141, 3 pages.;;Notice of Allowance, dated Mar. 11, 2016, received in Australian Patent Application No. 2013368443, which corresponds with U.S. Appl. No. 14/536,141, 2 pages.;;Office Action, dated Apr. 5, 2016, received in Korean Patent Application No. 102015-7018448, which corresponds with U.S. Appl. No. 14/536,141, 6 pages.;;Office Action, dated Jul. 9, 2015, received in Australian Patent Application No. 2013259630, which corresponds with U.S. Appl. No. 14/536,203, 3 pages.;;Office Action, dated Nov. 11, 2015, received in European Patent Application No. 13724104.8, which corresponds with U.S. Appl. No. 14/536,203, 5 pages.;;Office Action, dated Feb. 15, 2016, received in Japanese Patent Application No. 2015-511650, which corresponds with U.S. Appl. No. 14/536,203, 5 pages.;;Office Action, dated Dec. 4, 2015, received in Korean Patent Application No. 2014-7034520, which corresponds with U.S. Appl. No. 14/536,203, 4 pages.;;Office Action, dated Aug. 10, 2015, received in Australian Patent Application No. 2013259637, which corresponds with U.S. Appl. No. 14/536,267, 3 pages.;;Office Action, dated Jan. 29, 2016, received in Japanese Patent Application No. 2015-511652, which corresponds with U.S. Appl. No. 14/536,267, 3 pages.;;Office Action, dated Dec. 4, 2015, received in Korean Patent Application No. 2014-7034530, which corresponds with U.S. Appl. No. 14/536,267, 3 pages.;;Office Action, dated Aug. 18, 2015, received in Australian Patent Application No. 2013259642, which corresponds with U.S. Appl. No. 14/536,291, 3 pages.;;Office Action, dated Jan. 7, 2016, received in European Patent Application No. 13724107.1, which corresponds with U.S. Appl. No. 14/052,515, 11 pages.;;Office Action, dated Nov. 23, 2015, received in U.S. Appl. No. 14/183,316, 17 pages.;;Office Action, dated Jul. 7, 2015, received in U.S. Appl. No. 14/183,347, 14 pages.;;Final Office Action, dated Dec. 18, 2015, received in U.S. Appl. No. 14/183,347, 6 pages.;;Notice of Allowance, dated Apr. 6, 2016, received in U.S. Appl. No. 14/183,347, 7 pages.;;Notice of Allowance (corrected), dated Apr. 19, 2016, received in U.S. Appl. No. 14/183,347, 3 pages.;;Certificate of Grant, dated Apr. 7, 2016, received in Australian Patent Application No. 2016100293, which corresponds with U.S. Appl. No. 14/864,737, 1 page.;;Office Action, dated Apr. 5, 2016, received in Danish Patent Application No. 201500577, which corresponds with U.S. Appl. No. 14/864,737, 7 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 2016100254, which corresponds with U.S. Appl. No. 14/866,981, 1 page.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500575, which corresponds with U.S. Appl. No. 14/866,981, 9 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 2016100251, which corresponds with U.S. Appl. No. 14/866,159, 1 page.;;Office Action, dated Mar. 9, 2016, received in Danish Patent Application No. 201500574, which corresponds with U.S. Appl. No. 14/866,159, 11 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 2016100247, which corresponds with U.S. Appl. No. 14/868,078, 1 page.;;Office Action, dated Mar. 30, 2016, received in Danish Patent Application No. 201500588, which corresponds with U.S. Appl. No. 14/868,078, 9 pages.;;Office Action, Apr. 4, 2016, received in Danish Patent Application No. 201500582, which corresponds with U.S. Appl. No. 14/863,432, 10 pages.;;Office Action, dated Mar. 22, 2016, received in Danish Patent Application No. 201500576, which corresponds with U.S. Appl. No. 14/866,989, 10 pages.;;Office Action, dated Feb. 3, 2016, received in Danish Patent Application No. 201500592, which corresponds with U.S. Appl. No. 14/869,899, 9 pages.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500593, which corresponds with U.S. Appl. No. 14/866,992, 10 pages.;;Office Action, dated Nov. 30, 2015, received in U.S. Appl. No. 14/845,217, 24 pages.;;Final Office Action, dated Apr. 22, 2016, received in U.S. Appl. No. 14/845,217, 36 pages.;;Office Action, dated Feb. 3, 2016, received in U.S. Appl. No. 14/856,517, 36 pages.;;Office Action, dated Feb. 11, 2016, received in U.S. Appl. No. 14/856,519, 34 pages.;;Office Action, dated Feb. 1, 2016, received in U.S. Appl. No. 14/857,645, 15 pages.;;Office Action, dated Jan. 25, 2016, received in U.S. Appl. No. 14/864,580, 29 pages.;;Office Action, dated Apr. 8, 2016, received in Danish Patent Application No. 201500584, which corresponds with U.S. Appl. No. 14/864,580, 9 pages.;;Office Action, dated Apr. 19, 2016, received in U.S. Appl. No. 14/864,627, 9 pages.;;Office Action, dated Apr. 8, 2016, received in Danish Patent Application No. 201500585, which corresponds with U.S. Appl. No. 14/864,627, 9 pages.;;Office Action, dated Mar. 29, 2016, received in U.S. Appl. No. 14/866,361, 22 pages.;;Office Action, dated Apr. 7, 2016, received in Danish Patent Application No. 201500579, which corresponds with U.S. Appl. No. 14/866,361, 10 pages.;;Office Action, dated Mar. 22, 2016, received in Danish Patent Application No. 201500587, which corresponds with U.S. Appl. No. 14/866,987, 8 pages.;;Office Action, dated Apr. 1, 2016, received in Danish Patent Application No. 201500589, which corresponds with U.S. Appl. No. 14/866,989, 8 pages.;;Office Action, dated Apr. 11, 2016, received in U.S. Appl. No. 14/871,236, 23 pages.;;Office Action, dated Apr. 8, 2016, received in Danish Patent Application No. 201500595, which corresponds with U.S. Appl. No. 14/871,236, 12 pages.;;Office Action, dated Apr. 6, 2016, received in Danish Patent Application No. 201500596, which corresponds with U.S. Appl. No. 14/870,882, 7 pages.;;Office Action, dated Apr. 7, 2016, received in Danish Patent Application No. 201500597, which corresponds with U.S. Appl. No. 14/871,227, 7 pages.;;Office Action, dated Apr. 18, 2016, received in Danish Patent Application No. 201500601, which corresponds with U.S. Appl. No. 14/871,336, 8 pages.;;Notice of Allowance, dated Apr. 18, 2016, received in Danish Patent Application No. 201500600, which corresponds with U.S. Appl. No. 14/871,462, 7 pages.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500594, which corresponds with U.S. Appl. No. 14/867,823, 10 pages.;;Office Action, dated Mar. 21, 2016, received in Danish Patent Application No. 201500598, which corresponds with U.S. Appl. No. 14/867,892, 9 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 20161002253, which corresponds with U.S. Appl. No. 14/867,990, 1 page.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500581, which corresponds with U.S. Appl. No. 14/867,990, 9 pages.;;International Search Report and Written Opinion, dated Dec. 10, 2010, received in International Patent Application No. PCT/US2010/050057, which corresponds with U.S. Appl. No. 12/888,381, 9 pages.;;International Preliminary Search Report on Patentability, dated Oct. 9, 2012, received in International Patent Application No. PCT/US2010/050057, which corresponds with U.S. Appl. No. 12/888,381, 6 pages.;;International Search Report and Written Opinion dated May 26, 2014, received in International Application No. PCT/US2013/040053, which corresponds to U.S. Appl. No. 14/535,671, 32 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040053, which corresponds to U.S. Appl. No. 14/535,671, 26 pages.;;Invitation to Pay Additional Fees dated Feb. 10, 2014, received in International Application No. PCT/US2013/069472, which corresponds to U.S. Appl. No. 14/608,895, 6 pages.;;International Search Report and Written Opinion dated Apr. 7, 2014, received in International Application No. PCT/US2013/069472, which corresponds to U.S. Appl. No. 14/608,895, 24 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069472, which corresponds with U.S. Appl. No. 14/608,895, 18 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040054, which corresponds to U.S. Appl. No. 14/536,235, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040054, which corresponds to U.S. Appl. No. 14/536,235, 11 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040056, which corresponds to U.S. Appl. No. 14/536,367, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040056, which corresponds to U.S. Appl. No. 14/536,367, 11 pages.;;Extended European Search Report, dated Nov. 6, 2015, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;International Search Report and Written Opinion dated Aug. 6, 2013, received in International Application No. PCT/US2013/040058, which corresponds to U.S. Appl. No. 14/536,426, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040058, which corresponds to U.S. Appl. No. 14/536,426, 11 pages.;;Invitation to Pay Additional Fees dated Sep. 25, 2013, received in International Application No. PCT/US2013/040061, which corresponds to U.S. Appl. No. 14/536,464, 6 pages.;;International Search Report and Written Opinion dated Feb. 5, 2014, received in International Application No. PCT/US2013/040061, which corresponds to U.S. Appl. No. 14/536,464, 30 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040061, which corresponds to U.S. Appl. No. 14/536,464, 26 pages.;;Invitation to Pay Additional Fees dated Oct. 8, 2013, received in International Application No. PCT/US2013/040067, which corresponds to U.S. Appl. No. 14/536,644, 8 pages.;;International Search Report and Written Opinion dated May 8, 2014, received in International Application No. PCT/US2013/040067, which corresponds to U.S. Appl. No. 14/536,644, 45 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040067, which corresponds to U.S. Appl. No. 14/536,644, 36 pages.;;International Search Report and Written Opinion dated Mar. 12, 2014, received in International Application No. PCT/US2013/069479, which corresponds with U.S. Appl. No. 14/608,926, 14 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069479, which corresponds with U.S. Appl. No. 14/608,926, 11 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040070, which corresponds to U.S. Appl. No. 14/535,646, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040070, which corresponds to U.S. Appl. No. 14/535,646, 10 pages.;;Invitation to Pay Additional Fees dated Oct. 28, 2013, received in International Application No. PCT/US2013/040072, which corresponds to U.S. Appl. No. 14/536,141, 7 pages.;;International Search Report and Written Opinion dated Apr. 7, 2014, received in International Application No. PCT/US2013/040072, which corresponds to U.S. Appl. No. 14/536,141, 38 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040072, which corresponds to U.S. Appl. No. 14/536,141, 32 pages.;;Invitation to Pay Additional Fees dated Feb. 14, 2014, received in International Application No. PCT/US2013/069483, which corresponds with U.S. Appl. No. 14/608,942, 7 pages.;;International Search Report and Written Opinion dated Apr. 7, 2014, received in International Application No. PCT/US2013/069483, which corresponds with U.S. Appl. No. 14/608,942, 18 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Application No. PCT/2013/069483, which corresponds to U.S. Appl. No. 14/608,942, 13 pages.;;Invitation to Pay Additional Fees dated Oct. 28, 2013, received in International Application No. PCT/US2013/040087, which corresponds to U.S. Appl. No. 14/536,166, 8 pages.;;International Search Report and Written Opinion dated Mar. 3, 2014, received in International Application No. PCT/US2013/040087, which corresponds to U.S. Appl. No. 14/536,166, 35 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040087, which corresponds to U.S. Appl. No. 14/536,166, 29 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040093, which corresponds to U.S. Appl. No. 14/536,203, 11 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013040093, which corresponds to U.S. Appl. No. 14/536,203, 9 pages.;;Invitation to Pay Additional Fees dated Apr. 17, 2014, received in International Application No. PCT/US2013/069484, which corresponds with U.S. Appl. No. 14/608,965, 7 pages.;;International Search Report and Written Opinion dated Jul. 9, 2014, received in International Application No. PCT/US2013/069484, which corresponds with U.S. Appl. No. 14/608,965, 17 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069484, which corresponds with U.S. Appl. No. 14/608,965, 12 pages.;;Invitation to Pay Additional Fees dated Sep. 25, 2013, received in International Application No. PCT/US2013/040098, which corresponds to U.S. Appl. No. 14/536,247, 8 pages.;;International Search Report and Written Opinion dated Feb. 5, 2014, received in International Application No. PCT/US2013/040098, which corresponds to U.S. Appl. No. 14/536,247, 35 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040098, which corresponds to U.S. Appl. No. 14/536,247, 27 pages.;;Invitation to Pay Additional Fees dated Aug. 7, 2013, received in International Application No. PCT/US2013/040101, which corresponds to U.S. Appl. No. 14/536,267, 7 pages.;;International Search Report and Written Opinion dated Jan. 27, 2014, received in International Application No. PCT/US2013/040101, which corresponds to U.S. Appl. No. 14/536,267, 30 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040101, which corresponds to U.S. Appl. No. 14/536,267, 24 pages.;;Invitation to Pay Additional Fees dated Aug. 7, 2013, received in International Application No. PCT/US2013/040108, which corresponds to U.S. Appl. No. 14/536,291, 6 pages.;;International Search Report and Written Opinion dated Jan. 8, 2014, received in International Application No. PCT/US2013/040108, which corresponds to U.S. Appl. No. 14/536,291, 30 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040108, which corresponds to U.S. Appl. No. 14/536,291, 25 pages.;;Invitation to Pay Additional Fees dated Apr. 1, 2014, received in International Application No. PCT/US2013/069486, which corresponds with U.S. Appl. No. 14/608,985, 7 pages.;;International Search Report and Written Opinion dated Jun. 2, 2014, received in International Application No. PCT/US2013/069486, which corresponds with U.S. Appl. No. 14/608,985, 7 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069486, which corresponds with U.S. Appl. No. 14/608,985, 19 pages.;;International Search Report and Written Opinion dated Mar. 6, 2014, received in International Application No. PCT/US2013/069489, which corresponds with U.S. Appl. No. 14/609,006, 12 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069489, which corresponds with U.S. Appl. No. 14/609,006, 10 pages.;;Anonymous, “Nokia 808 PureView screenshots”, retrieved from Internet; no URL, Nov. 12, 2012, 8 pages.;;Anonymous, “Nokia 808 PureView User Guide,” http://download-fds.webapps.microsoft.com/supportFiles/phones/files/pdf—guides/devices/808/Nokia—808—UG—en—APAC.pdf, Jan. 1, 2012, 144 pages.;;B-log—betriebsraum weblog, “Extremely Efficient Menu Selection: Marking Menus for the Flash Platform,” http://www.betriebsraum.de/blog/2009/12/11/extremely-efficient-menu-selection-marking -for-the-flash-platform, Dec. 11, 2009, 9 pages.;;Bolluyt, “5 Apple Watch Revelations from Apple's New WatchKit”, http://www.cheatsheet.com/tecnology/5-apple-watch-revelations-from-apples-new-watchkit.html/?a=viewall, Nov. 22, 2014, 3 pages.;;Clark, “Global Moxie, Touch Means a Renaissance for Radial Menus,” http://globalmoxie.com/blog/radial-menus-for-touch-ui˜print.shtml, Jul. 17, 2012, 7 pages.;;Cohen, Cinemagraphs are Animated Gifs for Adults, http://www.tubefilter.com/2011/07/10/cinemagraph, Jul. 10, 2011, 3 pages.;;Farshad, “SageThumbs—Preview and Convert Pictures From Windows Context Menu”, https://web.addictivetips.com/windows-tips/sagethumbs-preview-and-convert-photos-from-windows-context-menu, Aug. 8, 2011, 5 pages. et al.",ACTIVE
242,US,A1,US 2023/0133870 A1,024-232-462-049-217,2023-05-04,2023,US 202218089397 A,2022-12-27,US 202218089397 A;;US 202117524692 A;;US 202017003869 A;;US 201916534214 A;;US 201916252478 A;;US 201514864529 A;;US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device having a camera, while displaying a live preview for the camera, detects activation of a shutter button at a first time. In response, the electronic device acquires, by the camera, a representative image that represents a first sequence of images, and a plurality of images after acquiring the representative image, and also displays an indication in the live preview that the camera is capturing images for the first sequence of images. The electronic device groups images acquired by the camera in temporal proximity to the activation of the shutter button at the first time into the first sequence of images, such that the first sequence of images includes a plurality of images acquired by the camera prior to detecting activation of the shutter button at the first time, the representative image, and the plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;MANZARI BEHKISH J;;MEZAK CHARLES A;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE,,https://lens.org/024-232-462-049-217,Patent Application,yes,5,3,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0487;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/0485;;G06F3/0488;;G06F3/04883;;G06V10/10;;G06V20/00;;G11B27/00;;G11B27/031;;G11B27/034;;G11B27/10;;G11B27/34;;H04N1/00;;H04N1/21;;H04N23/60;;H04N23/62;;H04N23/63;;H04N23/73,,0,0,,,,ACTIVE
243,US,B2,US 11835985 B2,005-644-593-335-223,2023-12-05,2023,US 202218089397 A,2022-12-27,US 202218089397 A;;US 202117524692 A;;US 202017003869 A;;US 201916534214 A;;US 201916252478 A;;US 201514864529 A;;US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device having a camera, while displaying a live preview for the camera, detects activation of a shutter button at a first time. In response, the electronic device acquires, by the camera, a representative image that represents a first sequence of images, and a plurality of images after acquiring the representative image, and also displays an indication in the live preview that the camera is capturing images for the first sequence of images. The electronic device groups images acquired by the camera in temporal proximity to the activation of the shutter button at the first time into the first sequence of images, such that the first sequence of images includes a plurality of images acquired by the camera prior to detecting activation of the shutter button at the first time, the representative image, and the plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;MANZARI BEHKISH J;;MEZAK CHARLES A;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE,,https://lens.org/005-644-593-335-223,Granted Patent,yes,1650,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N23/63;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/0485;;G06F3/0487;;G06F3/0488;;G06F3/04883;;G06V10/10;;G06V20/00;;G11B27/00;;G11B27/031;;G11B27/034;;G11B27/10;;G11B27/34;;H04N1/00;;H04N1/21;;H04N23/60;;H04N23/62;;H04N23/73;;H04N101/00,,1547,15,021-411-866-534-301;;019-871-666-840-588;;025-388-407-138-206;;106-749-109-549-186;;000-218-078-532-210;;081-936-153-515-803;;057-382-954-955-516;;142-794-696-385-160;;169-380-977-375-129;;102-140-305-428-255;;172-005-321-198-602;;057-933-840-517-153;;030-915-052-220-704;;032-349-806-075-996;;060-886-589-965-181,10.1145/1449715.1449730;;10.1109/whc.2011.5945553;;10.1145/1056808.1056920;;19910657;;10.1109/tvcg.2009.91;;10.1109/3dui.2012.6184186;;10.1109/mspec.2009.4907374;;10.1145/1120212.1120408;;10.1109/cisis.2011.118;;10.1145/142750.143079;;10.1145/1738826.1738856;;10.1145/964696.964719;;10.1145/765891.766030;;10.1145/1518701.1518933;;10.1109/infoseee.2014.6948192;;10.1145/1622176.1622198,"Office Action, dated Mar. 2, 2023, received in Chinese Patent Application No. 202010281684.2, which corresponds with U.S. Appl. No. 14/864,601, 4 pages.;;Office Action, dated Mar. 7, 2023, received in Brazilian Patent Application No. 11201701119-9, which corresponds with U.S. Appl. No. 14/871,236, 4 pages.;;Office Action, dated Mar. 2, 2023, received in Indian Patent Application No. 202118003907, which corresponds with U.S. Appl. No. 16/243,834, 11 pages.;;Final Office Action, dated Feb. 24, 2023, received in U.S. Appl. No. 16/896,141, 23 pages.;;Office Action, dated Feb. 22, 2023, received in Chinese Patent Application No. 202010290361.X, hich corresponds with U.S. Appl. No. 17/003,869, 4 pages.;;Notice of Allowance, dated Mar. 16, 2023, received in U.S. Appl. No. 17/351,035, 23 pages.;;Notice of Allowance, dated Mar. 6, 2023, received in U.S. Appl. No. 17/524,692, 14 pages.;;Office Action, dated Feb. 16, 2023, received in U.S. Appl. No. 17/728,909, 12 pages.;;Agarwal, “How to Copy and Paste Text on Windows Phone 8,” Guiding Tech, http://web.archive.org/web20130709204246/http://www.guidingtech.com/20280/copy-paste-text-windows-phone-8/, Jul. 9, 2013, 10 pages.;;Angelov, “Sponsor Flip Wall with Jquery & CSS”, Tutorialzine. N.p., Mar. 24, 2010. Web. http://tutorialzine.com/2010/03/sponsor-wall-slip-jquery-css/, Mar. 24, 2010, 8 pages.;;Anonymous, “1-Click Installer for Windows Media Taskbar Mini-Player for Windows 7, 8, 8.1 10”, http://metadataconsulting.blogspot.de/2014/05/installer-for-windows-media-taskbar.htm, May 5, 2014, 6 pages.;;Anonymous, “Acer Liquid Z5 Duo User's Manual”, https://global-download.acer.com, Feb. 21, 2014, 65 pages.;;Anonymous, “Android—What Should Status Bar Toggle Button Behavior Be?”, https://ux.stackechange.com/questions/34814, Jan. 15, 2015, 2 pages.;;Anonymous, “Google Android 5.0 Release Date, Specs and Editors Hands On Review—CNET”, http://www.cnet.com/products/google-an-android-5-0-lollipop/, Mar. 12, 2015, 10 pages.;;Anonymous, “How Do I Add Contextual Menu to My Apple Watch App?”, http://www.tech-recipes.com/rx/52578/how-do-i-add-contextual-menu-to-my-apple-watch-app, Jan. 13, 2015, 3 pages.;;Anonymous, “[new] WMP12 with Taskbar Toolbar for Windows 7—Windows Customization—WinMatrix”, http://www.winmatrix.com/forums/index/php?/topic/25528-new-wmp12-with-taskbar-toolbar-for-windows-7, Jan. 27, 2013, 6 pages.;;Anonymous, “Nokia 808 PureView screenshots”, retrieved from Internet; no URL, Nov. 12, 2012, 8 pages.;;Anonymous, “Nokia 808 PureView User Guide,” http://download-fds.webapps.microsoft.com/supportFiles/phones/files/pdf_guides/devices/808/Nokia_808_UG_en_APAC.pdf, Jan. 1, 2012, 144 pages.;;Anonymous, “Notifications, Android 4.4 and Lower”, Android Developers, https://developer.android.com/design/patterns/notifications_k.html, May 24, 2015, 9 pages.;;Anonymous, RX-V3800AV Receiver Owner's Manual, Yamaha Music Manuals, www.Manualslib.com, Dec. 31, 2007, 169 pages.;;Anonymous, “Taskbar Extensions”, https://web.archive.org/web/20141228124434/http://msdn.microsoft.com:80/en-us/library/windows/desktop/dd378460(v=vs.85).aspx, Dec. 28, 2014, 8 pages.;;Apple, “Final Cut Express 4 User Manual”, https://wsi.li.dl/mBGZWEQ8fh556f/, Jan. 1, 2007, 1,152 pages.;;Apple, “Apple—September Event 2014”, https://www.youtube.com/watch?v=38lqQpqwPe7s, Sep. 10, 2014, 5 pages.;;Azundris, “A Fire in the Pie,” http://web.archive.org/web/20140722062639/http://blog.azundrix.com/archives/168-A-fire-in-the-sky.html, Jul. 22, 2014, 8 pages.;;Billibi, “Android 5.0 Lollipop”, https://www.bilibili.comvideo/av1636046?from=search&seid=3128140235778895126, Oct. 19, 2014, 6 pages.;;B-log—betriebsraum weblog, “Extremely Efficient Menu Selection: Marking Menus for the Flash Platform,” http://www.betriebsraum.de/blog/2009/12/11/extremely-efficient-menu-selection-marking-for-the-flash-platform, Dec. 11, 2009, 9 pages.;;Bognot, “Microsoft Windows 7 Aero Shake, Snap, and Peek”, https://www.outube.com/watch?v=vgD7wGrsQg4, Apr. 3, 2012, 4 pages.;;Bolluyt, “5 Apple Watch Revelations from Apple's New WatchKit”, http://www.cheatsheet.com/tecnology/5-apple-watch-revelations-from-apples-new-watchkit.html/?a=viewall, Nov. 22, 2014, 3 pages.;;Boring, “The Fat Thumb: Using the Thumb's Contact Size for Single-Handed Mobile Interaction”, https://www.youtube.com/watch?v=E9vGU5R8nsc&feature=youtu.be, Jun. 14, 2012, 2 pages.;;Borowska, “6 Types of Digital Affordance that Impact Your Ux”, https://www.webdesignerdepot.com/2015/04/6-types-of-digital-affordance-that-implact-your-ux, Apr. 7, 2015, 6 pages.;;Brewster, “The Design and Evaluation of a Vibrotactile Progress Bar”, Glasgow Interactive Systems Group, University of Glasgow, Glasgow, G12 8QQ, UK, 2005, 2 pages.;;Brownlee, “Android 5.0 Lollipop Feature Review!”, https//www.youtube.com/watch?v=pEDQ1z1-PvU, Oct. 27, 2014, 5 pages.;;Cheng, “iPhone 5: a little bit taller, a little bit baller”,https://arstechnica.com/gadgets/2012/09/iphone-5-a-little-bit-taller-a little-bit-baller, Oct. 14, 2021, 22 pages.;;Clark, “Global Moxie, Touch Means a Renaissance for Radial Menus,” http://globalmoxie.com/blog/radial-menus-for-touch-ui˜print.shtml, Jul. 17, 2012, 7 pages.;;Cohen, Cinemagraphs are Animated Gifs for Adults, http://www.tubefilter.com/2011/07/10/cinemagraph, Jul. 10, 2011, 3 pages.;;CrackBerry Forums, Windows 8 Bezel Control and Gestures, http://wwwforums.crackberry.com/blackberry-playbook-f222/windows-8-bezel-control-gestures-705129/, Mar. 1, 2012, 8 pages.;;Crook, “Microsoft Patenting Multi-Screen, Milti-Touch Gestures,” http://techcrunch.com/2011/08/25/microsoft-awarded-patents-for-multi-screen-multi-touch-gestures/, Aug. 25, 2011, 8 pages.;;Cvil.ly—a design blog, Interesting Touch Interactions on Windows 8, http://cvil.ly/2011/06/04/interesting-touch-interactions-on-windows-8/, Jun. 4, 2011, 3 pages.;;Davidson, et al., “Extending 2D Object Arrangement with Pressure-Sensitive Layering Cues”, Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology, Oct. 19, 2008, 4 pages.;;Dinwiddie, et al., “Combined-User Interface for Computers, Television, Video Recorders, and Telephone, Etc”, IP.COM Journal, Aug. 1, 1990, 3 Pages.;;Drinkwater, “Glossary: Pre/Post Alarm Image Buffer,” http://www.networkwebcams.com/ip-camera-learning-center/2008/07/17/glossary-prepost-alarm-image-buffer/, Jul. 17, 2008, 1 page.;;Dzyre, “10 Android Notification Features You Can Fiddle With”, http://www.hongkiat.com/blog/android-notification-features, Mar. 10, 2014, 10 pages.;;Easton-Ellett, “Three Free Cydia Utilities To Remove iOS Notification Badges”, http://www.ijailbreak.com/cydia/three-free-cydia-utilies-to-remove-ios-notification-badges, Apr. 14, 2012, 2 pages.;;Elliot, “Mac System 7”, YouTube. Web. Mar. 8, 2017, http://www.youtube.com/watch?v=XLv22hfuuik, Aug. 3, 2011, 1 page.;;Farshad, “SageThumbs-Preview And Convert Pictures From Windows Context Menu”, https://web.addictivetips.com/windows-tips/sagethumbs-preview-and-convert-photos-from-windows-context-menu, Aug. 8, 2011, 5 pages.;;Fenlon, “The Case for Bezel Touch Gestures on Apple's iPad,” http://www.tested.com/tech/tablets/3104-the case-for-bezel-touch-gestures-on-apples-ipad/, Nov. 2, 2011, 6 pages.;;Flaherty, “Is Apple Watch's Pressure-Sensitive Screen A Bigger Deal Than The Gadget Itself?”, http://www.wired.com/2014/09/apple-watchs-pressure-sensitive-screen-bigger-deal-gadget, Sep. 15, 2014, 3 pages.;;Flixel, “Cinemagraph Pro For Mac”, https://flixel.com/products/mac/cinemagraph-pro, 2014, 7 pages.;;Flowplayer, “Slowmotion: Flowplayer,” https://web.archive.org/web/20150226191526/http://flash.flowplayer.org/plugins/stre aming/slowmotion.html, Feb. 26, 2015, 4 pages.;;Garcia-Hernandez et al., “Orientation Discrimination of Patterned Surfaces through an Actuated and Non-Actuated Tactile Display”, 2011 IEEE World Haptics Conference, Istanbul, Jun. 21-24, 2011, 3 pages.;;Forlines, et al., “Glimpse: a Novel Input Model for Multi-level Devices”, Chi '05 Extended Abstracts on Human Factors in Computing Systems, Apr. 2, 2005, 4 pages.;;Gardner, “Recenz—Recent Apps In One Tap”, You Tube, https://www.youtube.com/watch?v-qailSHRgsTo, May 15, 2015, 1 page.;;Geisler, “Enriched Links: A Framework For Improving Web Navigation Using Pop-Up Views”, Journal of the American Society for Information Science, Chapel Hill, NC, Jan. 1, 2000, 13 pages.;;Gonzalo et al., “Zliding: Fluid Zooming and Sliding for High Precision Parameter Manipulation”, Department of Computer Science, University of Toronto, Seattle, Washington, Oct. 23, 2005, 10 pages.;;Google-Chrome, “Android 5.0 Lollipop”, http://androidlover.net/android-os/android-5-0-lollipop/android-5-0-lollipop-recent-apps-card-google-search.html, Oct. 19, 2014, 10 pages.;;Grant, “Android's Notification Center”, https://www.objc.io/issues/11-android/android-notifications, Apr. 30, 2014, 26 pages.;;Gurman, “Force Touch on iPhone 6S Revealed: Expect Shortcuts, Faster Actions, iOS”, 9To5Mac Aug. 10, 2015, 31 pages.;;Henderson et al., “Opportunistic User Interfaces for Augmented Reality”, Department of Computer Science, New York, NY, Jan. 2010, 13 pages.;;IBM et al., “Pressure-Sensitive Icons”, IBM Technical Disclosure Bulletin, vol. 33, No. 1B, Jun. 1, 1990, 3 pages.;;ICIMS Recruiting Software, “Blackberry Playbook Review,” http://www.tested.com/tech.tablets/5749-blackberry-playbook-review/, 2015, 11 pages.;;IPhonehacksTV, “Confero allows you to easily manage your Badge notifications—iPhone Hacks”, youtube, https://wwwyoutube.com/watch?v=JCk61pnL4SU, Dec. 26, 2014, 3 pages.;;IPhoneOperator, “Wasser Liveeffekt fur Homescreen & Lockscreen—Aquaboard (Cydia)”, http://www.youtube.com/watch?v=fG9YMF-mBOQ, Sep. 22, 2012, 3 pages.;;IPodHacks 142: “Water Ripple Effects On The Home and Lock Screen: AquaBoard Cydia Tweak Review”, YouTube, https://www.youtube.comwatch?v-Auu_uRaYHJs, Sep. 24, 2012, 3 pages.;;Jauregui, “Design and Evaluation of 3D Cursors and Motion Parallax for the Exploration of Desktop Virtual Environments”, IEEE Symposium on 3D User Interfaces 2012, Mar. 4, 2012, 8 pages.;;Jones, “Touch Screen with Feeling”, IEEE Spectrum, ,spectrum.ieee.org/commuting/hardware/touch-screens-with-feeling, May 1, 2009, 2 pages.;;Kaaresoja, “Snap-Crackle-Pop: Tactile Feedback for Mobile Touch Screens,” Nokia Research Center, Helsinki, Finland, Proceedings of Eurohaptics vol. 2006, Jul. 3, 2006, 2 pages.;;Kiener, “Force Touch on iPhone”, https://www.youtube.com/watch?v=CEMmnsU5fC8, Aug. 4, 2015, 4 pages.;;Kleinman, “iPhone 6s Said to Sport Force Touch Display, 2GB of RAM”, https://www.technobuffalo.com/2015/01/15/iphone-6s-said-to-sport-force-touch-display-2gb-of-ram, Jan. 15, 2015, 2 pages.;;Kost, “LR3-Deselect All Images But One”, Julieanne Kost's Blog, blogs.adobe.com/jkost/2011/12/lr3-deselect-all-images-but-one.html, Dec. 22, 2011, 1 page.;;Kronfli, “HTC Zoe Comes To Google Play, Here's Everything You Need To Know,” Know Your Mobile, http://www.knowyourmobile.com/htc/htc-one/19550/what-htc-zoe, Aug. 14, 2014, 5 pages.;;Kumar, “How to Enable Ripple Effect on Lock Screen of Galaxy S2”, YouTube, http, http://www.youtube.com/watch?v+B9-4M5abLXA, Feb. 12, 2013, 3 pages.;;Kurdi, “XnView Shell Extension: A Powerful Image Utility Inside The Context Menu”, http://www.freewaregenius.com/xnview-shell-extension-a-powerful-image-utility-inside-the-context-menu, Jul. 30, 2008, 4 pages.;;Laurie, “The Power of the Right Click,” http://vlaurie.com/right-click/customize-context-menu.html, 2002-2016, 3 pages.;;MacKenzie et al., “The Tactile Touchpad”, Chi '97 Extended Abstracts on Human Factors in Computing Systems Looking to the Future, Chi '97, Mar. 22, 1997, 5 pages.;;Mahdi, Confero now available in Cydia, brings a new way to manage Notification badges [Jailbreak Tweak], http://www.iphonehacks.com/2015/01/confero/tweak-manage-notification-badges.html, Jan. 1, 2015, 2 pages.;;Matthew, “How to Preview Photos and Images From Right-Click Context Menue in Windows [Tip]”, http://www.dottech.org/159009/add-image-preview-in-windows-context-menu-tip, Jul. 4, 2014, 5 pages.;;McGarry, “Everything You Can Do With Force Touch on Apple Watch”, Macworld, www.macworld.com, May 6, 2015, 4 pages.;;McRitchie, “Internet Explorer Right-Click Menus,” http://web.archive.org/web-201405020/http:/dmcritchie.mvps.org/ie/rightie6.htm, May 2, 2014, 10 pages.;;Microsoft, “Lumia—How to Personalize Your Start Screen”, https://www.youtube.com/watch?v=6GI5Z3TrSEs, Nov. 11, 2014, 3 pages.;;Microsoft, “Use Radial Menus to Display Commands in OneNote for Windows 8,” https://support.office.com/en-us/article/Use-radial-menues-to-display-OneNote-commands-Od75f03f-cde7-493a-a8a0b2ed6f99fbe2, 2016, 5 pages.;;Microsoft, “Windows 7 Aero Shake, Snap, and Peek”, hr.msu.edu.techtipshrsds/window 7 snappeekandshake.pdf, Apr. 4, 2012, 6 pages.;;Minsky, “Computational Haptics The Sandpaper System for Synthesizing Texture for a Force-Feedback Display,” Massachusetts Institute of Technology, Jun. 1978, 217 pages.;;Mitroff, “Google Android 5.0 Lollipop,” http://www.cnet.com/products/google-android-5-0-lollipop, Mar. 12, 2015, 5 pages.;;Mohr, “Do Not Disturb—The iPhone Feature You Should Be Using”, http.www.wonderoftech.com/do-not-disturb-iphone, Jul. 14, 2014, 30 pages.;;Nacca, “NiLS Lock Screen Notifications / Floating Panel—Review”, https://www.youtube.com/watch?v=McT4QnS9TDY, Feb. 3, 2014, 4 pages.;;Neuburg, “Detailed Explanation iOS SDK”, Oreilly Japan, Dec. 22, 2014, vol. 4, P175-186, 15 pages.;;Nickinson, How to Use Do Not Disturb on the HTC One M8, https://www.androidcentral.com/how-to-use-do-not-disturb-htc-one-m8, Apr. 7, 2014, 9 pages.;;Nickinson, “Inside Android 4.2: Notifications and Quick Settings”, https://www.andrloidcentral.com/inside-android-42-notifications-and-quick-settings, Nov. 3, 2012, 3 pages.;;Nikon, “Scene Recognition System and Advanced SRS,” http://www.nikonusa.com/en.Learn-And-Explore/Article/ftlzi4rr/Scene-Recognition-System.html, Jul. 22, 2015, 2 pages.;;Nishino, “A Touch Screen Interface Design with Tactile Feedback”, Computer Science, 2011 International Conference on Complex, Intelligent, and Software Intensive Systems, 2011, 4 pages.;;Ogino, “iOS 7 Design Standard”, Japan, Impress Japan Corporation, 1st edition, Nov. 21, 2013, 2 pages.;;Oh, et al., “Moving Objects with 2D Input Devices in CAD Systems and Desktop Virtual Environments”, Proceedings of Graphics Interface 2005, 8 pages, May 2005.;;O'Hara, et al., “Pressure-Sensitive Icons”, IP.COM Journal, IP.COM Inc., West Henrietta, NY, US, Jun. 1, 1990, 2 Pages.;;Pallenberg, “Wow, the new iPad had gestures.” https://plus.google.com/+SaschaPallenberg/posts/aaJtJogu8ac, Mar. 7, 2012, 2 pages.;;Phonebuff, “How To Pair Bluetooth On The iPhone”, https://www.youtube.com/watch?v=LudNwEar9A8, Feb. 8, 2012, 3 pages.;;Plaisant et al., “Touchscreen Toggle Design”, Proceedings of CHI '92, pp. 667-668, May 3-7, 1992, 2 pages.;;PoliceOne.com, “COBAN Technologies Pre-Event Buffer & Fail Safe Feature,” http://www.policeone.com/police-products/police-technology/mobile-computures/videos/5955587-COBAN-Technologies-Pre-Event, Nov. 11, 2010, 2 pages.;;Pradeep, “Android App Development—Microsoft Awarded With Patents On Gestures Supported On Windows 8,” http://mspoweruser.com/microsoft-awarded-with-patents-on-gestures-supported-on-windows-8/, Aug. 25, 2011, 16 pages.;;“Quickly Preview Songs in Windows Media Player 12 in Windows 7,” Quickly Preview Songs in Windows Media Player 12 in Windows 7. How-to Geek, Apr. 28, 2010, Web. May 8, 2010, http://web.archive.org/web/20100502013134/http://www.howtogeek.com/howto/16157/quickly-preview-songs-in-windows-media-center-12-in-windows-7>, 6 pages.;;Quinn, et al., “Zoofing! Faster List Selections with Pressure-Zoom-Flick-Scrolling”, Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group on Design, Nov. 23, 2009, ACM Press, vol. 411, 8 pages.;;Rekimoto, et al., “PreSense: Interaction Techniques for Finger Sensing Input Devices”, Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology, Nov. 30, 2003, 10 pages.;;Rekimoto, et al., “PreSensell: Bi-directional Touch and Pressure Sensing Interactions with Tactile Feedback”, Conference on Human Factors in Computing Systems Archive, ACM, Apr. 22, 2006, 6 pages.;;Rekimoto, et al., “SmartPad: A Finger-Sensing Keypad for Mobile Interaction”, CHI 2003, Ft. Lauderdale, Florida, ACM 1-58113-637-Apr. 5-10, 2003, 2 pages.;;Ritchie, “How to see all the unread message notifications on your iPhone, all at once, all in the same place | iMore”, https://www.imore.com/how-see-all-unread-message-notifications-your-iphone-all-once-all-same-place, Feb. 22, 2014, 2 pages.;;Roth et al., “Bezel Swipe: Conflict-Free Scrolling and Miltiple Selection on Mobile Touch Screen Devices,” Chi 2009, Boston, Massachusetts, USA, Apr. 4-9, 2009, 4 pages.;;Rubino et al., “How to Enable 'Living Images' on your Nokia Lumia with Windows Phone 8.1”, https://www.youtube.com/watch?v=RX7vpoFy1Dg, Jun. 6, 2014, 5 pages.;;Sleepfreaks, “How to Easily Play/Loop an Event Range in Cubase”, https://sleepfreaks-dtm.com/for-advance-cubase/position-3/>, Apr. 4, 2011, 14 pages.;;Sony, “Intelligent Scene Recognition,” https://www.sony-asia.com/article/252999/section/product/product/dsc-t77, downloaded on May 20, 2016, 5 pages.;;Sood, “MultitaskingGestures”, http://cydia.saurik.com/package/org.thebigboxx.multitaskinggestures/, Mar. 3, 2014, 2 pages.;;Stewart, et al., “Characteristics of Pressure-Based Input for Mobile Devices”, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Apr. 2010, 10 pages.;;Stross, “Wearing A Badge, and a Video Camera,” The New York Times, http://www.nytimes.com/2013/04/07/business/wearable-video-cameras-for-police-offers.html? R=0, Apr. 6, 2013, 4 pages.;;Taser, “Taser Axon Body Camera User Manual,” https://www.taser.com/images/support/downloads/product-resourses/axon body_product_manual.pdf, Oct. 1, 2013, 24 pages.;;Tidwell, “Designing Interfaces,” O'Reilly Media, Inc., USA, Nov. 2005, 348 pages.;;Tweak, “QuickCenter—Add 3D-Touch Shortcuts to Control Center”, https://www.youtube.com/watch?v=8rHOFpGvZFM, Mar. 22, 2016, 2 pages.;;Tweak, “iOS 10 Tweak on iOS 9.0.2 Jailbread & 9.2.1-9.3 Support: QuickCenter 3D, Touch Cydia Tweak!” https://wwwyoutube.com/watch?v=opOBr30_Fkl, Mar. 6, 2016, 3 pages.;;UpDown-G, “Using Multiple Selection Mode in Android 4.0 / Getting Started”, https://techbooster.org/android/13946, Mar. 7, 2012, 7 pages.;;VGJFeliz, “How to Master Android Lollipop Notifications in Four Minutes!”, https://www.youtube.com/watch?v=S-zBRG7GJgs, Feb. 8, 2015, 5 pages.;;VisioGuy, “Getting a Handle on Selecting and Subselecting Visio Shapes”, http://www.visguy.com/2009/10/13/getting-a-handle-on-selecting-and-subselecting-visio-shapes/, Oct. 13, 2009, 18 pages.;;Viticci, “Apple Watch: Our Complete Overview—MacStories”, https://www.macstories.net, Sep. 10, 2014, 21 pages.;;Wikipedia, “AirDrop,”, Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/AirDrop, May 17, 2016, 5 pages.;;Wikipedia, “Cinemagraph,” Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/Cinemagraph, Last Modified Mar. 16, 2016, 2 pages.;;Wikipedia, “Context Menu,” Wikipedia, the free encyclopedia https://en.wikipedia.org/wiki/Context menu, Last Modified May 15, 2016, 4 pages.;;Wikipedia, “HTC One (M7),” Wikipedia, the free encyclopedia, https://en.wikipedia.org/wiki/HTC_One_(M7), Mar. 2013, 20 pages.;;Wikipedia, “Mobile Ad Hoc Network,” Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/Mobile_ad hoc_network, May 20, 2016, 4 pages.;;Wikipedia, “Pie Menu,” Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/Pie_menu, Last Modified Jun. 4, 2016, 3 pages.;;Wikipedia, “Quick Look,” from Wikipedia, the free encyclopedia, https;//en.wikipedia.org/wiki/Quick_Look, Last Modified Jan. 15, 2016, 3 pages.;;Wikipedia, “Sony Xperia Z1”, Wikipedia, the free encyclopedia, https://enwikipedia.org/wiki/Sony_Experia_Z1, Sep. 2013, 10 pages.;;Wilson, et al., “Augmenting Tactile Interaction with Pressure-Based Input”, School of Computing Science, Glasgow, UK, Nov. 15-17, 2011, 2 pages.;;Yang, et al., “Affordance Application on Visual Interface Design of Desk-Top Virtual Experiments”, 2014 International Conference on Information Science, Electronics and Electrical Engineering, IEEE, vol. 1, Apr. 26, 2014, 5 pages.;;Yatani, et al., SemFeel: A User Interface with Semantic Tactile Feedback for Mobile Touch-Screen Devices, Proceedings of the 22nd annual ACM symposium on user interface software and technology (UIST '09), Oct. 2009, 10 pages.;;Youtube, “Android Lollipop Lock-Screen Notification Tips”, https://www.youtube.com/watch?v=LZTxHBOwzIU, Nov. 13, 2014, 3 pages.;;Youtube, “Blackberry Playbook bezel interaction,” https://www.youtube.com/watch?v=YGkzFqnOwXI, Jan. 10, 2011, 2 pages.;;Youtube, “How to Master Android Lollipop Notifications in Four Minutes!”, Video Gadgets Journal (VGJFelix), https://www.youtube.com/watch?v=S-zBRG7GGJgs, Feb. 8, 2015, 4 pages.;;Youtube, “HTC One Favorite Camera Features”, http://www.youtube.com/watch?v=sUYHfcjl4RU, Apr. 28, 2013, 3 pages.;;Youtube, “Multitasking Gestures: Zephyr Like Gestures on iOS”, https://www.youtube.com/watch?v=Jcod-f7Lw0I, Jan. 27, 2014, 3 pages.;;Youtube, “Recentz—Recent Apps in A Tap”, https://www.youtube.com/watch?v=qailSHRgsTo, May 15, 2015, 1 page.;;Zylom, “House Secrets”, http://game.zylom.com/servlet/Entry?g=38&s=19521&nocache=1438641323066, Aug. 3, 2015, 1 page.;;Office Action, dated Mar. 15, 2017, received in U.S. Appl. No. 14/535,671, 13 pages.;;Office Action, dated Nov. 30, 2017, received in U.S. Appl. No. 14/535,671, 21 pages.;;Notice of Allowance, dated Sep. 5, 2018, received in U.S. Appl. No. 14/535,671, 5 pages.;;Office Action, dated Jun. 29, 2017, received in U.S. Appl. No. 14/608,895, 30 pages.;;Final Office Action, dated Feb. 22, 2018, received in U.S. Appl. No. 14/608,895, 20 pages.;;Notice of Allowance, dated Jun. 26, 2018, received in U.S. Appl. No. 14/608,895, 9 pages.;;Office Action, dated Dec. 18, 2015, received in Australian Patent Application No. 2013368440, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Oct. 18, 2016, received in Australian Patent Application No. 2013368440, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Notice of Allowance, dated Dec. 20, 2016, received in Australian Patent Application No. 2013368440, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Apr. 29, 2017, received in Australian Patent Application No. 2013368440, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 6, 2017, received in Chinese Patent Application No. 201380068493.6, which corresponds with U.S. Appl. No. 14/608,895, 5 pages.;;Office Action, dated Oct. 9, 2018, received in Chinese U.S. Appl. No. 201380068493.6, which corresponds with U.S. Appl. No. 14/608,895, 3 pages.;;Patent, dated Dec. 25, 2018, received in Chinese Patent Application No. 201380068493.6, which corresponds with U.S. Appl. No. 14/608,895, 4 pages.;;Office Action, dated Jul. 21, 2016, received in European Patent Application No. 13795391.5, which corresponds with U.S. Appl. No. 14/536,426, 9 pages.;;Office Action, dated Mar. 9, 2018, received in European Patent Application No. 13795391.5, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Intention to Grant, dated Jul. 6, 2018, received in European Patent Application No. 13795391.5, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Certificate of Grant, dated Dec. 26, 2018, received in European Patent Application No. 13795391.5, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Sep. 13, 2016, received in Japanese Patent Application No. 2015-547948, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Patent, dated May 12, 2017, received in Japanese Patent Application No. 2015-547948, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Apr. 5, 2016, received in Korean Patent Application No. 10-2015-7018851, which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;Office Action, dated Feb. 24, 2017, received in Korean Patent Application No. 10-2015-7018851, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Patent, dated May 26, 2017, received in Korean Patent Application No. 2015-7018851, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Oct. 5, 2018, received in Korean Patent Application No. 2018-7028236, which corresponds with U.S. Appl. No. 14/608,895, 6 pages.;;Notice of Allowance, dated May 24, 2019, received in Korean Patent Application No. 2018-7028236, which corresponds with U.S. Appl. No. 14/608,895, 4 pages.;;Patent, dated Jul. 9, 2019, received in Korean Patent Application No. 2018-7028236, which corresponds with U.S. Appl. No. 14/608,895, 4 pages.;;Office Action, dated Jul. 26, 2017, received in U.S. Appl. No. 14/536,235, 14 pages.;;Final Office Action, dated Feb. 26, 2018, received in U.S. Appl. No. 14/536,235, 13 pages.;;Notice of Allowance, dated Aug. 15, 2018, received in U.S. Appl. No. 14/536,235, 5 pages.;;Office Action, dated Apr. 5, 2017, received in U.S. Appl. No. 14/536,367, 16 pages.;;Notice of Allowance, dated Nov. 30, 2017, received in U.S. Appl. No. 14/536,367, 9 pages.;;Notice of Allowance, dated May 16, 2018, received in U.S. Appl. No. 14/536,367, 5 pages.;;Office Action, dated Dec. 17, 2015, received in U.S. Appl. No. 14/536,426, 28 pages.;;Final Office Action, dated May 6, 2016, received in U.S. Appl. No. 14/536,426, 23 pages.;;Office action, dated Aug. 3, 2017, received in U.S. Appl. No. 14/536,426, 10 pages.;;Office Action, dated Jul. 15, 2015, received in Australian Patent Application No. 2013259606, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Notice of Allowance, dated May 23, 2016, received in Australian Patent Application No. 2013259606, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Sep. 15, 2016, received in Australian Patent Australian No. 2013259606, which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Office Action, dated Nov. 18, 2015, received in Australian Patent Application No. 2015101231, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated May 15, 2017, received in Australian Patent Application No. 2016216580, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated May 8, 2018, received in Australian Patent Application No. 2016216580, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Notice of Allowance, dated May 17, 2018, received in Australian Patent Application No. 2016216580, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Sep. 13, 2018, received in Australian Patent Application No. 2016216580, which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Office Action, dated Apr. 12, 2019, received in Australian Patent Application No. 2018223021, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 18, 2019, received in Australian Patent Application No. 2018223021, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Feb. 18, 2020, received in Australian Patent Application No. 2018223021, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Notice of Allowance, dated Mar. 27, 2020, received in Australian Patent Application No. 2018223021, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Jul. 23, 2020, received in Australian Patent Application No. 2018223021, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Sep. 19, 2017, received in Chinese Patent Application No. 201380035982.1, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Notice of Allowance, dated May 10, 2018, received in Chinese Patent Application No. 201380035982.1, which corresponds with U.S. Appl. No. 14/536,426, 2 pages.;;Patent, dated Aug. 17, 2018, received in Chinese Patent Application No. 201380035982.1, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Sep. 20, 2017, received in Chinese Patent Application No. 201510566550.4, which corresponds with U.S. Appl. No. 14/536,426, 11 pages.;;Notice of Allowance, dated Aug. 8, 2018, received in Chinese Patent Application No. 201510566550.4, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Patent, dated Oct. 23, 2018, received in Chinese Patent Application No. 201510566550.4, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Jan. 4, 2021, received in Chinese Patent Application No. 201810826224.6, which corresponds with U.S. Appl. No. 14/536,426, 6 pages.;;Office Action, dated Jun. 24, 2021, received in Chinese Patent Application No. 201810826224.6, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Notice of Allowance, dated Oct. 11, 2021, received in Chinese Patent Application No. 201810826224.6, which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Patent, dated Nov. 12, 2021, received in Chinese Patent Application No. 201810826224.6, which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;Decision to Grant, dated Jul. 14, 2016, received in European Patent Application No. 13724100.6, which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Letters Patent, dated Aug. 10, 2016, received in European Patent Application No. 13724100.6, which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Office Action, dated Jan. 20, 2017, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Office Action, dated Aug. 21, 2017, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Intention to Grant, dated Mar. 9, 2018, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Intention to Grant, dated Aug. 14, 2018, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Decision to Grant, dated Jan. 10, 2019, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Patent, dated Feb. 6, 2019, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Sep. 6, 2019, received in European Patent Application No. 18180503.7, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Certificate of Grant, dated Nov. 10, 2017, received in Hong Kong Patent Application No. 15107535.0, which corresponds with U.S. Appl. No. 14/536,426, 2 pages.;;Certificate of Grant, dated Jul. 5, 2019, received in Hong Kong Patent Application No. 15108892.5, which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Patent, dated Nov. 22, 2019, received in Hong Kong Patent Application No. 16107033.6, which corresponds with U.S. Appl. No. 14/536,426, 6 pages.;;Office Action, dated Mar. 4, 2016, received in Japanese Patent Application No. 2015-511644, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Feb. 6, 2017, received in Japanese Patent Application No. 2015-511644, which corresponds with U.S. Appl. No. 14/536,426, 6 pages.;;Notice of Allowance, dated Dec. 8, 2017, received in Japanese Patent Application No. 2015-511644, which corresponds with U.S. Appl. No. 14/536,426, 6 pages.;;Patent, dated Jan. 12, 2018, received in Japanese Patent Application No. 2015-511644, which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 6, 2018, received in Japanese Patent Application No. 2018-000753 (5842JP01), which corresponds with U.S. Appl. No. 14/536,426, 8 pages.;;Office Action, dated Oct. 7, 2019, received in Japanese Patent Application No. 2018-000753, which corresponds with U.S. Appl. No. 14/536,426, 5 pages. et al.",ACTIVE
244,US,A1,US 2016/0360097 A1,031-455-680-431-977,2016-12-08,2016,US 201514864580 A,2015-09-24,US 201514864580 A;;US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device displays a representative image on a display. The representative image is one image in a sequence of images that includes images acquired by a camera before and after acquiring the representative image. While displaying the representative image, the device detects an input. In response to detecting the input, the device transitions from displaying the representative image to displaying a prior image in the sequence of images that was acquired by the camera before acquiring the representative image. After transitioning to displaying the respective prior image, the device displays, in sequence starting with the prior image, at least some of the images acquired by the camera before acquiring the representative image and at least some of the images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;FOSS CHRISTOPHER P;;IVE JONATHAN;;KING NICHOLAS V;;KOCIENDA KENNETH L;;MANZARI BEHKISH J;;PIVONKA PAVEL;;PRESTON DANIEL T;;MEZAK CHARLES A;;TITI JUSTIN S;;GOBERA RUBALCAVA DANIEL E,APPLE INC (2016-01-20),https://lens.org/031-455-680-431-977,Patent Application,yes,0,65,9,100,0,G06F3/04842;;G06F3/0488;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/62;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00,H04N5/232;;G06F3/0485;;G06F3/0488;;H04M1/72439,,0,0,,,,ACTIVE
245,US,B2,US 9674426 B2,038-474-845-528-362,2017-06-06,2017,US 201514864580 A,2015-09-24,US 201514864580 A;;US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device displays a representative image on a display. The representative image is one image in a sequence of images that includes images acquired by a camera before and after acquiring the representative image. While displaying the representative image, the device detects an input. In response to detecting the input, the device transitions from displaying the representative image to displaying a prior image in the sequence of images that was acquired by the camera before acquiring the representative image. After transitioning to displaying the respective prior image, the device displays, in sequence starting with the prior image, at least some of the images acquired by the camera before acquiring the representative image and at least some of the images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;FOSS CHRISTOPHER P;;IVE JONATHAN;;KING NICHOLAS V;;KOCIENDA KENNETH L;;MANZARI BEHKISH J;;PIVONKA PAVEL;;PRESTON DANIEL T;;MEZAK CHARLES A;;TITI JUSTIN S;;GOBERA RUBALCAVA DANIEL E,APPLE INC (2016-01-20),https://lens.org/038-474-845-528-362,Granted Patent,yes,963,6,9,100,0,G06F3/04842;;G06F3/0488;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/62;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00,H04N5/232;;G06F3/0482;;G06F3/0485;;G06F3/0488;;H04M1/72439;;H04N101/00,,437,5,021-411-866-534-301;;025-388-407-138-206;;102-140-305-428-255;;172-005-321-198-602;;115-594-732-723-118,10.1145/1449715.1449730;;10.1145/1056808.1056920;;10.1145/1738826.1738856;;10.1145/964696.964719;;10.1016/j.jss.2007.04.045,"Agarwal, “How to Copy and Paste Text on Windows Phone 8,” Guiding Tech, http://web.archive.org/web20130709204246/http://www.guidingtech.com/20280/copy-paste-text-windows-phone-8/, Jul. 9, 2013, 10 pages.;;Alzona, “Full Screen Maximization with RightZoom,” http://www.brighhub.com/computing/mac-platform/articles/31024.aspx>, Mar. 31, 2009, 6 pages.;;Apple Inc., “iPhone User Guide for iPhone and iPhone 3G,” http://manuals.info.apple.com/en—US/iPhone—User—Guide.pdf, Jul. 11, 2008, 154 pages.;;Ask.MetaFilter, “Enable Screen Resize?” ask. Metafilter.com, Jan. 29, 2006, http://ask.metafilter.com/31720/Enable-screen-resize, 4 pages.;;Awduche et al., “Synchronized Broadcast in Cellular Networks,” 2nd Telecommunications R&D Conference in Massachusetts, Mar. 1996, 12 pages.;;Azundris, “A Fire in the Sky,” http://web.archive.org/web/20140722062639/http://blog.azundrix.com/archives/168-A-fire-in-the-sky.html, Jul. 22, 2014, 8 pages.;;Bautisa, “Microsoft Mathematics Tutorial 7—The Ink Input”, <URL:http://mathandmultimedia.com/2012/05/23/microsoft-math-tutorial-7-ink>, May 23, 2012, 3 pages.;;cvil.ly—a design blog, Interesting Touch Interactions on Windows 8, http://cvil.ly/2011/06/04/interesting-touch-interactions-on-windows-8/, Jun. 4, 2011, 3 pages.;;CrackBerry Forums, Windows 8 Bezel Control and Gestures, http://wwwforums.crackberry.com/blackberry-playbook-f222/windows-8-bezel-control-gestures-705129/, Mar. 1, 2012, 8 pages.;;Crook, “Microsoft Patenting Multi-Screen, Milti-Touch Gesures,” http://techcrunch.com/2011/08/25/microsoft-awarded-patents-for-multi-screen-multi-touch-gestures/, Aug. 25, 2011, 8 pages.;;Davidson, et al., “Extending 2D Object Arrangement with Pressure-Sensitive Layering Cues”, Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology, Oct. 19, 2008, 4 pages.;;Deeter, “DigiStamp Signs Strategic Partnership with European Trust Center EuroSignCard to Safeguard Monetary Transactions in Financial Sector,” http://proquest.umi.com/, Mar. 14, 2001, 2 pages.;;Dilger, “Inside Apple's iPad: Multitasking,” Appleinsider.com, <http://www.appleinsider.com/articles/10/02/18/inside—apples—ipad—multitasking.html>, Feb. 17, 2010, 3 pages.;;Dinwiddie, et al., “Combined-User Interface for Computers, Television, Video Recorders, and Telephone, Etc”, ip.com Journal, Aug. 1, 1990, 3 Pages.;;Fahey, “The iPad Blows Up iPhone Apps Read Good,” Kotaku http://kotaku.com/5458316/the-ipad-blows-up-iphone-apps-rel-good, Jan. 27, 2010, 3 pages.;;Fehily, “Visual QuickStart Guide: Microsoft Windows 7,” Peachpit Press, 9 pages.;;Fenlon, “The Case for Bezel Touch Gestures on Apple's iPad,” http://www.tested.com/tech/tablets/3104-the case-for-bezel-touch-gestures-on-apples-ipad/, Nov. 2, 2011, 6 pages.;;Flowplayer, “Slowmotion: Flowplayer,” https://web.archive.org/web/20150226191526/http://flash.flowplayer.org/plugins/streaming/slowmotion.html, Feb. 26, 2015, 4 pages.;;Forlines, et al., “Glimpse: a Novel Input Model for Multi-level Devices”, Chi '05 Extended Abstracts on Human Factors in Computing Systems, Apr. 2, 2005, 4 pages.;;Gorman, “Hands-On With Immersion HD Integrator Hi-Fi Haptics,” http://www.engadget.com/2012/02/23/hands-on-with-immersion-hd-integrator-hi-fi-haptics/?utm—medium=referral&utm—source=pulsenews, Feb. 23, 2012, 10 pages.;;Harris, “Windows 8 Consumer Preview: Product Demo,” https://www.youtube.com/watch?feature=;auer-embedded&v=[jDYAQmQ-phX8, Feb. 28, 2012, 3 pages.;;Harrison, “Stylus-Based Interface with Full Mouse Emulation”, IBM Technical Disclosure Bulletin, vol. 34, No. 10B, Mar. 1, 1992, 3 pages.;;HTC, “HTC One (M7),” Wikipedia, the free encyclopedia, https://en.wikipedia.org/wiki/HTC—One—(M7), Mar. 2013, 20 pages.;;HTC, “User Manual—PDA Phone—HTC—P3050 Touch,” http://web.archive.org/web/20101228223033/http://www.comparecellular.com, Nov. 2, 2007, 154 pages.;;iCIMS Recruiting Software, “Blackberry Playbook Review,” http://www.tested.com/tech.tablets/5749-blackberry-playbook-review/, 2015, 11 pages.;;Jade et al., “Apple's iPhone 4.0 to Support Multitasking via Expose-like Interface,” AppleInsider.com, Mar. 31, 2010, 4 pages.;;Jade et al., “Apple's iPhone 4.0 Software to Deliver Multitasking Support,” AppleSider.com, Mar. 11, 2010, 3 pages.;;Kishore, “Make the OS X Maximize Button Work like Windows,” http://www.switchingtomac.com/making-the-switch/make-the-os-x-maximize-buttom-work-like-windows/, May 5, 2009, 11 pages.;;MacRumors, “Fit to Screen Buttom Poll for Mac / Windows Users,” http://forums.macrumors.com/showthread.php?t=615215>, Dec. 11, 2008, 15 pages.;;MacRumors, “Window, Fit to Screen?,” http://forums.macrumors.com/showthread.php?t=439783>, Feb. 22, 2008, 5 pages.;;McRitchie, “Internet Explorer Right-Click Menus,” http://web.archive.org/web-201405020/http:/dmcritchie.mvps.org/ie/rightie6.htm, May 2, 2014, 10 pages.;;MetaFilter Network Inc., “Enable Screen Resize?”, http://ask.metafilter.com/31720/Enable-screen-resize>, Jan. 29, 2006, 4 paes.;;Mick, “Iphone OS 4.0 Will Bring True Multitasking This Summer”, Daily Tech, http:///www.dailytech.com/report+iphone+os+40+will+bring+true+multitasking+this+summer/article 17878.htm>, Mar. 11, 2010, 3 pages.;;Minsky, “Computational Haptics The Sandpaper System for Synthesizing Texture for a Force-Feedback Display,” Massachusetts Institute of Technology, Jun. 1978, 217 pages.;;Moth, “Share Code—Write Code Once for Both Mobile and Desktop Apps,” MSDN Magazine, Jul. 2007, http://msdn.microsoft.com/en-us/magazine/cc163387.aspx, 8 pages.;;Newman, “Sprint's HTC EVO 4G: 5 Killer Features,” pcworld, http://www.pcworld.com/article/192286/sprints—htc—evo—4g—5—killer—features.html, Mar. 24, 2010, 3 pages.;;Nickinson, “Review: The New HTC Sense Interface on Android Phones,” Android Central, Feb. 22, 2010, http://www.androidcentral.com/review-new-htc-sense-android-phone, 10 pages.;;Nilsson, “Design Guidelines for Mobile Applications,” SINTEF ICT, Jun. 2008, 73 pages.;;Nilsson et al., “Design Patterns for User Interface for Mobile Applications,” Advances in Engineering Software, Elsevier Science, Oxford, GB vol. 40, No. 12, Dec. 1, 2009, 11 pages.;;O'Hara, et al., “Pressure-Sensitive Icons”, ip.com Journal, Jun. 1, 1990, 2 Pages.;;Pallenberg, “Wow, the new iPad had gestures.” https://plus.google.com/+SaschaPallenberg/posts/aaJtJogu8ac, Mar. 7, 2012, 2 pages.;;Pradeep, “Android App Development—Microsoft Awarded With Patents on Gestures Supported on Windows 8,” http://mspoweruser.com/microsoft-awarded-with-patents-on-gestures-supported-on-windows-8/, Aug. 25, 2011, 16 pages.;;Quinn, et al., “Zoofing! Faster List Selections with Pressure-Zoom-Flick-Scrolling”, Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group on Design, Nov. 23, 2009, ACM Press, vol. 411, 8 pages.;;Reiger, “Effective Design for Multiple Screen Sizes,” mobiForge, http://mobiforge.com/designing/story/effective-design-multiple-screen-sizes, Jan. 2009, 12 pages.;;Rekimoto, et al., “PreSense: Interaction Techniques for Finger Sensing Input Devices”, Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology, Nov. 30, 2003, 10 pages.;;Rekimoto, et al., “PreSensell: Bi-directional Touch and Pressure Sensing Interactions with Tactile Feedback”, Conference on Human Factors in Computing Systems Archive, ACM, Apr. 22, 2006, 6 pages.;;Robertson et al., “The Task Gallary: A 3D Window Manager,” Redmond, WA, Sep. 12, 1999, 8 pages.;;Savoy, “HTC Enhances Sense with Leap and Friend Stream (updated with video),” Engadget, http://www.engadget.com/2010/02/16/htc-enhances-sense-with-leap-and-friend-stream/, Feb. 16, 2010, 4 pages.;;Seffah et al., Multi-devices “Multiple” User Interfaces: Development Models and Research Opportunities, The Journal of Systems Software, www.sciencedirect.com, Dec. 25, 2003, 14 pages.;;Siracusa, “Antacid Tablet,” http://arstechnica.com/staff/2010/01/antacid-tablet/>, Jan. 1, 2010, 3 pages.;;Song, et al., “Grips and Gestures on a Multi-Touch Pen,” The ACM CHI Conference on Human Factors in Computing Systems, <URL:research.microsoft.com/pubs/.../gripsandgenstures%20mtpen-chi201>, May 7-12, 2011,10 pages.;;Sony, “Sony Xperia Z1”, Wikipedia, the free encyclopodia, https://en.wikipedia.org/wiki/Sony—Xperia—Z1, Sep. 2013, 10 pages.;;Tidwell, “Designing Interfaces,” O'Reilly Media, Inc., USA, Nov. 2005, 348 pages.;;Viana et al., “Xmobile: A MB-UID Environment for Semi-Automatic Generation of Adaptive Applications for Mobile Devices,” The Journal of Systems and Software, www.sciencedirect.com, Jun. 9, 2007, 13 pages.;;Windows,“Stupid Geek Tricks: Tile or Cascade Multiple Windows in Windows 7,” How to Geek, Feb. 18, 2010, 3 pages.;;YouTube, “Blackberry Playbook bezel interation,” https://www.youtube.com/watch?v=YGkzFqnOwXI, Jan. 10, 2011, 2 pages.;;Office Action, dated May 22, 2012, received in U.S. Appl. No. 12/888,381 (5274), 18 pages.;;Final Office Action, dated Nov. 19, 2012, received in U.S. Appl. No. 12/888,381(5274), 14 pages.;;Office Action, dated Dec. 10, 2013, received in U.S. Appl. No. 12/888,381 (5274), 13 pages.;;Notice of Allowance, dated Oct. 21, 2014, received in U.S. Appl. No. 12/888,381 (5274), 8 pages.;;Notice of Allowance, dated Feb. 17, 2015, received in U.S. Appl. No. 12/888,381 (5274), 5 pages.;;Notice of Allowance (corrected), dated Apr. 9, 2015, received in U.S. Appl. No. 12/888,381 (5274), 2 pages.;;Office Action, dated Aug. 8, 2013, received in Australian Patent Application No. 2010350740 (5274AU), 3 pages.;;Office Action, dated Aug. 28, 2012, received in Chinese Patent Application No. 201010602688.2 (5274CN), which corresponds with U.S. Appl. No. 12/888,381, 6 pages.;;Office Action, dated May 24, 2013, received in Chinese Patent Application No. 201010602688.2(5274CN), which corresponds with U.S. Appl. No. 12/888,381, 7 pages.;;Office Action, dated Aug. 6, 2013, received in European Patent Application No. 10760867.1 (5274EP), which corresponds with U.S. Appl. No. 12/888,381, 4 pages.;;Office Action, dated Dec. 6, 2013, received in Japanese Patent Application No. 2013-503722, which corresponds with U.S. Appl. No. 12/888,381, 2 pages.;;Office Action, dated May 10, 2012, received in U.S. Appl. No. 12/888,382 (5315), 9 pages.;;Final Office Action, dated Nov. 15, 2012, received in U.S. Appl. No. 12/888,382 (5315), 11 pages.;;Office Action, dated Dec. 10, 2013, received in U.S. Appl. No. 12/888,382 (5315), 12 pages.;;Notice of Allowance, dated Oct. 31, 2014, received in U.S. Appl. No. 12/888,382 (5315), 5 pages.;;Notice of Allowance, dated Feb. 13, 2015, received in U.S. Appl. No. 12/888,382 (5315), 6 pages.;;Office Action, dated May 17, 2012, received in U.S. Appl. No. 12/888,384 (5316), 15 pages.;;Final Office Action, dated Nov. 7, 2012, received in U.S. Appl. No. 12/888,384 (5316), 14 pages.;;Office Action, dated May 16, 2012, received in U.S. Appl. No. 12/888,386 (5317), 12 pages.;;Final Office Action, dated Nov. 8, 2012, received in U.S. Appl. No. 12/888,386 (5317), 13 pages.;;Office Action, dated Jan. 23, 2013, received in U.S. Appl. No. 12/888,389 (5318), 11 pages.;;Final Office Action, dated Sep. 12, 2013, received in U.S. Appl. No. 12/888,389 (5318), 10 pages.;;Notice of Allowance, dated Sep. 8, 2014, received in U.S. Appl. No. 12/888,389 (5318), 13 pages.;;Notice of Allowance, dated Feb. 11, 2015, received in U.S. Appl. No. 12/888,389 (5318), 13 pages.;;Notice of Allowance, dated Jun. 15, 2012, received in U.S. Appl. No. 12/888,391 (5319), 23 pages.;;Office Action, dated Jun. 28, 2013, received in U.S. Appl. No. 13/077,524 (5324), 17 pages.;;Office Action, dated Apr. 4, 2013, received in U.S. Appl. No. 12/789,426 (5324), 8 pages.;;Office Action, dated Feb. 12, 2014, received in U.S. Appl. No. 13/077,524 (5324), 13 pages.;;Notice of Allowance, dated May 27, 2015, received in U.S. Appl. No. 13/077,524 (5324), 9 pages.;;Notice of Allowance, dated Sep. 15, 2015, received in U.S. Appl. No. 13/077,524 (5324), 9 pages.;;Office Action, dated Mar. 19, 2013, received in U.S. Appl. No. 13/333,909 (5369), 18 pages.;;Office Action, dated Dec. 5, 2013, received in U.S. Appl. No. 13/333,909 (5369), 24 pages.;;Notice of Allowance, dated Mar. 31, 2014, received in U.S. Appl. No. 13/333,909 (5369). 20 pages.;;Office Action, dated Dec. 18, 2015, received in Australian Patent Application No. 2013368440 (5369AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Apr. 5, 2016, received in Korean Patent Application No. 102015-7018851 (5839KR), which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;Office Action, dated Dec. 17, 2015, received in U.S. Appl. No. 14/536,426 (5842), 28 pages.;;Office Action, dated Jul. 15, 2015, received in Australian Patent Application No. 2013259606 (5842AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 18, 2015, received in Australian Patent Application No. 2015101231 (5842AU01), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Mar. 4, 2016, received in Japanese Patent Application No. 2015-511644 (5842JP), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Feb. 1, 2016, received in Australian Patent Application No. 2013368441 (5845AU), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Notice of Allowance, dated Mar. 30, 2016, received in Australian Patent Application No. 2013368441 (5845AU), which corresponds with U.S. Appl. No. 14/608,926, 1 page.;;Office Action, dated Mar. 14, 2016, received in Japanese Patent Application No. 2015-549392 (5845JP), which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Office Action, dated Jul. 17, 2015, received in Australian Patent Application No. 2013259613 (5846AU), which corresponds with U.S. Appl. No. 14/536,646, 5 pages.;;Office Action, dated Nov. 12, 2015, received in European Patent Application No. 13724102.2 (5846EP), which corresponds with U.S. Appl. No. 14/536,646, 6 pages.;;Office Action, dated Feb. 29, 2016, received in Japanese Patent Application No. 2015-511645 (5846JP), which corresponds with U.S. Appl. No. 14/536,646, 5 pages.;;Office Action, dated Aug. 27, 2015, received in Australian Patent Application No. 2013259614 (5847AU), which corresponds with U.S. Appl. No. 14/536,141, 4 pages.;;Office Action, dated Jan. 7, 2016, received in European Patent Application No. 13726053.5 (5847EP), which corresponds with U.S. Appl. No. 14/536,141, 10 pages.;;Office Action, dated Feb. 29, 2016, received in Japanese Patent Application No. 2015-511646 (5847JP), which corresponds with U.S. Appl. No. 14/536,141, 3 pages.;;Office Action, dated Jan. 29, 2016, received in Australian Patent Application No. 2013368443 (5848AU), which corresponds with U.S. Appl. No. 14/536,141, 3 pages.;;Office Action, dated Apr. 5, 2016, received in Korean Patent Application No. 10-2015-7018448 (5848KR), which corresponds with U.S. Appl. No. 14/536,141, 6 pages.;;Office Action, dated Jul. 9, 2015, received in Australian Patent Application No. 2013259630 (5850AU), which corresponds with U.S. Appl. No. 14/536,203, 3 pages.;;Office Action, dated Nov. 11, 2015, received in European Patent Application No. 13724104.8 (5850EP), which corresponds with U.S. Appl. No. 14/536,203, 5 pages.;;Office Action, dated Feb. 15, 2016, received in Japanese Patent Application No. 2015-511650 (5850JP), which corresponds with U.S. Appl. No. 14/536,203, 5 pages.;;Office Action, dated Dec. 4, 2015, received in Korean Patent Application No. 2014-7034520 (5850KR), which corresponds with U.S. Appl. No. 14/536,203, 4 pages.;;Office Action, dated Aug. 10, 2015, received in Australian Patent Application No. 2013259637 (5853AU), which corresponds with U.S. Appl. No. 14/536,267, 3 pages.;;Office Action, dated Jan. 29, 2016, received in Japanese Patent Application No. 2015-511652 (5853JP), which corresponds with U.S. Appl. No. 14/536,267, 3 pages.;;Office Action, dated Dec. 4, 2015, received in Korean Patent Application No. 2014-7034530 (5853KR), which corresponds with U.S. Appl. No. 14/536,267, 3 pages.;;Office Action, dated Aug. 18, 2015, received in Australian Patent Application No. 2013259642 (5854AU), which corresponds with U.S. Appl. No. 14/536,291, 3 pages.;;Office Action, dated Jan. 7, 2016, received in European Patent Application No. 13724107.1 (5854EP), which corresponds with U.S. Appl. No. 14/052,515, 11 pages.;;Office Action, dated Mar. 8, 2016, received in Japanese Patent Application No. 2015-511655 (5854JP), which corresponds with U.S. Appl. No. 14/536,291, 4 pages.;;Office Action, dated Jan. 15, 2016, received in Australian Patent Application No. 2013368445 (5855AU), which corresponds with U.S. Appl. No. 14/608,985, 3 pages.;;Office Action, dated Nov. 23, 2015, received in U.S. Appl. No. 14/183,316 (5860), 17 pages.;;Office Action, dated Dec. 18, 2015, received in U.S. Appl. No. 14/183,347 (5861), 6 pages.;;Office Action, dated Mar. 31, 2016, received in U.S. Appl. No. 14/864,737 (7246), 17 pages.;;Office Action, dated Apr. 5, 2016, received in Danish Patent Application No. 201500577 (7246DK), which corresponds with U.S. Appl. No. 14/864,737, 7 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 2016100254 (7247AU), which corresponds with U.S. Appl. No. 14/866,981, 1 page.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500575 (7247DK), which corresponds with U.S. Appl. No. 14/866,981, 9 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 2016100251 (7265AU), which corresponds with U.S. Appl. No. 14/866,159, 1 page.;;Office Action, dated Mar. 9, 2016, received in Danish Patent Application No. 201500574 (7265DK), which corresponds with U.S. Appl. No. 14/866,159, 11 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patnet Application No. 2016100247 (7267AU), which corresponds with U.S. Appl. No. 14/868,078, 1 page.;;Office Action, dated Mar. 30, 2016, received in Danish Patent Application No. 201500588 (7267DK), which corresponds with U.S. Appl. No. 14/868,078, 9 pages.;;Office Action, Apr. 4, 2016, received in Danish Patent Application No. 201500582 (7270DK), which corresponds with U.S. Appl. No. 14,863,432, 10 pages.;;Office Action, dated Mar. 22, 2016, received in Danish Patent Application No. 201500576 (7294DK), which corresponds with U.S. Appl. No. 14/866,989, 10 pages.;;Office Action, dated Mar. 28, 2016, received in U.S. Appl. No. 14/869,899 (7309), 17 pages.;;Office Action, dated Feb. 3, 2016, received in Danish Patent Application No. 201500592 (7309DK), which corresponds with U.S. Appl. No. 14/869,899, 9 pages.;;Office Action, dated Mar. 4, 2016, received in U.S. Appl. No. 14/866,992 (7310), 30 pages.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500593 (7310DK), which corresponds with U.S. Appl. No. 14/866,992, 10 pages.;;Office Action, dated Nov. 30, 2015, received in U.S. Appl. No. 14/845,217 (7314), 24 pages.;;Final Office Action, dated Apr. 22, 2016, received in U.S. Appl. No. 14/845,217 (7314), 36 pages.;;Office Action, dated Feb. 3, 2016, received in U.S. Appl. No. 14/856,517 (7317), 36 pages.;;Office Action, dated Feb. 11, 2016, received in U.S. Appl. No. 14/856,519 (7318), 34 pages.;;Office Action, dated Feb. 1, 2016, received in U.S. Appl. No. 14/857,645 (7321), 15 pages.;;Office Action, dated Apr. 8, 2016, received in Danish Patent Application No. 201500584 (7330DK), which corresponds with U.S. Appl. No. 14/864,580, 9 pages.;;Office Action, dated Apr. 19, 2016, received in U.S. Appl. No. 14/864,627 (7332), 9 pages.;;Office Action, dated Apr. 8, 2016, received in Danish Patent Application No. 201500585 (7332DK), which corresponds with U.S. Appl. No. 14/864,627, 9 pages.;;Office Action, dated Mar. 29, 2016, received in U.S. Appl. No. 14/866,361 (7334), 22 pages.;;Office Adtion, dated Apr. 7, 2016, received in Danish Patent Application No. 201500579 (7334DK), which corresponds with U.S. Appl. No. 14/866,361, 10 pages.;;Office Action, dated Mar. 22, 2016, received in Danish Patent Application No. 201500587 (7335DK), which corresponds with U.S. Appl. No. 14/866,987, 8 pages.;;Office Action, dated Apr. 1, 2016, received in Danish Patent Application No. 201500589 (7336DK), which corresponds with U.S. Appl. No. 14/866,989, 8 pages.;;Office Action, dated Apr. 11, 2016, received in U.S. Appl. No. 14/871,236 (7337), 23 pages.;;Office Action, dated Apr. 8, 2016, received in Danish Patent Application No. 201500595 (7337DK), which corresponds with U.S. Appl. No. 14/871,236, 12 pages.;;Office Action, dated Apr. 6, 2016, received in Danish Patent Application No. 201500596 (7339DK), which corresponds with U.S. Appl. No. 14/870,882, 7 pages.;;Office Action, dated Apr. 7, 2016, received in Danish Patent Application No. 201500597 (7341DK), which corresponds with U.S. Appl. No. 14/871,227, 7 pages.;;Office Action, dated Apr. 18, 2016, received in Danish Patent Application No. 201500601 (7342DK), which corresponds with U.S. Appl. No. 14/871,336, 8 pages.;;Notice of Allowance, dated Apr. 18, 2016, received in Danish Patent Application No. 201500600 (7343DK), which corresponds with U.S. Appl. No. 14/871,462, 7 pages.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500594 (7344DK), which corresponds with U.S. Appl. No. 14/867,823, 10 pages.;;Office Action, dated Mar. 21, 2016, received in Danish Patent Application No. 201500598 (7345DK), which corresponds with U.S. Appl. No. 14/867,892, 9 pages.;;Certificate of Grant, dated Mar. 24, 2016, received in Australian Patent Application No. 20161002253 (7352AU), which corresponds with U.S. Appl. No. 14/867,990, 1 page.;;Office Action, dated Mar. 18, 2016, received in Danish Patent Application No. 201500581 (7352DK), which corresponds with U.S. Appl. No. 14/867,990, 9 pages.;;International Search Report and Written Opinion, dated Dec. 10, 2010, received in International Patent Application No. PCT/US2010/050057, which corresponds with U.S. Appl. No. 12/888,381, 9 pages.;;International Preliminary Search Report on Patentability, dated Oct. 9, 2012, received in International Patent Application No. PCT/US2010/050057, which corresponds with U.S. Appl. No. 12/888,381, 6 pages.;;International Search Report and Written Opinion dated May 26, 2014, received in International Application No. PCT/US2013/040053, which corresponds to U.S. Appl. No. 14/535,671, 32 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040053, which corresponds to U.S. Appl. No. 14/535,671, 26 pages.;;Invitation to Pay Additional Fees dated Feb. 10, 2014, received in International Application No. PCT/US2013/069472, which corresponds to U.S. Appl. No. 14/608,895, 6 pages.;;International Search Report and Written Opinion dated Apr. 7, 2014, received in International Application No. PCT/US2013/069472, which corresponds to U.S. Appl. No. 14/608,895, 24 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069472, which corresponds with U.S. Appl. No. 14/608,895, 18 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040054, which corresponds to U.S. Appl. No. 14/536,235, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040054, which corresponds to U.S. Appl. No. 14/536,235, 11 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040056, which corresponds to U.S. Appl. No. 14/536,367, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040056, which corresponds to U.S. Appl. No. 14/536,367, 11 pages.;;Extended European Search Report, dated Nov. 6, 2015, received in European Patent Application No. 15183980.0, which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;International Search Report and Written Opinion dated Aug. 6, 2013, received in International Application No. PCT/US2013/040058, which corresponds to U.S. Appl. No. 14/536,426, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040058, which corresponds to U.S. Appl. No. 14/536,426, 11 pages.;;Invitation to Pay Additional Fees dated Sep. 25, 2013, received in International Application No. PCT/US2013/040061, which corresponds to U.S. Appl. No. 14/536,464, 6 pages.;;International Search Report and Written Opinion dated Feb. 5, 2014, received in International Application No. PCT/US2013/040061, which corresponds to U.S. Appl. No. 14/536,464, 30 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040061, which corresponds to U.S. Appl. No. 14/536,464, 26 pages.;;Invitation to Pay Additional Fees dated Oct. 8, 2013, received in International Application No. PCT/US2013/040067, which corresponds to U.S. Appl. No. 14/536,644, 8 pages.;;International Search Report and Written Opinion dated May 8, 2014, received in International Application No. PCT/US2013/040067, which corresponds to US Appl. No. 14/536,644, 45 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040067, which corresponds to U.S. Appl. No. 14/536,644, 36 pages.;;International Search Report and Written Opinion dated Mar. 12, 2014, received in International Application No. PCT/US2013/069479, which corresponds with U.S. Appl. No. 14/608,926, 14 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069479, which corresponds with U.S. Appl. No. 14/608,926, 11 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040070, which corresponds to U.S. Appl. No. 14/535,646, 12 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040070, which corresponds to U.S. Appl. No. 14/535,646, 10 pages.;;Invitation to Pay Additional Fees dated Oct. 28, 2013, received in International Application No. PCT/US2013/040072, which corresponds to U.S. Appl. No. 14/536,141, 7 pages.;;International Search Report and Written Opinion dated Apr. 7, 2014, received in International Application No. PCT/US2013/040072, which corresponds to U.S. Appl. No. 14/536,141, 38 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/US2013/040072, which corresponds to U.S. Appl. No. 14/536,141, 32 pages.;;Invitation to Pay Additional Fees dated Feb. 14, 2014, received in International Application No. PCT/US2013/069483, which corresponds with U.S. Appl. No. 14/608,942, 7 pages.;;International Search Report and Written Opinion dated Apr. 7, 2014, received in International Application No. PCT/US2013/069483, which corresponds with U.S. Appl. No. 14/608,942, 18 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Application No. PCT/2013/069483, which corresponds to U.S. Appl. No. 14/608,942, 13 pages.;;Invitation to Pay Additional Fees dated Oct. 28, 2013, received in International Application No. PCT/US2013/040087, which corresponds to U.S. Appl. No. 14/536,166, 8 pages.;;International Search Report and Written Opinion dated Mar. 3, 2014, received in International Application No. PCT/US2013/040087, which corresponds to U.S. Appl. No. 14/536,166, 35 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040087, which corresponds to U.S. Appl. No. 14/536,166, 29 pages.;;International Search Report and Written Opinion dated Aug. 7, 2013, received in International Application No. PCT/US2013/040093, which corresponds to U.S. Appl. No. 14/536,203, 11 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013040093, which corresponds to U.S. Appl. No. 14/536,203, 9 pages.;;Invitation to Pay Additional Fees dated Apr. 17, 2014, received in International Application No. PCT/US2013/069484, which corresponds with U.S. Appl. No. 14/608,965, 7 pages.;;International Search Report and Written Opinion dated Jul. 9, 2014, received in International Application No. PCT/US2013/069484, which corresponds with U.S. Appl. No. 14/608,965, 17 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069484, which corresponds with U.S. Appl. No. 14/608,965, 12 pages.;;Invitation to Pay Additional Fees dated Sep. 25, 2013, received in International Application No. PCT/US2013/040098, which corresponds to U.S. Appl. No. 14/536,247, 8 pages.;;International Search Report and Written Opinion dated Feb. 5, 2014, received in International Application No. PCT/US2013/040098, which corresponds to U.S. Appl. No. 14/536,247, 35 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040098, which corresponds to U.S. Appl. No. 14/536,247, 27 pages.;;Invitation to Pay Additional Fees dated Aug. 7, 2013, received in International Application No. PCT/US2013/040101, which corresponds to U.S. Appl. No. 14/536,267, 7 pages.;;International Search Report and Written Opinion dated Jan. 27, 2014, received in International Application No. PCT/US2013/040101, which corresponds to U.S. Appl. No. 14/536,267, 30 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040101, which corresponds to U.S. Appl. No. 14/536,267, 24 pages.;;Invitation to Pay Additional Fees dated Aug. 7, 2013, received in International Application No. PCT/US2013/040108, which corresponds to U.S. Appl. No. 14/536,291, 6 pages.;;International Search Report and Written Opinion dated Jan. 8, 2014, received in International Application No. PCT/US2013/040108, which corresponds to U.S. Appl. No. 14/536,291, 30 pages.;;International Preliminary Report on Patentability dated Nov. 20, 2014, received in International Application No. PCT/2013/040108, which corresponds to U.S. Appl. No. 14/536,291, 25 pages.;;Invitation to Pay Additional Fees dated Apr. 1, 2014, received in International Application No. PCT/US2013/069486, which corresponds with U.S. Appl. No. 14/608,985, 7 pages.;;International Search Report and Written Opinion dated Jun. 2, 2014, received in International Application No. PCT/US2013/069486, which corresponds with U.S. Appl. No. 14/608,985, 7 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069486, which corresponds with U.S. Appl. No. 14/608,985, 19 pages.;;International Search Report and Written Opinion dated Mar. 6, 2014, received in International Application No. PCT/US2013/069489, which corresponds with U.S. Appl. No. 14/609,006, 12 pages.;;International Preliminary Report on Patentability, dated Jun. 30, 2015, received in International Patent Application No. PCT/US2013/069489, which corresponds with U.S. Appl. No. 14/609,006, 10 pages.;;Office Action, dated May 6, 2016, received in U.S. Appl. No. 14/536,426 (5842), 23 pages.;;Office Action, dated May 9, 2016, received in U.S. Appl. No. 14/863,432 (7270), 26 pages.;;Office Action, dated Apr. 29, 2016, received in U.S. Appl. No. 14/867,823 (7344), 28 pages.;;Office Action, dated Apr. 21, 2016, received in European Patent Application No. 13795392.3 (5845EP) which corresponds to U.S. Appl. No. 14/608,926, 6 pgs.;;Notice of Allowance, dated Mar. 11, 2016, received in Australian Patent Application No. 2013368443 (5848AU) which corresponds with U.S. Appl. No. 14/536,141, 2 pgs.;;Office Action, dated Apr. 25, 2016, received in Japanese Patent Application No. 2015-550384, which corresponds with U.S. Appl. No. 14/608,985, 4 pgs. et al.",ACTIVE
246,US,B2,US 10841484 B2,066-021-862-753-792,2020-11-17,2020,US 201916534214 A,2019-08-07,US 201916534214 A;;US 201916252478 A;;US 201514864529 A;;US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device displays a representative image. While displaying the representative image, the device detects a first input. In response to the first input, the device transitions from displaying the representative image to displaying a respective image that was acquired by a camera before acquiring the representative image. After transitioning from displaying the representative image to displaying the respective image, the device displays, in sequence starting with the respective image, at least some images acquired by the camera before acquiring the representative image and at least some of images acquired by the camera after acquiring the representative image. The device detects termination of the first input. In response to detecting termination of the first input, the device displays the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;FOSS CHRISTOPHER P;;IVE JONATHAN;;KING NICHOLAS V;;KOCIENDA KENNETH L;;MANZARI BEHKISH J;;PIVONKA PAVEL;;PRESTON DANIEL T;;MEZAK CHARLES A;;TITI JUSTIN S;;GOBERA RUBALCAVA DANIEL E,APPLE INC (2019-08-26),https://lens.org/066-021-862-753-792,Granted Patent,yes,1285,2,6,100,0,G06F3/04845;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;G06F3/0485;;G11B27/34;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00;;G06F3/04845;;G06F3/04883;;G11B27/105;;G11B27/005;;G11B27/034;;H04N23/62;;H04N23/632;;H04N23/634;;G06F3/04817;;G06F3/04842;;G11B27/031;;G11B27/34,H04N5/232;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0488;;G11B27/00;;G11B27/031;;G11B27/034;;G11B27/10;;G11B27/34;;H04N101/00,,1196,9,021-411-866-534-301;;025-388-407-138-206;;000-218-078-532-210;;057-382-954-955-516;;169-380-977-375-129;;102-140-305-428-255;;172-005-321-198-602;;060-886-589-965-181;;032-349-806-075-996,10.1145/1449715.1449730;;10.1145/1056808.1056920;;10.1109/3dui.2012.6184186;;10.1145/1120212.1120408;;10.1145/142750.143079;;10.1145/1738826.1738856;;10.1145/964696.964719;;10.1145/1622176.1622198;;10.1109/infoseee.2014.6948192,"Agarwal, “How to Copy and Paste Text on Windows Phone 8,” Guiding Tech, http://web.archive.org/web20130709204246/http://www.guidingtech.com/20280/copy-paste-text-windows-phone-8/, Jul. 9, 2013, 10 pages.;;Angelov, “Sponsor Flip Wall with Jquery & CSS”, Tutorialzine. N.p., Mar. 24, 2010. Web. http://tutorialzine.com/2010/03/sponsor-wall-slip-jquery-css/, Mar. 24, 2010, 8 pages.;;Anonymous, “1-Click Installer for Windows Media Taskbar Mini-Player for Windows 7, 8, 8.1 10”, http://metadataconsulting.blogspot.de/2014/05/installer-for-windows-media-taskbar.htm, May 5, 2014, 6 pages.;;Anonymous, “Acer Liquid Z5 Duo User's Manual”, https://global-download.acer.com, Feb. 21, 2014, 65 pages.;;Anonymous, “Android—What Should Status Bar Toggle Button Behavior Be?”, https://ux.stackechange.com/questions/34814, Jan. 15, 2015, 2 pages.;;Anonymous, “Google Android 5.0 Release Date, Specs and Editors Hands on Review—CNET”, http://www.cnet.com/products/google-an-android-5-0-lollipop/, Mar. 12, 2015, 10 pages.;;Anonymous, “How Do I Add Contextual Menu to My Apple Watch App?”, http://www.tech-recipes.com/rx/52578/how-do-i-add-contextual-menu-to-my-apple-watch-app, Jan. 13, 2015, 3 pages.;;Anonymous, “[new] WMP12 with Taskbar Toolbar for Windows 7—Windows Customization—WinMatrix”, http://www.winmatrix.com/forums/index/php?/topic/25528-new-wmp12-with-taskbar-toolbar-for-windows-7, Jan. 27, 2013, 6 pages.;;Anonymous, “Nokia 808 PureView screenshots”, retrieved from Internet; no URL, Nov. 12, 2012, 8 pages.;;Anonymous, “Nokia 808 PureView User Guide,” http://download-fds.webapps.microsoft.com/supportFiles/phones/files/pdf_guides/devices/808/Nokia_808_UG_en_APAC.pdf, Jan. 1, 2012, 144 pages.;;Anonymous, “Notifications, Android 4.4 and Lower”, Android Developers, https://developer.android.com/design/patterns/notifications_k.html, May 24, 2015, 9 pages.;;Anonymous, “Taskbar Extensions”, https://web.archive.org/web/20141228124434/http://msdn.microsoft.com:80/en-us/library/windows/desktop/dd378460(v=vs.85).aspx, Dec. 28, 2014, 8 pages.;;Azundris, “A Fire in the Pie,” http://web.archive.org/web/20140722062639/http://blog.azundrix.com/archives/168-A-fire-in-the-sky.html, Jul. 22, 2014, 8 pages.;;Billibi, “Android 5.0 Lollipop”, https://www.bilibili.comvideo/av1636046?from=search&seid=3128140235778895126, Oct. 19, 2014, 6 pages.;;B-log—betriebsraum weblog, “Extremely Efficient Menu Selection: Marking Menus for the Flash Platform,” http://www.betriebsraum.de/blog/2009/12/11/extremely-efficient-menu-selection-marking -for-the-flash-platform, Dec. 11, 2009, 9 pages.;;Bolluyt, “5 Apple Watch Revelations from Apple's New WatchKit”, http://www.cheatsheet.com/tecnology/5-apple-watch-revelations-from-apples-new-watchkit.html/?a=viewall, Nov. 22, 2014, 3 pages.;;Brownlee, “Android 5.0 Lollipop Feature Review!”, https//www.youtube.com/watch?v=pEDQ1z1-PvU, Oct. 27, 2014, 5 pages.;;Clark, “Global Moxie, Touch Means a Renaissance for Radial Menus,” http://globalmoxie.com/blog/radial-menus-for-touch-ui˜print.shtml, Jul. 17, 2012, 7 pages.;;Cohen, Cinemagraphs are Animated Gifs for Adults, http://www.tubefilter.com/2011/07/10/cinemagraph, Jul. 10, 2011, 3 pages.;;CrackBerry Forums, Windows 8 Bezel Control and Gestures, http://wwwforums.crackberry.com/blackberry-playbook-f222/windows-8-bezel-control-gestures-705129/, Mar. 1, 2012, 8 pages.;;Crook, “Microsoft Patenting Multi-Screen, Milti-Touch Gestures,” http://techcrunch.com/2011/08/25/microsoft-awarded-patents-for-multi-screen-multi-touch-gestures/, Aug. 25, 2011, 8 pages.;;Cvil.ly—a design blog, Interesting Touch Interactions on Windows 8, http://cvil.ly/2011/06/04/interesting-touch-interactions-on-windows-8/, Jun. 4, 2011, 3 pages.;;Davidson, et al., “Extending 2D Object Arrangement with Pressure-Sensitive Layering Cues”, Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology, Oct. 19, 2008, 4 pages.;;Dinwiddie, et al., “Combined-User Interface for Computers, Television, Video Recorders, and Telephone, Etc”, ip.com Journal, Aug. 1, 1990, 3 Pages.;;Drinkwater, “Glossary: Pre/Post Alarm Image Buffer,” http://www.networkwebcams.com/ip-camera-learning-center/2008/07/17/glossary-prepost-alarm-image-buffed, Jul. 17, 2008, 1 page.;;Dzyre, “10 Android Notification Features You Can Fiddle With”, http://www.hongkiat.com/blog/android-notification-features, Mar. 10, 2014, 10 pages.;;Easton-Ellett, “Three Free Cydia Utilities to Remove iOS Notification Badges”, http://www.ijailbreak.com/cydia/three-free-cydia-utilies-to-remove-ios-notification-badges, Apr. 14, 2012, 2 pages.;;Elliot, “Mac System 7”, YouTube. Web. Mar. 8, 2017, http://www.youtube.com/watch?v=XLv22hfuuik, Aug. 3, 2011, 1 page.;;Farshad, “SageThumbs—Preview and Convert Pictures From Windows Context Menu”, https://web.addictivetips.com/windows-tips/sagethumbs-preview-and-convert-photos-from-windows-context-menu, Aug. 8, 2011, 5 pages.;;Fenlon, “The Case for Bezel Touch Gestures on Apple's iPad,” http://www.tested.com/tech/tablets/3104-the case-for-bezel-touch-gestures-on-apples-ipad/, Nov. 2, 2011, 6 pages.;;Flaherty, “Is Apple Watch's Pressure-Sensitive Screen a Bigger Deal Than the Gadget Itself?”, http://www.wired.com/2014/09/apple-watchs-pressure-sensitive-screen-bigger-deal-gadget, Sep. 15, 2014, 3 pages.;;Flixel, “Cinemagraph Pro for Mac”, https://flixel.com/products/mac/cinemagraph-pro, 2014, 7 pages.;;Flowplayer, “Slowmotion: Flowplayer,” https://web.archive.org/web/20150226191526/http://flash.flowplayer.org/plugins/streaming/slowmotion.html, Feb. 26, 2015, 4 pages.;;Forlines, et al., “Glimpse: a Novel Input Model for Multi-level Devices”, Chi '05 Extended Abstracts on Human Factors in Computing Systems, Apr. 2, 2005, 4 pages.;;Gardner, “Recenz—Recent Apps in One Tap”, You Tube, https://www.youtube.com/watch?v-qailSHRgsTo, May 15, 2015, 1 page.;;Gonzalo et al., “Zliding: Fluid Zooming and Sliding for High Precision Parameter Manipulation”, Department of Computer Science, University of Toronto, Seattle, Washington, Oct. 23, 2005, 10 pages.;;Google-Chrome, “Android 5.0 Lollipop”, http://androidlover.net/android-os/android-5-0-lollipop/android-5-0-lollipop-recent-apps-card-google-search.html, Oct. 19, 2014, 10 pages.;;Grant, “Android's Notification Center”, https://www.objc.io/issues/11-android/android-notifications, Apr. 30, 2014, 26 pages.;;Gurman, “Force Touch on iPhone 6S Revealed: Expect Shortcuts, Faster Actions, iOS”, 9To5Mac Aug. 10, 2015, 31 pages.;;IBM et al., “Pressure-Sensitive Icons”, IBM Technical Disclosure Bulletin, vol. 33, No. 1B, Jun. 1, 1990, 3 pages.;;ICIMS Recruiting Software, “Blackberry Playbook Review,” http://www.tested.com/tech.tablets/5749-blackberry-playbook-review/, 2015, 11 pages.;;IPhoneHacksTV, “Confero allows you to easily manage your Badge notifications—iPhone Hacks”, youtube, https://wwwyoutube.com/watch?v=JCk61pnL4SU, Dec. 26, 2014, 3 pages.;;IPhoneOperator, “Wasser Liveeffekt fur Homescreen & Lockscreen—Aquaboard (Cydia)”, http://www.youtube.com/watch?v=fG9YMF-mB0Q, Sep. 22, 2012, 3 pages.;;IPodHacks 142: “Water Ripple Effects on the Home and Lock Screen: AquaBoard Cydia Tweak Review”, YouTube, https://www.youtube.comwatch?v-Auu_uRaYHJs, Sep. 24, 2012, 3 pages.;;Jauregui, “Design and Evaluation of 3D Cursors and Motion Parallax for the Exploration of Desktop Virtual Environments”, IEEE Symposium on 3D User Interfaces 2012, Mar. 4, 2012, 8 pages.;;Kaaresoja, “Snap-Crackle-Pop: Tactile Feedback for Mobile Touch Screens,” Nokia Research Center, Helsinki, Finland, Proceedings of Eurohaptics vol. 2006, Jul. 3, 2006, 2 pages.;;Kiener, “Force Touch on iPhone”, https://www.youtube.com/watch?v=CEMmnsU5fC8, Aug. 4, 2015, 4 pages.;;Kleinman, “iPhone 6s Said to Sport Force Touch Display, 2GB of RAM”, https://www.technobuffalo.com/2015/01/15/iphone-6s-said-to-sport-force-touch-display-2gb-of-ram, Jan. 15, 2015, 2 pages.;;Kost, “LR3-Deselect All Images But One”, Julieanne Kost's Blog, blogs.adobe.com/jkost/2011/12/lr3-deselect-all-images-but-one.html, Dec. 22, 2011, 1 page.;;Kronfli, “HTC Zoe Comes to Google Play, Here's Everything You Need to Know,” Know Your Mobile, http://www.knowyourmobile.com/htc/htc-one/19550/what-htc-zoe, Aug. 14, 2014, 5 pages.;;Kumar, “How to Enable Ripple Effect on Lock Screen of Galaxy S2”, YouTube, http, http://www.youtube.com/watch?v+B9-4M5abLXA, Feb. 12, 2013, 3 pages.;;Kurdi, “XnView Shell Extension: A Powerful Image Utility Inside the Context Menu”, http://www.freewaregenius.com/xnview-shell-extension-a-powerful-image-utility-inside-the-context-menu, Jul. 30, 2008, 4 pages.;;Laurie, “The Power of the Right Click,” http://vlaurie.com/right-click/customize-context-menu.html, 2002-2016, 3 pages.;;MacKenzie et al., “The Tactile Touchpad”, Chi '97 Extended Abstracts on Human Factors in Computing Systems Looking to the Future, Chi '97, Mar. 22, 1997, 5 pages.;;Mahdi, Confero now available in Cydia, brings a new way to manage Notification badges [Jailbreak Tweak], http://www.iphonehacks.com/2015/01/confero/tweak-manage-notification-badges.html, Jan. 1, 2015, 2 pages.;;Matthew, “How to Preview Photos and Images From Right-Click Context Menue in Windows [Tip]”, http://www.dottech.org/159009/add-image-preview-in-windows-context-menu-tip, Jul. 4, 2014, 5 pages.;;McGarry, “Everything You Can Do With Force Touch on Apple Watch”, Macworld, www.macworld.com, May 6, 2015, 4 pages.;;McRitchie, “Internet Explorer Right-Click Menus,” http://web.archive.org/web-201405020/http:/dmcritchie.mvps.org/ie/rightie6.htm, May 2, 2014, 10 pages.;;Microsoft, “Lumia—How to Personalize Your Start Screen”, https://www.youtube.com/watch?v=6GI5Z3TrSEs, Nov. 11, 2014, 3 pages.;;Microsoft, “Use Radial Menus to Display Commands in OneNote for Windows 8,” https://support.office.com/en-us/article/Use-radial-menues-to-display-OneNote-commands-Od75f03f-cde7-493a-a8a0b2ed6f99fbe2, 2016, 5 pages.;;Minsky, “Computational Haptics the Sandpaper System for Synthesizing Texture for a Force-Feedback Display,” Massachusetts Institute of Technology, Jun. 1978, 217 pages.;;Mitroff, “Google Android 5.0 Lollipop,” http://www.cnet.com/products/google-android-5-0-lollipop, Mar. 12, 2015, 5 pages.;;Mohr, “Do Not Disturb—The iPhone Feature You Should Be Using”, http.www.wonderoftech.com/do-not-disturb-iphone, Jul. 14, 2014, 30 pages.;;Nacca, “NiLS Lock Screen Notifications / Floating Panel—Review”, https://www.youtube.com/watch?v=McT4QnS9TDY, Feb. 3, 2014, 4 pages.;;Neuburg, “Detailed Explanation iOS SDK”, Oreilly Japan, Dec. 22, 2014, vol. 4, p. 175-186, 15 pages.;;Nickinson, How to Use Do Not Disturb on the HTC One M8, https://www.androidcentral.com/how-to-use-do-not-disturb-htc-one-m8, Apr. 7, 2014, 9 pages.;;Nickinson, “Inside Android 4.2: Notifications and Quick Settings”, https://www.andrloidcentral.com/inside-android-42-notifications-and-quick-settings, Nov. 3, 2012, 3 pages.;;Nikon, “Scene Recognition System and Advanced SRS,” http://www.nikonusa.com/en.Learn-And-Explore/Article/ftlzi4rr/Scene-Recognition-System.html, Jul. 22, 2015, 2 pages.;;Ogino, “iOS 7 Design Standard”, Japan, Impress Japan Corporation, 1st edition, Nov. 21, 2013, 2 pages.;;Oh, et al., “Moving Objects with 2D Input Devices in CAD Systems and Desktop Virtual Environments”, Proceedings of Graphics Interface 2005, 8 pages, May 2005.;;O'Hara, et al., “Pressure-Sensitive Icons”, ip.com Journal, ip.com Inc., West Henrietta, NY, US, Jun. 1, 1990, 2 Pages.;;Pallenberg, “Wow, the new iPad had gestures.” https://plus.google.com/+SaschaPallenberg/posts/aaJtJogu8ac, Mar. 7, 2012, 2 pages.;;Phonebuff, “How to Pair Bluetooth on the iPhone”, https://www.youtube.com/watch?v=LudNwEar9A8, Feb. 8, 2012, 3 pages.;;Plaisant et al, “Touchscreen Toggle Design”, Proceedings of CHI '92, pp. 667-668, May 3-7, 1992, 2 pages.;;PoliceOne.com, “COBAN Technologies Pre-Event Buffer & Fail Safe Feature,” http://www.policeone.com/police-products/police-technology/mobile-computures/videos/5955587-COBAN-Technologies-Pre-Event, Nov. 11, 2010, 2 pages.;;Pradeep, “Android App Development—Microsoft Awarded With Patents on Gestures Supported on Windows 8,” http://mspowerusercom/microsoft-awarded-with-patents-on-gestures-supported-on-windows-8/, Aug. 25, 2011, 16 pages.;;“Quickly Preview Songs in Windows Media Player 12 in Windows 7,” Quickly Preview Songs in Windows Media Player 12 in Windows 7. How-to Geek, Apr. 28, 2010, Web. May 8, 2010, http://web.archive.org/web/20100502013134/http://www.howtogeek.com/howto/16157/quickly-preview-songs-in-windows-media-center-12-in-windows-7>, 6 pages.;;Quinn, et al., “Zoofing! Faster List Selections with Pressure-Zoom-Flick-Scrolling”, Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group on Design, Nov. 23, 2009, ACM Press, vol. 411, 8 pages.;;Rekimoto, et al., “PreSense: Interaction Techniques for Finger Sensing Input Devices”, Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology, Nov. 30, 2003, 10 pages.;;Rekimoto, et al., “PreSensell: Bi-directional Touch and Pressure Sensing Interactions with Tactile Feedback”, Conference on Human Factors in Computing Systems Archive, ACM, Apr. 22, 2006, 6 pages.;;Ritchie, “How to see all the unread message notifications on your iPhone, all at once, all in the same place | iMore”, https://www.imore.com/how-see-all-unread-message-notifications-your-iphone-all-once-all-same-place, Feb. 22, 2014, 2 pages.;;Rubino et al., “How to Enable ‘Living Images’ on your Nokia Lumia with Windows Phone 8.1”, https://www.youtube.com/watch?v=RX7vpoFy1Dg, Jun. 6, 2014, 5 pages.;;Sony, “Intelligent Scene Recognition,” https://www.sony-asia.com/article/252999/section/product/product/dsc-t77, downloaded on May 20, 2016, 5 pages.;;Sood, “MultitaskingGestures”, http://cydia.saurik.com/package/org.thebigboxx.multitaskinggestures/, Mar. 3, 2014, 2 pages.;;Stewart, et al., “Characteristics of Pressure-Based Input for Mobile Devices”, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Apr. 2010, 10 pages.;;Stross, “Wearing A Badge, and a Video Camera,” The New York Times, http://www.nytimes.com/2013/04/07/business/wearable-video-cameras-for-police-offers.html? R=0, Apr. 6, 2013, 4 pages.;;Taser, “Taser Axon Body Camera User Manual,” https://www.taser.com/images/support/downloads/product-resourses/axon_body_product_manual.pdf, Oct. 1, 2013, 24 pages.;;Tidwell, “Designing Interfaces,” O'Reilly Media, Inc., USA, Nov. 2005, 348 pages.;;Tweak, “QuickCenter—Add 3D-Touch Shortcuts to Control Center”, https://www.youtube.com/watch?v=8rHOFpGvZFM, Mar. 22, 2016, 2 pages.;;Tweak, “iOS 10 Tweak on iOS 9.0.2 Jailbread & 9.2.1-9.3 Support: QuickCenter 3D, Touch Cydia Tweak!” https://wwwyoutube.com/watch?v=opOBr30_Fkl, Mar. 6, 2016, 3 pages.;;UpDown-G, “Using Multiple Selection Mode in Android 4.0 / Getting Started”, https://techbooster.org/android/13946, Mar. 7, 2012, 7 pages.;;VGJFeliz, “How to Master Android Lollipop Notifications in Four Minutes!”, https://www.youtube.com/watch?v=S-zBRG7GJgs, Feb. 8, 2015, 5 pages.;;VisioGuy, “Getting a Handle on Selecting and Subselecting Visio Shapes”, http://www.visguy.com/2009/10/13/getting-a-handle-on-selecting-and-subselecting-visio-shapes/, Oct. 13, 2009, 18 pages.;;Wikipedia, “AirDrop,”, Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/AirDrop, May 17, 2016, 5 pages.;;Wikipedia, “Cinemagraph,” Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/Cinemagraph, Last Modified Mar. 16, 2016, 2 pages.;;Wikipedia, “Context Menu,” Wikipedia, the free encyclopedia https://en.wikipedia.org/wiki/Context menu, Last Modified May 15, 2016, 4 pages.;;Wikipedia, “HTC One (M7),” Wikipedia, the free encyclopedia, https://en.wikipedia.org/wiki/HTC_One_(M7), Mar. 2013, 20 pages.;;Wikipedia, “Mobile Ad Hoc Network,” Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/Mobile_ad_hoc_network, May 20, 2016, 4 pages.;;Wikipedia, “Pie Menu,” Wikipedia, the free encyclopedia, http://en.wikipedia.org/wiki/Pie_menu, Last Modified Jun. 4, 2016, 3 pages.;;Wikipedia, “Quick Look,” from Wikipedia, the free encyclopedia, https;//en.wikipedia.org/wiki/Quick_Look, Last Modified Jan. 15, 2016, 3 pages.;;Wikipedia, “Sony Xperia Z1”, Wikipedia, the free encyclopedia, https://enwikipedia.org/wiki/Sony_Experia_Z1, Sep. 2013, 10 pages.;;Yatani, et al., SemFeel: A User Interface with Semantic Tactile Feedback for Mobile Touch-Screen Devices, Proceedings of the 22nd annual ACM symposium on user interface software and technology (UIST '09), Oct. 2009, 10 pages.;;YouTube, “Android Lollipop Lock-Screen Notification Tips”, https://www.youtube.com/watch?v=LZTxHBOwzIU, Nov. 13, 2014, 3 pages.;;YouTube, “Blackberry Playbook bezel interaction,” https://www.youtube.com/watch?v=YGkzFqnOwXl, Jan. 10, 2011, 2 pages.;;YouTube, “How to Master Android Lollipop Notifications in Four Minutes!”, Video Gadgets Journal (VGJFelix), https://www.youtube.com/watch?v=S-zBRG7GGJgs, Feb. 8, 2015, 4 pages.;;YouTube, “HTC One Favorite Camera Features”, http://www.youtube.com/watch?v=sUYHfcjI4RU, Apr. 28, 2013, 3 pages.;;YouTube, “Multitasking Gestures: Zephyr Like Gestures on iOS”, https://www.youtube.com/watch?v=Jcod-f7Lw0l, Jan. 27, 2014, 3 pages.;;YouTube, “Recentz—Recent Apps in a Tap”, https://www.youtube.com/watch?v=qailSHRgsTo, May 15, 2015, 1 page.;;Office Action, dated Mar. 15, 2017, received in U.S. Appl. No. 14/535,671 (5448), 13 pages.;;Office Action, dated Nov. 30, 2017, received in U.S. Appl. No. 14/535,671 (5448), 21 pages.;;Notice of Allowance, dated Sep. 5, 2018, received in U.S. Appl. No. 14/535,671 (5448), 5 pages.;;Office Action, dated Jun. 29, 2017, received in U.S. Appl. No. 14/608,895 (5839), 30 pages.;;Final Office Action, dated Feb. 22, 2018, received in U.S. Appl. No. 14/608,895 (5839), 20 pages.;;Notice of Allowance, dated Jun. 26, 2018, received in U.S. Appl. No. 14/608,895 (5839), 9 pages.;;Office Action, dated Dec. 18, 2015, received in Australian Patent Application No. 2013368440 (5839AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Oct. 18, 2016, received in Australian Patent Application No. 2013368440 (5839AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Notice of Allowance, dated Dec. 20, 2016, received in Australian Patent Application No. 2013368440 (5839AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Apr. 29, 2017, received in Australian Patent Application No. 2013368440 (5839AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 6, 2017, received in Chinese Patent Application No. 201380068493.6 (5839CN), which corresponds with U.S. Appl. No. 14/608,895, 5 pages.;;Office Action, dated Oct. 9, 2018, received in Chinese Patent Application No. 201380068493.6 (5839CN), which corresponds with U.S. Appl. No. 14/608,895, 3 pages.;;Patent, dated Dec. 25, 2018, received in Chinese Patent Application No. 201380068493.6 (5839CN), which corresponds with U.S. Appl. No. 14/608,895, 4 pages.;;Office Action, dated Jul. 21, 2016, received in European Patent Application No. 13795391.5 (5839EP), which corresponds with U.S. Appl. No. 14/536,426, 9 pages.;;Office Action, dated Mar. 9, 2018, received in European Patent Application No. 13795391.5 (5839EP), which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Intention to Grant, dated Jul. 6, 2018, received in European Patent Application No. 13795391.5 (5839EP), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Certificate of Grant, dated Dec. 26, 2018, received in European Patent Application No. 13795391.5 (5839EP), which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Sep. 13, 2016, received in Japanese Patent Application No. 2015-547948 (5839JP), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Patent, dated May 12, 2017, received in Japanese Patent Application No. 2015-547948 (5839JP), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Apr. 5, 2016, received in Korean Patent Application No. 10-2015-7018851 (5839KR), which corresponds with U.S. Appl. No. 14/536,426, 7 pages.;;Office Action, dated Feb. 24, 2017, received in Korean Patent Application No. 10-2015-7018851 (5839KR), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Patent, dated May 26, 2017, received in Korean Patent Application No. 2015-7018851 (5839KR), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Oct. 5, 2018, received in Korean Patent Application No. 2018-7028236 (5839KR01), which corresponds with U.S. Appl. No. 14/608,895, 6 pages.;;Office Action, dated Jul. 26, 2017, received in U.S. Appl. No. 14/536,235 (5840), 14 pages.;;Final Office Action, dated Feb. 26, 2018, received in U.S. Appl. No. 14/536,235 (5840), 13 pages.;;Notice of Allowance, dated Aug. 15, 2018, received in U.S. Appl. No. 14/536,235 (5840), 5 pages.;;Office Action, dated Apr. 5, 2017, received in U.S. Appl. No. 14/536,367 (5841), 16 pages.;;Notice of Allowance, dated Nov. 30, 2017, received in U.S. Appl. No. 14/536,367 (5841), 9 pages.;;Notice of Allowance, dated May 16, 2018, received in U.S. Appl. No. 14/536,367 (5841), 5 pages.;;Office Action, dated Dec. 17, 2015, received in U.S. Appl. No. 14/536,426 (5842), 28 pages.;;Final Office Action, dated May 6, 2016, received in U.S. Appl. No. 14/536,426 (5842), 23 pages.;;Office action, dated Aug. 3, 2017, received in U.S. Appl. No. 14/536,426 (5842), 10 pages.;;Office Action, dated Jul. 15, 2015, received in Australian Patent Application No. 2013259606 (5842AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Notice of Allowance, dated May 23, 2016, received in Australian Patent Application No. 2013259606 (5842AU), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Sep. 15, 2016, received in Australian Patent Australian Patent Application No. 2013259606 (5842AU), which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Office Action, dated Nov. 18, 2015, received in Australian Patent Application No. 2015101231 (5842AU01), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated May 15, 2017, received in Australian Patent Application No. 2016216580 (5842AU02), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated May 8, 2018, received in Australian Patent Application No. 2016216580 (5842AU02), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Notice of Allowance, dated May 17, 2018, received in Australian Patent Application No. 2016216580 (5842AU02), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Certificate of Grant, dated Sep. 13, 2018, received in Australian Patent Application No. 2016216580 (5842AU02), which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Office Action, dated Apr. 12, 2019, received in Australian Patent Application No. 2018223021 (5842AU03), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Sep. 19, 2017, received in Chinese Patent Application No. 201380035982.1 (5842CN), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Notice of Allowance, dated May 10, 2018, received in Chinese Patent Application No. 201380035982.1 (5842CN), which corresponds with U.S. Appl. No. 14/536,426, 2 pages.;;Patent, dated Aug. 17, 2018, received in Chinese Patent Application No. 201380035982.1 (5842CN), which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Office Action, dated Sep. 20, 2017, received in Chinese Patent Application No. 201510566550.4 (5842CN01), which corresponds with U.S. Appl. No. 14/536,426, 11 pages.;;Notice of Allowance, dated Aug. 8, 2018, received in Chinese Patent Application No. 201510566550.4 (5842CN01), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Patent, dated Oct. 23, 2018, received in Chinese Patent Application No. 201510566550.4 (5842CN01), which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Decision to Grant, dated Jul. 14, 2016, received in European Patent Application No. 13724100.6 (5842EP), which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Letters Patent, dated Aug. 10, 2016, received in European Patent Application No. 13724100.6 (5842EP), which corresponds with U.S. Appl. No. 14/536,426, 1 page.;;Office Action, dated Jan. 20, 2017, received in European Patent Application No. 15183980.0 (5842EP01), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Office Action, dated Aug. 21, 2017, received in European Patent Application No. 15183980.0 (5842EP01), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Intention to Grant, dated Mar. 9, 2018, received in European Patent Application No. 15183980.0 (5842EP01), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Intention to Grant, dated Aug. 14, 2018, received in European Patent Application No. 15183980.0 (5842EP01), which corresponds with U.S. Appl. No. 14/536,426, 5 pages.;;Decision to Grant, dated Jan. 10, 2019, received in European Patent Application No. 15183980.0 (5842EP01), which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Patent, dated Feb. 6, 2019, received in European Patent Application No. 15183980.0 (5842EP01), which corresponds with U.S. Appl. No. 14/536,426, 4 pages.;;Certificate of Grant, dated Nov. 10, 2017, received in Hong Kong Patent Application No. 15107535.0 (5842HK), which corresponds with U.S. Appl. No. 14/536,426, 2 pages.;;Office Action, dated Mar. 4, 2016, received in Japanese Patent Application No. 2015-511644 (5842JP), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Feb. 6, 2017, received in Japanese Patent Application No. 2015-511644 (5842JP), which corresponds with U.S. Appl. No. 14/536,426, 6 pages.;;Notice of Allowance, dated Dec. 8, 2017, received in Japanese Patent Application No. 2015-511644 (5842JP), which corresponds with U.S. Appl. No. 14/536,426, 6 pages.;;Patent, dated Jan. 12, 2018, received in Japanese Patent Application No. 2015-511644 (5842JP), which corresponds with U.S. Appl. No. 14/536,426, 3 pages.;;Office Action, dated Nov. 6, 2018, received in Japanese Patent Application No. 2018-000753 (5842JP01), which corresponds with U.S. Appl. No. 14/536,426, 8 pages.;;Office Action, dated Mar. 9, 2017, received in U.S. Appl. No. 14/536,464 (5843), 21 pages.;;Final Office Action, dated Aug. 25, 2017, received in U.S. Appl. No. 14/536,464 (5843), 30 pages.;;Office Action, dated Feb. 12, 2018, received in U.S. Appl. No. 14/536,464 (5843), 33 pages.;;Final Office Action, dated Jun. 22, 2018, received in U.S. Appl. No. 14/536,464 (5843), 32 pages.;;Office Action, dated Sep. 25, 2017, received in U.S. Appl. No. 14/536,644 (5844), 29 pages.;;Final Office Action, dated May 3, 2018, received in U.S. Appl. No. 14/536,644 (5844), 28 pages.;;Office Action, dated Nov. 2, 2018, received in U.S. Appl. No. 14/536,644 (5844), 24 pages.;;Office Action, dated Oct. 19, 2017, received in U.S. Appl. No. 14/608,926 (5845), 14 pages.;;Final Office Action, dated Jun. 6, 2018, received in U.S. Appl. No. 14/608,926 (5845), 19 pages.;;Notice of Allowance, dated Apr. 10, 2019, received in U.S. Appl. No. 14/608,926 (5845), 16 pages.;;Office Action, dated Feb. 1, 2016, received in Australian Patent Application No. 2013368441 (5845AU), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Notice of Allowance, dated Mar. 30, 2016, received in Australian Patent Application No. 2013368441 (5845AU), which corresponds with U.S. Appl. No. 14/608,926, 1 page.;;Certificate of Grant, dated Jul. 29, 2016, received in Australian Patent Application No. 2013368441 (5845AU), which corresponds with U.S. Appl. No. 14/608,926, 1 page.;;Office Action, dated Jan. 3, 2017, received in Australian Patent Application No. 2016201451 (5845AU01), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Notice of Acceptance, dated Dec. 20, 2017, received in Australian Patent Application No. 2016201451 (5845AU01), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Certificate of Grant, dated May 3, 2018, received in Australian Patent Application No. 2016201451 (5845AU01), which corresponds with U.S. Appl. No. 14/608,926, 1 page.;;Office Action, dated May 4, 2017, received in Chinese Patent Application No. 201380068414.1 (5845CN), which corresponds with U.S. Appl. No. 14/608,926, 5 pages.;;Notice of Allowance, dated Feb. 8, 2018, received in Chinese Patent Application No. 201380068414.1 (5845CN), which corresponds with U.S. Appl. No. 14/608,926, 2 pages.;;Patent, dated May 4, 2018, received in Chinese Patent Application No. 201380068414.1 (5845CN), which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Office Action, dated Apr. 21, 2016, received in European Patent Application No. 13795392.3 (5845EP), which corresponds with U.S. Appl. No. 14/608,926, 6 pages.;;Office Action, dated May 6, 2016, received in European Patent Application No. 13795392.3 (5845EP), which corresponds with U.S. Appl. No. 14/608,926, 6 pages.;;Office Action, dated Nov. 11, 2016, received in European Patent Application No. 13795392.3 (5845EP), which corresponds with U.S. Appl. No. 14/608,926, 6 pages.;;Office Action, dated Jul. 4, 2017, received in European Patent Application No. 13795392.3 (5845EP), which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Oral Summons, dated Feb. 13, 2017, received in European Patent Application No. 13795392.3 (5845EP), which corresponds with U.S. Appl. No. 14/608,926, 11 pages.;;Office Action, dated Mar. 14, 2016, received in Japanese Patent Application No. 2015-549392 (5845JP), which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Notice of Allowance, dated Jan. 17, 2017, received in Japanese Patent Application No. 2015-549392 (5845JP), which corresponds with U.S. Appl. No. 14/608,926, 2 pages.;;Patent, dated Feb. 17, 2017, received in Japanese Patent Application No. 2015-549392 (5845JP), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Patent, dated Apr. 27, 2018, received in Japanese Patent Application No. 2017-024234 (5845JP01), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Office Action, dated Feb. 22, 2019, received in Japanese Patent Application No. 2018-079290 (5845JP02), which corresponds with U.S. Appl. No. 14/608,926, 7 pages.;;Office Action, dated May 12, 2016, received in Korean Patent Application No. 10-2015-7018853, (5845KR), which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Notice of Allowance, dated Mar. 31, 2017, received in Korean Patent Application No. 2015-7018853 (5845KR), which corresponds with U.S. Appl. No. 14/608,926, 4 pages.;;Patent, dated Jun. 30, 2017, received in Korean Patent Application No. 2015-7018853 (5845KR), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Office Action, dated Aug. 22, 2017, received in Korean Patent Application No. 2017-7018250 (5845KR01), which corresponds with U.S. Appl. No. 14/608,926, 2 pages.;;Notice of Allowance, dated Dec. 29, 2017, received in Korean Patent Application No. 2017-7018250 (5845KR01), which corresponds with U.S. Appl. No. 14/608,926, 3 pages.;;Office Action, dated Oct. 19, 2017, received in U.S. Appl. No. 14/536,646 (5846), 21 pages.;;Notice of Allowance, dated Aug. 9, 2018, received in U.S. Appl. No. 14/536,646 (5846), 5 pages.;;Office Action, dated Jul. 17, 2015, received in Australian Patent Application No. 2013259613 (5846AU), which corresponds with U.S. Appl. No. 14/536,646, 5 pages.;;Office Action, dated May 31, 2016, received in Australian Patent Application No. 2013259613 (5846AU), which corresponds with U.S. Appl. No. 14/536,646, 4 pages.;;Notice of Allowance, dated Jul. 5, 2016, received in Australian Patent Application No. 2013259613 (5846AU), which corresponds with U.S. Appl. No. 14/536,646, 3 pages.;;Office Action, dated Dec. 1, 2016, received in Chinese Patent Application No. 2013800362059 (5846CN), which corresponds with U.S. Appl. No. 14/536,646, 3 pages.;;Notice of Allowance, dated Oct. 9, 2017, received in Chinese Patent Application No. 2013800362059 (5846CN), which corresponds with U.S. Appl. No. 14/536,646, 3 pages. et al.",ACTIVE
247,EP,A1,EP 3591953 A1,014-106-503-943-03X,2020-01-08,2020,EP 19194418 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;EP 16730554 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.
",APPLE INC,IVE JONATHAN;;DYE ALAN C;;FEDERIGHI CRAIG M;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;CLARKE GRAHAM R;;KING NICHOLAS V;;PRESTON DANIEL T;;CHAUDRI IMRAM A;;MANZARI BEHKISH J;;BAUER SEBASTIAN J;;PENHA HENRIQUE D;;MEZAK CHARLES A;;GOBERA RUBALCAVA DANIEL E;;TITI JUSTIN T;;PIVONKA PAVEL,,https://lens.org/014-106-503-943-03X,Patent Application,yes,4,2,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N1/21;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N5/232,,0,0,,,,PENDING
248,US,B2,US 11042266 B2,120-693-892-542-900,2021-06-22,2021,US 201916584776 A,2019-09-26,US 201916584776 A;;US 201962856052 P;;US 201962843930 P,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DEVINE LYNNE;;DYE ALAN C;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN S,APPLE INC (2020-01-23),https://lens.org/120-693-892-542-900,Granted Patent,yes,98,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/0482;;G06F3/01;;G06F3/0484;;G06F3/0485;;G06F3/0488;;G06F9/451;;G06F16/432;;G06F16/435;;G06F16/438;;G06F16/44,,52,0,,,"Decision to Grant received for Danish Patent Application No. PA201870385, datedMar. 26, 2020, 2 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2020-7005314, dated Mar. 23, 2020, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/109,487, dated Apr. 21, 2020, 5 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/584,783, dated May 4, 2020, 3 pages.;;Office Action received for Chinese Patent Application No. 201811616429.8, dated May 7, 2020, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA201970535, dated May 20, 2020, 3 pages.;;Applicant-Initiated Interview Summary for U.S. Appl. No. 16/402,057, dated Mar. 16, 2020, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Mar. 4, 2020, 50 pages.;;Office Action received for Japanese Patent Application No. 2018-138559, dated Jan. 27, 2020, 7 pages (3 pages of English Translation and 4 pages of Official Copy).;;Final Office Action received for U.S. Appl. No. 16/584,783, dated May 19, 2020, 19 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated May 12, 2020, 8 pages.;;Office Action received for Danish Patent Application No. PA201670609, dated May 4, 2020, 7 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/450,531, dated Jun. 10, 2020, 10 pages.;;Notice of Allowance received for Canadian Patent Application No. 2,984,527, dated Apr. 30, 2020, 1 page.;;Notice of Allowance received for U.S. Appl. No. 16/791,257, dated Jun. 12, 2020, 11 pages.;;Office Action received for European Patent Application No. 18197554.1, dated Jun. 15, 2020, 4 pages.;;Search Report and Opinion received for Danish Patent Application No. PA201970535, dated Nov. 5, 2019, 10 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/403,184, dated Nov. 21, 2019, 3 pages.;;Intention to Grant received for Danish Patent Application No. PA201870385, dated Jan. 24, 2020, 2 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/109,487, dated Feb. 5, 2020, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,783, dated Jan. 30, 2020, 18 pages.;;Office Action received for Indian Patent Application No. 9044/CHENP/2014, dated Jan. 24, 2020, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Mar. 12, 2020, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Mar. 25, 2020, 8 pages.;;Examiner's Pre-Review Report received for Japanese Patent Application No. 2018-138559, dated Jul. 29, 2020, 6 pages (3 pages of English Translation and 3 pages of Official Copy).;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2020/031442, dated Aug. 25, 2020, 22 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 16/791,257, dated Aug. 31, 2020, 3 pages.;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Sep. 22, 2020, 49 pages.;;Intention to Grant received for European Patent Application No. 17180535.1, dated Sep. 24, 2020, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 16/450,531 dated Sep. 25, 2020, 7 pages.;;Office Action received for Australian Patent Application No. 2019264623, dated Sep. 14, 2020, 3 pages.;;Office Action received for Korean Patent Application No. 10-2020-7018255, dated Sep. 10, 2020, 12 pages (5 pages of English Translation and 7 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2019-123115, dated Aug. 31, 2020, 9 pages (4 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2019271873, dated Oct. 5, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/450,531, dated Aug. 11, 2020, 5 pages.;;Office Action received for European Patent Application No. 19724963.4, dated Jul. 28, 2020, 6 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019271873, dated Nov. 30, 2020, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-123115, dated Nov. 30, 2020, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Nov. 24, 2020, 4 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Nov. 12, 2020, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2019/024790, dated Nov. 19, 2020, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Nov. 23, 2020, 3 pages.;;Office Action received for Chinese Patent Application No. 201811136445.7, dated Oct. 28, 2020, 17 pages (10 pages of English Translation and 7 pages of Official Copy).;;Office Action received for European Patent Application No. 17813778.2, dated Nov. 26, 2020, 10 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Oct. 30, 2020, 2 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/031442, dated Oct. 30, 2020, 28 pages.;;Office Action received for Danish Patent Application No. PA201970535, dated Oct. 27, 2020, 6 pages.;;Notice of Allowance received for Chinese Patent Application No. 201811616429.8, dated Aug. 5, 2020, 3 pages (2 pages of English Translation and 1 page of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Aug. 18, 2020, 8 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Dec. 23, 2020, 8 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Jun. 29, 2020, 5 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Jul. 6, 2020, 2 pages.",ACTIVE
249,US,A1,US 2019/0364194 A1,023-483-346-558-137,2019-11-28,2019,US 201916534214 A,2019-08-07,US 201916534214 A;;US 201916252478 A;;US 201514864529 A;;US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device displays a representative image. While displaying the representative image, the device detects a first input. In response to the first input, the device transitions from displaying the representative image to displaying a respective image that was acquired by a camera before acquiring the representative image. After transitioning from displaying the representative image to displaying the respective image, the device displays, in sequence starting with the respective image, at least some images acquired by the camera before acquiring the representative image and at least some of images acquired by the camera after acquiring the representative image. The device detects termination of the first input. In response to detecting termination of the first input, the device displays the representative image.",APPLE INC,PENHA HENRIQUE D;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;CLARKE GRAHAM R;;DYE ALAN C;;FEDERIGHI CRAIG M;;FOSS CHRISTOPHER P;;IVE JONATHAN;;KING NICHOLAS V;;KOCIENDA KENNETH L;;MANZARI BEHKISH J;;PIVONKA PAVEL;;PRESTON DANIEL T;;MEZAK CHARLES A;;TITI JUSTIN S;;GOBERA RUBALCAVA DANIEL E,APPLE INC (2019-08-26),https://lens.org/023-483-346-558-137,Patent Application,yes,0,33,6,100,0,G06F3/04845;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;G06F3/0485;;G11B27/34;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00;;G06F3/04845;;G06F3/04883;;G11B27/105;;G11B27/005;;G11B27/034;;H04N23/62;;H04N23/632;;H04N23/634;;G06F3/04817;;G06F3/04842;;G11B27/031;;G11B27/34,H04N5/232;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0488;;G11B27/00;;G11B27/031;;G11B27/034;;G11B27/10;;G11B27/34,,0,0,,,,ACTIVE
250,US,A1,US 2020/0356222 A1,171-956-750-072-597,2020-11-12,2020,US 201916584776 A,2019-09-26,US 201916584776 A;;US 201962856052 P;;US 201962843930 P,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DEVINE LYNNE;;DYE ALAN C;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN S,APPLE INC (2020-01-23),https://lens.org/171-956-750-072-597,Patent Application,yes,0,19,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/0482;;G06F3/01;;G06F3/0485;;G06F3/0488;;G06F9/451,,0,0,,,,ACTIVE
251,US,A1,US 2022/0206647 A1,023-902-455-260-456,2022-06-30,2022,US 202217697539 A,2022-03-17,US 202217697539 A;;US 201916584783 A;;US 201962856052 P;;US 201962843930 P,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DEVINE LYNNE;;DYE ALAN C;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;BURNETTE CHELSEA LEBLANC;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN S,,https://lens.org/023-902-455-260-456,Patent Application,yes,2,9,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/01;;G06F3/0482;;G06F3/04845;;G06F3/0485;;G06F3/04883;;G06F9/451;;G06F16/432;;G06F16/435;;G06F16/438;;G06F16/44,,0,0,,,,ACTIVE
252,US,B2,US 11625153 B2,058-239-184-367-826,2023-04-11,2023,US 202217697539 A,2022-03-17,US 202217697539 A;;US 201916584783 A;;US 201962856052 P;;US 201962843930 P,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DEVINE LYNNE;;DYE ALAN C;;HIRMER BENEDIKT M;;KARLSSON ANDREAS;;BURNETTE CHELSEA L;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN S,,https://lens.org/058-239-184-367-826,Granted Patent,yes,627,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/0482;;G06F3/01;;G06F3/04845;;G06F3/0485;;G06F3/04883;;G06F9/451;;G06F16/432;;G06F16/435;;G06F16/438;;G06F16/44,,422,2,160-334-930-313-946;;087-439-027-914-345,10.1109/icme.2006.262778;;10.1145/1054972.1055001,"US 2002/0018582 A1, 02/2002, Hagiwara et al. (withdrawn);;Notice of acceptance received for Australian Patent Application No. 2021202225, dated Jun. 20, 2022, 3 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/030,321, dated Aug. 15, 2022, 3 pages.;;Decision to Grant received for Danish Patent Application No. PA202070615, dated Jul. 29, 2022, 2 pages.;;Examiner's Answer to Appeal Brief received for U.S. Appl. No. 16/145,033, dated Aug. 4, 2022, 10 pages.;;Office Action received for Japanese Patent Application No. 2020-160053, dated Aug. 1, 2022, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/408,220, dated Oct. 18, 2022, 4 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/030,337, dated Oct. 18, 2022, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2020-079486, dated Oct. 21, 2022, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA202070613, dated Oct. 13, 2022, 7 pages.;;Updated Notice of Allowance received for U.S. Appl. No. 17/030,340, dated Nov. 2, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/030,337, dated Aug. 31, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/031,543, dated Aug. 22, 2022, 2 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2021/017736, dated Aug. 25, 2022, 19 pages.;;Notice of Allowance received for Japanese Patent Application No. 2022-107902, dated Aug. 26, 2022, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for Korean Patent Application No. 10-2020-0123815, dated Aug. 26, 2022, 7 pages (2 pages of English Translation and 5 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 17/030,337, dated Aug. 22, 2022, 10 pages.;;Notice of Allowance received for U.S. Appl. No. 17/153,703, dated Aug. 30, 2022, 8 pages.;;Office Action received for European Patent Application No. 21159939.4, dated Sep. 2, 2022, 6 pages.;;Office Action received for Korean Patent Application No. 10-2022-0061486, dated Aug. 29, 2022, 5 pages (2 pages of English Translation and 3 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 17/030,340, dated Sep. 28, 2022, 7 pages.;;Office Action received for Indian Patent Application No. 202048019639, dated Sep. 27, 2022, 5 pages.;;Office Action received for Korean Patent Application No. 10-2020-0123821, dated Sep. 20, 2022, 11 pages (5 pages of English Translation and 6 pages of Official Copy).;;Supplemental Notice of Allowance received for U.S. Appl. No. 17/030,343, dated Oct. 5, 2022, 2 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 17/031,543, dated Apr. 21, 2022, 2 pages.;;Notice of Allowance received for Japanese Patent Application No. 2020-160054, dated Apr. 4, 2022, 4 pages (1 page of English Translation and 3 pages of Official Copy).;;Office Action received for Australian Patent Application No. 2021202225, dated Apr. 7, 2022, 3 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 17/030,321, dated Apr. 15, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/030,337, dated Sep. 21, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/153,703, dated Sep. 14, 2022, 2 pages.;;Extended European Search Report received for European Patent Application No. 22164099.8, dated Aug. 25, 2022, 9 pages.;;Hourunranta et al., “Video and Audio Editing for Mobile Applications”, Proceedings/2006 IEEE international Conference on Multimedia and Expo, ICME 2006, Jul. 9, 2006, pp. 1305-1308.;;Hurwitz, Jon, “Interface For Small-Screen Media Playback Control”, Technical Disclosure Commons, Online available at: https://www.tdcommons.org/cgi/viewcontent.cgi?article=4231&context=dpubs_series, Apr. 17, 2020, pp. 1-9.;;Jin-Chang et al., “Multi-modal Interface Techniques and Its Application for Multimedia Retrieval”, China Academic Journal Electronic Publishing House, 2002, pp. 115-117 (Official Copy Only) (See Communication under 37 CFR § 1.98(a) (3)).;;Notice of Allowance received for U.S. Appl. No. 17/030,343, dated Sep. 16, 2022, 11 pages.;;Office Action received for Chinese Patent Application No. 202011127969.7, dated Jul. 28, 2022, 25 pages (14 pages of English Translation and 11 pages of Official Copy).;;Office Action received for Chinese Patent Application No. 202111487316.4, dated Aug. 8, 2022, 25 pages (13 pages of English Translation and 12 pages of Official Copy).;;Office Action received for Danish Patent Application No. PA202070612, dated Sep. 12, 2022, 3 pages.;;10-2013-0026541, KR, A, In an Office Action for related Patent Application No. 10-2021-7036310 dated Apr. 26, 2022.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/030,318, dated Jan. 24, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Dec. 8, 2021, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Dec. 24, 2021, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Mar. 10, 2022, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Mar. 30, 2022, 2 pages.;;Decision to Grant received for European Patent Application No. 19724963.4, dated Feb. 3, 2022, 2 pages.;;Decision to Refuse received for European Patent Application No. 17813778.2, dated Jan. 24, 2022, 17 pages.;;Intention to Grant received for Danish Patent Application No. PA202070615, dated Jan. 27, 2022, 2 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 17813778.2, mailed on Jan. 21, 2022, 7 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/031,543, dated Apr. 1, 2022, 9 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/153,703, dated Mar. 30, 2022, 10 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019266054, dated Nov. 25, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020239743, dated Jan. 13, 2022, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020239752, dated Jan. 31, 2022, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020267310, dated Feb. 23, 2022, 3 pages.;;Notice of Allowance received for Australian Patent Application No. 2020239748, dated Mar. 7, 2022, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2018-138559, dated Dec. 3, 2021, 3 pages (1 page of English Translation and 2 pages of Official Copy).;;Notice of Allowance received for U.S. Appl. No. 17/030,318, dated Jan. 5, 2022, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 17/030,321, dated Apr. 1, 2022, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 17/125,744, dated Feb. 7, 2022, 10 pages.;;Office Action received for Australian Patent Application No. 2020239748, dated Feb. 11, 2022, 2 pages.;;Office Action received for Danish Patent Application No. PA 2020 70612, dated Mar. 1, 2022, 2 pages.;;Office Action received for Danish Patent Application No. PA202070616, dated Jan. 27, 2022, 2 pages.;;Office Action received for German Patent Application No. 112007000067.8, dated Apr. 23, 2009, 15 pages (7 pages of English Translation and 8 pages of Official Copy).;;Office Action received for German Patent Application No. 112007000067.8, dated Sep. 14, 2010, 4 pages (2 pages of English Translation and 2 pages of Official Copy).;;Office Action received for Indian Patent Application No. 202014041563, dated Dec. 30, 2021, 6 pages.;;Office Action received for Indian Patent Application No. 202014041571, dated Dec. 17, 2021, 5 pages.;;Office Action received for Japanese Patent Application No. 2020-079486, dated Mar. 11, 2022, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-160052, dated Dec. 17, 2021, 10 pages (5 pages of English Translation and 5 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-160053, dated Jan. 31, 2022, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Japanese Patent Application No. 2020-160054, dated Jan. 21, 2022, 8 pages (4 pages of English Translation and 4 pages of Official Copy).;;Office Action received for Korean Patent Application No. 10-2021-7036310, dated Feb. 23, 2022, 6 pages (2 pages of English Translation and 4 pages of Official Copy).;;Result of Consultation received for European Patent Application No. 17813778.2, dated Dec. 6, 2021, 17 pages.;;Summons to Attend Oral Proceedings received for European Patent Application No. 18197554.1, mailed on Mar. 23, 2022, 7 pages.;;Summons to Oral Proceedings received for German Patent Application No. 112007000067.8, mailed on Dec. 8, 2021, 11 pages (5 pages of English Translation and 6 pages of Official Copy).;;Supplemental Notice of Allowance received for U.S. Appl. No. 17/030,318, dated Apr. 4, 2022, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 17/030,318, dated Feb. 22, 2022, 2 pages.;;Supplemental Notice of Allowance received for U.S. Appl. No. 17/030,318, dated Mar. 16, 2022, 2 pages.;;T&GG Channel,“Canon IXUS 700 / Screenshots of deleting an image”, Online available at: https://www.youtube.com/watch?v=8BL_L5hKZUM, May 2015, 2 pages.;;Advisory Action received for U.S. Appl. No. 10/497,076, dated Aug. 2, 2011, 3 pages.;;Adeniyi Samuel, “How to connect a second PS4 controller to a PlayStation 4 console”, Online available on:—https://www.youtube.com/watch?v=mOZX_SrNISE, May 28, 2017, 2 pages.;;Advisory Action received for U.S. Appl. No. 10/497,076, dated Oct. 28, 2008, 3 pages.;;Advisory Action received for U.S. Appl. No. 14/253,783, dated Feb. 15, 2017., 6 Pages.;;Advisory Action received for U.S. Appl. No. 16/145,033, dated Nov. 2, 2021, 5 pages.;;Allison Conor, “Working out with Fiit's wearable-powered boutique fitness classes”, Online available at:—<https://www.wareable.com/wearable-tech/fiit-fitness-classes-review-3849>, May 14, 2018, 8 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/109,487, dated Apr. 21, 2020, 5 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 16/584,783, dated May 4, 2020, 3 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 17/030,318, dated Jul. 30, 2021, 4 pages.;;Applicant Initiated Interview Summary received for U.S. Appl. No. 17/030,321, dated Jul. 30, 2021, 2 pages.;;Applicant-Initiated Interview Summary for U.S. Appl. No. 16/402,057, dated Mar. 16, 2020, 3 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Apr. 30, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Nov. 24, 2020, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Oct. 7, 2021, 4 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/450,531, dated Aug. 11, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,776, dated May 13, 2020, 9 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/584,776, dated Nov. 25, 2020, 5 pages.;;Applicant-Initiated Interview Summary received for U.S. Appl. No. 16/145,033, dated Jun. 29, 2020, 5 pages.;;Board Opinion received for Chinese Reexamination Patent Application No. 200780001142.8, dated Oct. 21, 2014, 13 pages.;;Brief Communication Regarding Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Jun. 22, 2021, 2 pages.;;CBS This Morning,“This smart mirror puts a personal trainer in your reflection”, Available on: https://www.youtube.com/watch?v=nSmTTZcpVGg, Oct. 13, 2018, 4 pages.;;Certificate of Examination received for Australian Patent Application No. 2019100490, dated Oct. 16, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 12/566,994, dated Jan. 22, 2015, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Aug. 11, 2016, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Jun. 3, 2019, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Jul. 6, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Nov. 12, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/450,531, dated Oct. 30, 2020, 2 pages.;;Corrected Notice of Allowance received for U.S. Appl. No. 16/983,815, dated Mar. 31, 2021, 6 pages.;;Decision on Appeal received for U.S. Appl. No. 16/584,783, dated Oct. 14, 2021, 12 pages.;;Decision to Grant received for Danish Patent Application No. PA201870385, dated Mar. 26, 2020, 2 pages.;;Decision to Grant received for European Patent Application No. 09756118.7, dated Jul. 13, 2017., 2 pages.;;Decision to Grant received for European Patent Application No. 11178259.5, dated Apr. 4, 2019, 3 pages.;;Decision to Grant received for European Patent Application No. 17180535.1, dated Feb. 4, 2021, 2 pages.;;Decision to Grant received for Japanese Patent Application No. 2009-526943, dated Dec. 2, 2011, dated Dec. 2, 2011, 3 pages.;;Decision to Grant received for the European Patent Application No. 07814633.9, dated Sep. 2, 2010, 3 pages.;;Decision to Grant received for the European Patent Application No. 10172417.7, dated Nov. 14, 2013, 3 pages.;;Decision to Grant received for the European Patent Application No. 11178257.9, dated Jun. 20, 2013, 3 pages.;;Ed Bott,“Chapter 14. Playing and Recording Digital Music”, Special Edition Using Microsoft Windows Millennium Edition, Nov. 2000, pp. 329-353.;;European Search Report received for the European Application No. 11178259.5, dated Oct. 31, 2011, 8 pages.;;European Search Report received for the European Patent Application No. 10172417.7, dated Jan. 7, 2011, dated Jan. 7, 2011, 4 pages.;;Examiner's Answer to Appeal Brief received for U.S. Appl. No. 16/584,783, dated Feb. 17, 2021, 9 pages.;;Examiner's Pre-Review Report received for Japanese Patent Application No. 2018138559, dated Jul. 29, 2020, 6 pages.;;Ex-Parte Quayle Action received for U.S. Appl. No. 12/567,570, mailed on Oct. 3, 2012, 6 pages.;;Extended European Search Report received for European Patent Application No. 11178257.9, dated Oct. 31, 2011, dated Oct. 31, 2011, 5 pages.;;Extended European Search Report received for European Patent Application No. 17813778.2, dated Jan. 10, 2020, 12 pages.;;Extended European Search Report received for European Patent Application No. 18197554.1, dated Jun. 3, 2019, 11 pages.;;Extended European Search Report received for European Patent Application No. 21159939.4, dated Sep. 28, 2021, 13 pages.;;Extended European Search Report received for European Patent Application No. 17180535.1, dated Oct. 30, 2017, 9 pages.;;Final Office Action received for U.S. Appl. No. 10/497,076 dated Feb. 10, 2012, 25 pages.;;Final Office Action received for U.S. Appl. No. 10/497,076, dated Apr. 26, 2013, 30 pages.;;Final Office Action received for U.S. Appl. No. 10/497,076, dated Feb. 2, 2011, 22 pages.;;Final Office Action received for U.S. Appl. No. 10/497,076, dated Jun. 12, 2008, 31 pages.;;Final Office Action received for U.S. Appl. No. 10/497,076, dated Oct. 6, 2009, 29 pages.;;Final Office Action received for U.S. Appl. No. 12/567,405, dated Dec. 17, 2012, dated Dec. 17, 2012, 19 pages.;;Final Office Action received for U.S. Appl. No. 12/567,553, dated Mar. 12, 2012, 15 pages.;;Final Office Action received for U.S. Appl. No. 15/281,524, dated Dec. 27, 2018, 6 pages.;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Jul. 6, 2021, 113 pages.;;Final Office Action received for U.S. Appl. No. 16/145,033, dated Sep. 22, 2020, 49 pages.;;Final Office Action received for U.S. Appl. No. 16/402,057, dated Oct. 17, 2019, 23 pages.;;Final Office Action received for U.S. Appl. No. 16/584,783, dated May 19, 2020, 19 pages.;;Final Office Action received for U.S. Appl. No. 17/030,318, dated Sep. 30, 2021, 28 pages.;;Final Office Action received for U.S. Appl. No. 17/030,321, dated Apr. 2, 2021, 28 pages.;;Final Office Action received for U.S. Appl. No. 14/253,783, dated Sep. 30, 2016, 18 pages.;;Hamilton Jim, “Peloton Tips”, Online available on:—<https://www.youtube.com/watch?app=desktop&v=OneXtB0kaD4>, Oct. 22, 2015, 3 pages.;;Helm Josh, “Microsoft® Windows Media™ Player Version 7—New features and Walk-through”, Jul. 2000, 20 pages.;;Hinckley et al., “Sensing Techniques for Mobile Interaction”, Symposium on User Interface Software and Technology, CHI Letters, vol. 2, No. 2, Nov. 2000, pp. 91-100.;;Hughes Neil, “Apple Explores Merging Cloud Content with Locally Stored Media Library”, Available at <http://appleinsider.com/articles/11/02/10/apple_explores_merging_cloud_content_with_locally_stored_media_library.html>, XP55040717, Feb. 10, 2011, 2 pages.;;Intention to Grant received for Danish Patent Application No. PA201870385, dated Jan. 24, 2020, 2 pages.;;Intention to Grant received for European Patent Application No. 09756118.7, dated Mar. 2, 2017., 8 Pages.;;Intention to Grant received for European Patent Application No. 10172417.7, dated Jul. 9, 2013, dated Jul. 9, 2013, 10 pages.;;Intention to Grant received for European Patent Application No. 11178257.9, dated Jan. 30, 2013, dated Jan. 30, 2013, 9 pages.;;Intention to Grant received for European Patent Application No. 11178259.5, dated Nov. 8, 2018, 16 pages.;;Intention to Grant received for European Patent Application No. 17180535.1, dated Sep. 24, 2020, 7 pages.;;Intention to Grant received for European Patent Application No. 19724963.4, dated Sep. 20, 2021, 7 pages.;;Intention to Grant received for the European Patent Application No. 07814633.9, dated Mar. 19, 2010, 4 pages.;;International Preliminary Examination Report on Patentability received for PCT Patent Application No. PCT/US2002/000484, dated Aug. 4, 2003, 7 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2007/077441, dated Mar. 10, 2009, 9 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2009/057899, dated Apr. 5, 2012, 14 pages., 14 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2011/020403, dated Jul. 19, 2012, 10 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2017/035322, dated Dec. 27, 2018, 13 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2019/024790, dated Nov. 19, 2020, 11 pages.;;International Preliminary Report on Patentability received for PCT Patent Application No. PCT/US2020/031442, dated Nov. 18, 2021, 21 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2002/000484, dated Jul. 11, 2002, 1 page.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2009/057899, dated Jun. 14, 2010, dated Jun. 14, 2010, 19 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2011/020403, dated May 26, 2011, dated May 26, 2011, 14 pages.;;International Search Report and Written Opinion Received for PCT Patent Application No. PCT/US2017/035322, dated Oct. 5, 2017, 18 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2019/024790, dated Sep. 11, 2019, 18 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2020/031442, dated Oct. 30, 2020, 28 pages.;;International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2021/017736, dated Sep. 2, 2021, 25 pages.;;International Search Report and Written Opinion, received for PCT Patent Application No. PCT/US2007/077441, dated May 8, 2008, dated May 8, 2008, 13 pages.;;Invitation to Pay Additional Fee received for PCT Patent Application No. PCT/US2019/024790, dated Jul. 18, 2019, 10 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2007/077441, dated Jan. 28, 2008, dated Jan. 28, 2008, 5 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2017/035322, dated Aug. 7, 2017, 4 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2020/031442, dated Aug. 25, 2020, 22 pages.;;Invitation to Pay Additional Fees received for PCT Patent Application No. PCT/US2021/017736, dated Jun. 15, 2021, 14 pages.;;Jobs Steve, “iPhone Introduction in 2007 (Complete)”, available at <https://www.youtube.com/watch?v=9hUIxyE2Ns8>,, Jan. 10, 2013, 3 pages.;;Karlson et al., “AppLens and LaunchTile: Two Designs for One-Handed Thumb Use on Small Devices”, CHI 2005, Papers: Small Devices 1, Apr. 2-7, 2005, pp. 201-210.;;Microsoft Support Webcasts, Windows Media Player 7: New features and Walk-through Transcript, Jul. 13, 2000, 7 pages.;;Microsoft Windows,“Microsoft Windows (Copyright 2009)”, 2 pages.;;Minutes of Oral Proceedings received for European Patent Application No. 11178259.5, mailed on Nov. 2, 2018, 9 pages.;;Minutes of the Oral Proceedings received for European Patent Application No. 19724963.4, mailed on Sep. 3, 2021, 6 pages.;;Mozilla Developer Network,“Mouse Gesture Events”, Available online at <https://developer.mozilla.org/en-US/docs/Web/Guide/Events/Mouse_gesture_events>, May 14, 2009, 3 pages.;;Non-Final Office Action received for U.S. Appl. No. 09/757,000, dated Jan. 30, 2003, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 09/757,000, dated Jun. 19, 2003, 11 Pages.;;Non-Final Office Action received for U.S. Appl. No. 10/497,076, dated Jan. 8, 2009, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 10/497,076, dated May 13, 2010, 24 pages.;;Non-Final Office Action received for U.S. Appl. No. 10/497,076, dated Oct. 3, 2012, 24 pages.;;Non-Final Office Action received for U.S. Appl. No. 10/497,076, dated Oct. 13, 2011, 24 pages.;;Non-Final Office Action received for U.S. Appl. No. 10/497,076, dated Sep. 13, 2007, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 11/848,210, dated Jun. 30, 2011, dated Jun. 30, 2011, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/566,994, dated Dec. 13, 2013, dated Dec. 13, 2013, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/566,994, dated Jan. 9, 2013, dated Jan. 9, 2013, 15 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/566,994, dated Jun. 13, 2014, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/567,405, dated Jan. 16, 2014, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/567,405, dated May 17, 2012, dated May 17, 2012, 14 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/567,460, dated Aug. 4, 2011, dated Aug. 4, 2011, 13 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/567,553, dated Sep. 16, 2011, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/849,767, dated Jul. 9, 2012, dated Jul. 9, 2012, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/361,912, dated Mar. 22, 2012, dated Mar. 22, 2012, 8 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/909,001, dated Sep. 26, 2013, 7 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/909,002, dated Jun. 23, 2015, 6 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/088,450, dated Jul. 23, 2018, 12 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Dec. 23, 2016., 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/275,294, dated Nov. 3, 2017, 29 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/281,524, dated Jun. 19, 2018, 23 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/391,269, dated Aug. 22, 2019, 44 pages.;;Non-Final Office Action received for U.S. Appl. No. 15/687,384, dated Jul. 6, 2018, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/109,487, dated Feb. 5, 2020, 19 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Feb. 9, 2021, 55 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/145,033, dated Mar. 4, 2020, 50 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/402,057, dated May 23, 2019, 16 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/450,531, dated Jun. 10, 2020, 10 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,776, dated Aug. 18, 2020, 36 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,776, dated Feb. 13, 2020, 31 pages.;;Non-Final Office Action received for U.S. Appl. No. 16/584,783, dated Jan. 30, 2020, 18 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/030,318, dated Apr. 2, 2021, 28 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/030,318, dated Dec. 3, 2020, 22 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/030,321, dated Dec. 15, 2020, 25 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/030,321, dated Oct. 18, 2021, 28 pages.;;Non-Final Office Action received for U.S. Appl. No. 17/035,367, dated Jun. 11, 2021, 11 pages.;;Non-Final Office Action received for U.S. Appl. No. 12/789,441, dated Jan. 17, 2013, dated Jan. 17, 2013, 24 pages.;;Non-Final Office Action received for U.S. Appl. No. 13/666,943, dated Oct. 26, 2015, 12 Pages.;;Non-Final Office Action received for U.S. Appl. No. 14/253,783, dated Feb. 23, 2016, 18 pages.;;Notice of Acceptance received for Australian Patent Application No. 2011265412, dated Nov. 12, 2014, 2 pages.;;Notice of Acceptance received for Australian Patent Application No. 2015201028, dated Mar. 21, 2017., 3 Pages.;;Notice of Acceptance received for Australian Patent Application No. 2017201548, dated Sep. 3, 2018, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2018214074, dated Aug. 6, 2019, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019264623, dated Jan. 4, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2019271873, dated Nov. 30, 2020, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2020267396, dated Dec. 7, 2021, 3 pages.;;Notice of Acceptance received for Australian Patent Application No. 2017284958, dated Sep. 3, 2019, 3 Pages.;;Notice of Allowance received for Canadian Patent Application No. 2,935,875, dated May 3, 2017, 1 page.;;Notice of Allowance received for Canadian Patent Application No. 2,984,527, dated Apr. 30, 2020, 1 page.;;Notice of Allowance received for Chinese Patent Application No. 201811136445.7, dated Aug. 11, 2021, 2 pages.;;Notice of Allowance received for Chinese Patent Application No. 201811616429.8, dated Aug. 5, 2020, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2013-140171, dated May 29, 2015, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2014-259225, dated Feb. 27, 2017., 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2015-129152, dated May 8, 2017, 3 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-057997, dated Apr. 23, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2017-132229, dated Jun. 25, 2018, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2019-123115, dated Nov. 30, 2020, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2021-000224, dated May 7, 2021, 4 pages.;;Notice of Allowance received for Japanese Patent Application No. 2021-094529, dated Sep. 6, 2021, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2018-7034875, dated Dec. 12, 2018, 4 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Dec. 19, 2019, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2019-7007053, dated Mar. 12, 2020, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2020-7005314, dated Mar. 23, 2020, 6 pages.;;Notice of Allowance received for Korean Patent Application No. 10-2020-7018255, dated Feb. 24, 2021, 5 pages.;;Notice of Allowance received for the Canadian Patent Application No. 2,853,273, dated Jan. 12, 2016, dated Jan. 12, 2016, 1 page.;;Notice of Allowance received for U.S. Appl. No. 09/757,000, dated Dec. 15, 2003, 4 pages.;;Notice of Allowance received for U.S. Appl. No. 11/848,210, dated Dec. 20, 2011, dated Dec. 20, 2011, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 12/566,994, dated May 22, 2013, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 12/566,994, dated Oct. 6, 2014, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,405, dated Jun. 11, 2014, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,460, dated Apr. 10, 2013, dated Apr. 10, 2013, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,460, dated Aug. 10, 2012, dated Aug. 10, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,460, dated Dec. 24, 2012, dated Dec. 24, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,460, dated Jan. 18, 2012, dated Jan. 18, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,553, dated Apr. 2, 2013, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,553, dated Aug. 10, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,553, dated Dec. 24, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,553, dated Jun. 12, 2012, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,570, dated Dec. 19, 2012, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 12/567,570, dated Mar. 27, 2013, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 12/789,441, dated Dec. 6, 2013, dated Dec. 6, 2013, 11 pages.;;Notice of Allowance received for U.S. Appl. No. 12/849,767, dated Apr. 25, 2014, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 12/849,767, dated Jan. 8, 2013, dated Jan. 8, 2013, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 13/361,912, dated Jul. 2, 2012, dated Jul. 2, 2012, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 2, 2016, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 13/666,943, dated Jun. 17, 2015, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 13/909,001, dated Mar. 3, 2014, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 13/909,002, dated Dec. 4, 2015, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Apr. 14, 2017., 12 Pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Jul. 12, 2017, 5 pages.;;Notice of Allowance received for U.S. Appl. No. 14/253,783, dated Sep. 5, 2017, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/088,450, dated Dec. 13, 2018, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 6, 2018, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 15/275,294, dated Jun. 30, 2017., 8 Pages.;;Notice of Allowance received for U.S. Appl. No. 15/281,524, dated Apr. 11, 2019, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 15/687,384, dated Jan. 8, 2019, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Aug. 18, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated May 12, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/109,487, dated Nov. 23, 2020, 3 pages.;;Notice of Allowance received for U.S. Appl. No. 16/402,057, dated Mar. 25, 2020, 8 pages.;;Notice of Allowance received for U.S. Appl. No. 16/403,184, dated Oct. 11, 2019, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/450,531 dated Sep. 25, 2020, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 16/584,776, dated Feb. 1, 2021, 9 pages.;;Notice of Allowance received for U.S. Appl. No. 16/584,783, dated Dec. 20, 2021, 7 pages.;;Notice of Allowance received for U.S. Appl. No. 16/791,257, dated Jun. 12, 2020, 11 pages. et al.",ACTIVE
253,EP,A2,EP 4318270 A2,055-107-128-569-155,2024-02-07,2024,EP 23218010 A,2020-05-05,US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;EP 20729331 A;;US 2020/0031442 W,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.
",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI JOHNNIE B;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/055-107-128-569-155,Patent Application,yes,28,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/74,,0,0,,,,PENDING
254,AU,A1,AU 2022/201810 A1,172-692-429-626-987,2022-04-07,2022,AU 2022/201810 A,2022-03-16,AU 2022/201810 A;;AU 2020/267396 A;;US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/172-692-429-626-987,Patent Application,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,ACTIVE
255,CN,A,CN 113795818 A,016-665-706-947-173,2021-12-14,2021,CN 202080033708 A,2020-05-05,DK PA201970535 A;;US 201962843930 P;;US 201962856052 P;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,G R CLARK;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/016-665-706-947-173,Patent Application,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/0484;;G06F3/01;;G06F3/0482;;G06F3/0485;;G06F3/0488;;G06F9/451;;G06F16/432;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/54;;G06F16/74,,0,0,,,,PENDING
256,AU,A1,AU 2023/237163 A1,084-687-905-765-704,2023-10-19,2023,AU 2023/237163 A,2023-09-29,AU 2023/237163 A;;AU 2022/201810 A;;AU 2020/267396 A;;US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI JOHNNIE B;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/084-687-905-765-704,Patent Application,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,ACTIVE
257,WO,A1,WO 2020/227273 A1,081-552-512-013-07X,2020-11-12,2020,US 2020/0031442 W,2020-05-05,US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/081-552-512-013-07X,Patent Application,yes,31,0,1,25,0,G06F3/016;;G06F3/0488;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F2203/04808;;G06F3/04845;;G06F2203/04806,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,PENDING
258,CN,A,CN 114115667 A,139-558-264-759-250,2022-03-01,2022,CN 202111487316 A,2020-05-05,DK PA201970535 A;;US 201962843930 P;;US 201962856052 P;;US 201916584776 A;;US 201916584783 A;;CN 202080033708 A,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to a media browsing user interface with intelligently selected representative media items. According to one embodiment, in response to receiving an input, a device displays a first view of a set of media items, including simultaneously displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that the current time is associated with a first repeating time event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second repeating time event: the representation of the first time period includes a third representative media item, and the representation of the second time period includes a fourth representative media item.",APPLE COMPANY,G R CLARK;;AUJULE KEVIN;;BESSIERE KEVIN;;BOVI SAMIR;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;L DEVINE;;ALAN C DYE;;GOBERA RUBALCAVA DANIEL E;;HAIMER BRIAN;;KARLSSON ANDERS;;LEBLANC CATHERINE;;LUCAS MATTHEW;;MANZARI BEHKISH J;;N R RYAN;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/139-558-264-759-250,Patent Application,no,4,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/04845;;G06F3/01;;G06F3/0482;;G06F3/0485;;G06F3/04883;;G06F9/451;;G06F16/432;;G06F16/435;;G06F16/438;;G06F16/44;;G06F16/54;;G06F16/74,,0,0,,,,PENDING
259,AU,A1,AU 2020/267396 A1,158-241-744-332-241,2021-12-02,2021,AU 2020/267396 A,2020-05-05,US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/158-241-744-332-241,Patent Application,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,ACTIVE
260,AU,B2,AU 2023/237163 B2,072-607-401-176-879,2024-01-11,2024,AU 2023/237163 A,2023-09-29,AU 2023/237163 A;;AU 2022/201810 A;;AU 2020/267396 A;;US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI JOHNNIE B;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/072-607-401-176-879,Granted Patent,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,ACTIVE
261,KR,A,KR 20220112860 A,047-249-323-472-600,2022-08-11,2022,KR 20227026174 A,2020-05-05,US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;KR 20217036310 A;;US 2020/0031442 W,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,"본 개시내용은 일반적으로 미디어 항목들의 집합을 내비게이팅하는 것에 관한 것이다. 일 실시예에 따르면, 입력을 수신하는 것에 응답하여, 디바이스는 미디어 항목들의 집합의 제1 뷰를 디스플레이하며, 디스플레이하는 것은 제1 시간 기간의 표현 및 제2 시간 기간의 표현을 동시에 디스플레이하는 것을 포함한다. 현재 시간이 제1 반복적인 시간 이벤트와 연관된다는 결정에 따라, 제1 시간 기간의 표현은 제1 대표 미디어 항목을 포함하고, 제2 시간 기간의 표현은 제2 대표 미디어 항목을 포함한다. 현재 시간이 제2 반복적인 시간 이벤트와 연관된다는 결정에 따라, 제1 시간 기간의 표현은 제3 대표 미디어 항목을 포함하고, 제2 시간 기간의 표현은 제4 대표 미디어 항목을 포함한다.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/047-249-323-472-600,Patent Application,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/041;;G06F3/04845;;G06F3/0485;;G06F3/0488;;G06F3/16;;G06F16/54;;G06F16/74,,0,0,,,,PENDING
262,AU,B2,AU 2022/201810 B2,027-886-119-948-671,2023-06-29,2023,AU 2022/201810 A,2022-03-16,AU 2022/201810 A;;AU 2020/267396 A;;US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/027-886-119-948-671,Granted Patent,no,3,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,ACTIVE
263,AU,B2,AU 2020/267396 B2,122-875-686-267-143,2021-12-16,2021,AU 2020/267396 A,2020-05-05,US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,Media browsing user interface with intelligently selected representative media items,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN;;CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J,,https://lens.org/122-875-686-267-143,Granted Patent,no,5,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,ACTIVE
264,EP,A1,EP 3948581 A1,156-921-229-265-52X,2022-02-09,2022,EP 20729331 A,2020-05-05,US 201962843930 P;;US 201962856052 P;;DK PA201970535 A;;US 201916584776 A;;US 201916584783 A;;US 2020/0031442 W,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,,APPLE INC,CLARKE GRAHAM R;;AUJOULET KEVIN;;BESSIERE KEVIN;;BOVET SIMON;;CIRCLAEYS ERIC M G;;DELLINGER RICHARD R;;DEVINE LYNNE;;DYE ALAN C;;GOBERA RUBALCAVA DANIEL E;;HIRMER BENEDIKT;;KARLSSON ANDREAS;;LEBLANC CHELSEA;;LUCAS MATTHIEU;;MANZARI BEHKISH J;;RYAN NICOLE R;;SORRENTINO III WILLIAM A;;SOUZA DOS SANTOS ANDRE;;SUZUKI GREGG;;TATARCHUK SERGEY;;TITI JUSTIN,,https://lens.org/156-921-229-265-52X,Patent Application,yes,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F16/44;;G06F3/01;;G06F3/0482;;G06F16/54;;G06F16/74,,0,0,,,,DISCONTINUED
265,DK,A1,DK 201970535 A1,194-494-788-271-269,2020-12-21,2020,DK PA201970535 A,2019-08-27,US 201962843930 P;;US 201962856052 P,2019-05-06,MEDIA BROWSING USER INTERFACE WITH INTELLIGENTLY SELECTED REPRESENTATIVE MEDIA ITEMS,"The present disclosure generally relates to navigating a collection of media items. In accordance with one embodiment, in response to receiving an input, a device displays a first view of a collection of media items, including concurrently displaying a representation of a first time period and a representation of a second time period. In accordance with a determination that a current time is associated with a first recurring temporal event: the representation of the first time period includes a first representative media item and the representation of the second time period includes a second representative media item. In accordance with a determination that the current time is associated with a second recurring temporal event, the representation of the first time period includes a third representative media item and the representation of the second time period includes a fourth representative media item.",APPLE INC,LYNNE DEVINE;;GREGG SUZUKI;;WILLIAM A SORRENTINO III;;BEHKISH J MANZARI;;ALAN C DYE;;GRAHAM R CLARKE;;ANDRE SOUZA DOS SANTOS;;NICOLE R RYAN;;ERIC M G CIRCLAEYS;;MATTHIEU LUCAS;;ANDREAS KARLSSON;;SERGEY TATARCHUK;;SIMON BOVET;;RICHARD R DELLINGER;;DANIEL E GOBERA RUBALCAVA;;KEVIN AUJOULET;;KEVIN BESSIERE;;BENEDIKT HIRMER;;JUSTIN S TITI;;CHELSEA LEBLANC,,https://lens.org/194-494-788-271-269,Unknown,no,0,0,24,25,0,G06F3/04845;;G06F3/0485;;G06F16/435;;G06F16/447;;G06F16/743;;G06F9/451;;G06F3/0482;;G06F16/438;;G06F16/54;;G06F16/434;;G06F3/016;;G06F3/04883;;G06F2203/04806;;G06F2203/04803;;G06F2203/04808;;G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74;;G06F16/55;;G06F9/451;;G06F3/04883;;G06F2203/04808;;G06F3/04845;;G06F2203/04806;;G06F3/0485;;G06F3/0488;;G06F3/016;;G06F16/447;;G06F16/54;;G06F16/743;;G06F2203/04803;;G06F16/54;;G06F16/743;;G06F3/04845;;G06F3/0488;;G06F2203/04803;;G06F2203/04806;;G06F2203/04808;;G06F16/44;;G06F3/16;;G06F3/0485;;G06F3/0412;;G06F3/0482;;G06F3/0485;;G06F9/451;;G06F3/04883;;G06F3/016;;G06F16/435;;G06F16/434;;G06F16/438;;G06F16/447;;G06F3/04845,G06F3/0482;;G06F3/0484;;G06F16/44;;G06F16/54;;G06F16/74,,0,0,,,,DISCONTINUED
266,NL,A,NL 2016801 A,096-541-414-949-772,2016-12-12,2016,NL 2016801 A,2016-05-19,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;BEHKISH J MANZARI;;PAULO M LOPEZ;;GRAHAM R CLARKE;;PAVEL PIVONKA;;IMRAN A CHAUDHRI;;SEBASTIAN BAUER;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC,,https://lens.org/096-541-414-949-772,Patent Application,no,2,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06V10/10;;H04N5/232;;G06V20/00,,0,0,,,,ACTIVE
267,NL,B1,NL 2016801 B1,030-727-102-407-975,2017-07-21,2017,NL 2016801 A,2016-05-19,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;BEHKISH J MANZARI;;PAULO M LOPEZ;;GRAHAM R CLARKE;;PAVEL PIVONKA;;IMRAN A CHAUDHRI;;SEBASTIAN BAUER;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC,,https://lens.org/030-727-102-407-975,Granted Patent,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
268,NL,A,NL 2019214 A,008-999-053-544-165,2017-08-24,2017,NL 2019214 A,2017-07-10,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;IMRAN A CHAUDHRI;;BEHKISH J MANZARI;;PAULO M LOPEZ;;PAVEL PIVONKA;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC;;GRAHAM R CLARKE;;SEBASTIAN J BAUER,,https://lens.org/008-999-053-544-165,Patent Application,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
269,AU,A1,AU 2022/202892 A1,069-225-002-379-693,2022-05-26,2022,AU 2022/202892 A,2022-05-02,AU 2022/202892 A;;AU 2020/244406 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;AU 2019/257437 A;;AU 2019/200872 A;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"A method comprising at an electronic device with a display and a touch-sensitive surface, displaying an image on the display. Wherein the image is one image in a sequence of images taken by a camera and where the sequence of images includes a representative image. The sequence of images includes one or more images acquired by the camera after acquiring the representative image and the sequence of images includes one or more images acquired by the camera before acquiring the representative image. While displaying the image in the sequence of images on the display, detecting a first input. In response to detecting the first input, displaying an image editing user interface for editing the sequence of images, the image editing user interface including an affordance for turning on animated playback of the sequence of images or turning off animated playback of the sequence of images while retaining the sequence of images. While displaying the image editing user interface, detecting a second input on the affordance. In response to detecting a second input, turning on animated playback of the sequence of images or turning off animated playback of the sequence of images while retaining the sequence of images.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/069-225-002-379-693,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
270,KR,A,KR 20190077128 A,177-254-737-814-121,2019-07-02,2019,KR 20197018317 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/177-254-737-814-121,Patent Application,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
271,KR,A,KR 20190130059 A,047-104-144-474-507,2019-11-20,2019,KR 20197033444 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/047-104-144-474-507,Patent Application,no,4,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
272,CN,A,CN 111475084 A,065-779-527-775-735,2020-07-31,2020,CN 202010281127 A,2016-05-20,CN 202010281127 A;;CN 201610342313 A;;US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"The disclosure relates to devices and methods for capturing and interacting with enhanced digital images. The disclosure provides an electronic device, an apparatus and method for grouping multiple images. The electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activationof the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the cameraafter acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/065-779-527-775-735,Patent Application,no,6,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0484;;G06F3/01;;G06F3/0488;;G06V10/10;;G06V20/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
273,KR,A,KR 20220066198 A,167-664-243-592-222,2022-05-23,2022,KR 20227015718 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;KR 20227003345 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/167-664-243-592-222,Patent Application,no,7,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/04817;;H04N5/232;;G06F3/04842;;G06F3/04845;;G06F3/04847;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
274,AU,A1,AU 2019/200872 A1,008-765-048-030-408,2019-02-28,2019,AU 2019/200872 A,2019-02-08,AU 2019/200872 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/008-765-048-030-408,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
275,JP,A,JP 2019126026 A,106-710-072-131-860,2019-07-25,2019,JP 2018243773 A,2018-12-26,US 201562215689 P;;US 201562172223 P;;US 201514863432 A;;US 201562172233 P,2015-06-07,DEVICE AND METHOD FOR ENHANCED DIGITAL IMAGE CAPTURE AND INTERACTION WITH ENHANCED DIGITAL IMAGE,"To provide a devices and a method for developing photography beyond a static image.SOLUTION: An electronic device 100 includes a camera. During a first media acquisition mode for the camera, the device displays a live preview on a display. While the live preview is displayed, the device detects shutter button activation. In response to detection of the shutter button activation, the device groups a plurality of images 512-1 to 512-6 acquired by the camera into an image sequence in the temporal vicinity of the shutter button activation. The image sequence includes a plurality of images captured by the camera prior to detecting shutter button activation, a representative image 512-4 representative of the first image sequence and acquired by the camera after one or more of the other images in the first image sequence, and a plurality of images acquired by the camera after acquiring the representative image.SELECTED DRAWING: Figure 5J",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;BEHKISH J MANZARI;;PAULO M LOPEZ;;GRAHAM R CLARKE;;PAVEL PIVONKA;;SEBASTIAN J BAUER;;IMRAN A CHAUDHRI;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC,,https://lens.org/106-710-072-131-860,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06F3/0488;;G06V10/10;;G06V20/00;;H04M1/00;;H04N5/91,,0,0,,,,ACTIVE
276,KR,A,KR 20170139621 A,008-142-319-595-54X,2017-12-19,2017,KR 20177033756 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,향상된 디지털 이미지들을 캡처하고 그들과 상호작용하기 위한 디바이스들 및 방법들,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/008-142-319-595-54X,Patent Application,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
277,AU,A4,AU 2016/100647 A4,030-558-752-031-012,2016-06-23,2016,AU 2016/100647 A,2016-05-19,US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image. Processing unit 3108 ---------------- F | Display enabling unit | 3110 ------------- Display unit I Detecting unit 3102 I 3112 L------------- I Trimming unit r 1 3114 1 Touch-sensitive L---------- I surface unit L- - - - -_- _ - Selecting unit | 3116 L------------- | Moving unit ------------- | Deleting unit | 3120 Figure 31",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN I;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/030-558-752-031-012,Limited Patent,no,0,2,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F17/00;;G06V10/10;;G06V20/00;;G09G5/00,,0,0,,,,ACTIVE
278,EP,B1,EP 3304270 B1,060-661-403-028-29X,2019-10-09,2019,EP 16730554 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,,APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,APPLE INC. (2018-08-01),https://lens.org/060-661-403-028-29X,Granted Patent,yes,4,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,2,0,,,"DANIEL RUBINO ET AL: ""Nokia Living Images"", YOUTUBE, 6 June 2014 (2014-06-06), pages 5 pp., XP054979043, Retrieved from the Internet <URL:https://www.youtube.com/watch?v=RX7vpoFy1Dg> [retrieved on 20190118];;DANIEL RUBINO ET AL: ""Nokia Living Images"", YOUTUBE, 6 June 2014 (2014-06-06), pages 5 pp., XP054979043, Retrieved from the Internet <URL:https://www.youtube.com/watch?v=RX7vpoFy1Dg> [retrieved on 20190118]",ACTIVE
279,CN,A,CN 106227441 A,106-157-237-668-797,2016-12-14,2016,CN 201610342313 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"Electronic Devices, apparatuses and methods for grouping images. An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image. The application further deals with different ways of navigating in the sequence of image, e.g via dragging or pressure detection of touch input.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/106-157-237-668-797,Patent Application,no,6,5,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06V10/10;;G06V20/00,,0,0,,,,ACTIVE
280,KR,A,KR 20200031701 A,152-917-006-830-694,2020-03-24,2020,KR 20207007399 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/152-917-006-830-694,Patent Application,no,4,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
281,KR,A,KR 20200119909 A,050-714-489-261-095,2020-10-20,2020,KR 20207029178 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;KR 20207015964 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/050-714-489-261-095,Patent Application,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
282,AU,B4,AU 2016/100647 B4,061-797-340-080-582,2017-02-23,2017,AU 2016/100647 A,2016-05-19,US 201514863432 A;;US 201562215689 P;;US 201562172233 P;;US 201562172223 P,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN I;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/061-797-340-080-582,Limited Patent,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F17/00;;G06V10/10;;G06V20/00;;G09G5/00,,0,0,,,,ACTIVE
283,JP,A,JP 2021048592 A,079-308-158-433-971,2021-03-25,2021,JP 2020185336 A,2020-11-05,US 201562215689 P;;US 201562172223 P;;US 201514863432 A;;US 201562172233 P,2015-06-07,DEVICE AND METHOD FOR CAPTURING EXTENDED DIGITAL IMAGE AND INTERACTING WITH EXTENDED DIGITAL IMAGE,"To provide an improved method of capturing a moment.SOLUTION: In a method, a live preview is displayed, a plurality of images acquired by a camera in the temporal vicinity of the activation of a shutter button are grouped into an image sequence in response to detection of the activation of the shutter button. The image sequence includes a plurality of images captured by the camera before detecting the activation of the shutter button, a representative image acquired by the camera after one or more other images in a first image sequence, representing the first image sequence, and a plurality of images acquired by the camera after acquiring the representative image.SELECTED DRAWING: Figure 9A",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;BEHKISH J MANZARI;;PAULO M LOPEZ;;GRAHAM R CLARKE;;PAVEL PIVONKA;;SEBASTIAN J BAUER;;IMRAN A CHAUDHRI;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC,,https://lens.org/079-308-158-433-971,Patent Application,no,6,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0484;;G06F3/0488;;G06V10/10;;G06V20/00;;H04N5/77;;H04N5/92;;H04N5/93,,0,0,,,,ACTIVE
284,AU,A4,AU 2016/100648 A4,156-186-682-698-229,2016-06-23,2016,AU 2016/100648 A,2016-05-19,US 201562215689 P;;US 201514863432 A;;US 201562172223 P;;US 201562172233 P;;US 201514864580 A,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN I;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/156-186-682-698-229,Limited Patent,no,0,0,9,100,0,G06F3/04842;;G06F3/0488;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/62;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00,H04N5/232;;G06F17/00;;G09G5/00;;H04M1/72439,,0,0,,,,ACTIVE
285,AU,A1,AU 2016/276030 A1,174-138-239-884-015,2017-11-30,2017,AU 2016/276030 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image. The application further deals with different ways of navigating in the sequence of image, e.g via dragging or pressure detection of touch input.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/174-138-239-884-015,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
286,KR,A,KR 20210124503 A,131-306-844-212-700,2021-10-14,2021,KR 20217031223 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;KR 20207029178 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/131-306-844-212-700,Patent Application,no,5,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
287,EP,A1,EP 3304270 A1,164-566-161-791-780,2018-04-11,2018,EP 16730554 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,,APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,APPLE INC. (2018-08-01),https://lens.org/164-566-161-791-780,Patent Application,yes,0,1,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
288,CN,A,CN 111475085 A,065-120-784-298-065,2020-07-31,2020,CN 202010281684 A,2016-05-20,CN 202010281684 A;;CN 201610342313 A;;US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"The disclosure relates to devices and methods for capturing and interacting with enhanced digital images. The disclosure provides an electronic device, an apparatus and method for grouping multiple images. The electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activationof the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the cameraafter acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/065-120-784-298-065,Patent Application,no,5,1,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0484;;G06F3/01;;G06F3/0488;;G06V10/10;;G06V20/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
289,AU,B4,AU 2016/100648 B4,154-421-223-362-253,2017-02-23,2017,AU 2016/100648 A,2016-05-19,US 201562215689 P;;US 201514863432 A;;US 201562172223 P;;US 201562172233 P;;US 201514864580 A,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN I;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/154-421-223-362-253,Limited Patent,no,0,0,9,100,0,G06F3/04842;;G06F3/0488;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/62;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00,H04N5/232;;G06F17/00;;G09G5/00;;H04M1/72439,,0,0,,,,ACTIVE
290,NL,B1,NL 2019214 B1,000-736-795-152-093,2018-04-10,2018,NL 2019214 A,2017-07-10,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;IMRAN A CHAUDHRI;;BEHKISH J MANZARI;;PAULO M LOPEZ;;PAVEL PIVONKA;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC;;GRAHAM R CLARKE;;SEBASTIAN J BAUER,,https://lens.org/000-736-795-152-093,Granted Patent,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
291,AU,B2,AU 2019/200872 B2,053-493-400-413-308,2019-10-10,2019,AU 2019/200872 A,2019-02-08,AU 2019/200872 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/053-493-400-413-308,Granted Patent,no,4,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
292,KR,A,KR 20220021004 A,072-304-795-191-052,2022-02-21,2022,KR 20227003345 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;KR 20217031223 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/072-304-795-191-052,Patent Application,no,7,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
293,AU,A1,AU 2019/257437 A1,156-382-971-492-751,2019-11-21,2019,AU 2019/257437 A,2019-10-30,AU 2019/257437 A;;AU 2019/200872 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"A method, comprising: at an electronic device with a display and a touch-sensitive surface: storing a plurality of sequences of images, wherein a respective sequence of images includes: a respective representative image taken by a camera, one or more images acquired by the camera after acquiring the respective representative image, and one or more images acquired by the camera before acquiring the respective representative image; storing a plurality of images that are distinct from the images in the plurality of sequences of images, wherein a respective image in the plurality of images is not part of a sequence of images in the plurality of sequences of images; displaying a first image on the display; while displaying the first image on the display, detecting a first input; in response to detecting the first input: in accordance with a determination that the first image is an image in a first sequence of images, performing a first operation that includes displaying at least some of the images in the first sequence of images besides the first image; and in accordance with a determination that the first image is an image in the plurality of images that are distinct from the images in the plurality of sequences of images, performing a second operation, distinct from the first operation, involving the first image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/156-382-971-492-751,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
294,AU,B2,AU 2016/276030 B2,185-109-172-466-770,2018-11-08,2018,AU 2016/276030 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image. The application further deals with different ways of navigating in the sequence of image, e.g via dragging or pressure detection of touch input.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/185-109-172-466-770,Granted Patent,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
295,AU,B2,AU 2020/244406 B2,020-840-778-905-087,2022-02-03,2022,AU 2020/244406 A,2020-09-29,AU 2020/244406 A;;AU 2019/257437 A;;AU 2019/200872 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"A method, comprising: at an electronic device with a display, a camera, one or more processors, and memory: while a first media acquisition mode is active on the electronic device, in response to detecting a single activation of a shutter button at a first time, capturing media corresponding to a scene; performing scene recognition on the scene; in response to detecting a user input: in accordance with a determination that the scene recognition meets first criteria, displaying the media as a sequence of images acquired by the camera in temporal proximity to the single activation of the shutter button at the first time, wherein the sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button at the first time; a representative image that represents the sequence of images and was acquired by the camera after one or more other images in the sequence of images; and a plurality of images acquired by the camera after acquiring the representative image; and, in accordance with a determination that the scene recognition does not meet the first criteria, displaying the media as a single image in temporal proximity to the activation of the shutter button at the first time.",APPLE INC,PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C;;PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L,,https://lens.org/020-840-778-905-087,Granted Patent,no,2,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
296,NL,A,NL 2019215 A,135-977-770-027-58X,2017-09-20,2017,NL 2019215 A,2017-07-10,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;IMRAN A CHAUDHRI;;BEHKISH J MANZARI;;PAULO M LOPEZ;;PAVEL PIVONKA;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC;;GRAHAM R CLARKE;;SEBASTIAN J BAUER,,https://lens.org/135-977-770-027-58X,Patent Application,no,2,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0481;;G06F3/0484;;G06F3/0485;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
297,AU,B2,AU 2019/257437 B2,012-349-974-052-181,2020-10-08,2020,AU 2019/257437 A,2019-10-30,AU 2019/257437 A;;AU 2019/200872 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"A method, comprising: at an electronic device with a display and a touch-sensitive surface: storing a plurality of sequences of images, wherein a respective sequence of images includes: a respective representative image taken by a camera, one or more images acquired by the camera after acquiring the respective representative image, and one or more images acquired by the camera before acquiring the respective representative image; storing a plurality of images that are distinct from the images in the plurality of sequences of images, wherein a respective image in the plurality of images is not part of a sequence of images in the plurality of sequences of images; displaying a first image on the display; while displaying the first image on the display, detecting a first input; in response to detecting the first input: in accordance with a determination that the first image is an image in a first sequence of images, performing a first operation that includes displaying at least some of the images in the first sequence of images besides the first image; and in accordance with a determination that the first image is an image in the plurality of images that are distinct from the images in the plurality of sequences of images, performing a second operation, distinct from the first operation, involving the first image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/012-349-974-052-181,Granted Patent,no,2,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
298,AU,A1,AU 2020/244406 A1,059-278-927-033-826,2020-10-29,2020,AU 2020/244406 A,2020-09-29,AU 2020/244406 A;;AU 2019/257437 A;;AU 2019/200872 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"A method, comprising: at an electronic device with a display, a camera, one or more processors, and memory: while a first media acquisition mode is active on the electronic device, in response to detecting a single activation of a shutter button at a first time, capturing media corresponding to a scene; performing scene recognition on the scene; in response to detecting a user input: in accordance with a determination that the scene recognition meets first criteria, displaying the media as a sequence of images acquired by the camera in temporal proximity to the single activation of the shutter button at the first time, wherein the sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button at the first time; a representative image that represents the sequence of images and was acquired by the camera after one or more other images in the sequence of images; and a plurality of images acquired by the camera after acquiring the representative image; and, in accordance with a determination that the scene recognition does not meet the first criteria, displaying the media as a single image in temporal proximity to the activation of the shutter button at the first time.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;LANGOULANT BRENDAN J;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/059-278-927-033-826,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
299,AU,A1,AU 2023/226703 A1,051-498-964-750-844,2023-09-21,2023,AU 2023/226703 A,2023-09-06,AU 2023/226703 A;;AU 2022/202892 A;;US 201514863432 A;;US 201562215689 P;;AU 2019/257437 A;;AU 2020/244406 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;AU 2019/200872 A;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/051-498-964-750-844,Patent Application,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;H04N1/00;;H04N1/21,,0,0,,,,PENDING
300,CN,A,CN 106227439 A,069-272-608-456-595,2016-12-14,2016,CN 201610342151 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 201514864580 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"The invention provides an electronic device, an apparatus for displaying images, and a method of displaying the images. The electronic device includes a camera, and when the device is under a status of a first media collection mode of the camera, the electronic device displays a representative image on a display. The representative image is one image in a sequence of images that includes images acquired by a camera before and after acquiring the representative image. While displaying the representative image, the device detects an input. In response to detecting the input, the device transitions from displaying the representative image to displaying a prior image in the sequence of images that was acquired by the camera before acquiring the representative image. After transitioning to displaying the respective prior image, the device displays, in sequence starting with the prior image, at least some of the images acquired by the camera before acquiring the representative image and at least some of the images acquired by the camera after acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN I;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/069-272-608-456-595,Patent Application,no,14,4,9,100,0,G06F3/04842;;G06F3/0488;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/632;;G06F3/0482;;G06F3/04883;;H04N23/62;;H04N23/632;;G06F3/0485;;G06F3/0488;;H04N2101/00,G06F3/0488;;G06F3/0484;;H04M1/72439,,0,0,,,,ACTIVE
301,WO,A1,WO 2016/200587 A1,096-601-479-037-610,2016-12-15,2016,US 2016/0033578 W,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image. The application further deals with different ways of navigating in the sequence of image, e.g via dragging or pressure detection of touch input.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/096-601-479-037-610,Patent Application,yes,4,3,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,PENDING
302,NL,B1,NL 2019215 B1,011-897-557-429-129,2018-04-16,2018,NL 2019215 A,2017-07-10,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and Methods for Capturing and Interacting with Enhanced Digital Images,"An electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activation of the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the camera after acquiring the representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;IMRAN A CHAUDHRI;;BEHKISH J MANZARI;;PAULO M LOPEZ;;PAVEL PIVONKA;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLAS V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC;;GRAHAM R CLARKE;;SEBASTIAN J BAUER,,https://lens.org/011-897-557-429-129,Granted Patent,no,0,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
303,CN,U,CN 205942662 U,012-769-792-277-196,2017-02-08,2017,CN 201620470063 U,2016-05-20,CN 201620470063 U,2016-05-20,Electronic equipment with be used for device that divides into groups to a plurality of images,"The present disclosure provides a device that electronic equipment and being used for divides into groups to a plurality of images. An electronic equipment includes the camera. When when being arranged in the first media acquisition mode of camera, this equipment shows real -time preview on the display. When showing real -time preview, this equipment inspection is to the activation of shutter release button. In response to detecting the activation to the shutter release button, this equipment will be divided into groups by a plurality of images that the camera was gathered on the time that the activation with to the shutter release button is close to the image sequence in. This image sequence includes: a plurality of images by camera collection before detecting the activation of shutter release button, representative image, this representativeness image first image sequence of representative is and by gathering after the one or more in camera other images in first image sequence, and by a plurality of images of camera collection after gathering representative image.",APPLE INC,HENRIQUE D PENHA;;CHARLES A MEZAK;;BEHKISH J MANZARI;;PAULO M LOPEZ;;GRAHAM R CLARKE;;PAVEL PIVONKA;;SANGRAM JYOTI BAL;;I A CHOWDHURY;;ALAN C DYE;;CRAIG M FEDERIGHI;;AURELIO GUZMAN;;JONATHAN IVE;;NICHOLASV V KING;;JUSTIN S TITI;;CHRISTOPHER I WILSON;;ELLIOTT B HARRIS;;EMILIE KIM;;BRENDAN J LANGOULANT;;BRITT S MIURA;;DANIEL E GOBERA RUBALCAVA;;CHRISTOPHER P FOSS;;KENNETH L KOCIENDA;;DANIEL T PRESTON;;GREGORY M APODACA;;SIMON BOVET;;MICHAEL T JUREWITZ;;BETHANY B CONOLLY;;NATALIA C MARIC,,https://lens.org/012-769-792-277-196,Limited Patent,no,0,2,1,1,0,,G06F3/0484;;G06F3/0488,,0,0,,,,ACTIVE
304,KR,A,KR 20200067931 A,048-804-248-801-529,2020-06-12,2020,KR 20207015964 A,2016-05-20,US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A;;US 2016/0033578 W,2015-06-07,DEVICES AND METHODS FOR CAPTURING AND INTERACTING WITH ENHANCED DIGITAL IMAGES,"전자 디바이스가 카메라를 포함한다. 카메라에 대한 제1 미디어 획득 모드에 있는 동안, 디바이스는 디스플레이 상에 라이브 프리뷰를 디스플레이한다. 라이브 프리뷰를 디스플레이하는 동안, 디바이스는 셔터 버튼의 활성화를 검출한다. 셔터 버튼의 활성화를 검출한 것에 응답하여, 디바이스는 셔터 버튼의 활성화에 시간적으로 근접해서 카메라에 의해 획득된 복수의 이미지들을 이미지들의 시퀀스로 그룹화한다. 이미지들의 시퀀스는 하기를 포함한다: 셔터 버튼의 활성화를 검출하기 전에 카메라에 의해 획득된 복수의 이미지들; 이미지들의 제1 시퀀스를 나타내고 이미지들의 제1 시퀀스 내의 다른 이미지들 중 하나 이상의 이미지 이후에 카메라에 의해 획득된 대표 이미지; 및 대표 이미지를 획득한 후에 카메라에 의해 획득된 복수의 이미지들. 본 출원은, 예컨대 터치 입력의 드래깅 또는 압력 검출을 통해, 이미지의 시퀀스에서 탐색하는 상이한 방식들을 추가로 다룬다.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOTT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/048-804-248-801-529,Patent Application,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,H04N5/232;;G06F3/0481;;G06F3/0484;;G06V10/10;;G06V20/00;;H04N1/00;;H04N1/21;;H04N5/235,,0,0,,,,ACTIVE
305,AU,B2,AU 2022/202892 B2,052-313-677-868-287,2023-06-29,2023,AU 2022/202892 A,2022-05-02,AU 2022/202892 A;;AU 2020/244406 A;;AU 2016/276030 A;;US 201562172223 P;;US 201562172233 P;;US 201514863432 A;;US 201562215689 P;;AU 2019/257437 A;;AU 2019/200872 A;;US 2016/0033578 W,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"A method comprising at an electronic device with a display and a touch-sensitive surface, displaying an image on the display. Wherein the image is one image in a sequence of images taken by a camera and where the sequence of images includes a representative image. The sequence of images includes one or more images acquired by the camera after acquiring the representative image and the sequence of images includes one or more images acquired by the camera before acquiring the representative image. While displaying the image in the sequence of images on the display, detecting a first input. In response to detecting the first input, displaying an image editing user interface for editing the sequence of images, the image editing user interface including an affordance for turning on animated playback of the sequence of images or turning off animated playback of the sequence of images while retaining the sequence of images. While displaying the image editing user interface, detecting a second input on the affordance. In response to detecting a second input, turning on animated playback of the sequence of images or turning off animated playback of the sequence of images while retaining the sequence of images.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONOLLY BETHANY B;;MARIC NATALIA C,,https://lens.org/052-313-677-868-287,Granted Patent,no,3,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0488;;G06F3/0484;;G06F3/0487;;G06F18/00;;H04N1/00;;H04N1/21;;H04N23/60,,0,0,,,,ACTIVE
306,CN,A,CN 111475086 A,113-403-946-973-326,2020-07-31,2020,CN 202010290361 A,2016-05-20,CN 202010290361 A;;CN 201610342313 A;;US 201562172223 P;;US 201562172233 P;;US 201562215689 P;;US 201514863432 A,2015-06-07,Devices and methods for capturing and interacting with enhanced digital images,"The disclosure relates to devices and methods for capturing and interacting with enhanced digital images. The disclosure provides an electronic device, an apparatus and method for grouping multiple images. The electronic device includes a camera. While in a first media acquisition mode for the camera the device displays a live preview on the display. While displaying the live preview, the device detects activation of a shutter button. In response to detecting activation of the shutter button, the device groups a plurality of images acquired by the camera in temporal proximity to the activationof the shutter button into a sequence of images. The sequence of images includes: a plurality of images acquired by the camera prior to detecting activation of the shutter button; a representative image that represents the first sequence of images and was acquired by the camera after one or more of the other images in the first sequence of images; and a plurality of images acquired by the cameraafter acquiring the representative image.",APPLE INC,PENHA HENRIQUE D;;MEZAK CHARLES A;;MANZARI BEHKISH J;;LOPEZ PAULO M;;CLARKE GRAHAM R;;PIVONKA PAVEL;;BAUER SEBASTIAN J;;CHAUDHRI IMRAN A;;DYE ALAN C;;FEDERIGHI CRAIG M;;GUZMAN AURELIO;;IVE JONATHAN;;KING NICHOLAS V;;TITI JUSTIN S;;WILSON CHRISTOPHER I;;HARRIS ELLIOT B;;KIM EMILIE;;LANGOULANT BRENDAN J;;MIURA BRITT S;;GOBERA RUBALCAVA DANIEL E;;FOSS CHRISTOPHER P;;KOCIENDA KENNETH L;;PRESTON DANIEL T;;APODACA GREGORY M;;BOVET SIMON;;JUREWITZ MICHAEL T;;CONNOLY BETHANY B;;MARIC NATALIA C,,https://lens.org/113-403-946-973-326,Patent Application,no,12,0,72,100,0,G06F3/04842;;G06F3/04845;;G06F3/04883;;G06F3/016;;H04N1/2112;;H04N1/2125;;G06F2203/04806;;H04N23/64;;H04N23/62;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;H04N1/2125;;G11B27/34;;G11B27/031;;G06V20/00;;G06V10/10;;G06F3/0485;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/64;;H04N23/62;;H04N23/634;;H04N23/632;;G06F3/04817;;G06F3/04842;;G06F3/04845;;G06F3/04847;;H04N1/00204;;H04N1/2125;;H04N1/2145;;H04N23/64;;H04N23/63;;H04N23/62;;H04N23/73;;G06F3/0487;;G06F3/04845;;H04N1/00204;;H04N1/2145;;H04N1/2112;;G06V10/10;;G06V20/00;;G06F3/04883;;G11B27/005;;G11B27/034;;G11B27/105;;H04N23/62;;H04N23/64;;H04N23/73;;H04N23/632;;H04N23/634;;G06T2207/10016;;H04N1/2125;;G06F3/0485;;G06F3/0488;;G11B27/031;;G11B27/34;;G06F3/04817;;G06F3/04842;;H04N2101/00,G06F3/0484;;G06F3/01;;G06F3/0488;;G06V10/10;;G06V20/00;;H04N1/21;;H04N5/232,,0,0,,,,ACTIVE
