"#",Jurisdiction,Kind,Display Key,Lens ID,Publication Date,Publication Year,Application Number,Application Date,Priority Numbers,Earliest Priority Date,Title,Abstract,Applicants,Inventors,Owners,URL,Document Type,Has Full Text,Cites Patent Count,Cited by Patent Count,Simple Family Size,Extended Family Size,Sequence Count,CPC Classifications,IPCR Classifications,US Classifications,NPL Citation Count,NPL Resolved Citation Count,NPL Resolved Lens ID(s),NPL Resolved External ID(s),NPL Citations,Legal Status
1,DD,A5,DD 291773 A5,003-361-217-411-314,1991-07-11,1991,DD 33759590 A,1990-02-05,DD 33759590 A,1990-02-05,"VERFAHREN ZUR HERSTELLUNG VON DEN 1,3,4,2-OXADIAZABORIN-REST ENTHALTENDEN STYRYLFARBSTOFFEN",,TECH HOCHSCHULE C SCHORLEMMER,HARTMANN HORST;;STEFFEN KAY;;WEBER MICHAEL;;EBERSOLD LIANE,,https://lens.org/003-361-217-411-314,Granted Patent,no,0,0,1,1,0,,C07F5/02;;C09B23/14,,0,0,,,,EXPIRED
2,DD,A5,DD 289047 A5,094-923-983-487-564,1991-04-18,1991,DD 33463989 A,1989-11-17,DD 33463989 A,1989-11-17,"VERFAHREN ZUR HERSTELLUNG VON METHYLSUBSTITUIERTEN 2H-1,3,4,2-OXADIAZABORINEN",,TECH HOCHSCHULE C SCHORLEMMER,HARTMANN HORST;;STEFFEN KAY;;WEBER MICHAEL;;EBERSOLD LIANE,,https://lens.org/094-923-983-487-564,Granted Patent,no,0,0,1,1,0,,C07F5/02,,0,0,,,,EXPIRED
3,US,A1,US 2022/0000311 A1,115-830-164-421-040,2022-01-06,2022,US 202117447960 A,2021-09-17,US 202117447960 A;;US 201916439812 A;;US 201715617022 A;;US 201662353605 P,2016-06-23,Canted Grill,"A canted grill has a lid, a base, a cooking grate and a charcoal grate. The lid and base collectively form a cooking chamber with the cooking grate and charcoal grate inside. The lid has a deep side on its right and a shallow side on its left. The base has a deep side on its left and a shallow side on its right. The charcoal grate holds charcoal in the deep side of the base. This provides direct heat to food placed on the cooking grate above it under the shallow side of the lid. Food placed on the cooking grate on the shallow side of the base and under the deep side of the lid is away from the charcoal and heated indirectly.",SCS DIRECT INC,EBERSOLD BENJAMIN;;COSTEN MICHAEL KITTREDGE;;LEE CHUL HEE,SCS DIRECT INC (2019-06-14),https://lens.org/115-830-164-421-040,Patent Application,yes,0,1,2,3,0,A47J37/0704;;A47J37/0763;;A47J37/0704;;A47J37/0763;;A47J2037/0795;;A47J2037/0777;;A47J37/0786,A47J37/07,,0,0,,,,PENDING
4,US,A1,US 2019/0290065 A1,192-221-556-926-506,2019-09-26,2019,US 201916439812 A,2019-06-13,US 201916439812 A;;US 201715617022 A;;US 201662353605 P,2016-06-23,Canted Grill,"A canted grill has a lid, a base, a cooking grate and a charcoal grate. The lid and base collectively form a cooking chamber with the cooking grate and charcoal grate inside. The lid has a deep side on its right and a shallow side on its left. The base has a deep side on its left and a shallow side on its right. The charcoal grate holds charcoal in the deep side of the base. This provides direct heat to food placed on the cooking grate above it under the shallow side of the lid. Food placed on the cooking grate on the shallow side of the base and under the deep side of the lid is away from the charcoal and heated indirectly.",SCS DIRECT INC,EBERSOLD BENJAMIN;;COSTEN MICHAEL KITTREDGE;;LEE CHUL HEE,SCS DIRECT INC (2019-06-14),https://lens.org/192-221-556-926-506,Patent Application,yes,0,2,2,3,0,A47J37/0704;;A47J37/0763;;A47J37/0704;;A47J37/0763;;A47J2037/0795;;A47J2037/0777;;A47J37/0786,A47J37/07,,0,0,,,,DISCONTINUED
5,US,B2,US 8515765 B2,170-737-582-669-346,2013-08-20,2013,US 201113251712 A,2011-10-03,US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS;;VOICEBOX TECHNOLOGIES INC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/170-737-582-669-346,Granted Patent,yes,111,40,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/27;;G10L21/00,704/275;;704/9;;704/270;;704/270.1,18,5,052-977-165-653-882;;039-759-935-043-735;;021-442-002-762-19X;;160-444-942-829-234;;090-169-265-026-758,10.3115/1072133.1072149;;10.1109/5254.988442;;10.1109/ccece.1995.526599;;10.1109/icassp.2000.861804;;10.1109/jproc.2003.817117,"Reuters, ""IBM to Enable Honda Drivers to Talk to Cars"", Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Lin, Bor-shen, et al., ""A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History"", ASRU'99, 1999, 4 pages.;;Kuhn, Thomas, et al., ""Hybrid In-Car Speech Recognition for Mobile Multimedia Applications"", Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Belvin, Robert, et al,, ""Development of the HRL Route Navigation Dialogue System"", Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Lind, R., et al., ""The Network Vehicle-A Glimpse into the Future of Mobile Multi-Media"", IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Zhao, Yilin, ""Telematics: Safe and Fun Driving"", IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.;;Chai et al., ""Mind: A Semantics-Based Multimodal Interpretation Framework for Conversational System"", Proceedings of the International Class Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., ""Multimodal Maps: An Agent-Based Approach"", International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Elio et al., ""On Abstract Task Models and Conversation Policies"" in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Turunen, ""Adaptive Interaction Methods in Speech User Interfaces"", Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Mao, Mark Z., ""Automatic Training Set Segmentation for Multi-Pass Speech Recognition"", Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;Vanhoucke, Vincent, ""Confidence Scoring and Rejection Using Multi-Pass Speech Recognition"", Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., ""Efficient Lattice Representation and Generation"", Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;El Meliani et al., ""A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary"", Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Arrington, Michael, ""Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0"", TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redefines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;Bazzi, Issam et al., ""Heterogeneous Lexical Units for Automatic Speech Recognition: Preliminary Investigations"" Processing of the IEEE International Conference on Acoustics, Speech, and Signal Processing, vol. 3, Jun. 5-9, 2000, XP010507574, pp. 1257-1260.;;O'Shaughnessy, Douglas, ""Interacting with Computers by Voice: Automatic Speech Recognition and Synthesis"", Proceedings of the IEEE, vol. 91, No. 9, Sep. 1, 2003, XP011100665, pp. 1272-1305.;;Statement in Accordance with the Notice from the European Patent Office dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.",ACTIVE
6,CN,A,CN 101535983 A,097-086-695-271-498,2009-09-16,2009,CN 200780042315 A,2007-10-16,US 2007/0081481 W;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES INC,LARRY BALDWIN;;TOM FREEMAN;;MICHAEL TJALVE;;BLANE EBERSOLD;;CHRIS WEIDER,,https://lens.org/097-086-695-271-498,Patent Application,no,0,235,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,,0,0,,,,ACTIVE
7,US,A1,US 2008/0091406 A1,171-344-111-023-61X,2008-04-17,2008,US 58092606 A,2006-10-16,US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES INC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/171-344-111-023-61X,Patent Application,yes,99,414,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,704/4,0,0,,,,ACTIVE
8,WO,A3,WO 2008/118195 A3,076-652-485-345-382,2008-12-04,2008,US 2007/0081481 W,2007-10-16,US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES INC;;BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,,https://lens.org/076-652-485-345-382,Search Report,yes,3,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,,0,0,,,,PENDING
9,US,A1,US 2015/0228276 A1,099-365-174-806-295,2015-08-13,2015,US 201514691445 A,2015-04-20,US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES CORP,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/099-365-174-806-295,Patent Application,yes,121,32,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G10L17/22,,0,0,,,,ACTIVE
10,EP,A2,EP 2082335 A2,182-432-446-791-679,2009-07-29,2009,EP 07873538 A,2007-10-16,US 2007/0081481 W;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,,VOICEBOX TECHNOLOGIES INC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES CORPORATION (2016-05-18),https://lens.org/182-432-446-791-679,Patent Application,yes,0,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,,0,0,,,,DISCONTINUED
11,US,A1,US 2020/0388274 A1,127-060-777-747-374,2020-12-10,2020,US 202017000502 A,2020-08-24,US 202017000502 A;;US 201916417178 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/127-060-777-747-374,Patent Application,yes,0,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F40/30;;G10L15/22;;G10L17/22;;G10L25/51;;G10L25/63,,0,0,,,,DISCONTINUED
12,US,B2,US 8073681 B2,163-967-278-043-197,2011-12-06,2011,US 58092606 A,2006-10-16,US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS;;VOICEBOX TECHNOLOGIES INC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/163-967-278-043-197,Granted Patent,yes,114,492,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/27;;G10L11/00;;G10L21/00,704/9;;704/270;;704/275,18,5,021-442-002-762-19X;;052-977-165-653-882;;039-759-935-043-735;;160-444-942-829-234;;090-169-265-026-758,10.1109/ccece.1995.526599;;10.3115/1072133.1072149;;10.1109/5254.988442;;10.1109/icassp.2000.861804;;10.1109/jproc.2003.817117,"Chai et al., ""Mind: A Semantics-Based Multimodal Interpretation Framework for Conversational System"", Proceedings of the International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., ""Multimodal Maps: An Agent-Based Approach"", International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Elio et al., ""On Abstract Task Models and Conversation Policies"" in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Turunen, ""Adaptive Interaction Methods in Speech User Interfaces"", Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Mao, Mark Z., ""Automatic Training Set Segmentation for Multi-Pass Speech Recognition"", Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;Vanhoucke, Vincent, ""Confidence Scoring and Rejection Using Multi-Pass Speech Recognition"", Nuance Communications, Menlo Park, CA, [no date], 4 pages.;;Weng, Fuliang, et al., ""Efficient Lattice Representation and Generation"", Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, [no date], 4 pages.;;El Meliani et al., ""A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary"", Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Arrington, Michael, ""Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0"", TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redefines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;Reuters, ""IBM to Enable Honda Drivers to Talk to Cars"", Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Lin, Bor-shen, et al., ""A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History"", ASRU'99, 1999, 4 pages.;;Kuhn, Thomas, et al., ""Hybrid In-Car Speech Recognition for Mobile Multimedia Applications"", Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Belvin, Robert, et al., ""Development of the HRL Route Navigation Dialogue System"", Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Lind, R., et al., ""The Network Vehicle-A Glimpse into the Future of Mobile Multi-Media"", IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Zhao, Yilin, ""Telematics: Safe and Fun Driving"", IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.;;Bazzi, Issam et al., ""Heterogeneous Lexical Units for Automatic Speech Recognition: Preliminary Investigations"", Processing of the IEEE International Conference on Acoustics, Speech, and Signal Processing, vol. 3, Jun. 5-9, 2000, XP010507574, pp. 1257-1260.;;O'Shaughnessy, Douglas, ""Interacting with Computers by Voice: Automatic Speech Recognition and Synthesis"", Proceedings of the IEEE, vol. 91, No. 9, Sep. 1. 2003. XP011100665, pp. 1272-1305.;;Statement in Accordance with the Notice from the European Patent Office dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.",ACTIVE
13,US,B1,US 10510341 B1,181-820-467-464-739,2019-12-17,2019,US 201916555125 A,2019-08-29,US 201916555125 A;;US 201916417173 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/181-820-467-464-739,Granted Patent,yes,977,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F17/27;;G10L15/06;;G10L15/183;;G10L15/22;;G10L17/22;;G10L21/0216;;G10L25/51,,22,9,160-444-942-829-234;;052-977-165-653-882;;063-803-644-850-620;;021-442-002-762-19X;;170-989-037-425-195;;090-169-265-026-758;;036-173-204-155-410;;050-692-723-877-767;;039-759-935-043-735,10.1109/icassp.2000.861804;;10.3115/1072133.1072149;;10.1109/icns.2006.10;;10.1109/ccece.1995.526599;;10.1109/icslp.1996.607260;;10.1109/jproc.2003.817117;;10.1109/icassp.1998.675366;;10.1109/icassp.1997.596105;;10.1109/5254.988442,"“Statement in Accordance with the Notice from the European Patent Office” dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.;;Arrington, Michael, “Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0”, TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redetines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;BAZZI I., GLASS J.: ""Heterogeneous lexical units for automatic speech recognition: preliminary investigations"", ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, 2000. ICASSP '00. PROCEEDING S. 2000 IEEE INTERNATIONAL CONFERENCE ON 5-9 JUNE 2000, PISCATAWAY, NJ, USA,IEEE, vol. 3, 5 June 2000 (2000-06-05) - 9 June 2000 (2000-06-09), pages 1257 - 1260, XP010507574, ISBN: 978-0-7803-6293-2;;Belvin, Robert, et al., “Development of the HRL Route Navigation Dialogue System”, Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Chai et al., “MIND: A Semantics-Based Multimodal Interpretation Framework for Conversational Systems”, Proceedings of the International Class Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., “Multimodal Maps: An Agent-Based Approach”, International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Davis, Z., et al., A Personal Handheld Multi-Modal Shopping Assistant, IEEE, 2006, 9 pages.;;El Meliani et al., “A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary”, Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Elio et al., “On Abstract Task Models and Conversation Policies” in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Kirchhoff, Katrin, “Syllable-Level Desynchronisation of Phonetic Features for Speech Recognition”, Proceedings of the Fourth International Conference on Spoken Language, 1996, ICSLP 96, vol. 4, IEEE, 1996, 3 pages.;;Kuhn, Thomas, et al., “Hybrid In-Car Speech Recognition for Mobile Multimedia Applications”, Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Lin, Bor-shen, et al., “A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History”, ASRU'99, 1999, 4 pages.;;Lind, R., et al., The Network Vehicle—A Glimpse into the Future of Mobile Multi-Media, IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Mao, Mark Z., “Automatic Training Set Segmentation for Multi-Pass Speech Recognition”, Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;O'SHAUGHNESSY D.: ""Interacting with computers by voice: automatic speech recognition and synthesis"", PROCEEDINGS OF THE IEEE., IEEE. NEW YORK., US, vol. 91, no. 9, 1 September 2003 (2003-09-01), US, pages 1272 - 1305, XP011100665, ISSN: 0018-9219, DOI: 10.1109/JPROC.2003.817117;;Reuters, “IBM to Enable Honda Drivers to Talk to Cars”, Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Turunen, “Adaptive Interaction Methods in Speech User Interfaces”, Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Vanhoucke, Vincent, “Confidence Scoring and Rejection Using Multi-Pass Speech Recognition”, Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., “Efficient Lattice Representation and Generation”, Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;Wu, Su-Lin, et al., “Incorporating Information from Syllable-Length Time Scales into Automatic Speech Recognition”, Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, 1998, vol. 2, IEEE, 1998, 4 pages.;;Wu, Su-Lin, et al., “Integrating Syllable Boundary Information into Speech Recognition”, IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP-97, 1997, vol. 2, IEEE, 1997, 4 pages.;;Zhao, Yilin, “Telematics: Safe and Fun Driving”, IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.",ACTIVE
14,US,A1,US 2019/0272821 A1,002-059-050-879-420,2019-09-05,2019,US 201916416884 A,2019-05-20,US 201916416884 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/002-059-050-879-420,Patent Application,yes,0,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F17/27;;G10L15/22;;G10L17/22;;G10L25/51,,0,0,,,,ACTIVE
15,US,A1,US 2019/0272823 A1,114-998-162-350-085,2019-09-05,2019,US 201916417178 A,2019-05-20,US 201916417178 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/114-998-162-350-085,Patent Application,yes,14,2,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F17/27;;G10L15/22;;G10L17/22;;G10L25/51,,0,0,,,,ACTIVE
16,EP,A4,EP 2082335 A4,036-154-224-830-133,2010-11-10,2010,EP 07873538 A,2007-10-16,US 2007/0081481 W;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,,VOICEBOX TECHNOLOGIES INC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES CORPORATION (2016-05-18),https://lens.org/036-154-224-830-133,Search Report,no,4,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,,0,0,,,,DISCONTINUED
17,US,B2,US 10515628 B2,048-233-463-238-779,2019-12-24,2019,US 201916417173 A,2019-05-20,US 201916417173 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/048-233-463-238-779,Granted Patent,yes,977,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F17/27;;G10L15/06;;G10L15/183;;G10L15/22;;G10L17/22;;G10L21/0216;;G10L25/51,,22,9,160-444-942-829-234;;052-977-165-653-882;;063-803-644-850-620;;021-442-002-762-19X;;170-989-037-425-195;;090-169-265-026-758;;036-173-204-155-410;;050-692-723-877-767;;039-759-935-043-735,10.1109/icassp.2000.861804;;10.3115/1072133.1072149;;10.1109/icns.2006.10;;10.1109/ccece.1995.526599;;10.1109/icslp.1996.607260;;10.1109/jproc.2003.817117;;10.1109/icassp.1998.675366;;10.1109/icassp.1997.596105;;10.1109/5254.988442,"“Statement in Accordance with the Notice from the European Patent Office” dated Oct. 1, 2007 Concerning Business Methods (OJ EPO 1112007, 592-593), XP002456252.;;Arrington, Michael, “Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0”, TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redefines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;BAZZI I., GLASS J.: ""Heterogeneous lexical units for automatic speech recognition: preliminary investigations"", ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, 2000. ICASSP '00. PROCEEDING S. 2000 IEEE INTERNATIONAL CONFERENCE ON 5-9 JUNE 2000, PISCATAWAY, NJ, USA,IEEE, vol. 3, 5 June 2000 (2000-06-05) - 9 June 2000 (2000-06-09), pages 1257 - 1260, XP010507574, ISBN: 978-0-7803-6293-2;;Belvin, Robert, et al., “Development of the HRL Route Navigation Dialogue System”, Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Chai et al., “MIND: A Semantics-Based Multimodal Interpretation Framework for Conversational Systems”, Proceedings of the International Class Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., “Multimodal Maps: An Agent-Based Approach”, International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Davis, Z., et al., A Personal Handheld Multi-Modal Shopping Assistant, IEEE, 2006, 9 pages.;;El Meliani et al., “A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary”, Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Elio et al., “On Abstract Task Models and Conversation Policies” in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Kirchhoff, Katrin, “Syllable-Level Desynchronisation of Phonetic Features for Speech Recognition”, Proceedings of the Fourth International Conference on Spoken Language, 1996, ICSLP 96, vol. 4, IEEE, 1996, 3 pages.;;Kuhn, Thomas, et al., “Hybrid In-Car Speech Recognition for Mobile Multimedia Applications”, Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Lin, Bor-shen, et al., “A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History”, ASRU'99, 1999, 4 pages.;;Lind, R., et al., The Network Vehicle—A Glimpse into the Future of Mobile Multi-Media, IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Mao, Mark Z., “Automatic Training Set Segmentation for Multi-Pass Speech Recognition”, Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;O'SHAUGHNESSY D.: ""Interacting with computers by voice: automatic speech recognition and synthesis"", PROCEEDINGS OF THE IEEE., IEEE. NEW YORK., US, vol. 91, no. 9, 1 September 2003 (2003-09-01), US, pages 1272 - 1305, XP011100665, ISSN: 0018-9219, DOI: 10.1109/JPROC.2003.817117;;Reuters, “IBM to Enable Honda Drivers to Talk to Cars”, Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Turunen, “Adaptive Interaction Methods in Speech User Interfaces”, Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Vanhoucke, Vincent, “Confidence Scoring and Rejection Using Multi-Pass Speech Recognition”, Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., “Efficient Lattice Representation and Generation”, Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;Wu, Su-Lin, et al., “Incorporating Information from Syllable-Length Time Scales into Automatic Speech Recognition”, Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, 1998, vol. 2, IEEE, 1998, 4 pages.;;Wu, Su-Lin, et al., “Integrating Syllable Boundary Information into Speech Recognition”, IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP-97, 1997, vol. 2, IEEE, 1997, 4 pages.;;Zhao, Yilin, “Telematics: Safe and Fun Driving”, IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.",ACTIVE
18,US,A1,US 2012/0022857 A1,137-802-664-800-573,2012-01-26,2012,US 201113251712 A,2011-10-03,US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS;;VOICEBOX TECHNOLOGIES INC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/137-802-664-800-573,Patent Application,yes,12,399,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/27,704/9;;X704E11001,0,0,,,,ACTIVE
19,US,B2,US 10755699 B2,114-506-179-049-412,2020-08-25,2020,US 201916417178 A,2019-05-20,US 201916417178 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/114-506-179-049-412,Granted Patent,yes,989,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F40/30;;G10L15/06;;G10L15/183;;G10L15/22;;G10L17/22;;G10L21/0216;;G10L25/51;;G10L25/63,,23,9,160-444-942-829-234;;052-977-165-653-882;;063-803-644-850-620;;021-442-002-762-19X;;170-989-037-425-195;;090-169-265-026-758;;036-173-204-155-410;;050-692-723-877-767;;039-759-935-043-735,10.1109/icassp.2000.861804;;10.3115/1072133.1072149;;10.1109/icns.2006.10;;10.1109/ccece.1995.526599;;10.1109/icslp.1996.607260;;10.1109/jproc.2003.817117;;10.1109/icassp.1998.675366;;10.1109/icassp.1997.596105;;10.1109/5254.988442,"“Statement in Accordance with the Notice from the European Patent Office” dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.;;Arrington, Michael, “Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0”, TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redetines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;BAZZI I., GLASS J.: ""Heterogeneous lexical units for automatic speech recognition: preliminary investigations"", ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, 2000. ICASSP '00. PROCEEDING S. 2000 IEEE INTERNATIONAL CONFERENCE ON 5-9 JUNE 2000, PISCATAWAY, NJ, USA,IEEE, vol. 3, 5 June 2000 (2000-06-05) - 9 June 2000 (2000-06-09), pages 1257 - 1260, XP010507574, ISBN: 978-0-7803-6293-2;;Belvin, Robert, et al., “Development of the HRL Route Navigation Dialogue System”, Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Chai et al., “MIND: A Semantics-Based Multimodal Interpretation Framework for Conversational Systems”, Proceedings of the International Class Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., “Multimodal Maps: An Agent-Based Approach”, International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Davis, Z., et al., A Personal Handheld Multi-Modal Shopping Assistant, IEEE, 2006, 9 pages.;;El Meliani et al., “A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary”, Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Elio et al., “On Abstract Task Models and Conversation Policies” in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Kirchhoff, Katrin, “Syllable-Level Desynchronisation of Phonetic Features for Speech Recognition”, Proceedings of the Fourth International Conference on Spoken Language, 1996, ICSLP 96, vol. 4, IEEE, 1996, 3 pages.;;Kuhn, Thomas, et al., “Hybrid In-Car Speech Recognition for Mobile Multimedia Applications”, Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Lin, Bor-shen, et al., “A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History”, ASRU'99, 1999, 4 pages.;;Lind, R., et al., “The Network Vehicle—A Glimpse into the Future of Mobile Multi-Media”, IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Mao, Mark Z., “Automatic Training Set Segmentation for Multi-Pass Speech Recognition”, Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. 1-685 to 1-688.;;O'SHAUGHNESSY D.: ""Interacting with computers by voice: automatic speech recognition and synthesis"", PROCEEDINGS OF THE IEEE., IEEE. NEW YORK., US, vol. 91, no. 9, 1 September 2003 (2003-09-01), US, pages 1272 - 1305, XP011100665, ISSN: 0018-9219, DOI: 10.1109/JPROC.2003.817117;;Reuters, “IBM to Enable Honda Drivers to Talk to Cars”, Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Turunen, “Adaptive Interaction Methods in Speech User Interfaces”, Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Vanhoucke, Vincent, “Confidence Scoring and Rejection Using Multi-Pass Speech Recognition”, Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., “Efficient Lattice Representation and Generation”, Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;Wu, Su-Lin, et al., “Incorporating Information from Syllable-Length Time Scales into Automatic Speech Recognition”, Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, 1998, vol. 2 IEEE, 1998, 4 pages.;;Wu, Su-Lin, et al., “Integrating Syllable Boundary Information into Speech Recognition”, IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP-97, 1997, vol. 2, IEEE, 1997, 4 pages.;;Zhao, Yilin, “Telematics: Safe and Fun Driving”, IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.;;Office Action issued in Chinese Patent Application No. 201580060519.1 dated Mar. 13, 2020, with its English translation, 40 pages.",ACTIVE
20,US,A1,US 2013/0339022 A1,140-507-630-156-026,2013-12-19,2013,US 201313987645 A,2013-08-19,US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES CORP,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/140-507-630-156-026,Patent Application,yes,17,42,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F3/16,704/257,0,0,,,,ACTIVE
21,CN,B,CN 101535983 B,151-501-576-360-502,2012-08-22,2012,CN 200780042315 A,2007-10-16,US 2007/0081481 W;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES INC,TOM FREEMAN;;LARRY BALDWIN;;MICHAEL TJALVE;;CHRIS WEIDER;;BLANE EBERSOLD,,https://lens.org/151-501-576-360-502,Granted Patent,no,0,1,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,,0,0,,,,ACTIVE
22,US,A1,US 2019/0272822 A1,154-990-736-672-820,2019-09-05,2019,US 201916417173 A,2019-05-20,US 201916417173 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/154-990-736-672-820,Patent Application,yes,10,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F17/27;;G10L15/22;;G10L17/22;;G10L25/51,,0,0,,,,ACTIVE
23,US,B2,US 10297249 B2,171-895-638-819-121,2019-05-21,2019,US 201514691445 A,2015-04-20,US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/171-895-638-819-121,Granted Patent,yes,964,2,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F3/16;;G06F17/27;;G10L15/06;;G10L15/18;;G10L15/183;;G10L15/22;;G10L17/22;;G10L21/0216;;G10L25/51,,22,9,170-989-037-425-195;;036-173-204-155-410;;050-692-723-877-767;;052-977-165-653-882;;039-759-935-043-735;;021-442-002-762-19X;;160-444-942-829-234;;090-169-265-026-758;;063-803-644-850-620,10.1109/icslp.1996.607260;;10.1109/icassp.1998.675366;;10.1109/icassp.1997.596105;;10.3115/1072133.1072149;;10.1109/5254.988442;;10.1109/ccece.1995.526599;;10.1109/icassp.2000.861804;;10.1109/jproc.2003.817117;;10.1109/icns.2006.10,"Kirchhoff, Katrin, “Syllable-Level Desynchronisation of Phonetic Features for Speech Recognition”, Proceedings of the Fourth International Conference on Spoken Language, 1996, ICSLP 96, vol. 4, IEEE, 1996, 3 pages.;;Wu, Su-Lin, et al., “Incorporating Information from Syllable-Length Time Scales into Automatic Speech Recognition”, Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, 1998, vol. 2, IEEE, 1998, 4 pages.;;Wu, Su-Lin, et al., “Integrating Syllable Boundary Information into Speech Recognition”, IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP-97, 1997, vol. 2, IEEE, 1997, 4 pages.;;Reuters, “IBM to Enable Honda Drivers to Talk to Cars”, Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Lin, Bor-shen, et al., “A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History”, ASRU'99, 1999, 4 pages.;;Kuhn, Thomas, et al., “Hybrid In-Car Speech Recognition for Mobile Multimedia Applications”, Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Belvin, Robert, et al., “Development of the HRL Route Navigation Dialogue System”, Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Lind, R., et al., “The Network Vehicle—A Glimpse into the Future of Mobile Multi-Media” IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Zhao, Yilin, “Telematics: Safe and Fun Driving”, IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.;;Chai et al., “MIND: A Semantics-Based Multimodal Interpretation Framework for Conversational System”, Proceedings of the International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., “Multimodal Maps: An Agent-Based Approach”, International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Elio et al., “On Abstract Task Models and Conversation Policies” in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Turunen, “Adaptive Interaction Methods in Speech User Interfaces”, Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Mao, Mark Z., “Automatic Training Set Segmentation for Multi-Pass Speech Recognition”, Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;Vanhoucke, Vincent, “Confidence Scoring and Rejection Using Multi-Pass Speech Recognition”, Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., “Efficient Lattice Representation and Generation”, Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;El Meliani et al., “A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary”, Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Arrington, Michael, “Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0”, TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redefines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;BAZZI I., GLASS J.: ""Heterogeneous lexical units for automatic speech recognition: preliminary investigations"", ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, 2000. ICASSP '00. PROCEEDING S. 2000 IEEE INTERNATIONAL CONFERENCE ON 5-9 JUNE 2000, PISCATAWAY, NJ, USA,IEEE, vol. 3, 5 June 2000 (2000-06-05) - 9 June 2000 (2000-06-09), pages 1257 - 1260, XP010507574, ISBN: 978-0-7803-6293-2;;O'SHAUGHNESSY D.: ""Interacting with computers by voice: automatic speech recognition and synthesis"", PROCEEDINGS OF THE IEEE., IEEE. NEW YORK., US, vol. 91, no. 9, 1 September 2003 (2003-09-01), US, pages 1272 - 1305, XP011100665, ISSN: 0018-9219, DOI: 10.1109/JPROC.2003.817117;;Statement in Accordance with the Notice from the European Patent Office dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.;;Davis, Z., et al., A Personal Handheld Multi-Modal Shopping Assistant, IEEE, 2006, 9 pages.",ACTIVE
24,US,B2,US 11222626 B2,010-383-763-117-842,2022-01-11,2022,US 201916416884 A,2019-05-20,US 201916416884 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/010-383-763-117-842,Granted Patent,yes,1009,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F40/30;;G10L15/06;;G10L15/183;;G10L15/22;;G10L17/22;;G10L21/0216;;G10L25/51;;G10L25/63,,36,13,160-444-942-829-234;;052-977-165-653-882;;063-803-644-850-620;;021-442-002-762-19X;;170-989-037-425-195;;090-169-265-026-758;;036-173-204-155-410;;050-692-723-877-767;;039-759-935-043-735;;132-235-507-824-344;;132-235-507-824-344;;039-078-206-343-996;;007-864-848-873-670,10.1109/icassp.2000.861804;;10.3115/1072133.1072149;;10.1109/icns.2006.10;;10.1109/ccece.1995.526599;;10.1109/icslp.1996.607260;;10.1109/jproc.2003.817117;;10.1109/icassp.1998.675366;;10.1109/icassp.1997.596105;;10.1109/5254.988442;;10.1007/978-1-4842-0653-9_1;;10.1007/978-1-4842-0653-9_1;;10.1109/icpwc.1994.567942;;10.1145/348941.348988,"“Statement in Accordance with the Notice from the European Patent Office” dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.;;Arrington, Michael, “Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0”, TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redefines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;BAZZI I., GLASS J.: ""Heterogeneous lexical units for automatic speech recognition: preliminary investigations"", ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, 2000. ICASSP '00. PROCEEDING S. 2000 IEEE INTERNATIONAL CONFERENCE ON 5-9 JUNE 2000, PISCATAWAY, NJ, USA,IEEE, vol. 3, 5 June 2000 (2000-06-05) - 9 June 2000 (2000-06-09), pages 1257 - 1260, XP010507574, ISBN: 978-0-7803-6293-2;;Belvin, Robert, et al., “Development of the HRL Route Navigation Dialogue System”, Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Chai et al., “MIND: A Semantics-Based Multimodal Interpretation Framework for Conversational System”, Proceedings of the International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., “Multimodal Maps: An Agent-Based Approach”, International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Davis, Z., et al., A Personal Handheld Multi-Modal Shopping Assistant, IEEE, 2006, 9 pages.;;El Meliani et al., “A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary”, Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Elio et al., “On Abstract Task Models and Conversation Policies” in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Kirchhoff, Katrin, “Syllable-Level Desynchronisation of Phonetic Features for Speech Recognition”, Proceedings of the Fourth International Conference on Spoken Language, 1996, ICSLP 96, vol. 4, IEEE, 1996, 3 pages.;;Kuhn, Thomas, et al., “Hybrid In-Car Speech Recognition for Mobile Multimedia Applications”, Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Lin, Bor-shen, et al., “A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History”, ASRU'99, 1999, 4 pages.;;Lind, R., et al., “The Network Vehicle—A Glimpse into the Future of Mobile Multi-Media”, IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Miao, Mark Z., “Automatic Training Set Segmentation for Multi-Pass Speech Recognition”, Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;O'SHAUGHNESSY D.: ""Interacting with computers by voice: automatic speech recognition and synthesis"", PROCEEDINGS OF THE IEEE., IEEE. NEW YORK., US, vol. 91, no. 9, 1 September 2003 (2003-09-01), US , pages 1272 - 1305, XP011100665, ISSN: 0018-9219, DOI: 10.1109/JPROC.2003.817117;;Reuters, “IBM to Enable Honda Drivers to Talk to Cars”, Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Turunen, “Adaptive Interaction Methods in Speech User Interfaces”, Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Vanhoucke, Vincent, “Confidence Scoring and Rejection Using Multi-Pass Speech Recognition”, Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., “Efficient Lattice Representation and Generation”, Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;Wu, Su-Lin, et al., “Incorporating Information from Syllable-Length Time Scales into Automatic Speech Recognition”, Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, 1998, vol. 2, IEEE, 1998, 4 pages.;;Wu, Su-Lin, et al., “Integrating Syllable Boundary Information into Speech Recognition”, IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP-97, 1997, vol. 2, IEEE, 1997, 4 pages.;;Zhao, Yilin, “Telematics: Safe and Fun Driving”, IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.;;Office Action issued in Chinese Patent Application No. 201580060519.1 dated Mar. 13, 2020, with its English translation, 40 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01346, Decision Granting Institution of Inter Partes Review of U.S. Pat. No. 9,015,049 B2, entered Feb. 4, 2021, 24 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01367, Decision Granting Institution of Inter Partes Review of U.S. Pat. No. 8,073,681 B2, entered Mar. 11, 2021, 22 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01374, Decision Denying Institution of Inter Partes Review of U.S. Pat. No. 8,886,536 B2, entered Feb. 4, 2021, 37 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01377, Decision Denying Institution of Inter Partes Review of U.S. Pat. No. 8,886,536 B2, entered Feb. 4, 2021, 29 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01380, Decision Denying Institution of Inter Partes Review of U.S. Pat. No. 9,626,703 B2, entered Feb. 4, 2021, 28 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01381, Decision Denying Institution of Inter Partes Review of U.S. Pat. No. 9,626,703 B2, entered Feb. 4, 2021, 29 pages.;;Amazon.vom, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01388, Decision Denying Institution of Inter Partes Review of U.S. Pat. No. 9,269,097 B2, entered Feb. 24, 2021, 25 pages.;;Amazon.com, Inc., Amazon.com LLC, Amazon Web Services, Inc., A2Z Development Center, Inc. d/b/a/ Lab126, Rawles LLC, Amzn Mobile LLC, Amzn Mobile 2 LLC, Amazon.com Services, Inc. f/k/a Amazon Fulfillment Services, Inc., and Amazon.com Services LLC (formerly Amazon Digital Services LLC) v. VB Assets, LLC, IPR2020-01390, Decision Denying Institution of Inter Partes Review of U.S. Pat. No. 7,818,176, entered Mar. 11, 2021, 27 pages.;;Asthana, A., et al., “A Small Domain Communications System for Personalized Shopping Assistance”, Proceedings of 1994 International Conference on Personal Wireless Communications, IEEE Press, Aug. 1994, pp. 199-203.;;Huang et al., “Spoken Language Processing: A Guide to Theory, Algorithm, and System Development”, Prentice Hall, 2001, 1010 pages.;;IEEE 100 The Authoritative Dictionary of IEEE Standards Terms, Seventh Edition, Standards Information Network, IEEE Press, Print ISBN 0-7381-2601-2, Published Dec. 2000, 3 pages.;;Lucente, Mark, “Conversational Interfaces for E-Commerce Applications”, Communications of the ACM, vol. 43, No. 9, Sep. 2000, pp. 59-61.;;Seneff, Stephanie, et al., “Hypothesis Selection and Resolution in the Mercury Flight Reservation System”, Spoken Language Systems Group, MIT, 2001, 8 pages.",ACTIVE
25,WO,A2,WO 2008/118195 A2,025-652-728-452-917,2008-10-02,2008,US 2007/0081481 W,2007-10-16,US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES INC;;BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,,https://lens.org/025-652-728-452-917,Patent Application,yes,0,27,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G06F17/28,,0,0,,,,PENDING
26,US,B2,US 9015049 B2,139-987-515-866-268,2015-04-21,2015,US 201313987645 A,2013-08-19,US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,System and method for a cooperative conversational voice user interface,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VOICEBOX TECHNOLOGIES CORP,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,NUANCE COMMUNICATIONS INC (2018-03-12);;VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/139-987-515-866-268,Granted Patent,yes,116,145,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/00;;G06F3/16;;G06F17/27;;G10L15/06;;G10L15/183;;G10L15/22;;G10L25/00,704/275;;704/9;;704/270;;704/270.1,18,5,052-977-165-653-882;;039-759-935-043-735;;021-442-002-762-19X;;160-444-942-829-234;;090-169-265-026-758,10.3115/1072133.1072149;;10.1109/5254.988442;;10.1109/ccece.1995.526599;;10.1109/icassp.2000.861804;;10.1109/jproc.2003.817117,"Reuters, ""IBM to Enable Honda Drivers to Talk to Cars"", Charles Schwab & Co., Inc., Jul. 28, 2002, 1 page.;;Lin, Bor-shen, et al., ""A Distributed Architecture for Cooperative Spoken Dialogue Agents with Coherent Dialogue State and History"", ASRU'99, 1999, 4 pages.;;Kuhn, Thomas, et al., ""Hybrid In-Car Speech Recognition for Mobile Multimedia Applications"", Vehicular Technology Conference, IEEE, Jul. 1999, pp. 2009-2013.;;Belvin, Robert, et al., ""Development of the HRL Route Navigation Dialogue System"", Proceedings of the First International Conference on Human Language Technology Research, San Diego, 2001, pp. 1-5.;;Lind, R., et al., ""The Network Vehicle-A Glimpse into the Future of Mobile Multi-Media"", IEEE Aerosp. Electron. Systems Magazine, vol. 14, No. 9, Sep. 1999, pp. 27-32.;;Zhao, Yilin, ""Telematics: Safe and Fun Driving"", IEEE Intelligent Systems, vol. 17, Issue 1, 2002, pp. 10-14.;;Chai et al., ""MIND: A Semantics-Based Multimodal Interpretation Framework for Conversational System"", Proceedings of the International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems, Jun. 2002, pp. 37-46.;;Cheyer et al., ""Multimodal Maps: An Agent-Based Approach"", International Conference on Cooperative Multimodal Communication (CMC/95), May 24-26, 1995, pp. 111-121.;;Elio et al., ""On Abstract Task Models and Conversation Policies"" in Workshop on Specifying and Implementing Conversation Policies, Autonomous Agents '99, Seattle, 1999, 10 pages.;;Turunen, ""Adaptive Interaction Methods in Speech User Interfaces"", Conference on Human Factors in Computing Systems, Seattle, Washington, 2001, pp. 91-92.;;Mao, Mark Z., ""Automatic Training Set Segmentation for Multi-Pass Speech Recognition"", Department of Electrical Engineering, Stanford University, CA, copyright 2005, IEEE, pp. I-685 to I-688.;;Vanhoucke, Vincent, ""Confidence Scoring and Rejection Using Multi-Pass Speech Recognition"", Nuance Communications, Menlo Park, CA, 2005, 4 pages.;;Weng, Fuliang, et al., ""Efficient Lattice Representation and Generation"", Speech Technology and Research Laboratory, SRI International, Menlo Park, CA, 1998, 4 pages.;;El Meliani et al., ""A Syllabic-Filler-Based Continuous Speech Recognizer for Unlimited Vocabulary"", Canadian Conference on Electrical and Computer Engineering, vol. 2, Sep. 5-8, 1995, pp. 1007-1010.;;Arrington, Michael, ""Google Redefines GPS Navigation Landscape: Google Maps Navigation for Android 2.0"", TechCrunch, printed from the Internet <http://www.techcrunch.com/2009/10/28/google-redefines-car-gps-navigation-google-maps-navigation-android/>, Oct. 28, 2009, 4 pages.;;Bazzi, Issam et al., ""Heterogeneous Lexical Units for Automatic Speech Recognition: Preliminary Investigations"", Processing of the IEEE International Conference on Acoustics, Speech, and Signal Processing, vol. 3, Jun. 5-9, 2000, XP010507574, pp. 1257-1260.;;O'Shaughnessy, Douglas, ""Interacting with Computers by Voice: Automatic Speech Recognition and Synthesis"", Proceedings of the IEEE, vol. 91, No. 9, Sep. 1, 2003, XP011100665, pp. 1272-1305.;;Statement in Accordance with the Notice from the European Patent Office dated Oct. 1, 2007 Concerning Business Methods (OJ EPO Nov. 2007, 592-593), XP002456252.",ACTIVE
27,US,A1,US 2019/0385596 A1,143-631-577-085-763,2019-12-19,2019,US 201916555125 A,2019-08-29,US 201916555125 A;;US 201916417173 A;;US 201514691445 A;;US 201313987645 A;;US 201113251712 A;;US 58092606 A,2006-10-16,SYSTEM AND METHOD FOR A COOPERATIVE CONVERSATIONAL VOICE USER INTERFACE,"A cooperative conversational voice user interface is provided. The cooperative conversational voice user interface may build upon short-term and long-term shared knowledge to generate one or more explicit and/or implicit hypotheses about an intent of a user utterance. The hypotheses may be ranked based on varying degrees of certainty, and an adaptive response may be generated for the user. Responses may be worded based on the degrees of certainty and to frame an appropriate domain for a subsequent utterance. In one implementation, misrecognitions may be tolerated, and conversational course may be corrected based on subsequent utterances and/or responses.",VB ASSETS LLC,BALDWIN LARRY;;FREEMAN TOM;;TJALVE MICHAEL;;EBERSOLD BLANE;;WEIDER CHRIS,VOICEBOX TECHNOLOGIES INC (2006-12-28);;VOICEBOX TECHNOLOGIES CORPORATION (2008-09-15);;VB ASSETS LLC (2018-03-12),https://lens.org/143-631-577-085-763,Patent Application,yes,0,0,23,23,0,G10L15/183;;G10L15/22;;G10L2015/0631;;G10L15/1815;;G10L15/1822;;G10L2015/228;;G10L2015/225;;G10L2021/02166;;G10L25/51;;G10L15/183;;G10L15/22;;G10L2015/0631;;G06F40/30;;G10L25/63;;G06F3/167;;G10L15/18;;G10L17/22,G10L15/18;;G06F3/16;;G06F17/27;;G10L15/22;;G10L17/22;;G10L25/51,,0,0,,,,ACTIVE
28,CA,A1,CA 2700131 A1,162-627-243-266-625,2009-04-02,2009,CA 2700131 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,"Ternary fungicidal compositionscomprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles; B) strobilurins; C) carboxamides; D) heterocyclic compounds; E) carbamates; F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositionsof boscalid, chlorothalonilandat least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agentsand seed comprising such compositions.",BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/162-627-243-266-625,Patent Application,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,INACTIVE
29,UA,C2,UA 103008 C2,192-735-506-445-403,2013-09-10,2013,UA A201004235 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,"Ternary fungicidal compositions comprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active fungicidal compound III, selected from groups A) to D), where: A) azoles; B) strobilurins; C) heterocyclic compounds; D) carbamates in a synergistically effective amount, also the methods for controlling phytopathogenic harmful fungi using compositions of fungicidal agent on the basis of composition, and agentsand seed comprising such compositions.",BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/192-735-506-445-403,Limited Patent,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N37/34;;A01N43/40;;A01P3/00,,0,0,,,,EXPIRED
30,MX,A,MX 2010002524 A,071-413-074-438-277,2010-03-25,2010,MX 2010002524 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL.,"Ternary fungicidal compositionscomprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles; B) strobilurins; C) carboxamides; D) heterocyclic compounds; E) carbamates; F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositionsof boscalid, chlorothalonilandat least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agentsand seed comprising such compositions.",BASF SE,VONEND MICHAEL;;BRIX HORST DIETER;;SEMAR MARTIN;;BRUNS JENS;;EBERSOLD DANIEL,,https://lens.org/071-413-074-438-277,Patent Application,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,ACTIVE
31,ZA,B,ZA 201002833 B,098-960-971-241-960,2011-07-27,2011,ZA 201002833 A,2010-04-22,EP 07117274 A;;EP 2008062851 W,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,,BASF SE,EBERSOLD DANIEL;;VONEND MICHAEL;;BRUNS JENS;;SEMAR MARTIN;;BRIX HORST DIETER,,https://lens.org/098-960-971-241-960,Granted Patent,no,0,0,21,21,0,A01N43/40;;A01N43/40,,,0,0,,,,ACTIVE
32,US,B2,US 8349877 B2,006-815-272-208-32X,2013-01-08,2013,US 67952308 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,Ternary fungicidal compositions comprising boscalid and chlorothalonil,"Ternary fungicidal compositions comprising as active components 1) boscalid,2) chlorothalonil and3) at least one active compound III, selected from groups A) to F): A) azoles;B) strobilurins;C) carboxamides;D) heterocyclic compounds;E) carbamates;F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositions of boscalid, chlorothalonil and at least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agents and seed comprising such compositions.",BASF SE;;BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,BASF SE (2008-10-14),https://lens.org/006-815-272-208-32X,Granted Patent,yes,4,25,21,21,0,A01N43/40;;A01N43/40,A01P3/00;;A01N25/26;;A01N43/40,514/355;;514/354;;514/525;;514/259.31;;514/561;;514/551;;504/100;;424/637,3,0,,,"International Search Report for International Application No. PCT/EP2008/062851.;;International Preliminary Report on Patentability for International Application No. PCT/EP2008/062851.;;Worthing et al., ""The Pesticide Manual, Tenth Edition Ed"", (1995), pp. 1335-1341, XP002031460 Search Report.",INACTIVE
33,EP,B1,EP 2205082 B1,138-559-973-290-617,2012-04-04,2012,EP 08804746 A,2008-09-25,EP 2008062851 W;;EP 07117274 A;;EP 08804746 A,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,,BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/138-559-973-290-617,Granted Patent,yes,1,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,1,0,,,"""THE PESTICIDE MANUAL, TENTH EDITION ED - WORTHING C R; HANCE R J"" 1 January 1995 (1995-01-01), PESTICIDE MANUAL. WORLD COMPENDIUM; [PESTICIDE MANUAL], FARNHAM, BCPC, GB, PAGE(S) 1335 - 1341 , XP002031460 ISBN: 978-0-948404-79-5 *the whole document*",ACTIVE
34,CA,C,CA 2700131 C,012-616-141-470-008,2016-02-23,2016,CA 2700131 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,"Ternary fungicidal compositionscomprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles; B) strobilurins; C) carboxamides; D) heterocyclic compounds; E) carbamates; F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositionsof boscalid, chlorothalonilandat least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agentsand seed comprising such compositions.",BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/012-616-141-470-008,Granted Patent,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,INACTIVE
35,PT,E,PT 2205082 E,056-206-942-341-956,2012-05-02,2012,PT 08804746 T,2008-09-25,EP 07117274 A,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,,BASF SE,VONEND MICHAEL;;BRIX HORST DIETER;;SEMAR MARTIN;;BRUNS JENS;;EBERSOLD DANIEL,,https://lens.org/056-206-942-341-956,Granted Patent,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,ACTIVE
36,WO,A1,WO 2009/040397 A1,158-816-736-751-838,2009-04-02,2009,EP 2008062851 W,2008-09-25,EP 07117274 A,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,"Ternary fungicidal compositionscomprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles; B) strobilurins; C) carboxamides; D) heterocyclic compounds; E) carbamates; F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositionsof boscalid, chlorothalonilandat least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agentsand seed comprising such compositions.",BASF SE;;BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/158-816-736-751-838,Patent Application,yes,117,57,21,21,0,A01N43/40;;A01N43/40,A01N37/34;;A01N43/40;;A01P3/00,,21,3,056-357-183-925-763;;056-357-183-925-763;;139-238-698-379-172,10.1016/s0261-2194(97)00118-x;;10.1016/s0261-2194(97)00118-x;;10.2307/4041058,"""THE PESTICIDE MANUAL, TENTH EDITION ED - WORTHING C R; HANCE R J"", 1 January 1995, PESTICIDE MANUAL. WORLD COMPENDIUM; [PESTICIDE MANUAL], FARNHAM, BCPC, GB, PAGE(S) 1335 - 1341, ISBN: 978-0-948404-79-5, XP002031460;;PLANT DIS. REP., vol. 41, 1957, pages 1029;;CONGR. PLANT PATHOL., vol. 1, 1968, pages 27;;J. AM. CHEM. SOC., vol. 69, 1947, pages 1234;;PROC. 1990 BR. CROP. PROT. CONF. - PESTS DIS., vol. 1, 1990, pages 459;;NOYAKU KAGAKU, vol. 8, 1983, pages 575;;FRUITS, vol. 28, 1973, pages 545;;PROC. 1988 BR. CROP PROT. CONF. - PESTS DIS., vol. 1, 1988, pages 33;;PROC. BR. CROP PROT. CONF.-PESTS DIS., vol. 5-3, 1992, pages 411;;BULL. SOC. CHIM. FR., vol. 15, 1897, pages 891;;PROC. INSECTIC. FUNGIC. CONF. 8., vol. 2, 1975, pages 715;;AGRIC. BIOL. CHEM., vol. 37, 1973, pages 737;;PROC. BR. INSECTIC. FUNGIC. CONF. 7., vol. 2, 1973, pages 673;;PROC. 1988 BR. CROP PROT. CONF. - PESTS DIS., vol. 1, 1988, pages 65;;""The Pesticide Manual"", 1995, THE BRITISH CROP PROTECTION COUNCIL, pages: 482;;PROC. BR. CROP PROT. CONF. - PESTS DIS., vol. 2, 1998, pages 327;;""The Pesticide Manual"", 1995, THE BRITISH CROP PROTECTION COUNCIL, pages: 474;;C. R. SEANCES ACAD. AGRIC. FR., vol. 31, 1945, pages 24;;PHYTOPATHOLOGY, vol. 52, 1962, pages 754;;AGROW, 1995, pages 22;;COLBY, S.R.: ""Calculating synergistic and antagonistic responses of herbicide combinations"", WEEDS, vol. 15, 1967, pages 20 - 22",PENDING
37,ES,T3,ES 2381320 T3,188-426-037-034-033,2012-05-25,2012,ES 08804746 T,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,Composiciones fungicidas ternarias que comprenden boscalida y clorotalonil,"Una composición fungicida para controlar hongos dañinos fitopatógenos, que comprende 1) boscalida, 2) clorotalonil y 3) al menos un compuesto III fungicidamente activo seleccionado de los grupos A) a D): A) azoles seleccionados del grupo que consiste en bitertanol, bromuconazol, ciproconazol, difenoconazol, diniconazol, enilconazol, epoxiconazol, fluquinconazol, fenbuconazol, flusilazol, flutriafol, hexaconazol, imibenconazol, ipconazol, metconazol, miclobutanil, penconazol, propiconazol, protioconazol, simeconazol, triadimefona, triadimenol, tebuconazol, tetraconazol, triticonazol, procloraz, pefurazoato, imazalil, triflumizol, ciazofamid, benomil, carbendazim, tiabendazol, fuberidazol, etaboxam, etridiazol e himexazol, azaconazol, diniconazol-M, oxpoconazol, paclobutrazol, uniconazol, 1- (4-cloro-fenil) -2- ([1, 2, 4]triazol-1-il) -cicloheptanol y sulfato de imazalil; B) estrobilurinas seleccionadas del grupo que consiste en azoxiestrobina, dimoxiestrobina, enestroburina, fluoxastrobina, kresoxim-metilo, metominoestrobina, orisaestrobina, picoxiestrobina, piracloestrobina, trifloxiestrobina, enestroburina, (2-cloro-5-[1- (3-metilbenciloxiimino) etil]bencil) carbamato de metilo, (2-cloro-5-[1- (6metilpiridin-2-ilmetoxiimino) etil]bencil) -carbamato de metilo y 2- (orto- (2, 5-dimetilfeniloximetilen) -fenil) -3-metoxiacrilato de metilo, 2- (2- (6- (3-cloro-2-metil-fenoxi) -5-fluoro-pirimidin-4-iloxi) -fenil) -2-metoxiimino-N-metil-acetamida y éster metílico de ácido 3-metoxi-2- (2- (N- (4-metoxi-fenil) -ciclopropanocarboximidoil-sulfanilmetil) -fenil) -acrílico; C) compuestos heterocíclicos seleccionados del grupo que consiste en ciprodinil, mepanipirim, pirimetanil, iprodiona, procimidona, vinclozolina, captafol, captán y folpet; D) carbamatos seleccionados del grupo que consiste en iprovalicarb y bentiavalicarb; en una cantidad sinérgicamente eficaz.",BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/188-426-037-034-033,Granted Patent,no,0,2,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,ACTIVE
38,US,A1,US 2010/0197741 A1,022-014-819-949-974,2010-08-05,2010,US 67952308 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,Ternary Fungicidal Compositions Comprising Boscalid and Chlorothalonil,"Ternary fungicidal compositions comprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles;B) strobilurins;C) carboxamides;D) heterocyclic compounds;E) carbamates;F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositions of boscalid, chlorothalonil and at least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agents and seed comprising such compositions.",BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,BASF SE (2008-10-14),https://lens.org/022-014-819-949-974,Patent Application,yes,3,13,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01P3/00,514/355,0,0,,,,INACTIVE
39,PL,T3,PL 2205082 T3,107-083-935-978-044,2012-08-31,2012,PL 08804746 T,2008-09-25,EP 07117274 A;;EP 08804746 A;;EP 2008062851 W,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,,BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/107-083-935-978-044,Patent Application,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,PENDING
40,AU,B2,AU 2008/303528 B2,130-694-019-095-138,2013-05-23,2013,AU 2008/303528 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,Ternary fungicidal compositions comprising boscalid and chlorothalonil,"Ternary fungicidal compositionscomprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles; B) strobilurins; C) carboxamides; D) heterocyclic compounds; E) carbamates; F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositionsof boscalid, chlorothalonilandat least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agentsand seed comprising such compositions.",BASF SE,VONEND MICHAEL;;SEMAR MARTIN;;BRUNS JENS;;EBERSOLD DANIEL;;BRIX HORST DIETER,,https://lens.org/130-694-019-095-138,Granted Patent,no,1,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,1,0,,,"D2 : THE PESTICIDE MANUAL, TENTH EDITION ED - WORTHING C. R; HANCE R. J, 1 January 1995, FARNHAM, BCPC, GB, Pages 1335 - 1341, XP002031460 ISBN: 978-0-948404-79-5",INACTIVE
41,CN,A,CN 101808521 A,160-194-715-477-591,2010-08-18,2010,CN 200880108688 A,2008-09-25,EP 2008062851 W;;EP 07117274 A,2007-09-26,Ternary fungicidal compositions comprising boscalid and chlorothalonil,"Ternary fungicidal compositionscomprising as active components 1) boscalid, 2) chlorothalonil and 3) at least one active compound III, selected from groups A) to F): A) azoles; B) strobilurins; C) carboxamides; D) heterocyclic compounds; E) carbamates; F) other fungicides; in a synergistically effective amount, methods for controlling phytopathogenic harmful fungi using compositionsof boscalid, chlorothalonilandat least one active compound III, the use of boscalid and chlorothalonil with at least one active compound III for preparing such compositions, and also agentsand seed comprising such compositions.",BASF SE,DIETER BRIX HORST;;DANIEL EBERSOLD;;MARTIN SEMAR;;JENS BRUNS;;MICHAEL VONEND,,https://lens.org/160-194-715-477-591,Patent Application,no,2,37,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,DISCONTINUED
42,BR,A2,BR PI0817285 A2,050-645-246-749-786,2014-10-07,2014,BR PI0817285 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,"COMPOSIÇÃO FUNGICIDA, AGENTE FUNGICIDA, MÉTODO PARA O CONTROLE DE FUNDOS NOCIVOS FITOPATOGÊNICOS, SEMEMTE, E, USO DE BOSCALIDA, CLOROTALONILA E UM COMPOSTO",,BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/050-645-246-749-786,Patent Application,no,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,DISCONTINUED
43,AT,T1,AT E551901 T1,186-270-770-396-263,2012-04-15,2012,AT 08804746 T,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,TERNÄRE FUNGIZIDZUSAMMENSETZUNGEN MIT BOSCALID UND CHLORTHALONIL,,BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/186-270-770-396-263,Granted Patent,no,0,0,21,21,0,A01N43/40;;A01N43/40,,,0,0,,,,ACTIVE
44,AU,A1,AU 2008/303528 A1,126-237-981-168-091,2009-04-02,2009,AU 2008/303528 A,2008-09-25,EP 07117274 A;;EP 2008062851 W,2007-09-26,Ternary fungicidal compositions comprising boscalid and chlorothalonil,,BASF SE,SEMAR MARTIN;;BRIX HORST DIETER;;VONEND MICHAEL;;BRUNS JENS;;EBERSOLD DANIEL,,https://lens.org/126-237-981-168-091,Patent Application,no,0,1,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,INACTIVE
45,EP,A1,EP 2205082 A1,184-028-398-208-167,2010-07-14,2010,EP 08804746 A,2008-09-25,EP 2008062851 W;;EP 07117274 A;;EP 08804746 A,2007-09-26,TERNARY FUNGICIDAL COMPOSITIONS COMPRISING BOSCALID AND CHLOROTHALONIL,,BASF SE,BRIX HORST DIETER;;EBERSOLD DANIEL;;SEMAR MARTIN;;BRUNS JENS;;VONEND MICHAEL,,https://lens.org/184-028-398-208-167,Patent Application,yes,0,0,21,21,0,A01N43/40;;A01N43/40,A01N43/40;;A01N37/34;;A01P3/00,,0,0,,,,ACTIVE
