"#",Jurisdiction,Kind,Display Key,Lens ID,Publication Date,Publication Year,Application Number,Application Date,Priority Numbers,Earliest Priority Date,Title,Abstract,Applicants,Inventors,Owners,URL,Document Type,Has Full Text,Cites Patent Count,Cited by Patent Count,Simple Family Size,Extended Family Size,Sequence Count,CPC Classifications,IPCR Classifications,US Classifications,NPL Citation Count,NPL Resolved Citation Count,NPL Resolved Lens ID(s),NPL Resolved External ID(s),NPL Citations,Legal Status
1,ZA,B,ZA 887970 B,136-970-924-394-054,1989-12-27,1989,ZA 887970 A,1988-10-25,ZA 887970 A;;ZA 881634 A,1988-03-08,CABLE DRUM FLANGES AND CABLE DRUMS EMBODYING SAME,,DERGLEN CC,COHEN RONALD;;RONALD COHEN,,https://lens.org/136-970-924-394-054,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
2,ZA,B,ZA 881099 B,198-075-955-649-02X,1988-10-26,1988,ZA 881099 A,1988-02-17,ZA 881099 A;;ZA 871058 A,1987-02-13,MOTOR VEHICLE SECURITY DEVICE,,RONALD COHEN,COHEN RONALD;;RONALD COHEN,,https://lens.org/198-075-955-649-02X,Granted Patent,no,0,0,1,1,0,,B60R/,,0,0,,,,EXPIRED
3,ZA,B,ZA 891764 B,043-450-583-139-352,1989-11-29,1989,ZA 891764 A,1989-03-08,ZA 891764 A;;ZA 881633 A,1988-03-08,CABLE DRUM COVER ARRANGEMENT,,DERGLEN CC,COHEN RONALD;;RONALD COHEN,,https://lens.org/043-450-583-139-352,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
4,ZA,B,ZA 898173 B,040-033-805-310-957,1991-02-27,1991,ZA 898173 A,1989-10-27,ZA 898173 A;;ZA 888759 A,1988-11-23,MINE PROP OR LIKE SUPPORT,,DERGLEN CC,COHEN RONALD;;RONALD COHEN,,https://lens.org/040-033-805-310-957,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
5,ZA,B,ZA 888883 B,186-720-500-719-515,1989-08-30,1989,ZA 888883 A,1988-11-28,ZA 888883 A;;ZA 878075 A,1987-10-28,YIELDABLE MINE SUPPORT OR THE LIKE,,DERGLEN CC,COHEN RONALD RAYMOND;;RONALD RAYMOND COHEN,,https://lens.org/186-720-500-719-515,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
6,ZA,B,ZA 94637 B,125-829-009-309-491,1994-09-15,1994,ZA 94637 A,1994-01-31,ZA 931281 A,1993-02-24,Cable drum flanges and cable drums embodying same,,DERGLEN CC CK85 15474 23,COHEN RONALD,,https://lens.org/125-829-009-309-491,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
7,US,A1,US 2018/0010494 A1,071-279-218-360-196,2018-01-11,2018,US 201715444197 A,2017-02-27,US 201715444197 A;;US 201662360199 P,2016-07-08,MAGNETIC DRAIN PLUG,A magnetic drain plug includes a plug body that has a head section and a screw section protruding from the head section. The screw section is includes external threads for threading into a drain hole of a device containing lubricating fluid. The plug body has an axial bore for receiving a removable magnet through the head section. The axial bore has an axial depth such that a bottom of the axial bore extends into the screw section.,COHEN RONALD,COHEN RONALD,,https://lens.org/071-279-218-360-196,Patent Application,yes,3,7,2,2,0,B65D2313/04;;F01M11/0408;;F01M11/0408;;F01M11/0004;;F01M2011/0416;;F01M2011/0416;;F16N2031/008;;F16N2031/008,F01M11/04;;F01M11/00,,0,0,,,,ACTIVE
8,US,B2,US 8633946 B2,154-160-914-833-023,2014-01-21,2014,US 50572609 A,2009-07-20,US 50572609 A;;US 97206208 A;;US 71259005 P,2005-08-29,Interactivity with a mixed reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",COHEN RONALD;;NANT HOLDINGS IP LLC,COHEN RONALD,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/154-160-914-833-023,Granted Patent,yes,31,31,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G09G5/00;;G06T13/00;;G06T13/80;;G06T19/00;;H04M1/72427,345/632;;345/630;;345/631;;345/633;;463/37;;463/38;;463/39;;463/40;;463/41;;463/42;;715/863,0,0,,,,ACTIVE
9,ZA,B,ZA 981320 B,194-537-985-800-542,1998-08-27,1998,ZA 981320 A,1998-02-18,ZA 971505 A,1997-02-21,Bed base,,COHEN RONALD,COHEN RONALD,,https://lens.org/194-537-985-800-542,Granted Patent,no,0,0,1,1,0,,A47C/,,0,0,,,,EXPIRED
10,ZA,B,ZA 952270 B,116-565-472-137-000,1995-12-12,1995,ZA 952270 A,1995-03-20,ZA 947780 A,1994-10-05,Cable drum flanges and cable drums embodying same,,COHEN RONALD,COHEN RONALD,,https://lens.org/116-565-472-137-000,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
11,AT,T1,AT E423462 T1,197-029-979-200-127,2009-03-15,2009,AT 99944166 T,1999-08-30,AU PP554998 A;;AU PP078499 A,1998-08-28,VERFAHREN ZUR DIAGNOSE VON PROSTATAKREBS,,UROPATH PTY LTD,COHEN RONALD,,https://lens.org/197-029-979-200-127,Granted Patent,no,0,0,5,12,0,,A01N1/00;;C12N5/08;;G01N1/30,,0,0,,,,EXPIRED
12,ZA,B,ZA 914748 B,129-231-968-026-621,1993-03-22,1993,ZA 914748 A,1991-06-20,ZA 905301 A,1990-06-06,Reconstituted timber.,,DERGLEN C C,COHEN RONALD,,https://lens.org/129-231-968-026-621,Granted Patent,no,0,0,1,1,0,,B27N/;;D21J/,,0,0,,,,EXPIRED
13,US,A1,US 2008/0094417 A1,031-081-740-454-166,2008-04-24,2008,US 97206208 A,2008-01-10,US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity with a Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",EVRYX TECHNOLOGIES INC,COHEN RONALD,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/031-081-740-454-166,Patent Application,yes,17,140,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G09G5/00;;G06T13/00;;G06T13/80;;H04M1/72427,345/632,0,0,,,,ACTIVE
14,ZA,B,ZA 200108981 B,118-682-048-745-627,2002-09-06,2002,ZA 200108981 A,2001-10-31,ZA 200108981 A;;ZA 200003910 A,2000-08-02,Cable drum for storing and transporting lengths of prefabricated cable.,,DERGLEN CC,COHEN RONALD,,https://lens.org/118-682-048-745-627,Granted Patent,no,0,0,1,1,0,,B65D/;;B65G/;;B65H/,,0,0,,,,EXPIRED
15,ZA,B,ZA 962921 B,020-080-866-791-340,1996-11-27,1996,ZA 962921 A,1996-04-12,ZA 953058 A,1995-04-13,Cable drum flanges and cable drums embodying same,,DERGLEN CC,COHEN RONALD,,https://lens.org/020-080-866-791-340,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
16,US,B2,US 9957859 B2,144-235-027-922-688,2018-05-01,2018,US 201715444197 A,2017-02-27,US 201715444197 A;;US 201662360199 P,2016-07-08,Magnetic drain plug,A magnetic drain plug includes a plug body that has a head section and a screw section protruding from the head section. The screw section is includes external threads for threading into a drain hole of a device containing lubricating fluid. The plug body has an axial bore for receiving a removable magnet through the head section. The axial bore has an axial depth such that a bottom of the axial bore extends into the screw section.,COHEN RONALD,COHEN RONALD,,https://lens.org/144-235-027-922-688,Granted Patent,yes,23,4,2,2,0,B65D2313/04;;F01M11/0408;;F01M11/0408;;F01M11/0004;;F01M2011/0416;;F01M2011/0416;;F16N2031/008;;F16N2031/008,F01M11/04;;F01M11/00;;F16N31/00,,0,0,,,,ACTIVE
17,ZA,B,ZA 9624 B,165-787-446-431-75X,1996-07-10,1996,ZA 9624 A,1996-01-03,ZA 947779 A,1994-10-05,Method of storing and transporting lengths of prefabricated cable,,COHEN RONALD,COHEN RONALD,,https://lens.org/165-787-446-431-75X,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
18,US,A,US 4994331 A,001-819-070-561-551,1991-02-19,1991,US 39968089 A,1989-08-28,US 39968089 A,1989-08-28,Fuel cell evaporative cooling using fuel as a carrier gas,"Removal of waste heat from a fuel cell is necessary for continuous operation. Evaporation, can be used to remove the heat produced by the exothermic reaction within the fuel cell. Water sprayed into a gaseous fuel stream is evaporated in an evaporative cooler adjacent to the fuel cell. The fuel/steam stream can then be utilized in the various other fuel cell system operations.",INT FUEL CELLS CORP,COHEN RONALD,INTERNATIONAL FUEL CELLS CORPORATION (1989-08-22),https://lens.org/001-819-070-561-551,Granted Patent,yes,5,160,5,5,0,H01M8/0612;;H01M8/0612;;H01M8/04119;;H01M8/04119;;Y02E60/50,H01M8/04;;H01M8/06,429/17;;429/20;;429/26;;423/652,0,0,,,,EXPIRED
19,CA,A1,CA 2024066 A1,011-446-204-720-559,1991-03-01,1991,CA 2024066 A,1990-08-27,US 39968089 A,1989-08-28,FUEL CELL EVAPORATION COOLING USING FUEL AS A CARRIER GAS,"Fuel Cell Evaporative Cooling Using Fuel As A Carrier Gas Removal of waste heat from a fuel cell is necessary for continuous operation. Evaporation, can be used to remove the heat produced by the exothermic reaction within the fuel cell. Water sprayed into a gaseous fuel stream is evaporated in an evaporative cooler adjacent to the fuel cell. The fuel/steam stream can then be utilized in the various other fuel cell system operations.",INT FUEL CELLS CORP,COHEN RONALD,,https://lens.org/011-446-204-720-559,Patent Application,no,0,0,5,5,0,H01M8/0612;;H01M8/0612;;H01M8/04119;;H01M8/04119;;Y02E60/50,H01M8/04;;H01M8/06,D33190003    M,0,0,,,,DISCONTINUED
20,EP,A3,EP 0415330 A3,001-772-178-678-385,1991-07-31,1991,EP 90116403 A,1990-08-27,US 39968089 A,1989-08-28,FUEL CELL EVAPORATIVE COOLING USING FUEL AS A CARRIER GAS,"Removal of waste heat from a fuel cell [9] is necessary for continuous operation. Evaporation, can be used to remove the heat produced by the exothermic reaction within the fuel cell. Water sprayed into a gaseous fuel stream [4] is evaporated in an evaporative cooler [5] adjacent to the fuel cell. The fuel/steam stream can then be utilized in the various other fuel cell system operations [7].  ",INTERNATIONAL FUEL CELLS CORPORATION,"COHEN, RONALD",,https://lens.org/001-772-178-678-385,Search Report,yes,7,0,5,5,0,H01M8/0612;;H01M8/0612;;H01M8/04119;;H01M8/04119;;Y02E60/50,H01M8/04;;H01M8/06,,1,0,,,"PATENT ABSTRACTS OF JAPAN, vol. 13, no. 31 (E-707)[3379], 24th January 1989; & JP-A-63 232 273 (HITACHI LTD) 28-09-1988",DISCONTINUED
21,US,A1,US 2010/0017722 A1,076-763-093-308-656,2010-01-21,2010,US 50572609 A,2009-07-20,US 50572609 A;;US 97206208 A;;US 71259005 P,2005-08-29,Interactivity with a Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",COHEN RONALD,COHEN RONALD,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/076-763-093-308-656,Patent Application,yes,29,63,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F3/048;;A63F9/24;;G06F15/16;;G06F17/00;;G06T13/00;;G06T13/80;;G09G5/00;;H04M1/72427,715/740;;345/632;;463/1;;709/203;;700/94,0,0,,,,ACTIVE
22,ZA,B,ZA 964124 B,104-101-670-808-150,1996-12-03,1996,ZA 964124 A,1996-05-23,ZA 952776 A,1995-04-05,Cable drum for storing and transporting lengths of prefabricated cable,,COHEN RONALD,COHEN RONALD,,https://lens.org/104-101-670-808-150,Granted Patent,no,0,0,1,1,0,,B65H/,,0,0,,,,EXPIRED
23,US,B2,US 7564469 B2,166-301-008-272-043,2009-07-21,2009,US 97206208 A,2008-01-10,US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity with a mixed reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",EVRYX TECHNOLOGIES INC,COHEN RONALD,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/166-301-008-272-043,Granted Patent,yes,17,253,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G09G5/00;;A63F9/24;;G06F3/02;;G06F3/033;;G06F13/00;;G06F17/00;;G06F19/00;;G06T13/00;;G06T13/80;;H04M1/72427,345/632;;345/158;;345/169;;463/37;;463/38;;715/863,0,0,,,,ACTIVE
24,WO,A1,WO 2015/191766 A1,006-931-375-178-280,2015-12-17,2015,US 2015/0035182 W,2015-06-10,US 201462010108 P,2014-06-10,DEEP WATER WIND ENERGY CAPTURE SYSTEM,The Inventive Subject Matter is a System for harvesting wind energy and natural wave energy. The harvesting can be performed on a body of water. The body of water can be an ocean or lake. The harvesting can be performed autonomously and create portable energy for ships or other purposes.,COHEN RONALD,COHEN RONALD,,https://lens.org/006-931-375-178-280,Patent Application,yes,8,0,2,2,0,F03D1/0625;;F05B2240/93;;Y02E10/727;;F03D9/25;;F03D13/25;;F03D80/70;;F03D9/11;;Y02E10/74;;Y02E10/72;;Y02E70/30;;F03D1/0625;;F03D9/25;;F03D13/25;;F03D80/70;;F05B2240/93;;Y02E10/727;;Y02E10/72;;F03D1/0658;;F03D9/11;;B63B35/44;;B63B2035/446;;B63B2035/4466;;B63B2209/14;;B63B2209/20;;F03D3/005,F03D1/00;;F03D3/00,,0,0,,,,PENDING
25,EP,A2,EP 0415330 A2,185-934-379-809-54X,1991-03-06,1991,EP 90116403 A,1990-08-27,US 39968089 A,1989-08-28,Fuel cell evaporative cooling using fuel as a carrier gas.,"Removal of waste heat from a fuel cell [9] is necessary for continuous operation. Evaporation, can be used to remove the heat produced by the exothermic reaction within the fuel cell. Water sprayed into a gaseous fuel stream [4] is evaporated in an evaporative cooler [5] adjacent to the fuel cell. The fuel/steam stream can then be utilized in the various other fuel cell system operations [7].  ",INT FUEL CELLS CORP,COHEN RONALD,,https://lens.org/185-934-379-809-54X,Patent Application,yes,0,9,5,5,0,H01M8/0612;;H01M8/0612;;H01M8/04119;;H01M8/04119;;Y02E60/50,H01M8/04;;H01M8/06,,0,0,,,,DISCONTINUED
26,ZA,B,ZA 934315 B,111-082-364-819-225,1994-01-05,1994,ZA 934315 A,1993-06-17,ZA 921870 A,1992-03-20,Reconstituted timber laminates,,DERGLEN CC CK85 15474 23,COHEN RONALD,,https://lens.org/111-082-364-819-225,Granted Patent,no,0,0,1,1,0,,B27N/;;D21J/,,0,0,,,,EXPIRED
27,ZA,B,ZA 873081 B,117-246-173-331-987,1988-04-27,1988,ZA 873081 A,1987-04-29,ZA 873081 A,1987-04-29,MINE PROP OR LIKE SUPPORT,,DERGLEN CC,COHEN LANCE FARREL;;LANCE FARREL COHEN;;COHEN RONALD;;RONALD COHEN,,https://lens.org/117-246-173-331-987,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
28,ZA,B,ZA 947601 B,163-538-384-413-934,1997-01-23,1997,ZA 947601 A,1994-09-29,ZA 947601 A;;ZA 937219 A,1993-09-29,Process for reconstituting articles from polymers,,COHEN RONALD,COHEN RONALD;;COHEN LIOYD,,https://lens.org/163-538-384-413-934,Granted Patent,no,0,0,1,1,0,,B29B/,,0,0,,,,EXPIRED
29,US,A,US 4106591 A,120-360-551-172-598,1978-08-15,1978,US 78708977 A,1977-04-13,US 78708977 A,1977-04-13,Knock-down open riser stairway,"A stairway capable of being shipped in a knock-down condition and erected with a minimum of labor and without special tools is disclosed. The stairway comprises a square tubular elongated support member having mounting brackets at each end enabling it to be mounted in inclined relation between different levels of a structure. A plurality of step assemblies are clamped in spaced relation onto the support member. Each step assembly includes a tread support having a horizontal load bearing portion and an angulated integral strut portion both fastened to a mounting flange which engages the topside of the support member. A locking sleeve surrounds the bottom and side walls of the support member and has outturned flanges which are fastened to the mounting plate by bolts. In one embodiment, the bottom of the locking sleeve has a slight upward convexity which flexes elastically when the bolts are tightened to maintain clamping pressure against the support member. In another embodiment the bottom of the locking sleeve engages flush against the bottom of the support member and the locking sleeve flanges are spaced from the mounting flange and flexed to provide the clamping action.",COHEN & SONS INC M,COHEN ALLEN;;COHEN HOWARD;;COHEN RONALD,,https://lens.org/120-360-551-172-598,Granted Patent,yes,7,21,1,1,0,E04F11/028;;E04F11/028,E04F11/028,182/93,0,0,,,,EXPIRED
30,ZA,B,ZA 200101211 B,126-537-981-622-287,2001-06-21,2001,ZA 200101211 A,2001-02-13,ZA 200101211 A;;ZA 997369 A,1999-11-29,Mine prop headboard. Mine prop headboard.,,DERGLEN CC DERGLEN CC,COHEN RONALD RAYMOND COHEN RON,,https://lens.org/126-537-981-622-287,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
31,US,A1,US 2015/0119076 A1,058-173-631-775-225,2015-04-30,2015,US 201414530247 A,2014-10-31,US 201414530247 A;;US 201361898185 P,2013-10-31,"SELF-CALIBRATING MOBILE INDOOR LOCATION ESTIMATIONS, SYSTEMS AND METHODS","A system for estimating a device's location is presented. Disclosed systems utilize a known digital map of an area to determine when a device's location violates one or more forbidden zones. When such an intrusion is detected, the system updates tunable parameters of a corresponding location estimation algorithm to minimize estimated intrusions. Thus, the location estimation algorithm can be self-calibrated based on real-time, in-the-field data.",COHEN RONALD H;;NANT HOLDINGS IP LLC,COHEN RONALD H,NANT HOLDINGS IP LLC (2014-01-20),https://lens.org/058-173-631-775-225,Patent Application,yes,2,21,1,1,0,G01S5/0236;;H04W4/021;;G07C9/00;;G07C9/28;;G01S5/02521;;G01S5/0236;;H04W4/021;;G07C9/00;;G07C9/28;;G01S5/02521,G01S5/02,455/456.1,0,0,,,,DISCONTINUED
32,CA,A1,CA 2341897 A1,070-106-707-444-073,2000-03-09,2000,CA 2341897 A,1999-08-30,AU PP554998 A;;AU PQ078499 A;;AU 1998/099006 W,1998-08-28,METHOD OF DIAGNOSIS OF PROSTATE CANCER,"The present invention relates to structures involved in the secretory processes of reproductive tissues, including the prostatic secretory processes, and their protein products which may be used as tools for diagnosing reproductive pathology including prostate disease. The present invention also relates to reagents, such as antibodies, other ligands and oligonucleotides, for detecting these structures or their contents and to methods of diagnosing prostate pathology, including prostate cancer and prostatitis. The invention further relates to an improved tissue and cell fixation process for the detection of secretory structures in reproductive tissue. The fixation process is useful for the diagnosis of prostate, testes and renal cancer.",UROPATH PTY LTD,COHEN RONALD JOSEPH,,https://lens.org/070-106-707-444-073,Patent Application,no,0,0,5,12,0,G01N1/30;;G01N1/30;;G01N33/57434;;G01N33/57434,A01N1/00;;C12N5/08;;G01N1/30;;G01N33/574,,0,0,,,,DISCONTINUED
33,US,A1,US 2017/0144068 A1,076-835-849-102-376,2017-05-25,2017,US 201715425984 A,2017-02-06,US 201715425984 A;;US 201414184510 A;;US 201414159318 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/076-835-849-102-376,Patent Application,yes,2,5,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,A63F13/52;;A63F13/213;;A63F13/25;;A63F13/65;;G06T13/00;;G06T13/80;;G06T19/00;;H04M1/72427,,0,0,,,,ACTIVE
34,CA,A,CA 850404 A,159-175-573-152-863,1970-09-01,1970,CA 850404D A,,CA 850404T A,,AUTOMATIC ANIMAL SELECTIVE FEEDER,,BEHAVIORAL CONTROLS,COHEN RONALD S,,https://lens.org/159-175-573-152-863,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
35,CA,A,CA 831297 A,197-421-178-569-879,1970-01-06,1970,CA 831297D A,,CA 831297T A,,AUTOMATIC ANIMAL SELECTIVE FEEDER,,BEHAVIORAL CONTROLS,COHEN RONALD S,,https://lens.org/197-421-178-569-879,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
36,CA,A,CA 814192 A,023-606-192-330-726,1969-06-03,1969,CA 814192D A,,CA 814192T A,,WEIGHT CONTROL APPARATUS FOR ANIMALS,,MODERN TEACHING ASSOCIATES,COHEN RONALD S,,https://lens.org/023-606-192-330-726,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
37,US,B2,US 7775437 B2,035-779-783-670-838,2010-08-17,2010,US 44578406 A,2006-06-01,US 44578406 A,2006-06-01,Methods and devices for detecting linkable objects,"A camera portion of a portable consumer device obtains data from a field of view, and at least a portion of the data is used to determine existence of an object in the field of view for which the information is available from a reference source. An indication is then provided to the user that the object is in the field of view. This can all be accomplished by a functionality, such as computer software, that executes on one or both of the device and a distal server. Objects within the field that the system can identify and provide information are deemed “linkable.” Once a user is presented with an indication of which objects around him are linkable, he can then directly point and click on the linkable objects without the “trial-and-error” process of pointing and clicking on non-linkable objects.",EVRYX TECHNOLOGIES INC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2006-06-01);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/035-779-783-670-838,Granted Patent,yes,11,142,5,5,0,H04M2250/52;;H04N1/00307;;H04N1/00326;;H04N7/17318;;H04N21/23418;;H04N21/44008;;H04N21/4725;;H04N21/6581;;H04N21/6582;;H04M1/72445;;G06V20/10;;H04N21/6582;;H04N21/6581;;H04N1/00326;;H04M2250/52;;H04N21/23418;;H04N1/00307;;H04N21/4725;;H04N7/17318;;H04N21/44008;;H04M1/72445;;G06V20/10,G06K7/10,235/462.45;;235/462.3;;235/462.1;;235/462.07;;235/462.11;;235/462.21;;235/472.02;;235/375,0,0,,,,ACTIVE
38,ZA,B,ZA 200000963 B,092-271-342-803-201,2000-10-16,2000,ZA 200000963 A,2000-05-17,ZA 200000963 A;;ZA 9810819 A,1998-11-26,Mine prop prestressing means.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/092-271-342-803-201,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
39,AU,B2,AU 770643 B2,155-919-953-076-667,2004-02-26,2004,AU 1999/057210 A,1999-08-30,AU 1999/057210 A;;AU PP554998 A;;AU PQ078499 A;;AU 1998/099006 W,1998-08-28,Method of diagnosis of prostate cancer,,UROPATH PTY LTD,COHEN RONALD JOSEPH,,https://lens.org/155-919-953-076-667,Granted Patent,no,1,0,5,12,0,G01N1/30;;G01N1/30;;G01N33/57434;;G01N33/57434,A01N1/00;;C12N5/08;;G01N1/30;;G01N33/574,,1,1,049-834-198-437-805,6649193;;10.3109/03009738309178440,"BRODY ET AL.,(1983) UPSALA J. MED. SCI VOL.88 P 63-80",EXPIRED
40,US,A1,US 2014/0055493 A1,180-017-963-766-569,2014-02-27,2014,US 201314070591 A,2013-11-04,US 201314070591 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/180-017-963-766-569,Patent Application,yes,9,3,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06T19/00;;G06T13/00;;G06T13/80;;H04M1/72427,345/633,0,0,,,,DISCONTINUED
41,BR,A2,BR PI0615283 A2,196-901-215-452-407,2011-05-17,2011,BR PI0615283 A,2006-08-29,US 71259005 P;;US 2006/0033811 W,2005-08-29,interatividade por meio de reconhecimento de imagem móvel,"INTERATIVIDADE POR MEIO DE RECONHECIMENTO DE IMAGEM MóVEL. A presente invenção refere-se a sistemas e métodos de interação com um espaço virtual, no qual um dispositivo móvel é usado para capturar eletronicamente dados de imagem de um objeto do mundo real, os ddos de imagem são usados para identificar informação relacionada ao objeto do mundo real, e a informação é usada para interagir com software para controlar pelo menos um de: (a) um aspecto de um jogo eletrónico; e (b) um segundo local de dispositivo para o dispositivo móvel, Os métodos e siste- mas considerados podem ser usados para jogo, no qual os dados de ima- gem podem ser usados para identificar um nome do objeto do mundo real, para classificar o objeto do mundo real, identificar o objeto do mundo real como um jogador no jogo, para identificar o objeto do mundo real como um objeto alvo ou como sendo dotado de algum valor no jogo, usar os dados de imagem para identificar o objeto do mundo real como um objeto alvo no jogo.",EVRYX TECHNOLOGIES INC,COHEN RONALD H,,https://lens.org/196-901-215-452-407,Patent Application,no,0,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,DISCONTINUED
42,WO,B1,WO 2007/143148 B1,110-025-882-204-338,2008-12-11,2008,US 2007/0013037 W,2007-05-31,US 44578406 A,2006-06-01,METHODS AND DEVICES FOR DETECTING LINKABLE OBJECTS,"A camera portion of a portable consumer device obtains data from a field of view, and at least a portion of the data is used to determine existence of an object in the field of view for which the information is available from a reference source. An indication is then provided to the user that the object is in the field of view. This can all be accomplished by a functionality, such as computer software, that executes on one or both of the device and a distal server. Objects within the field that the system can identify and provide information are deemed ""linkable"". Once a user is presented with an indication of which objects around him are linkable, he can then directly point and click on the linkable objects without the ""trial-and-error"" process of pointing and clicking on non-linkable objects.",EVYRX TECHNOLOGIES INC;;COHEN RONALD H,COHEN RONALD H,,https://lens.org/110-025-882-204-338,Patent Application,no,0,0,5,5,0,H04M2250/52;;H04N1/00307;;H04N1/00326;;H04N7/17318;;H04N21/23418;;H04N21/44008;;H04N21/4725;;H04N21/6581;;H04N21/6582;;H04M1/72445;;G06V20/10;;H04N21/6582;;H04N21/6581;;H04N1/00326;;H04M2250/52;;H04N21/23418;;H04N1/00307;;H04N21/4725;;H04N7/17318;;H04N21/44008;;H04M1/72445;;G06V20/10,G06K7/10;;G06F17/00,,0,0,,,,PENDING
43,EP,A4,EP 1107665 A4,123-956-343-168-312,2003-04-02,2003,EP 99944166 A,1999-08-30,AU 1998/099006 W;;AU PP554998 A;;AU PP078499 A,1998-08-28,METHOD OF DIAGNOSIS OF PROSTATE CANCER,,UROPATH PTY LTD,COHEN RONALD JOSEPH,UROPATH PTY. LTD. (2008-12-31),https://lens.org/123-956-343-168-312,Search Report,no,2,0,5,12,0,,A01N1/00;;C12N5/08;;G01N1/30,,2,0,,,"DATABASE WPI Section Ch Week 199829, Derwent World Patents Index; Class D22, AN 1998-325447, XP002212191;;See also references of WO 0011947A1",EXPIRED
44,WO,A2,WO 2007/143148 A2,139-880-822-499-680,2007-12-13,2007,US 2007/0013037 W,2007-05-31,US 44578406 A,2006-06-01,METHODS AND DEVICES FOR DETECTING LINKABLE OBJECTS,"A camera portion of a portable consumer device obtains data from a field of view, and at least a portion of the data is used to determine existence of an object in the field of view for which the information is available from a reference source. An indication is then provided to the user that the object is in the field of view. This can all be accomplished by a functionality, such as computer software, that executes on one or both of the device and a distal server. Objects within the field that the system can identify and provide information are deemed ""linkable"". Once a user is presented with an indication of which objects around him are linkable, he can then directly point and click on the linkable objects without the ""trial-and-error"" process of pointing and clicking on non-linkable objects.",EVYRX TECHNOLOGIES INC;;COHEN RONALD H,COHEN RONALD H,,https://lens.org/139-880-822-499-680,Patent Application,yes,0,0,5,5,0,H04M2250/52;;H04N1/00307;;H04N1/00326;;H04N7/17318;;H04N21/23418;;H04N21/44008;;H04N21/4725;;H04N21/6581;;H04N21/6582;;H04M1/72445;;G06V20/10;;H04N21/6582;;H04N21/6581;;H04N1/00326;;H04M2250/52;;H04N21/23418;;H04N1/00307;;H04N21/4725;;H04N7/17318;;H04N21/44008;;H04M1/72445;;G06V20/10,H04N5/225;;G06F9/44;;G06F17/00;;G06F17/30;;G08B1/00,,0,0,,,,PENDING
45,US,S,US D0490510 S,151-435-841-752-978,2004-05-25,2004,US 17323602 F,2002-12-23,US 17323602 F,2002-12-23,Fan assembly for an umbrella,,SUMMER BLAST LLC,COHEN RONALD B,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;SUMMER BLAST LLC (2003-02-07),https://lens.org/151-435-841-752-978,Design Right,no,0,6,1,1,0,,,D23/379,0,0,,,,EXPIRED
46,US,A1,US 2007/0029846 A1,144-439-302-530-051,2007-02-08,2007,US 33252806 A,2006-01-12,US 33252806 A;;US 70154805 P,2005-07-22,Locking mechanism for a folding chair,"A folding chair including a seat frame, a leg frame hinged to the seat frame, a hinge mechanism between the seat frame and the leg frame, a quick-release locking mechanism for releasably locking the seat frame with respect to the leg frame, and a supplemental locking mechanism including an orifice in one of the seat frame and the leg frame, an opening in the hinge mechanism aligned with the orifice when the chair is unfolded, and a fastener extending through the opening in the hinge mechanism and into the orifice to secure the seat frame to the leg frame.",COHEN RONALD B,COHEN RONALD B,JAKKS PACIFIC INC (2009-07-02);;NEW PRODUCTS LLC (2006-03-27);;KIDS ONLY INC (2008-08-14),https://lens.org/144-439-302-530-051,Patent Application,yes,14,12,2,2,0,A47C4/20;;A47C4/20,A47D1/02,297/16.1,0,0,,,,ACTIVE
47,US,A1,US 2016/0206043 A1,005-240-966-599-897,2016-07-21,2016,US 201514626668 A,2015-02-19,US 201514626668 A;;US 201562105940 P,2015-01-21,FOOTWEAR HAVING SURFACE-DETECTING PROTRUSIONS,"A piece of footwear including an upper portion operably configured to at least partially surround a user's foot, a sole having an outsole and an insole, and at least one surface-detecting protrusion spanning through the sole. The insole and the upper portion define a foot placement zone. The at least one surface-detecting protrusion includes a proximal end defining a foot contact surface disposed within the foot placement zone. The proximal end is in a spaced relationship away from the insole. The at least one surface-detecting protrusion also includes a distal end, opposite the proximal end. The distal end defines an outer contact surface disposed in a spaced relationship away from the outsole. The foot contact surface is operably configured to translate when the outer contact surface is subjected to a compression force.",COHEN RONALD JAY,COHEN RONALD JAY,,https://lens.org/005-240-966-599-897,Patent Application,yes,1,4,1,1,0,A43B7/146;;A43B13/26;;A43B13/26;;A43B7/146,A43B13/22,,0,0,,,,DISCONTINUED
48,ZA,B,ZA 831332 B,038-484-038-931-007,1983-11-30,1983,ZA 831332 A,1983-02-28,ZA 831332 A;;ZA 821854 A,1982-03-19,PROP OR ELONGATED SUPPORT,,DERGLEN PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/038-484-038-931-007,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
49,WO,A3,WO 2007/143148 A3,089-510-675-652-402,2008-10-30,2008,US 2007/0013037 W,2007-05-31,US 44578406 A,2006-06-01,METHODS AND DEVICES FOR DETECTING LINKABLE OBJECTS,"A camera portion of a portable consumer device obtains data from a field of view, and at least a portion of the data is used to determine existence of an object in the field of view for which the information is available from a reference source. An indication is then provided to the user that the object is in the field of view. This can all be accomplished by a functionality, such as computer software, that executes on one or both of the device and a distal server. Objects within the field that the system can identify and provide information are deemed ""linkable"". Once a user is presented with an indication of which objects around him are linkable, he can then directly point and click on the linkable objects without the ""trial-and-error"" process of pointing and clicking on non-linkable objects.",EVYRX TECHNOLOGIES INC;;COHEN RONALD H,COHEN RONALD H,,https://lens.org/089-510-675-652-402,Search Report,yes,2,0,5,5,0,H04M2250/52;;H04N1/00307;;H04N1/00326;;H04N7/17318;;H04N21/23418;;H04N21/44008;;H04N21/4725;;H04N21/6581;;H04N21/6582;;H04M1/72445;;G06V20/10;;H04N21/6582;;H04N21/6581;;H04N1/00326;;H04M2250/52;;H04N21/23418;;H04N1/00307;;H04N21/4725;;H04N7/17318;;H04N21/44008;;H04M1/72445;;G06V20/10,G06K7/10;;G06F17/00,,0,0,,,,PENDING
50,DE,D1,DE 69940474 D1,091-395-390-784-146,2009-04-09,2009,DE 69940474 T,1999-08-30,AU PP554998 A;;AU PP078499 A;;AU 1998/099006 W,1998-08-28,VERFAHREN ZUR DIAGNOSE VON PROSTATAKREBS,,UROPATH PTY LTD,COHEN RONALD JOSEPH,,https://lens.org/091-395-390-784-146,Granted Patent,no,0,0,5,12,0,,A01N1/00;;C12N5/08;;G01N1/30,,0,0,,,,EXPIRED
51,US,A1,US 2013/0272574 A1,125-921-370-513-620,2013-10-17,2013,US 201313915731 A,2013-06-12,US 201313915731 A;;US 201113069157 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,Interactivity Via Mobile Image Recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",COHEN RONALD H;;NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/125-921-370-513-620,Patent Application,yes,9,10,6,173,0,G06F3/011;;G09G5/14;;G06T19/00;;G06T19/006;;H04M1/72427;;G06V30/142;;G06V10/56;;G06V10/7515;;H04M1/72427;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/21;;G06F3/011;;G06T19/00;;G06T19/006;;G09G5/14,G06V10/56;;G06V30/142;;H04M1/72427,382/103,0,0,,,,EXPIRED
52,US,B1,US 6677157 B1,059-489-482-693-804,2004-01-13,2004,US 78609001 A,2001-05-09,AU PP554998 A;;AU PQ078499 A;;AU 1998/099006 W,1998-08-28,Method of diagnosis of prostate cancer,"
    The present invention relates to structures involved in the secretory processes of reproductive tissues, including the prostatic secretory processes, and their protein products which may have used as tools for diagnosing reproductive pathology including prostate disease. The present invention also relates to reagents, such as antibodies, other ligands and oligonucleotides, for detecting these structures o their contents and to methods of diagnosing prostate pathology, including prostate cancer and prostatitis. The invention further relates to an improved tissue and cell fixation process for the detection of secretory structures in reproductive tissue. The fixation process is useful for the diagnosis of prostate, testes and renal cancer. 
",UROPATH PTY LTD A C N,COHEN RONALD JOSEPH,UROPATH PTY LTD. A.C.N (2001-05-04),https://lens.org/059-489-482-693-804,Granted Patent,yes,7,43,5,12,0,G01N1/30;;G01N1/30;;G01N33/57434;;G01N33/57434,A01N1/00;;C12N5/08;;G01N1/30;;G01N33/574,436/63,5,4,011-888-785-760-791;;027-232-867-917-966;;027-029-608-347-379;;027-029-608-347-379,10.1093/ajcp/104.6.620;;8526203;;10.1016/0046-8177(94)90268-2;;7509774;;3830358;;10.1139/y85-264;;3830358;;10.1139/y85-264,"Gaudin et al. (American J. Clin. Path, 104(6): 620-6).*;;Adlakha et al. (Human Path, 25(2): 135-9.*;;CA Plus-Frenette et al. (Can. J. Physiol. Pharmacol. 1985 63(12), 1603-7.*;;Master*Tech Bulletin: Ultrum II Concentrate, American Master*Tech Scientific, Inc. P.O. Box 2539, Lodi, CA 95241-2539.;;Frenette et al., Can. J. Physiol. Pharmacol. 63:1603-1607 (1985).",EXPIRED
53,US,A1,US 2012/0154438 A1,102-407-661-744-203,2012-06-21,2012,US 201213406720 A,2012-02-28,US 201213406720 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Interactivity Via Mobile Image Recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",COHEN RONALD H;;NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/102-407-661-744-203,Patent Application,yes,15,11,3,173,0,G06F16/29;;G06F16/51;;A63F13/216;;A63F13/35;;A63F13/655;;A63F13/92;;A63F2300/8082;;G06V20/20;;G06V30/142;;G06V10/245;;G06V10/56;;G06V10/462;;G06V10/7515;;G06F16/29;;G06F16/51;;G06V10/56;;G06V10/245;;G06V10/462;;G06V10/7515;;G06V20/20;;G06V30/142;;G06F18/22;;G06F18/24;;A63F13/216;;A63F13/25;;A63F13/335;;A63F13/35;;A63F13/655;;A63F13/92;;A63F2300/8082;;G06T19/006,G09G5/377;;G06V10/56,345/632,0,0,,,,DISCONTINUED
54,US,B2,US 8162389 B2,140-354-332-628-844,2012-04-24,2012,US 33252806 A,2006-01-12,US 33252806 A;;US 70154805 P,2005-07-22,Locking mechanism for a folding chair,"A folding chair including a seat frame, a leg frame hinged to the seat frame, a hinge mechanism between the seat frame and the leg frame, a quick-release locking mechanism for releasably locking the seat frame with respect to the leg frame, and a supplemental locking mechanism including an orifice in one of the seat frame and the leg frame, an opening in the hinge mechanism aligned with the orifice when the chair is unfolded, and a fastener extending through the opening in the hinge mechanism and into the orifice to secure the seat frame to the leg frame.",COHEN RONALD B;;NEW PRODUCTS LLC,COHEN RONALD B,JAKKS PACIFIC INC (2009-07-02);;NEW PRODUCTS LLC (2006-03-27);;KIDS ONLY INC (2008-08-14),https://lens.org/140-354-332-628-844,Granted Patent,yes,14,1,2,2,0,A47C4/20;;A47C4/20,A47C4/00,297/16.1;;297/55;;297/58,0,0,,,,ACTIVE
55,ZA,B,ZA 200001902 B,199-787-774-681-233,2000-10-31,2000,ZA 200001902 A,2000-04-14,ZA 200001902 A;;ZA 992836 A,1999-04-21,Yieldability control means.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/199-787-774-681-233,Granted Patent,no,0,0,1,2,0,,E21D/,,0,0,,,,EXPIRED
56,US,A,US 3303823 A,004-487-911-444-167,1967-02-14,1967,US 47635965 A,1965-08-02,US 47635965 A,1965-08-02,Weight control apparatus for animals,,MODERN TEACHING ASSOCIATES INC,COHEN RONALD S,,https://lens.org/004-487-911-444-167,Granted Patent,no,6,9,1,1,0,A01K1/035;;G01G17/08;;A01K29/00;;G01G17/08;;A01K1/035,A01K1/035;;G01G17/08,,0,0,,,,EXPIRED
57,EP,A2,EP 2764899 A2,030-370-657-213-737,2014-08-13,2014,EP 14166069 A,2006-08-29,US 71259005 P;;EP 06790088 A,2005-08-29,Interactivity via mobile image recognition,"A method of interacting with a virtual space, comprising: 
allowing a mobile device to electronically capture image data of a real-world object and a user; 
using the image data to identify information related to the real-world object, where the identified information includes a real-world visual appearance of the real-world object; 
interacting with software being operated at least in part on the device by deriving a real-world position and orientation of the object with respect to user from the real-world visual appearance of the real-world object in the identified information; and 
controlling interactive advertisement content on a publicly available information kiosk local to the device as a function of the real-world visual appearance of the real-world object including the derived position and orientation of the real-world object relative to the user.
",NANT HOLDINGS IP LLC,COHEN RONALD H,,https://lens.org/030-370-657-213-737,Patent Application,yes,1,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,A63F13/213;;G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,DISCONTINUED
58,US,A1,US 2019/0244255 A1,137-584-707-466-200,2019-08-08,2019,US 201916266298 A,2019-02-04,US 201916266298 A;;US 201862625522 P,2018-02-02,METHODS FOR DELIVERING CONTENT USING AN ON-DEMAND ACCESS PLATFORM,"A system includes a platform that allows consumers to access content from a content provider as desired. The consumer pays a transaction fee to access the content, and is not tied to any subscription based service. The consumer may receive the content directly from the content provider. Advertisers can bid upon access to deliver content to users. The advertisers bid to underwrite delivery of the content. The platform also allows advertisers to purchase additional delivery of the content using real-time data from the platform. Real-time information is provided to content providers and other entities as the content is accessed.",COHEN JEFFREY RONALD,COHEN JEFFREY RONALD,,https://lens.org/137-584-707-466-200,Patent Application,yes,0,0,1,1,0,G06Q30/0275;;G06Q30/0275,G06Q30/02,,0,0,,,,DISCONTINUED
59,ZA,B,ZA 997159 B,179-303-242-705-979,2000-06-13,2000,ZA 997159 A,1999-11-17,ZA 997159 A;;ZA 989761 A,1998-10-27,Mine prop prestressing means.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/179-303-242-705-979,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
60,ZA,B,ZA 9710500 B,015-666-024-675-797,1998-06-10,1998,ZA 9710500 A,1997-11-21,ZA 9710500 A;;ZA 969664 A,1996-11-19,Mine prop.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/015-666-024-675-797,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
61,ZA,B,ZA 825944 B,023-738-127-203-442,1983-07-27,1983,ZA 825944 A,1982-08-17,ZA 825944 A;;ZA 815934 A,1981-08-27,PROP OR OTHER ELONGATED SUPPORT,,DERGLEN PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/023-738-127-203-442,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
62,ZA,B,ZA 9710396 B,098-132-885-385-85X,1998-06-10,1998,ZA 9710396 A,1997-11-19,ZA 9710396 A;;ZA 969668 A,1996-11-19,Prestressing apparatus.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/098-132-885-385-85X,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
63,ZA,B,ZA 817628 B,151-966-177-526-544,1982-10-27,1982,ZA 817628 A,1981-11-04,ZA 817628 A;;ZA 815166 A,1981-07-28,PROP OR OTHER ELONGATED SUPPORT,,DERGLEN PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/151-966-177-526-544,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
64,US,A,US 3303822 A,034-934-601-585-431,1967-02-14,1967,US 47632465 A,1965-08-02,US 47632465 A,1965-08-02,Automatic animal selective feeder,,MODERN TEACHING ASSOCIATES INC,COHEN RONALD S,,https://lens.org/034-934-601-585-431,Granted Patent,no,9,7,1,1,0,A01K1/0356;;A01K5/0283;;A01K1/0356;;A01K5/0283,A01K1/035;;A01K5/02,,0,0,,,,EXPIRED
65,WO,A1,WO 2000/011947 A1,090-895-285-490-124,2000-03-09,2000,AU 1998/099006 W,1999-08-30,AU PP554998 A;;AU PQ078499 A,1998-08-28,METHOD OF DIAGNOSIS OF PROSTATE CANCER,"The present invention relates to structures involved in the secretory processes of reproductive tissues, including the prostatic secretory processes, and their protein products which may be used as tools for diagnosing reproductive pathology including prostate disease. The present invention also relates to reagents, such as antibodies, other ligands and oligonucleotides, for detecting these structures or their contents and to methods of diagnosing prostate pathology, including prostate cancer and prostatitis. The invention further relates to an improved tissue and cell fixation process for the detection of secretory structures in reproductive tissue. The fixation process is useful for the diagnosis of prostate, testes and renal cancer.",UROPATH PTY LTD;;COHEN RONALD JOSEPH,COHEN RONALD JOSEPH,,https://lens.org/090-895-285-490-124,Patent Application,yes,1,1,5,12,0,G01N1/30;;G01N1/30;;G01N33/57434;;G01N33/57434,A01N1/00;;C12N5/08;;G01N1/30;;G01N33/574,,21,20,023-057-424-533-284;;049-834-198-437-805;;027-029-608-347-379;;020-988-800-949-90X;;027-968-149-052-103;;057-150-996-615-402;;092-506-204-239-60X;;011-888-785-760-791;;007-797-471-681-574;;027-232-867-917-966;;004-316-601-112-726;;035-158-977-153-159;;077-840-731-268-525;;071-533-486-347-888;;028-375-172-942-529;;048-579-489-434-450;;119-068-147-191-961;;051-049-882-355-433;;113-347-244-518-27X;;150-847-164-517-472,7258144;;10.1093/ajcp/75.6.854;;6649193;;10.3109/03009738309178440;;3830358;;10.1139/y85-264;;pmc502216;;10.1136/jcp.43.1.13;;1690221;;pmc495061;;1385482;;10.1136/jcp.45.10.894;;10.1016/0046-8177(93)90041-e;;8454275;;7802135;;10.1097/00000478-199501000-00004;;10.1093/ajcp/104.6.620;;8526203;;8958549;;10.1016/s0344-0338(96)80041-0;;10.1016/0046-8177(94)90268-2;;7509774;;8430906;;10.1002/ar.1092350305;;pmc1255406;;3349405;;3739615;;10.1159/000146194;;10.1111/j.1365-2818.1983.tb04227.x;;6310118;;10.1016/s0022-5320(83)90055-2;;6827649;;7070588;;10.1159/000123282;;6947400;;10.1016/s0014-4908(75)80031-7;;1233286;;10.1007/bf02464417;;4418;;9151134,"CRAMER S.F.: ""Benign glandular inclusion in prostatic nerve"", AMERICAN J. CLIN. PATH.,, vol. 75, no. 6, 1981, pages 854 - 855;;BRODY I., RONQUIST G. AND GOTTFRIES A.: ""Ultrastructural localisation of the protasome - an organelle in human seminal plasma"", UPSALA J. MED. SCI.,, vol. 88, no. 2, 1983, pages 63 - 80;;FRENETTE G. ET AL.: ""Arginine esterase from isolated dog prostate secretory granules is fully active enzymatically"", CANADIAN J. PHYSIOL. AND PHARMACOL.,, vol. 63, no. 12, pages 1603 - 1637;;RODE J., BENTLEY A. AND PARKINSON C.: ""Paraganglial cells of uninary bladder and prostate: potential diagnostic problem"", J. CLIN. PATH.,, vol. 43, no. 1, 1990, pages 13 - 16;;CROSS P.A., BARTLEY C.J. AND MCCLURE J.: ""Amyloid in prostatic corpora amylacea"", J. CLIN. PATH.,, vol. 45, no. 10, 1992, pages 894 - 897;;BOSTWICK D.G. ET AL.: ""Architectural patterns of high-grade prostatic intraepithelial neoplasia"", HUMAN PATH.,, vol. 24, no. 3, 1993, pages 298 - 310;;GAGUCAS R.J., BROWN R.W. AND WHEELER T.M.: ""Verumontanum mucosal gland hyperplasia"", AMERICAN J. SURGICAL PATH.,, vol. 19, no. 1, 1995, pages 30 - 36;;GAUDIN P.B., WHEELER T.M. AND EPSTEIN J.I.: ""Verumontanum mucosal gland hyperplasia in prostatic needle biopsy specimens"", AMERICAN J. CLIN. PATH.,, vol. 104, no. 6, 1995, pages 620 - 626;;ROCKEN C., LINKE R.P. AND SAEGER W.: ""Corpora amylacea in the lung, prostate and uterus. A comparative and immunohistochemical study"", PATHOLOGY, RESEARCH AND PRACTICE,, vol. 192, no. 10, 1996, pages 998 - 1006;;ADLAKHA H. AND BOSTWICK D.G.: ""Paneth cel-like change in prostatic adnocarcinoma represent neuroendocrine differentiation: report of 30 cases"", HUMAN PATHOLOGY,, vol. 25, no. 2, 1994, pages 135 - 139;;CLERMONT Y. ET AL.: ""Transport of casein submicelles and formation of secretion granules in the Golgi apparatus of epithelial cells of the lactating mammary gland of the rat"", ANATOMICAL RECORD,, vol. 235, no. 3, 1993, pages 363 - 373;;SNELGROVE-HOBSON S.M., RAO P.V. AND BHATNAGER M.K.: ""Ultrastructural alterations in the kidneys of pekin ducks fed methylmercury"", CANADIAN J. VET. RESEARCH,, vol. 52, no. 1, 1988, pages 89 - 98;;WILD P. ET AL.: ""Ultrastructural alterations in mammalian parathyroid glands induced by fixation"", ACTA ANATOMICA,, vol. 126, no. 2, 1986, pages 87 - 96;;HEMMING F.J. ET AL.: ""Cryoultramicrotomy versus plastic embedding: comparative immunocytochemistry of rat anterior pituitary cells"", J. MICROSCOPY,, vol. 131, no. 1, 1983, pages 25 - 34;;CHANDLER D.E., BENNETT J.P. AND GOMPERTS B.: ""Freeze-fracture studies of chemotactic peptide-induced exocytosis in neutrophils evidence for two patterns of secretory granule fusion"", J. ULTRASTRUCTURE RESEARCH,, vol. 82, no. 2, 1983, pages 221 - 232;;MOREL G. ET AL.: ""Ultrastructural evidence for endogenous vasoactive intestinal peptide-like immunoreactivity in the pituitary gland"", NEUROENDOCRINOLOGY,, vol. 34, no. 2, 1982, pages 85 - 89;;JONES J.G. AND ELMES E.: ""The quantification of zinc in the mucosal cells of human small intestine using x-ray microanalysis"", SCANDINAVIAN J. GASTROENT.,, 1981, pages 37 - 48, SUPPLEMENT 70;;WEIDENACH H. AND MASSMANN J.: ""Electron microscopic study on the ""ghost bodies"" in experimental arteeriosclerotic lesions of the vascular wall"", EXPERIMENTELLE PATHOLOGIE,, vol. 10, no. 5-6, 1975, pages 251 - 257;;HERZOG V. AND FAHIMI H.D.: ""Intracellular distinction between peroxidase and catalase in exocrine cells of rat lacrimal gland: a biochemical and cytochemical study"", HISTOCHEMISTRY,, vol. 46, no. 4, 1976, pages 273 - 286;;WATANABE I., JIN C. AND NAGATA T.: ""Field emission SEM, conventional TEM and HVTEM study of submandibular gland in prenatal and postnatal aging mouse"", HISTOLOGY AND HISTOPATHOLOGY,, vol. 12, no. 2, 1997, pages 447 - 457;;See also references of EP 1107665A4",PATENTED
66,AU,A,AU 1999/057210 A,098-707-646-458-390,2000-03-21,2000,AU 1999/057210 A,1999-08-30,AU 1999/057210 A;;AU PP554998 A;;AU PQ078499 A;;AU 1998/099006 W,1998-08-28,Method of diagnosis of prostate cancer,,UROPATH PTY LTD,COHEN RONALD JOSEPH,,https://lens.org/098-707-646-458-390,Patent Application,no,0,0,5,12,0,G01N1/30;;G01N1/30;;G01N33/57434;;G01N33/57434,A01N1/00;;C12N5/08;;G01N1/30;;G01N33/574,,0,0,,,,EXPIRED
67,CA,A1,CA 2621191 A1,149-276-998-082-40X,2007-03-08,2007,CA 2621191 A,2006-08-29,US 71259005 P;;US 2006/0033811 W,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,,EVRYX TECHNOLOGIES INC,COHEN RONALD H,,https://lens.org/149-276-998-082-40X,Patent Application,no,0,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,ACTIVE
68,US,A1,US 2010/0281108 A1,024-595-046-086-636,2010-11-04,2010,US 77206510 A,2010-04-30,US 77206510 A;;US 17480909 P;;US 17875909 P;;US 22808509 P;;US 26703209 P;;US 29988510 P,2009-05-01,Provision of Content Correlated with Events,The invention relates to providing time-varying information synchronized with real-world events or time-based media.,COHEN RONALD H,COHEN RONALD H,,https://lens.org/024-595-046-086-636,Patent Application,yes,18,216,1,1,0,H04N21/235;;H04N21/26291;;H04N21/435;;H04N21/458;;H04N21/6547;;H04N21/6581;;H04N21/858;;G06F16/4393;;G06F16/9566;;G06F16/58;;H04N21/435;;H04N21/6581;;H04N21/6547;;H04N21/26291;;H04N21/235;;H04N21/858;;H04N21/458;;G06F16/9566;;G06F16/58;;G06F16/4393,G06F15/16,709/203,0,0,,,,DISCONTINUED
69,US,A1,US 2015/0199851 A1,058-315-065-606-320,2015-07-16,2015,US 201514668988 A,2015-03-26,US 201514668988 A;;US 201414159318 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/058-315-065-606-320,Patent Application,yes,13,1,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06T19/00;;G06T13/00;;G06T13/80;;G09G5/18;;H04M1/72427,,0,0,,,,DISCONTINUED
70,ZA,B,ZA 98210 B,096-394-948-664-272,1998-08-13,1998,ZA 98210 A,1998-01-12,ZA 97391 A,1997-01-17,Timber panels,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/096-394-948-664-272,Granted Patent,no,0,0,1,1,0,,B27B/,,0,0,,,,EXPIRED
71,US,B2,US 9600935 B2,123-589-382-046-463,2017-03-21,2017,US 201414184510 A,2014-02-19,US 201414184510 A;;US 201414159318 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity with a mixed reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/123-589-382-046-463,Granted Patent,yes,109,11,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F3/048;;A63F13/213;;A63F13/332;;A63F13/40;;A63F13/655;;G06F3/0484;;G06F3/16;;G06T13/00;;G06T13/80;;G06T19/00;;G09G5/18;;G09G5/377;;H04M1/72427;;H04N21/4223;;H04N21/658,,7,0,,,"European Search Report for Application No. EP14166069, mailed on Nov. 6, 2014, 10 pages.;;Partial European Search Report for Application No. EP14166069, mailed on Jul. 4, 2014, 6 pages.;;Rosenberg L., ""A Method and Apparatus for an On-screen/Off-screen First Person Gaming Experience,"" Mar. 31, 2005.;;Russell B., ""Use Your Phone as a Golf Club,"" MobHappy, 1 page, [retrieved on Jan. 31, 2005]. Retrieved from the Internet:.< URL: http:// mobhappy-typepad-com/russell-buckleys-mobhappy/2005/01/index.html>.;;Snow B., ""GPS Gaming,"" Joystiq.com, 1 page, [retrieved on Feb. 24, 2006]. Retrieved from the Internet:..;;Supplementary European Search Report for Application No. EP06790088, mailed on May 26, 2011, 11 pages.;;Welle D., ""Virtual Graffiti-A Sign of the Future?,"" 2 pages, [retrieved on Feb. 14, 2005]. Retrieved from the Internet::.",ACTIVE
72,US,A1,US 2011/0170747 A1,028-088-126-743-498,2011-07-14,2011,US 201113069157 A,2011-03-22,US 201113069157 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71559005 P,2000-11-06,Interactivity Via Mobile Image Recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world Object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",COHEN RONALD H,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/028-088-126-743-498,Patent Application,yes,66,5,6,173,0,G06F3/011;;G09G5/14;;G06T19/00;;G06T19/006;;H04M1/72427;;G06V30/142;;G06V10/56;;G06V10/7515;;H04M1/72427;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/21;;G06F3/011;;G06T19/00;;G06T19/006;;G09G5/14,G06V30/142;;G06V10/56;;H04M1/72427,382/103,0,0,,,,EXPIRED
73,WO,A3,WO 2007/027738 A3,037-206-789-833-727,2007-09-20,2007,US 2006/0033811 W,2006-08-29,US 71259005 P,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of : (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",EVRYX TECHNOLOGIES INC;;COHEN RONALD H,COHEN RONALD H,,https://lens.org/037-206-789-833-727,Search Report,yes,2,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,PENDING
74,ZA,B,ZA 817629 B,063-846-642-149-662,1982-10-27,1982,ZA 817629 A,1981-11-04,ZA 817629 A;;ZA 813519 A,1981-05-26,PROP OR OTHER ELONGATED SUPPORT,,DERGLEN PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/063-846-642-149-662,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
75,CA,C,CA 2621191 C,183-746-341-521-662,2012-12-18,2012,CA 2621191 A,2006-08-29,US 71259005 P;;US 2006/0033811 W,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of : (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",EVRYX TECHNOLOGIES INC,COHEN RONALD H,,https://lens.org/183-746-341-521-662,Granted Patent,no,0,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,ACTIVE
76,US,A1,US 2014/0173493 A1,029-550-008-432-086,2014-06-19,2014,US 201414184510 A,2014-02-19,US 201414184510 A;;US 201414159318 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/029-550-008-432-086,Patent Application,yes,10,1,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F3/0484;;G06T13/00;;G06T13/80;;G06T19/00;;H04M1/72427,715/773,0,0,,,,ACTIVE
77,US,A1,US 2007/0104348 A1,041-176-390-593-514,2007-05-10,2007,US 51000906 A,2006-08-25,US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,Interactivity via mobile image recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",EVRYX TECHNOLOGIES INC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/041-176-390-593-514,Patent Application,yes,16,101,2,173,0,A63F13/10;;A63F13/12;;A63F2300/1087;;A63F2300/538;;H04N7/17318;;H04N21/41407;;H04N21/4223;;H04N21/47815;;H04N21/6582;;A63F13/45;;A63F13/30;;A63F13/355;;A63F13/332;;A63F13/213;;H04N7/17318;;H04N21/41407;;H04N21/4223;;H04N21/47815;;A63F2300/1087;;H04N21/6582;;A63F2300/538,G06K9/00;;H04N5/225;;H04N7/14,382/100;;348/207.1;;348/14.04,0,0,,,,EXPIRED
78,ZA,B,ZA 200905763 B,078-252-521-945-677,2010-07-28,2010,ZA 200905763 A,2009-08-19,ZA 200809558 A;;ZA 200905763 A,2008-11-10,Cable drum and associated method of manufacture,,SPRINGBOK BOX PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/078-252-521-945-677,Granted Patent,no,0,0,1,1,0,,B27H/;;B65D/,,0,0,,,,ACTIVE
79,ZA,B,ZA 200105862 B,067-078-455-313-726,2002-03-08,2002,ZA 200105862 A,2001-07-17,ZA 200105862 A;;ZA 200003067 A,2000-06-19,Mine prop prestressing means.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/067-078-455-313-726,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
80,WO,A2,WO 2007/027738 A2,150-712-461-422-009,2007-03-08,2007,US 2006/0033811 W,2006-08-29,US 71259005 P,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of : (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",EVRYX TECHNOLOGIES INC;;COHEN RONALD H,COHEN RONALD H,,https://lens.org/150-712-461-422-009,Patent Application,yes,0,1,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F19/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,PENDING
81,US,B2,US 8817045 B2,155-554-061-418-175,2014-08-26,2014,US 201113069157 A,2011-03-22,US 201113069157 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71559005 P,2000-11-06,Interactivity via mobile image recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",COHEN RONALD H;;NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/155-554-061-418-175,Granted Patent,yes,74,14,6,173,0,G06F3/011;;G09G5/14;;G06T19/00;;G06T19/006;;H04M1/72427;;G06V30/142;;G06V10/56;;G06V10/7515;;H04M1/72427;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/21;;G06F3/011;;G06T19/00;;G06T19/006;;G09G5/14,G06F3/01;;G06V30/142;;G06T19/00;;G09G5/00;;G06V10/56;;G09G5/14;;H04M1/72427,345/633;;345/632;;345/634;;345/158;;345/169;;709/201;;709/203;;725/37;;725/40;;725/42;;725/50;;725/51;;725/59;;725/60;;725/61;;463/37;;463/38,5,0,,,"Rosenberg, L, ""A Method and Apparatus for an On-screen/Off-screen First Person Gaming Experience"", Mar. 31, 2005.;;Russell B., ""Use Your Phone as a Golf Club,"" MobHappy, 1 page, [retrieved on Jan. 31, 2005]. Retrieved from the Internet< URL: http:// mobhappy-typepad-com/russell-buckleys-mobhappy/2005/01/index.html>.;;Snow B., ""GPS Gaming,"" Joystiq.com, 1 page, [retrieved on Feb. 24, 2006]. Retrieved from the Internet:.;;Supplementary European Search Report for Application No. EP06790088, mailed on May 26, 2011, 11 pages.;;Welle D., ""Virtual Graffiti-A Sign of the Future?,"" 2 pages, [retrieved on Feb. 14, 2005]. Retrieved from the Internet:.",EXPIRED
82,ZA,B,ZA 9710397 B,188-627-654-828-876,1998-08-26,1998,ZA 9710397 A,1997-11-19,ZA 9710397 A,1997-11-19,Mine prop prestressing device.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/188-627-654-828-876,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
83,US,A1,US 2007/0279521 A1,189-541-995-224-105,2007-12-06,2007,US 44578406 A,2006-06-01,US 44578406 A,2006-06-01,Methods and devices for detecting linkable objects,"A camera portion of a portable consumer device obtains data from a field of view, and at least a portion of the data is used to determine existence of an object in the field of view for which the information is available from a reference source. An indication is then provided to the user that the object is in the field of view. This can all be accomplished by a functionality, such as computer software, that executes on one or both of the device and a distal server. Objects within the field that the system can identify and provide information are deemed “linkable.” Once a user is presented with an indication of which objects around him are linkable, he can then directly point and click on the linkable objects without the “trial-and-error” process of pointing and clicking on non-linkable objects.",EVRYX TECHNOLOGIES INC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2006-06-01);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/189-541-995-224-105,Patent Application,yes,11,93,5,5,0,H04M2250/52;;H04N1/00307;;H04N1/00326;;H04N7/17318;;H04N21/23418;;H04N21/44008;;H04N21/4725;;H04N21/6581;;H04N21/6582;;H04M1/72445;;G06V20/10;;H04N21/6582;;H04N21/6581;;H04N1/00326;;H04M2250/52;;H04N21/23418;;H04N1/00307;;H04N21/4725;;H04N7/17318;;H04N21/44008;;H04M1/72445;;G06V20/10,G06F9/44;;H04N5/225;;G06F17/00;;G06F17/30;;G08B1/00,348/376;;705/7;;707/1;;340/531;;235/375,0,0,,,,ACTIVE
84,US,A1,US 2014/0055492 A1,004-978-342-565-431,2014-02-27,2014,US 201314070028 A,2013-11-01,US 201314070028 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/004-978-342-565-431,Patent Application,yes,16,4,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G09G5/377;;G06T13/00;;G06T13/80;;H04M1/72427,345/633,0,0,,,,DISCONTINUED
85,US,B2,US 9076077 B2,169-057-585-948-848,2015-07-07,2015,US 201414468301 A,2014-08-25,US 201414468301 A;;US 201113069157 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,Interactivity via mobile image recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/169-057-585-948-848,Granted Patent,yes,87,24,6,173,0,G06F3/011;;G09G5/14;;G06T19/00;;G06T19/006;;H04M1/72427;;G06V30/142;;G06V10/56;;G06V10/7515;;H04M1/72427;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/21;;G06F3/011;;G06T19/00;;G06T19/006;;G09G5/14,G06V30/142;;G06F3/01;;G06T19/00;;G06V10/56;;G09G5/14;;H04M1/72427,,5,0,,,"Rosenberg L., ""A Method and Apparatus for an On-screen/Off-screen First Person Gaming Experience,"" Mar. 31, 2005.;;Russell B., ""Use Your Phone as a Golf Club,"" MobHappy, 1 page, [retrieved on Jan. 31, 2005]. Retrieved from the Internet:< URL: http:// mobhappy-typepad-com/russell-buckleys-mobhappy/2005/01/index.html>.;;Snow B., ""GPS Gaming,"" Joystiq.com, 1 page, [retrieved on Feb. 24, 2006]. Retrieved from the Internet:.;;Supplementary European Search Report for Application No. EP06790088, mailed on May 26, 2011, 11 pages.;;Welle D., ""Virtual Graffiti-A Sign of the Future?,"" 2 pages, [retrieved on Feb. 14, 2005]. Retrieved from the Internet:.",EXPIRED
86,EP,A3,EP 2764899 A3,037-380-528-828-456,2014-12-10,2014,EP 14166069 A,2006-08-29,US 71259005 P;;EP 06790088 A,2005-08-29,Interactivity via mobile image recognition,"A method of interacting with a virtual space, comprising: 
allowing a mobile device to electronically capture image data of a real-world object and a user; 
using the image data to identify information related to the real-world object, where the identified information includes a real-world visual appearance of the real-world object; 
interacting with software being operated at least in part on the device by deriving a real-world position and orientation of the object with respect to user from the real-world visual appearance of the real-world object in the identified information; and 
controlling interactive advertisement content on a publicly available information kiosk local to the device as a function of the real-world visual appearance of the real-world object including the derived position and orientation of the real-world object relative to the user.
",NANT HOLDINGS IP LLC,COHEN RONALD H,,https://lens.org/037-380-528-828-456,Search Report,yes,4,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,A63F13/213;;G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,DISCONTINUED
87,US,A,US 3662770 A,050-420-545-628-557,1972-05-16,1972,US 3662770D A,1968-11-29,US 77983668 A,1968-11-29,DISPENSING APPARATUS FOR SEQUENTIALLY DISCHARGING TOKENS FROM AN INCLINED STACK OF TOKENS,"This disclosure relates to a coin dispenser. A ""U"" shaped tray is angularly mounted with the lower end slightly spaced from a stop plate to define a discharge opening. The tray opens upwardly with the coins disposed in the tray with one or more backing balls continuously urging them downwardly into clamping engagement against the stop plate. A wiper blade is centrally secured to a motor shaft to one side of the discharge opening such that the shaft rotation moves the opposite ends of the blade through the discharge space or opening.",BEHAVIORAL CONTROLS INC,COHEN RONALD S,,https://lens.org/050-420-545-628-557,Granted Patent,no,8,4,1,1,0,G07D1/00;;G07D1/00,G07D1/00,133  5   R;;221/231,0,0,,,,EXPIRED
88,EP,A1,EP 1107665 A1,104-509-845-785-608,2001-06-20,2001,EP 99944166 A,1999-08-30,AU 1998/099006 W;;AU PP554998 A;;AU PP078499 A,1998-08-28,METHOD OF DIAGNOSIS OF PROSTATE CANCER,,UROPATH PTY LTD,COHEN RONALD JOSEPH,UROPATH PTY. LTD. (2008-12-31),https://lens.org/104-509-845-785-608,Patent Application,yes,0,2,5,12,0,,A01N1/00;;C12N5/08;;G01N1/30,,0,0,,,,EXPIRED
89,US,B2,US 10463961 B2,016-908-417-451-343,2019-11-05,2019,US 201314070571 A,2013-11-03,US 201314070571 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity with a mixed reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/016-908-417-451-343,Granted Patent,yes,122,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F3/16;;A63F13/20;;A63F13/213;;A63F13/25;;A63F13/30;;A63F13/323;;A63F13/332;;A63F13/40;;A63F13/52;;A63F13/65;;A63F13/655;;G06F3/0484;;G06T13/00;;G06T13/80;;G06T19/00;;G09G5/18;;G09G5/377;;H04M1/72427;;H04N21/4223;;H04N21/658,,7,0,,,"Rosenberg L., “A Method and Apparatus for an On-screen/Off-screen First Person Gaming Experience,” Mar. 31, 2005.;;Russell B., “Use Your Phone as a Golf Club,” MobHappy, 1 page, [retrieved on Jan. 31, 2005]. Retrieved from the Internet:< URL: http:// mobhappy_typepad_com/russell_buckleys_mobhappy/2005/01/index.html>.;;Snow B., “GPS Gaming,” Joystiq.com, 1 page, [retrieved on Feb. 24, 2006]. Retrieved from the Internet< URL: http://www.joystiq.com/ 20061021241gps-gaming/>.;;Supplementary European Search Report for Application No. EP06790088, dated May 26, 2011, 11 pages.;;Welle D., “Virtual Graffiti—A Sign of the Future?,” 2 pages, [retrieved on Feb. 14, 2005]. Retrieved from the Internet:<URL: http://www. dw-world.de/dw/article/0,1564,1481993,00.html>.;;European Search Report for Application No. EP14166069, dated Nov. 6, 2014, 10 pages.;;Partial European Search Report for Application No. EP14166069, dated Jul. 4, 2014, 6 pages.",ACTIVE
90,ZA,B,ZA 200003678 B,029-145-194-607-441,2001-02-28,2001,ZA 200003678 A,2000-07-20,ZA 200003678 A;;ZA 992836 A,1999-04-21,Yieldability control means.,,DERGLEN CC,COHEN RONALD RAYMOND,,https://lens.org/029-145-194-607-441,Granted Patent,no,0,0,1,2,0,,E21D/,,0,0,,,,EXPIRED
91,US,A1,US 2014/0363086 A1,000-730-466-233-493,2014-12-11,2014,US 201414468301 A,2014-08-25,US 201414468301 A;;US 201113069157 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/000-730-466-233-493,Patent Application,yes,8,2,6,173,0,G06F3/011;;G09G5/14;;G06T19/00;;G06T19/006;;H04M1/72427;;G06V30/142;;G06V10/56;;G06V10/7515;;H04M1/72427;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/21;;G06F3/011;;G06T19/00;;G06T19/006;;G09G5/14,G06V30/142;;G06V10/56;;H04M1/72427,382/190,0,0,,,,EXPIRED
92,US,B2,US 9087270 B2,009-364-228-328-403,2015-07-21,2015,US 201313915731 A,2013-06-12,US 201313915731 A;;US 201113069157 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,Interactivity via mobile image recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/009-364-228-328-403,Granted Patent,yes,90,0,6,173,0,G06F3/011;;G09G5/14;;G06T19/00;;G06T19/006;;H04M1/72427;;G06V30/142;;G06V10/56;;G06V10/7515;;H04M1/72427;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/21;;G06F3/011;;G06T19/00;;G06T19/006;;G09G5/14,G06V30/142;;G06F3/01;;G06T19/00;;G06V10/56;;G09G5/14;;H04M1/72427,,5,0,,,"Rosenberg, L, ""A Method and Apparatus for an On-screen/Off-screen First Person Gaming Experience"", Mar. 31, 2005.;;Russell B., ""Use Your Phone as a Golf Club,"" MobHappy, 1 page, [retrieved on Jan. 31, 2005]. Retrieved from the Internet:< URL: http:// mobhappy-typepad-com/russell-buckleys-mobhappy/2005/01/index.html>.;;Snow B., ""GPS Gaming,"" Joystiq.com, 1 page, [retrieved on Feb. 24, 2006]. Retrieved from the Internet:.;;Supplementary European Search Report for Application No. EP06790088, mailed on May 26, 2011, 11 pages.;;Welle D., ""Virtual Graffiti-A Sign of the Future?,"" 2 pages, [retrieved on Feb. 14, 2005]. Retrieved from the Internet:.",EXPIRED
93,US,A,US 3667138 A,024-617-571-120-235,1972-06-06,1972,US 3667138D A,1970-06-29,US 5074770 A,1970-06-29,SPEECH TRAINING APPARATUS AND METHOD OF TEACHING THEREWITH,"A housing has an upper dome illuminated by a lamp. A pair of permanent magnet cone speakers are mounted in the opposite sidewalls of the housing and connected in series across the input to a preamplifier. An amplifier connects the sound related output signal to the input of a power transistor connected in series with the lamp to a regulated DC supply. The speakers, housing and amplifier establish a response range from 250 to 4,000 Hertz to reject voiceless sounds. A potentiometer connects the supply directly to the input of the power transistor for preheating of the lamp and controlling the response. A delay switch connects and disconnects a resistor in the base circuit of the transistor to vary the timing and cutoff of the lamp.",BEHAVIORAL CONTROLS INC,COHEN RONALD S,,https://lens.org/024-617-571-120-235,Granted Patent,no,4,6,1,1,0,G09B5/04;;G09B5/04,G09B5/04,35 35   C,0,0,,,,EXPIRED
94,EP,B1,EP 1107665 B1,026-392-971-789-390,2009-02-25,2009,EP 99944166 A,1999-08-30,AU 1998/099006 W;;AU PP554998 A;;AU PP078499 A,1998-08-28,METHOD OF DIAGNOSIS OF PROSTATE CANCER,,UROPATH PTY LTD,COHEN RONALD JOSEPH,UROPATH PTY. LTD. (2008-12-31),https://lens.org/026-392-971-789-390,Granted Patent,yes,3,0,5,12,0,,A01N1/00;;C12N5/08;;G01N1/30,,21,0,,,"DATABASE WPI Section Ch, Week 199829, Derwent Publications Ltd., London, GB; Class D22, AN 1998-325447, XP002212191 & IE 78 909 B2 (KENNEDY S M) 11 March 1998;;CRAMER S.F.: 'Benign glandular inclusion in prostatic nerve' AMERICAN J. CLIN. PATH., vol. 75, no. 6, 1981, pages 854 - 855;;BRODY I., RONQUIST G. AND GOTTFRIES A.: 'Ultrastructural localisation of the protasome - an organelle in human seminal plasma' UPSALA J. MED. SCI., vol. 88, no. 2, 1983, pages 63 - 80;;FRENETTE G. ET AL.: 'Arginine esterase from isolated dog prostate secretory granules is fully active enzymatically' CANADIAN J. PHYSIOL. AND PHARMACOL., vol. 63, no. 12, pages 1603 - 1637;;RODE J., BENTLEY A. AND PARKINSON C.: 'Paraganglial cells of uninary bladder and prostate: potential diagnostic problem' J. CLIN. PATH., vol. 43, no. 1, 1990, pages 13 - 16;;CROSS P.A., BARTLEY C.J. AND MCCLURE J.: 'Amyloid in prostatic corpora amylacea' J. CLIN. PATH., vol. 45, no. 10, 1992, pages 894 - 897;;BOSTWICK D.G. ET AL.: 'Architectural patterns of high-grade prostatic intraepithelial neoplasia' HUMAN PATH., vol. 24, no. 3, 1993, pages 298 - 310;;GAGUCAS R.J., BROWN R.W. AND WHEELER T.M.: 'Verumontanum mucosal gland hyperplasia' AMERICAN J. SURGICAL PATH., vol. 19, no. 1, 1995, pages 30 - 36;;GAUDIN P.B., WHEELER T.M. AND EPSTEIN J.I.: 'Verumontanum mucosal gland hyperplasia in prostatic needle biopsy specimens' AMERICAN J. CLIN. PATH., vol. 104, no. 6, 1995, pages 620 - 626;;ROCKEN C., LINKE R.P. AND SAEGER W.: 'Corpora amylacea in the lung, prostate and uterus. A comparative and immunohistochemical study' PATHOLOGY, RESEARCH AND PRACTICE, vol. 192, no. 10, 1996, pages 998 - 1006;;ADLAKHA H. AND BOSTWICK D.G.: 'Paneth cel-like change in prostatic adnocarcinoma represent neuroendocrine differentiation: report of 30 cases' HUMAN PATHOLOGY, vol. 25, no. 2, 1994, pages 135 - 139;;CLERMONT Y. ET AL.: 'Transport of casein submicelles and formation of secretion granules in the Golgi apparatus of epithelial cells of the lactating mammary gland of the rat' ANATOMICAL RECORD, vol. 235, no. 3, 1993, pages 363 - 373;;SNELGROVE-HOBSON S.M., RAO P.V. AND BHATNAGER M.K.: 'Ultrastructural alterations in the kidneys of pekin ducks fed methylmercury' CANADIAN J. VET. RESEARCH, vol. 52, no. 1, 1988, pages 89 - 98;;WILD P. ET AL.: 'Ultrastructural alterations in mammalian parathyroid glands induced by fixation' ACTA ANATOMICA, vol. 126, no. 2, 1986, pages 87 - 96;;HEMMING F.J. ET AL.: 'Cryoultramicrotomy versus plastic embedding: comparative immunocytochemistry of rat anterior pituitary cells' J. MICROSCOPY, vol. 131, no. 1, 1983, pages 25 - 34;;CHANDLER D.E., BENNETT J.P. AND GOMPERTS B.: 'Freeze-fracture studies of chemotactic peptide-induced exocytosis in neutrophils evidence for two patterns of secretory granule fusion' J. ULTRASTRUCTURE RESEARCH, vol. 82, no. 2, 1983, pages 221 - 232;;MOREL G. ET AL.: 'Ultrastructural evidence for endogenous vasoactive intestinal peptide-like immunoreactivity in the pituitary gland' NEUROENDOCRINOLOGY, vol. 34, no. 2, 1982, pages 85 - 89;;JONES J.G. AND ELMES E.: 'The quantification of zinc in the mucosal cells of human small intestine using x-ray microanalysis' SCANDINAVIAN J. GASTROENT., 1981, pages 37 - 48, SUPPLEMENT 70;;WEIDENACH H. AND MASSMANN J.: 'Electron microscopic study on the ""ghost bodies"" in experimental arteeriosclerotic lesions of the vascular wall' EXPERIMENTELLE PATHOLOGIE, vol. 10, no. 5-6, 1975, pages 251 - 257;;HERZOG V. AND FAHIMI H.D.: 'Intracellular distinction between peroxidase and catalase in exocrine cells of rat lacrimal gland: a biochemical and cytochemical study' HISTOCHEMISTRY, vol. 46, no. 4, 1976, pages 273 - 286;;WATANABE I., JIN C. AND NAGATA T.: 'Field emission SEM, conventional TEM and HVTEM study of submandibular gland in prenatal and postnatal aging mouse' HISTOLOGY AND HISTOPATHOLOGY, vol. 12, no. 2, 1997, pages 447 - 457",EXPIRED
95,ZA,B,ZA 817627 B,065-075-942-381-850,1982-10-27,1982,ZA 817627 A,1981-11-04,ZA 817627 A,1981-11-04,PROP OR OTHER ELONGATE SUPPORT,,DERGLEN PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/065-075-942-381-850,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
96,EP,A4,EP 1929430 A4,167-378-668-223-564,2011-06-29,2011,EP 06790088 A,2006-08-29,US 2006/0033811 W;;US 71259005 P,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,,EVRYX TECHNOLOGIES INC,COHEN RONALD H,"EVRYX TECHNOLOGIES, INC. (2009-02-18);;NANT HOLDINGS IP, LLC (2011-11-23)",https://lens.org/167-378-668-223-564,Search Report,no,6,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,A63F13/10;;G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,DISCONTINUED
97,EP,A2,EP 1929430 A2,173-980-014-654-540,2008-06-11,2008,EP 06790088 A,2006-08-29,US 2006/0033811 W;;US 71259005 P,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,,EVRYX TECHNOLOGIES INC,COHEN RONALD H,"EVRYX TECHNOLOGIES, INC. (2009-02-18);;NANT HOLDINGS IP, LLC (2011-11-23)",https://lens.org/173-980-014-654-540,Patent Application,yes,0,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,A63F13/10;;G06K9/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,DISCONTINUED
98,US,B1,US 6325084 B1,179-832-600-317-698,2001-12-04,2001,US 55018300 A,2000-04-14,US 55018300 A,2000-04-14,Combined umbrella and fan device,"A combined umbrella and fan device wherein the umbrella includes a fabric or vinyl canopy, an umbrella hub, a plurality of splines hingedly attached to the umbrella hub supporting the fabric or vinyl canopy, an umbrella shaft extending from the umbrella hub, and a slide collar on the umbrella shaft including a plurality of support stays hingedly interconnected with the splines. The fan subassembly includes a fan motor housing, a clamp for attaching the motor housing to the umbrella shaft below the slide collar of the umbrella, a fan blade hub assembly rotatably disposed about the umbrella shaft between the slide collar and the clamp and having fan blades extending therefrom, a drive collar about the umbrella shaft and attached to and disposed beneath the fan blade hub assembly, a bushing on the shaft between the clamp and the drive collar for rotatably supporting the drive collar, and a drive wheel extending from the motor housing and engaging the drive collar for rotating the drive collar.",KIDS ONLY INC,COHEN RONALD B,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2008-09-09);;KIDS ONLY INC (2008-08-14),https://lens.org/179-832-600-317-698,Granted Patent,yes,12,42,1,12,0,A45B3/00;;A45B2200/1036;;A45B2200/1063;;F04D25/088;;F04D25/088;;A45B3/00;;A45B2200/1063;;A45B2200/1036,A45B3/00;;F04D25/08,135/16;;417/313,0,0,,,,EXPIRED
99,US,A1,US 2014/0132632 A1,054-399-899-137-028,2014-05-15,2014,US 201414159318 A,2014-01-20,US 201414159318 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/054-399-899-137-028,Patent Application,yes,21,4,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06T19/00;;G06T13/00;;G06T13/80;;H04M1/72427,345/633,0,0,,,,DISCONTINUED
100,ZA,B,ZA 838204 B,062-244-208-269-296,1984-06-27,1984,ZA 838204 A,1983-11-03,ZA 838204 A;;ZA 825584 A,1982-08-03,PROP OR ELONGATED SUPPORT,,DERGLEN PTY LTD,COHEN RONALD RAYMOND,,https://lens.org/062-244-208-269-296,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
101,US,B2,US 10617951 B2,076-133-957-252-412,2020-04-14,2020,US 201715425984 A,2017-02-06,US 201715425984 A;;US 201414184510 A;;US 201414159318 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity with a mixed reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/076-133-957-252-412,Granted Patent,yes,128,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F3/048;;A63F13/213;;A63F13/25;;A63F13/323;;A63F13/332;;A63F13/52;;A63F13/65;;A63F13/655;;G06F3/0484;;G06F3/16;;G06T13/00;;G06T13/80;;G06T19/00;;G09G5/18;;G09G5/377;;H04M1/72427;;H04N21/4223;;H04N21/658,,7,0,,,"European Search Report for Application No. EP14166069, dated Nov. 6, 2014, 10 pages.;;Partial European Search Report for Application No. EP14166069, dated Jul. 4, 2014, 6 pages.;;Rosenberg L., “A Method and Apparatus for an On-screen/Off-screen First Person Gaming Experience,” Mar. 31, 2005.;;Russell B., “Use Your Phone as a Golf Club,” MobHappy, 1 page, [retrieved on Jan. 31, 2005]. Retrieved from the Internet:.;;Snow B., “GPS Gaming,” Joystiq.com, 1 page, [retrieved on Feb. 24, 2006]. Retrieved from the Internet:.;;Supplementary European Search Report for Application No. EP06790088, dated May 26, 2011, 11 pages.;;Welle D., “Virtual Graffiti—A Sign of the Future?,” 2 pages, [retrieved on Feb. 14, 2005]. Retrieved from the Internet:.",ACTIVE
102,US,A1,US 2014/0059437 A1,125-073-336-497-795,2014-02-27,2014,US 201314070571 A,2013-11-03,US 201314070571 A;;US 50572609 A;;US 97206208 A;;US 2006/0033811 W;;US 71259005 P,2005-08-29,Interactivity With A Mixed Reality,"Methods of interacting with a mixed reality are presented. A mobile device captures an image of a real-world object where the image has content information that can be used to control a mixed reality object through an offered command set. The mixed reality object can be real, virtual, or a mixture of both real and virtual.",NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2011-02-22);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/125-073-336-497-795,Patent Application,yes,14,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,G06F3/16;;G06T13/00;;G06T13/80;;H04M1/72427,715/727,0,0,,,,ACTIVE
103,US,A1,US 2017/0122293 A1,136-270-634-030-79X,2017-05-04,2017,US 201515318343 A,2015-06-10,US 201515318343 A;;US 201462010108 P;;US 2015/0035182 W,2014-06-10,Deep Water Wind Energy Capture System,The Inventive Subject Matter is a System for harvesting wind energy and natural wave energy. The harvesting can be performed on a body of water. The body of water can be an ocean or lake. The harvesting can be performed autonomously and create portable energy for ships or other purposes.,COHEN RONALD,COHEN RONALD H,,https://lens.org/136-270-634-030-79X,Patent Application,yes,0,2,2,2,0,F03D1/0625;;F05B2240/93;;Y02E10/727;;F03D9/25;;F03D13/25;;F03D80/70;;F03D9/11;;Y02E10/74;;Y02E10/72;;Y02E70/30;;F03D1/0625;;F03D9/25;;F03D13/25;;F03D80/70;;F05B2240/93;;Y02E10/727;;Y02E10/72;;F03D1/0658;;F03D9/11;;B63B35/44;;B63B2035/446;;B63B2035/4466;;B63B2209/14;;B63B2209/20;;F03D3/005,F03D13/25;;B63B35/44;;F03D1/06;;F03D3/00;;F03D9/00;;F03D9/11;;F03D9/25,,0,0,,,,DISCONTINUED
104,KR,A,KR 20080042148 A,172-323-883-336-265,2008-05-14,2008,KR 20087007433 A,2006-08-29,US 71259005 P,2005-08-29,INTERACTIVITY VIA MOBILE IMAGE RECOGNITION,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of : (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",EVRYX TECHNOLOGIES INC,COHEN RONALD H,,https://lens.org/172-323-883-336-265,Patent Application,no,0,0,28,173,0,A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;G06T19/00;;G06T19/006;;H04M1/72427;;A63F13/216;;A63F13/355;;A63F13/655;;A63F2300/8088;;A63F13/63;;A63F13/332;;A63F13/655;;A63F13/213;;A63F2300/1093;;A63F2300/538;;A63F2300/5573;;A63F2300/6018;;A63F2300/695;;A63F2300/8094;;H04M2250/52;;H04N21/4223;;H04N21/6582;;H04M1/72427;;G06T19/00;;G06T19/006;;G09G5/377;;G06F3/167;;G06F3/0484;;G06T15/00;;G09G5/18;;A63F13/323;;A63F13/25;;A63F13/52;;A63F13/65;;A63F2300/8082,H04Q7/24;;G06Q20/00;;G06T13/00;;G06T13/80;;H04M1/72427,,0,0,,,,ACTIVE
105,US,B2,US 8130242 B2,198-865-601-627-954,2012-03-06,2012,US 51000906 A,2006-08-25,US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,Interactivity via mobile image recognition,"Systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, and the information is used to interact with software to control at least one of: (a) an aspect of an electronic game; and (b) a second device local to the mobile device. Contemplated systems and methods can be used to gaming, in which the image data can be used to identify a name of the real-world object, to classify the real-world object, identify the real-world object as a player in the game, to identify the real-world object as a goal object or as having some other value in the game, to use the image data to identify the real-world object as a goal object in the game.",COHEN RONALD H;;NANT HOLDINGS IP LLC,COHEN RONALD H,EVRYX TECHNOLOGIES INC (2006-09-24);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/198-865-601-627-954,Granted Patent,yes,14,82,2,173,0,A63F13/10;;A63F13/12;;A63F2300/1087;;A63F2300/538;;H04N7/17318;;H04N21/41407;;H04N21/4223;;H04N21/47815;;H04N21/6582;;A63F13/45;;A63F13/30;;A63F13/355;;A63F13/332;;A63F13/213;;H04N7/17318;;H04N21/41407;;H04N21/4223;;H04N21/47815;;A63F2300/1087;;H04N21/6582;;A63F2300/538,G09G5/00;;A63F9/24;;G06F3/02;;G06F3/033;;G06F13/00;;G06F17/00;;G06F19/00,345/632;;345/619;;345/629;;345/158;;345/169;;463/37;;463/38;;715/700;;715/863;;382/100,0,0,,,,EXPIRED
106,AU,A,AU 1986/055677 A,074-238-394-725-324,1987-10-08,1987,AU 1986/055677 A,1986-04-04,AU 1986/055677 A,1986-04-04,YIELDABLE MIME ROOF SUPPORT,,DERGLEN CLOSE CORP,COHEN RONALD RAYMOND;;COHEN ALAN ABRAHAM,,https://lens.org/074-238-394-725-324,Patent Application,no,0,1,1,1,0,,E21D15/22,,0,0,,,,DISCONTINUED
107,ZA,B,ZA 858732 B,003-880-137-669-686,1987-01-28,1987,ZA 858732 A,1985-11-14,ZA 858732 A;;ZA 848862 A,1984-11-14,SUPPORTS,,DERGLEN PROPRIETARY LIMITED,COHEN RONALD RAYMOND;;COHEN ALAN ABRAHAM,,https://lens.org/003-880-137-669-686,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
108,WO,A3,WO 2009/126199 A3,121-608-334-610-638,2009-12-30,2009,US 2009/0001548 W,2009-03-11,US 6455008 P,2008-03-11,NEW CLASS OF PURE PIEZOELETRIC MATERIALS,A modification of PbTiO 3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,CARNEGIE INST OF WASHINGTON;;COHEN RONALD;;PANCHAPAKESAN GANESH,COHEN RONALD;;PANCHAPAKESAN GANESH,,https://lens.org/121-608-334-610-638,Search Report,yes,0,0,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,C04B35/495,,3,3,019-065-141-980-266;;001-770-727-496-13X;;174-595-501-492-927,18235495;;10.1038/nature06459;;10.1016/j.ceramint.2003.12.143;;10.1143/jjap.41.6761,"AHART, M. ET AL.: ""Origin of morphotropic phase boundaries in ferroelectrics"", NATURE, vol. 451, 31 January 2008 (2008-01-31), pages 545 - 549, Retrieved from the Internet <URL:http://www.nature.com/nature/journal/v451/n7178/pdf/nature06459.pdf> [retrieved on 20090825];;CHOPRA, S. ET AL.: ""Sol-gel preparation and characterization of calcium modified lead titanate (PCT) thin films"", CERAMICS INTERNATIONAL, vol. 30, 10 May 2004 (2004-05-10), pages 1477 - 1481, Retrieved from the Internet <URL:http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TWH-4CBW5P6-3&_user=952835&_rdoc=1&_fmt=&_orig=search&_sort=d&_docanchor=&view=c&_searchStrld=991019359&_rerunOrigin=google&_acct=C000049198&_version=1&_urlVersion=0&_userid=952835&md5=c9b7a6bad9ce5128f6ffbf401ff3aa5a> [retrieved on 20090825];;KARAKI, T. ET AL.: ""Electrical properties of epitaxial (Pb,Sr)Ti03 thin films prepared by RF magnetron sputtering"", JAP. JOURNAL OF APPLIED PHYSICS, vol. 41, no. 11B, November 2002 (2002-11-01), pages 6761 - 6764, Retrieved from the Internet <URL:http://jjap.ipap.jp/link?JJAP/41/6761/pdf> [retrieved on 20090825]",PENDING
109,US,A1,US 2009/0291324 A1,042-064-532-934-653,2009-11-26,2009,US 40193509 A,2009-03-11,US 40193509 A;;US 6455008 P,2008-03-11,Class of Pure Piezoelectric Materials,A modification of PbTiO 3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,COHEN RONALD;;GANESH PANCHAPAKESAN,COHEN RONALD;;GANESH PANCHAPAKESAN,CARNEGIE INSTITUTION OF WASHINGTON (2009-06-01),https://lens.org/042-064-532-934-653,Patent Application,yes,7,4,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,B32B9/00;;C01G23/00,428/701;;423/598,0,0,,,,INACTIVE
110,KR,A,KR 20100131485 A,084-217-972-212-513,2010-12-15,2010,KR 20107022713 A,2009-03-11,US 6455008 P,2008-03-11,NEW CLASS OF PURE PIEZOELETRIC MATERIALS,,CARNEGIE INST OF WASHINGTON,COHEN RONALD;;PANCHAPAKESAN GANESH,,https://lens.org/084-217-972-212-513,Patent Application,no,0,0,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,C01G23/00;;C04B35/472;;H01B3/12;;H01L41/18,,0,0,,,,INACTIVE
111,WO,A1,WO 2008/092201 A1,182-922-882-037-965,2008-08-07,2008,AU 2008/000105 W,2008-01-31,AU 2007/900486 A,2007-02-02,A METHOD FOR DIAGNOSING PROSTATIC DISEASE,The present invention provides a method for diagnosing prostatic disease and/or risk of prostatic disease in men comprising obtaining a body fluid sample from a patient and assaying for the presence of antibodies specific for Propionibacterium acnes (P. acnes) in the body fluid sample.,TISSUGEN PTY LTD;;O'BRIEN BEVERLEY;;COHEN RONALD,O'BRIEN BEVERLEY;;COHEN RONALD,,https://lens.org/182-922-882-037-965,Patent Application,yes,1,2,1,1,0,G01N33/56911;;G01N33/57434;;G01N33/6854;;G01N33/6893;;G01N2800/342,C12Q1/04;;G01N33/50;;G01N33/53;;G01N33/68,,4,4,126-255-128-630-348;;077-788-756-659-033;;058-453-998-108-759;;015-261-814-009-080,10.1111/j.1464-410x.2007.07214.x;;17850358;;10.1097/01.ju.0000158161.15277.78;;15879794;;16879683;;10.1111/j.1464-410x.2006.06273.x;;10.2217/14796694.2.2.225;;16563091,"SHANNON B.A. ET AL.: ""The antibody response to Propionibacterium acnes is an independent predictor of serum prostate-specific antigen levels in biopsy-negative men"", BJU INTERNATIONAL, vol. 101, no. 4, 10 September 2007 (2007-09-10), pages 429 - 435;;COHEN R.J. ET AL.: ""PROPIONIBACTERIUM ACNES ASSOCIATED WITH INFLAMMATION IN RADICAL PROSTATEECTOMY SPECIMENS: A POSSIBLE LINK TO CANCER EVOLUTION"", THE JOURNAL OF UROLOGY, vol. 173, no. 6, 2005, pages 1969 - 1974, XP005375240;;SHANNON B.A. ET AL.: ""Polymerase chain reaction-based identification of Propionibacterium acnes types isolated from the male urinary tract: evaluation of adolescents, normal adults and men with prostatic pathology"", BJU INTERNATIONAL, vol. 98, no. 2, 2006, pages 388 - 392;;SHANNON B.A. ET AL.: ""Links between Propionibacterium acnes and prostate cancer"", FUTURE ONCOLOGY, vol. 2, no. 2, 2006, pages 225 - 232",PENDING
112,WO,A2,WO 2008/130458 A2,038-750-116-333-758,2008-10-30,2008,US 2008/0000164 W,2008-01-04,US 87839207 P;;US 87901107 P,2007-01-04,ORDERED OXYNITRIDE PEROVSKITES,"This invention relates to partially ordered and ordered oxynitride perovskites of the general formula ABO 2 N that are polar insulators. A comprises one or more cations or set of cations that sit in sites derived from the A-site in the perovskite structure. B comprises one ore more cations or set of cations that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A + B is equal to the total valence of the anions 2 C + D. Also disclosed are methods of producing such oxynitride perovskites and uses of such oxynitride perovskites.",CARNEGIE INST OF WASHINGTON;;COHEN RONALD;;CARACAS RAZVAN,COHEN RONALD;;CARACAS RAZVAN,,https://lens.org/038-750-116-333-758,Patent Application,yes,0,3,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,C01F17/00,,0,0,,,,PENDING
113,US,A1,US 2012/0009361 A1,069-539-254-651-894,2012-01-12,2012,US 201113231286 A,2011-09-13,US 201113231286 A;;US 40193509 A;;US 6455008 P,2008-03-11,New Class of Pure Piezoelectric Materials,A modification of PbTiO 3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,COHEN RONALD;;GANESH PANCHAPAKESAN,COHEN RONALD;;GANESH PANCHAPAKESAN,,https://lens.org/069-539-254-651-894,Patent Application,yes,0,0,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,B32B9/00;;C01G23/04,428/16;;423/598;;428/701,0,0,,,,INACTIVE
114,CA,A1,CA 2717350 A1,081-888-547-794-266,2009-10-15,2009,CA 2717350 A,2009-03-11,US 6455008 P;;US 2009/0001548 W,2008-03-11,NEW CLASS OF PURE PIEZOELETRIC MATERIALS,A modification of PbTiO3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,CARNEGIE INST OF WASHINGTON,COHEN RONALD;;PANCHAPAKESAN GANESH,,https://lens.org/081-888-547-794-266,Patent Application,no,0,0,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,C01G23/04;;C01G17/00;;C01G21/00;;H01L41/18,,0,0,,,,DISCONTINUED
115,WO,A1,WO 2012/078654 A1,077-545-817-639-196,2012-06-14,2012,US 2011/0063563 W,2011-12-06,US 96215210 A,2010-12-07,EDITING BASED ON FORCE-BASED PHYSICAL CUES,"A method is provided for formatting. A force-based physical cue performed on or to a mobile computing device is detected. The force-based physical cue is associated with a formatting function. Formatting of text or characters in a document, message or form is performed according to the formatting function in response to the detecting. An extent of the formatting is correlated to an amount of the detected force-based physical cue.",GOOGLE INC;;HO RONALD;;COHEN GABRIEL,HO RONALD;;COHEN GABRIEL,,https://lens.org/077-545-817-639-196,Patent Application,yes,5,5,1,1,0,G06F1/1694;;G06F3/0481;;G06F3/04847;;G06F2200/1637;;H04M2250/12;;H04M2250/22;;H04M2250/70;;G06F40/103;;H04M1/72436,G06F3/048;;G06F1/16;;G06F3/0481;;G06F3/0484;;G06F17/21;;G06F17/24;;H04M1/72436,,0,0,,,,PENDING
116,US,B2,US 8039131 B2,097-926-115-871-817,2011-10-18,2011,US 40193509 A,2009-03-11,US 40193509 A;;US 6455008 P,2008-03-11,Class of pure piezoelectric materials,A modification of PbTiO 3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,CARNEGIE INST OF WASHINGTON,COHEN RONALD;;GANESH PANCHAPAKESAN,CARNEGIE INSTITUTION OF WASHINGTON (2009-06-01),https://lens.org/097-926-115-871-817,Granted Patent,yes,7,1,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,C01G23/00;;B32B9/00,428/701;;423/598,8,4,050-232-594-895-397;;019-065-141-980-266;;019-065-141-980-266;;001-770-727-496-13X,16090770;;10.1103/physrevlett.95.037601;;18235495;;10.1038/nature06459;;18235495;;10.1038/nature06459;;10.1016/j.ceramint.2003.12.143,"Das et al. 2002, Kluwer Academic Publishers, p. 239-247.;;Zhigang. Wu and R. E. Cohen, Pressure-Induced Anomolous Phase Transitions and Colossal Enhancement of Piezoelectricity in PbTiO3, Phys. Rev. Lett., 95, 37601 (2005).;;Muhetaer Ahart, Maddury Somayazulu, R. E. Cohen, P. Ganesh, Przmeyslaw Dera,Ho-Kwang Mao, Russell J. Hemley, Yang Ren, Peter Liermann and Zhigang Wu, Origin of Morphotropic phase boundaries in ferroelectrics, Nature 451, 06459 (2008).;;X. Gonze et.al., First-principles computation of material properties: the ABINIT software project, Comput. Mater. Sci. 25, 478 (2002).;;Muhtar Ahart et al., Origin of morphotropic phase boudaries in ferroelectrics, vol. 451/31, Jan. 2008.;;Sonalee Chopra et al., Sol-gel preparation and characterization of calcium modified lead titanate (PCT) thin films, Ceramics International 30 (2004) 1477-1481.;;Tomoaki Karaki et al., Electrical Properties of Epitaxial (Pb, Sr) TiO3 Thin Films Prepared by RF Magnetron Sputtering, Japanese Society of Applied Physics No. 118, Nov. 2002.;;International Search Report and Written Opinion dated Sep. 8, 2009.",INACTIVE
117,US,B2,US 8287831 B2,175-212-097-185-110,2012-10-16,2012,US 704308 A,2008-01-04,US 704308 A;;US 87839207 P;;US 87901107 P,2007-01-04,Ordered oxynitride perovskites,"This invention relates to partially ordered and ordered oxynitride perovskites of the general formula ABO 2 N that are polar insulators. A comprises one or more cations or set of cations that sit in sites derived from the A-site in the perovskite structure. B comprises one or more cations or set of cations that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A+B is equal to the total valence of the anions 2 C+D. Also disclosed are methods of producing such oxynitride perovskites and uses of such oxynitride perovskites.",COHEN RONALD;;CARACAS RAZVAN;;CARNEGIE INST OF WASHINGTON,COHEN RONALD;;CARACAS RAZVAN,CARNEGIE INSTITUTION OF WASHINGTON (2008-03-07),https://lens.org/175-212-097-185-110,Granted Patent,yes,6,7,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,C04B35/50;;C01B21/20;;C01F17/00;;C04B35/505;;H01L41/18;;H01L41/187,423/263;;X252 629 R;;423/385;;423/326;;501/152;;501/96.1;;257/21.009,8,5,030-563-299-495-279;;017-521-612-382-961;;058-545-029-493-334;;077-686-695-538-141;;120-492-113-836-280,10.1021/cm010577v;;10.1016/0025-5408(94)90206-2;;10.1021/cm034756j;;10.1006/jssc.1999.8372;;10.1016/s0022-3697(02)00296-2,"Ching et al, Electronic Structure and Bonding in the Y-Si-O-N Quarternary Crystals, Aug. 10, 2004, Physical Review B 70, 085105 (2004), pp. 1-14.;;Kim, Young (2005), Thesis entitled ""Syntheses, Crystal, Structure and Dielectric Property of Oxynitride Perovskite"" Ohio State University, Columbus, OH, 66(6), 3125, p. 123-156.;;Clarke et al. (2002), Oxynitride Perovskites: Synthesis and Structures of LaZrO2N, NdTiO2N and LaTiO2N and Comparison with Oxide Perovskites, Chem. Mater. 12: 288-294.;;Grins et al. (1994), Synthesis of Oxynitride Perovskites (AZrxTa1-xO2+xN1-x, A = Ca, A,Sr, Ba and 0 ≰ X ≰ 1), Materials Research Bulletin 29(7): 801-809.;;Kim et al. (2004), Characterization of Structural, Optical and Dielectrical Properties of Oxynitride Perovskites AMO2N (A = Ba, Sr, Ca; M = Ta, Nb), Chem. Mater. 16: 1267-1276.;;Clark et al., ""Structure of Zr2ON2 by Neutron Powder Diffraction: The Absence of Nitride-Oxide Ordering"", Journal of Solid State Chemistry, 146:399-405 (1999).;;Fang et al., ""Local structure and electronic properties of BaTaO2N with perovskite-type structure"", Journal of Physics and Chemistry of Solids, 64:281-286 (2003).;;Günther et al., Structural Investigations on the Oxidenitrides SrTaO2N, CaTaO2N and LaTaON2 by Neutron and X-ray Powder Diffraction, Z. Anorg. Allg. Chem., 626:1519-1525 (2000) (English Abstract).",ACTIVE
118,WO,A3,WO 2008/130458 A3,108-174-266-352-529,2008-12-31,2008,US 2008/0000164 W,2008-01-04,US 87839207 P;;US 87901107 P,2007-01-04,ORDERED OXYNITRIDE PEROVSKITES,"This invention relates to partially ordered and ordered oxynitride perovskites of the general formula ABO 2 N that are polar insulators. A comprises one or more cations or set of cations that sit in sites derived from the A-site in the perovskite structure. B comprises one ore more cations or set of cations that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A + B is equal to the total valence of the anions 2 C + D. Also disclosed are methods of producing such oxynitride perovskites and uses of such oxynitride perovskites.",CARNEGIE INST OF WASHINGTON;;COHEN RONALD;;CARACAS RAZVAN,COHEN RONALD;;CARACAS RAZVAN,,https://lens.org/108-174-266-352-529,Search Report,yes,2,0,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,H01B1/08,,1,0,,,"YOUNG-II THESIS K.: ""SYNTHESES, CRYSTAL STRUCTURES, AND DIELECTRIC PROPERTY OF OCYNITRIDE PEROVSKITES"", OHIO STATE UNIV. COLUMBUS, OH, USA, vol. 66, no. 6, 2005, pages 123 - 156",PENDING
119,CA,A1,CA 2674035 A1,055-482-589-472-879,2008-10-30,2008,CA 2674035 A,2008-01-04,US 87839207 P;;US 87901107 P;;US 2008/0000164 W,2007-01-04,ORDERED OXYNITRIDE PEROVSKITES,"This invention relates to partially ordered and ordered oxynitride perovs kites of the general formula ABO2N that are polar insulators. A comprises on e or more cations or set of cations that sit in sites derived from the A-sit e in the perovskite structure. B comprises one ore more cations or set of ca tions that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A + B is equal to the total valence of the anions 2 C + D. Also disclosed are methods of produ cing such oxynitride perovskites and uses of such oxynitride perovskites.</S DOAB>",CARNEGIE INST OF WASHINGTON,COHEN RONALD;;CARACAS RAZVAN,,https://lens.org/055-482-589-472-879,Patent Application,no,0,0,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,H01B1/08,,0,0,,,,DISCONTINUED
120,US,A1,US 2013/0071312 A1,082-729-926-936-314,2013-03-21,2013,US 201213614074 A,2012-09-13,US 201213614074 A;;US 704308 A;;US 87901107 P;;US 87839207 P,2007-01-04,Ordered Oxynitride Perovskites,"This invention relates to partially ordered and ordered oxynitride perovskites of the general formula ABO 2 N that are polar insulators. A comprises one or more cations or set of cations that sit in sites derived from the A-site in the perovskite structure. B comprises one or more cations or set of cations that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A+B is equal to the total valence of the anions 2 C+D. Also disclosed are methods of producing such oxynitride perovskites and uses of such oxynitride perovskites.",COHEN RONALD;;CARACAS RAZVAN,COHEN RONALD;;CARACAS RAZVAN,,https://lens.org/082-729-926-936-314,Patent Application,yes,1,0,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,C01B21/082,423/263;;423/385,2,1,030-563-299-495-279,10.1021/cm010577v,"Gunther et al, ""Structural Investigations on the Oxidenitrides SrTaO2N, CaTaO2N and LaTaOn2 by Neutron and X-ray Powder Diffraction"", Z. Anorg. Chem. 2000, 626, pp. 1519-1525.;;Clark et al, ""Oxynitride Perovskites: Synthesis and Structure of LaZrO2N, NdTiO2N and LaTiO2N and Comparison with Oxide Perovskites"", Chem. Mater. 2002, 14, pp. 288-294.",ACTIVE
121,US,B2,US 8679652 B2,131-088-190-633-713,2014-03-25,2014,US 201113231286 A,2011-09-13,US 201113231286 A;;US 40193509 A;;US 6455008 P,2008-03-11,Class of pure piezoelectric materials,A modification of PbTiO 3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,COHEN RONALD;;GANESH PANCHAPAKESAN;;CARNEGIE INST OF WASHINGTON,COHEN RONALD;;GANESH PANCHAPAKESAN,,https://lens.org/131-088-190-633-713,Granted Patent,yes,16,0,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,B32B9/00;;C01G23/04,428/701;;428/702;;423/598,8,4,129-988-687-753-624;;019-065-141-980-266;;001-770-727-496-13X;;050-232-594-895-397,10.1111/j.1551-2916.2005.00314.x;;18235495;;10.1038/nature06459;;10.1016/j.ceramint.2003.12.143;;16090770;;10.1103/physrevlett.95.037601,"Chen et al. J. Am. Cer. Soc. 2005, 88(5), 1356-1358.;;International Search Report and Written Opinion dated Sep. 8, 2009.;;Ahart et al., ""Origin of Morphotropic phase boundaries in ferroelectrics"", Nature, 451:06459 (2008).;;Chopra et al., ""Sci-gel preparation and characterization of calcium modified lead titanate (PCT) thin films"", Ceramics International, 30:1477-1481 (2004).;;Das et al., Kluwer Academic Publishers, p. 239-247 (2002).;;Gonze et al., First-principles computation of material properties: the ABINIT software project, Comput. Mater. Sci., 25:478 (2002).;;Karaki et al., ""Electrical Properties of Epitaxial (Pb, Sr) TiO3 Thin Films Prepared by RF Magnetron Sputtering"", Japanese Society of Applied Physics No. 118 (Nov. 2002).;;Zhigang et al., ""Pressure-Induced Anomolous Phase Transitions and Colossal Enhancement of Piezoelectricity in Pb TiO3"", Phys. Rev. Lett., 95:37601 (2005).",INACTIVE
122,US,B2,US 8721915 B2,038-077-269-776-093,2014-05-13,2014,US 201213614074 A,2012-09-13,US 201213614074 A;;US 704308 A;;US 87901107 P;;US 87839207 P,2007-01-04,Ordered oxynitride perovskites,"This invention relates to partially ordered and ordered oxynitride perovskites of the general formula ABO 2 N that are polar insulators. A comprises one or more cations or set of cations that sit in sites derived from the A-site in the perovskite structure. B comprises one or more cations or set of cations that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A+B is equal to the total valence of the anions 2 C+D. Also disclosed are methods of producing such oxynitride perovskites and uses of such oxynitride perovskites.",COHEN RONALD;;CARACAS RAZVAN;;CARNEGIE INST OF WASHINGTON,COHEN RONALD;;CARACAS RAZVAN,,https://lens.org/038-077-269-776-093,Granted Patent,yes,7,2,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,C01B21/00,252 629R;;501/153;;501/152;;501/96.1;;423/263;;423/358;;117/944,10,6,030-563-299-495-279;;077-686-695-538-141;;120-492-113-836-280;;030-563-299-495-279;;017-521-612-382-961;;058-545-029-493-334,10.1021/cm010577v;;10.1006/jssc.1999.8372;;10.1016/s0022-3697(02)00296-2;;10.1021/cm010577v;;10.1016/0025-5408(94)90206-2;;10.1021/cm034756j,"Gunther et al, ""Structural Investigations on the Oxidenitrides SrTaO2N, CaTaO2N and LaTaOn2 by Neutron and X-ray Powder Diffraction"", Z. Anorg. Chem. 2000, 626, pp. 1519-1525.;;Clark et al, ""Oxynitride Perovskites: Synthesis and Structure of LaZrO2N, NdTiO2N and LaTiO2N and Comparison with Oxide Perovskites"", Chem. Mater. 2002, 14, pp. 288-294.;;Clark et al., ""Structure of Zr2ON2 by Neutron Powder Diffraction: The Absence of Nitride-Oxide Ordering,"" Journal of Solid State Chemistry, 146:399-405 (1999).;;Fang et al., ""Local structure and electronic properties of BaTaO2N with perovskite-type structure,"" Journal of Physics and Chemistry of Solids, 64:281-286 (2003).;;Gunther et al., ""Structural Investigations on the Oxidenitrides SrTaO2N, CaTaO2N and LaTaON2 by Neutron and X-ray Powder Diffraction,"" Z. Anorg. Allg. Chem., 626:1519-1525 (2000) (English Abstract).;;Kim, Young , Thesis entitled ""Syntheses, Crystal, Structure and Dielectric Property of Oxynitride Perovskite"" Ohio State University, Columbus, OH, 66(6), 3125, p. 123-156 (2005).;;Clarke et al., Oxynitride Perovskites: Synthesis and Structures of LaZrO2N, NdTiO2N and LaTiO2N and Comparison with Oxide Perovskites, Chem. Mater. 12: 288-294 (2002).;;Grins et al., Synthesis of Oxynitride Perovskites (AZrxTa1-xO2+XN1-X, A = Ca, A, Sr, Ba and 0 < X < 1), Materials Research Bulletin 29(7): 801-809 (1994).;;Kim et al., Characterization of Structural, Optical and Dielectric Properties of Oxynitride Perovskites AMO2N (A=Ba, Sr, Ca; M=Ta, Nb), Chem. Mater. 16: 1267-1276 (2004).;;Ching et al. ""Electronic structure and bonding in the Y-Si-O-N quarternary crystals,"" Aug. 10, 2004, Physical Review B 70, 085105, pp. 1-14 (2004).",ACTIVE
123,US,A1,US 2010/0284883 A1,061-946-561-381-473,2010-11-11,2010,US 704308 A,2008-01-04,US 704308 A;;US 87839207 P;;US 87901107 P,2007-01-04,Ordered Oxynitride Perovskites,"This invention relates to partially ordered and ordered oxynitride perovskites of the general formula ABO 2 N that are polar insulators. A comprises one or more cations or set of cations that sit in sites derived from the A-site in the perovskite structure. B comprises one or more cations or set of cations that sit in sites derived from the B-site in the perovskite structure. C comprises oxygen, O, with optionally some nitrogen, N, and D comprises N, with optionally some O. The total valence of the cations A+B is equal to the total valence of the anions 2 C+D. Also disclosed are methods of producing such oxynitride perovskites and uses of such oxynitride perovskites.",CARNEGIE INST OF WASHINGTON,COHEN RONALD;;CARACAS RAZVAN,CARNEGIE INSTITUTION OF WASHINGTON (2008-03-07),https://lens.org/061-946-561-381-473,Patent Application,yes,6,2,10,10,0,C01B21/082;;C01B21/0823;;C01P2002/34;;C01P2002/76;;C01P2006/40;;C01P2006/42;;G02F1/3551;;H10N30/853;;H10N30/8561;;C01B21/0821;;C01B21/0823;;G02F1/3551;;C01P2002/34;;C01P2006/40;;C01P2006/42;;H10N30/853;;C01B21/0823;;C01B21/082;;C01P2002/76;;C01P2006/40;;C01P2002/34;;G02F1/3551;;C01P2006/42;;H10N30/853;;H10N30/8561;;C01B21/0821,C01B33/20;;C01B21/082,423/326;;423/385,0,0,,,,ACTIVE
124,WO,A2,WO 2009/126199 A2,084-916-279-512-641,2009-10-15,2009,US 2009/0001548 W,2009-03-11,US 6455008 P,2008-03-11,NEW CLASS OF PURE PIEZOELETRIC MATERIALS,A modification of PbTiO 3 perovskite wherein at least part of Pb is replaced by a smaller atom with a similar ionic charge.,CARNEGIE INST OF WASHINGTON;;COHEN RONALD;;PANCHAPAKESAN GANESH,COHEN RONALD;;PANCHAPAKESAN GANESH,,https://lens.org/084-916-279-512-641,Patent Application,yes,0,0,11,11,0,C01G23/003;;C01P2002/52;;C01P2002/77;;C01P2006/40;;C04B35/462;;C04B35/472;;C04B2235/3287;;C04B2235/3293;;C04B2235/768;;H10N30/8548;;C01G23/003;;C01P2006/40;;C01P2002/77;;C01P2002/52;;C04B35/462;;C04B2235/3287;;C04B2235/3293;;C04B35/472;;C04B2235/768;;H10N30/8548,C01G23/04,,0,0,,,,PENDING
125,AU,A1,AU 2002/360782 A1,050-012-222-523-408,2004-02-02,2004,AU 2002/360782 A,2002-12-27,US 19387902 A;;US 0241437 W,2002-07-12,FAN ASSEMBLY FOR AN UMBRELLA,,SUMMER BLAST LLC,COHEN RONALD B;;WALLEN WAYNE,,https://lens.org/050-012-222-523-408,Patent Application,no,0,0,7,12,0,A45B3/00;;A45B3/00;;A45B2023/0012;;A45B2023/0012;;A45B2200/1036;;A45B2200/1036;;F04D25/088;;F04D25/088,A45B3/00;;F04D25/08,,0,0,,,,DISCONTINUED
126,US,A,US 4743517 A,079-380-364-736-179,1988-05-10,1988,US 9030387 A,1987-08-27,US 9030387 A,1987-08-27,Fuel cell power plant with increased reactant pressures,"The fuel cell power plant operates at higher reactant pressures, and thus higher power density (lower cost) and efficiency, by providing reactant reformer steam from a separate steam boiler. Instead of supplying coolant steam to the reformer, the coolant is operated in a closed loop apart from the reformer, and the coolant steam is used to drive a steam generator to produce additional electricity. A portion of the raw fuel is burned within the steam boiler and the remainder is passed through the reformer and thence to the fuel cells. Boiler exhaust is used to drive a turocompressor which pressurizes the air used on the cathode side of the fuel cells.",INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,INTERNATIONAL FUEL CELLS CORPORATION A CORP. OF MARYLAND (1987-07-30),https://lens.org/079-380-364-736-179,Granted Patent,yes,8,34,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/06;;H01M8/04,429/17;;429/20,0,0,,,,EXPIRED
127,AT,B,AT 352810 B,046-363-629-211-553,1979-10-10,1979,AT 94076 A,1976-02-11,US 54960075 A,1975-02-12,BRENNSTOFFZELLENSTROMVERSORGUNGSANLAGE,,UNITED TECHNOLOGIES CORP,BLOOMFIELD DAVID PETER;;COHEN RONALD,,https://lens.org/046-363-629-211-553,Granted Patent,no,0,0,8,38,0,F02C6/00;;F02C6/10;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;H01M8/0612;;Y02E60/50;;H01M8/0612;;H01M8/04014;;H01M8/04156;;H01M8/04007;;H01M8/04089;;F02C6/00;;F02C6/10;;H01M8/04029,F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,"21B ,010",0,0,,,,EXPIRED
128,AT,A,AT A94076 A,173-839-227-837-444,1979-03-15,1979,AT 94076 A,1976-02-11,US 54960075 A,1975-02-12,BRENNSTOFFZELLENSTROMVERSORGUNGSANLAGE,,UNITED TECHNOLOGIES CORP,BLOOMFIELD DAVID PETER;;COHEN RONALD,,https://lens.org/173-839-227-837-444,Patent Application,no,0,0,8,38,0,F02C6/00;;F02C6/10;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;H01M8/0612;;Y02E60/50;;H01M8/0612;;H01M8/04014;;H01M8/04156;;H01M8/04007;;H01M8/04089;;F02C6/00;;F02C6/10;;H01M8/04029,F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,"21B ,010",0,0,,,,EXPIRED
129,CA,A,CA 958762 A,010-334-172-754-339,1974-12-03,1974,CA 135639 A,1972-02-25,US 12877471 A,1971-03-29,DUAL MODE FUEL CELL SYSTEM,,UNITED AIRCRAFT CORP,STEDMAN JAMES K;;COHEN RONALD,,https://lens.org/010-334-172-754-339,Granted Patent,no,0,0,4,4,0,H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04097;;H01M8/04119;;H01M8/04156;;Y02E60/50;;H01M8/04007;;H01M8/04156;;H01M8/04029;;H01M8/04097;;H01M8/04014;;H01M8/04119,H01M8/04,319-2,0,0,,,,EXPIRED
130,ES,A4,ES 2008644 A4,058-450-013-501-211,1989-08-01,1989,ES 88113992 T,1988-08-26,US 9030387 A,1987-08-27,SISTEMA DE INSTALACION DE PRODUCCION DE ENERGIA DEL TIPO DE PILAS DE COMBUSTIBLE CON PRESIONES ELEVADAS DEL REACTIVO.,"PLANTA ELECTRICA DE CELULA ELECTROQUIMICA QUE OPERA A PRESIONES REACTIVAS MAS ELEVADAS, CON UNA DENSIDAD DE ENERGIA ELECTRICA MAS ALTA (A MENOR COSTE) Y MAYOR EFICACIA, PROPORCIONANDO VAPOR (42) DE CONVERSION REACTIVO PROVENIENTE DE UNA CALDERA DE VAPOR (42). EN LUGAR DE SUMINISTRAR VAPOR DE REFRIGERACION AL CONVERTIDOR (46), EL REFRIGERANTE ES OPERADO EN UN CIRCUITO CERRADO (10,12) SEPARADO DEL CONVERTIDOR (46), Y EL VAPOR REFRIGERANTE ES UTILIZADO PARA ACTIVAR UN GENERADOR DE VAPOR (20,22) PARA PRODUCIR ELECTRICIDAD ADICIONAL. PARTE DEL COMBUSTIBLE CRUDO (40) ES QUEMADO EN LA CALDERA DE VAPOR Y EL RESTO PASA POR EL CONVERTIDOR Y DE AHI A LAS CELULAS ELECTROQUIMICAS (2). LA EXHAUSTACION (64) DE LA CALDERA ES UTILIZADA PARA ACCIONAR UN TURBOCOMPRESOR (62) QUE PRESURIZA EL AIRE (30) UTILIZADO EN EL CATODO (6) DE LAS CELULAS ELECTROQUIMICAS.",INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/058-450-013-501-211,Patent Application,no,0,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
131,US,A,US 4828940 A,145-965-088-124-891,1989-05-09,1989,US 18993588 A,1988-05-03,US 18993588 A;;US 9030387 A,1987-08-27,Fuel cell power plant with increased reactant pressures,"The fuel cell power plant operates at higher reactant pressures, and thus higher power density (lower cost) and efficiency, by providing reactant reformer steam from a separate steam boiler. Instead of supplying coolant steam to the reformer, the coolant is operated in a closed loop apart from the reformer, and the coolant steam is used to drive a steam generator to produce additional electricity. A portion of the raw fuel is burned within the steam boiler and the remainder is passed through the reformer and thence to the fuel cells. Boiler exhaust is used to drive a turocompressor which pressurizes the air used on the cathode side of the fuel cells.",INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/145-965-088-124-891,Granted Patent,yes,1,66,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/06;;H01M8/04,429/20,0,0,,,,EXPIRED
132,EP,A3,EP 1814060 A3,166-618-445-445-710,2008-12-10,2008,EP 06018047 A,2006-08-29,US 34209406 A,2006-01-26,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image. The identification is carried out remotely; the object is associated with an information address, which is utilized to retrieve an item of information related to the object.
",EVRYX TECHNOLOGIES INC,BONCYK WAYNE;;COHEN RONALD H,,https://lens.org/166-618-445-445-710,Search Report,yes,3,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,DISCONTINUED
133,DE,D1,DE 3868784 D1,169-300-096-947-147,1992-04-09,1992,DE 3868784 T,1988-08-26,US 9030387 A,1987-08-27,BRENNSTOFFZELLEN-KRAFTANLAGE MIT ERHOEHTEN REAKTIONSSTOFFDRUECKEN.,,INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/169-300-096-947-147,Granted Patent,no,0,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
134,US,B2,US 6732752 B2,025-305-418-548-247,2004-05-11,2004,US 609701 A,2001-12-04,US 609701 A;;US 55018300 A,2000-04-14,Fan assembly for an umbrella,"
    A fan assembly for an umbrella including a first integrated sub-assembly clampable about an umbrella pole. The first integrated sub-assembly has a split collar surrounding the umbrella pole, a support housing on a lower end of the collar defining a drive ring support plate, and a motor housing enclosing a motor therein on an upper end of the collar spaced from the drive ring support plate. A second integrated sub-assembly is rotatably disposable about the collar and the umbrella pole and includes a drive ring having a lower surface which is supported by the drive ring support plate of the support housing, a drive ring drive mechanism, and a plurality of fan blades coupled to the drive ring. 
",CONTINENTAL IND INC,COHEN RONALD B;;WALLEN WAYNE,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;CONTINENTAL INDUSTRIES INC (2002-02-25);;SUMMER BLAST LLC (2002-09-24),https://lens.org/025-305-418-548-247,Granted Patent,yes,17,27,2,12,0,A45B3/00;;A45B2200/1036;;A45B2200/1063;;F04D25/088;;A45B3/00;;A45B2200/1063;;F04D25/088;;A45B2200/1036,A45B3/00;;F04D25/08,135/16;;X416244 R;;417/313,0,0,,,,EXPIRED
135,US,A,US 5069985 A,120-508-854-672-344,1991-12-03,1991,US 48024390 A,1990-02-15,US 48024390 A,1990-02-15,Plaque fuel cell stack,"A stacked fuel cell has a plurality of cell plaques, each plaque having a plurality of horizontally disposed fuel cells placed in an insulating frame. By utilizing a plurality of cell plaques, overall fuel cell stack voltage can be substantially increased by interconnecting adjacent plaque cells to form substacks which are in turn connected in series. Thus stack voltage is increased without requiring additional fuel cell height.",INT FUEL CELLS CORP,COHEN RONALD;;HALL EUGENE W,INTERNATIONAL FUEL CELLS CORPORATION A CORP. OF MD (1990-02-13),https://lens.org/120-508-854-672-344,Granted Patent,yes,5,38,1,1,0,H01M8/04007;;H01M8/04074;;Y02E60/50;;H01M8/2484;;H01M8/0273;;H01M8/2484;;H01M8/04074;;H01M8/04007,H01M8/02;;H01M8/04;;H01M8/24,429/26;;429/38;;429/39,0,0,,,,EXPIRED
136,WO,A2,WO 2007/089533 A2,084-999-618-415-878,2007-08-09,2007,US 2007/0002010 W,2007-01-23,US 34209406 A,2006-01-26,DATA CAPTURE AND IDENTIFICATION SYSTEM AND PROCESS,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES INC;;BONCYK WAYNE C;;COHEN RONALD,BONCYK WAYNE C;;COHEN RONALD,,https://lens.org/084-999-618-415-878,Patent Application,yes,0,1,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,H04N7/14;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,PENDING
137,DK,D0,DK 479288 D0,115-708-485-241-308,1988-08-26,1988,DK 479288 A,1988-08-26,US 9030387 A,1987-08-27,BRAENDSELSCELLEKRAFTANLAEG MED FOROEGEDE REAKTANTTRYK,,INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/115-708-485-241-308,Patent Application,no,0,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,0,0,,,,DISCONTINUED
138,DK,A,DK 479288 A,119-541-980-595-799,1989-02-28,1989,DK 479288 A,1988-08-26,US 9030387 A,1987-08-27,BRAENDSELSCELLEKRAFTANLAEG MED FOROEGEDE REAKTANTTRYK,,INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/119-541-980-595-799,Patent Application,no,0,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,0,0,,,,DISCONTINUED
139,ES,T3,ES 2008644 T3,124-097-300-776-688,1992-10-16,1992,ES 88113992 T,1988-08-26,US 9030387 A,1987-08-27,SISTEMA DE INSTALACION DE PRODUCCION DE ENERGIA DEL TIPO DE PILAS DE COMBUSTIBLE CON PRESIONES ELEVADAS DEL REACTIVO.,"PLANTA ELECTRICA DE CELULA ELECTROQUIMICA QUE OPERA A PRESIONES REACTIVAS MAS ELEVADAS, CON UNA DENSIDAD DE ENERGIA ELECTRICA MAS ALTA (A MENOR COSTE) Y MAYOR EFICACIA, PROPORCIONANDO VAPOR (42) DE CONVERSION REACTIVO PROVENIENTE DE UNA CALDERA DE VAPOR (42). EN LUGAR DE SUMINISTRAR VAPOR DE REFRIGERACION AL CONVERTIDOR (46), EL REFRIGERANTE ES OPERADO EN UN CIRCUITO CERRADO (10,12) SEPARADO DEL CONVERTIDOR (46), Y EL VAPOR REFRIGERANTE ES UTILIZADO PARA ACTIVAR UN GENERADOR DE VAPOR (20,22) PARA PRODUCIR ELECTRICIDAD ADICIONAL. PARTE DEL COMBUSTIBLE CRUDO (40) ES QUEMADO EN LA CALDERA DE VAPOR Y EL RESTO PASA POR EL CONVERTIDOR Y DE AHI A LAS CELULAS ELECTROQUIMICAS (2). LA EXHAUSTACION (64) DE LA CALDERA ES UTILIZADA PARA ACCIONAR UN TURBOCOMPRESOR (62) QUE PRESURIZA EL AIRE (30) UTILIZADO EN EL CATODO (6) DE LAS CELULAS ELECTROQUIMICAS.",INTERNATIONAL FUEL CELLS CORPORATION,"COHEN, RONALD;;BUSWELL, RICHARD F.",,https://lens.org/124-097-300-776-688,Granted Patent,no,0,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
140,EP,A2,EP 1814060 A2,150-959-119-687-92X,2007-08-01,2007,EP 06018047 A,2006-08-29,US 34209406 A,2006-01-26,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image. The identification is carried out remotely; the object is associated with an information address, which is utilized to retrieve an item of information related to the object.
",EVRYX TECHNOLOGIES INC,BONCYK WAYNE;;COHEN RONALD H,,https://lens.org/150-959-119-687-92X,Patent Application,yes,0,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,DISCONTINUED
141,US,B2,US 6840742 B2,058-860-737-753-205,2005-01-11,2005,US 19387902 A,2002-07-12,US 19387902 A;;US 609701 A,2001-12-04,Fan assembly for an umbrella,"A fan assembly with a split collar clampable about a pole, the split collar including a drive ring support. A split motor housing is clampable about the split collar and the split motor housing includes a drive mechanism. A split drive ring is rotatably clampable about the split collar and supported by the drive ring support. The split drive ring includes a driven mechanism driven by the drive mechanism. A plurality of fan blades are coupled to the split drive ring.",NEW PRODUCTS TOO LLC,COHEN RONALD B;;WALLEN WAYNE,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;SUMMER BLAST LLC (2002-10-07),https://lens.org/058-860-737-753-205,Granted Patent,yes,16,6,7,12,0,A45B3/00;;A45B3/00;;A45B2023/0012;;A45B2023/0012;;A45B2200/1036;;A45B2200/1036;;F04D25/088;;F04D25/088,A45B3/00;;F04D25/08,416244R;;135/16,0,0,,,,EXPIRED
142,WO,A3,WO 2007/089533 A3,087-151-952-308-251,2008-01-10,2008,US 2007/0002010 W,2007-01-23,US 34209406 A,2006-01-26,DATA CAPTURE AND IDENTIFICATION SYSTEM AND PROCESS,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES INC;;BONCYK WAYNE C;;COHEN RONALD,BONCYK WAYNE C;;COHEN RONALD,,https://lens.org/087-151-952-308-251,Search Report,yes,4,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,PENDING
143,US,A,US 4948639 A,103-523-330-012-352,1990-08-14,1990,US 43530189 A,1989-11-13,US 43530189 A;;US 24168288 A;;US 89252986 A,1986-07-31,Vacuum cleaner bag,"Particle-laden meltblown material, methods of forming such material, composite laminate fabrics using such material as a layer of the laminate, and uses of such material and/or laminate thereof are disclosed. The particle-laden meltblown material is a coform of the particles and meltblown fibers, consolidated into a meltblown material. The meltblown fibers are made of polymeric materials such that the fibers are tacky after extrusion from the meltblowing die and prior to consolidation as meltblown material; active particles (such as active carbon) are incorporated in the stream of meltblown fibers, as the fibers pass from the die to the consolidation surface, at a location where the fibers are tacky, so that the particles adhere to the surface of the fibers. The polymeric materials forming the meltblown fibers can be elastomeric materials, and/or blends of polymers. The formed meltblown material can be used as a layer of a laminate, with other layers of the laminate providing abrasion resistance and mechanical strength. The meltblown material, and/or laminate including the meltblown material, can be used for gas/vapor filtering and/or adsorbing, and specifically can be used for disposable vacuum cleaner bags and the like.",KIMBERLY CLARK CO,BROOKER RONALD W;;COHEN BERNARD,KIMBERLY-CLARK WORLDWIDE INC (1996-11-30),https://lens.org/103-523-330-012-352,Granted Patent,yes,30,102,1,7,0,A61F2013/15967;;A61F2013/15967;;A61F2013/530496;;A61F2013/530496;;B01D39/1623;;B01D39/1623;;B01D2239/0407;;B01D2239/0407;;B01D2239/0618;;B01D2239/0618;;B01D2239/0622;;B01D2239/0622;;B01D2239/0627;;B01D2239/0627;;B01D2239/064;;B01D2239/064;;B01D2239/065;;B01D2239/065;;B01D2239/0654;;B01D2239/0654;;B01D2239/086;;B01D2239/086;;B01D2239/10;;B01D2239/10;;B01D2239/1233;;B01D2239/1233;;B01D2239/1241;;B01D2239/1241;;D04H1/56;;D04H1/56;;Y10T428/1334;;Y10T428/1334;;Y10T428/1345;;Y10T428/1345;;Y10T428/1362;;Y10T428/1362,B01D39/08;;B01D39/16;;D04H1/56,428/35.2;;383/117;;428/35.5;;428/36.1,1,0,,,"Butin, Rober R. et al., Melt Blowing A One Step Web Process for New Nonwoven Products, TAPPI, vol. 56, No. 4, Apr. 1973, pp. 74 77.",EXPIRED
144,EP,A1,EP 0304949 A1,143-870-974-603-622,1989-03-01,1989,EP 88113992 A,1988-08-26,US 9030387 A,1987-08-27,Fuel cell power plant with increased reactant pressures.,"The fuel cell power plant operates at higher reactant pressures, and thus higher power density (lower cost) and efficiency, by providing reactant reformer steam (42) from a separate steam boiler (42). Instead of supplying coolant steam to the reformer, the coolant is operated in a closed loop apart (10, 12) from the reformer (46), and the coolant steam is used to drive a steam generator (20, 22) to produce additional electricity. A portion of the raw fuel (40) is burned within the steam boiler and the remainder is passed through the reformer and thence to the fuel cells (2). Boiler exhaust (64) is used to drive a turocompressor (62) which pressurizes the air (30) used on the cathode side (6) of the fuel cells.  ",INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/143-870-974-603-622,Patent Application,yes,5,6,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,3,0,,,"PATENT ABSTRACTS OF JAPAN, vol. 11, no. 275 (E-537)[2722], 5th September 1987; & JP-A-62 076 163 (TOSHIBA CORP.) 08-04-1987;;PATENT ABSTRACTS OF JAPAN, vol. 7, no. 107 (E-174)[1252], 11th May 1983; & JP-A-58 028 176 (TOKYO SHIBAURA DENKI K.K.) 19-02-1983;;PATENT ABSTRACTS OF JAPAN, vol. 7, no. 76 (E-167)[1221], 30th March 1983; & JP-A-58 005 974 (TOKYO SHIBAURA DENKI K.K.) 13-11-1983",EXPIRED
145,US,A1,US 2003/0168091 A1,156-506-380-663-741,2003-09-11,2003,US 33574503 A,2003-01-02,US 33574503 A;;US 19387902 A;;US 609701 A,2001-12-04,Fan assembly for an umbrella,"
   A fan assembly with a split collar clampable about a pole, the split collar including a drive ring support. A split motor housing is clampable about the split collar and the split motor housing includes a drive mechanism. A split drive ring is rotatably clampable about the split collar and supported by the drive ring support. The split drive ring includes a driven mechanism driven by the drive mechanism. A plurality of fan blades are coupled to the split drive ring. The fan assembly can be easily raised up or lowered down an umbrella pole. When the fan assembly is in the lowered position and the fan blades are removed, the umbrella can be easily stored away with the fan assembly still assembled about the umbrella pole. 
",COHEN RONALD B.;;WALLEN WAYNE,COHEN RONALD B;;WALLEN WAYNE,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;SUMMER BLAST LLC (2003-06-13),https://lens.org/156-506-380-663-741,Patent Application,yes,0,13,2,12,0,A45B3/00;;A45B2200/1036;;F04D25/088;;F04D25/088;;A45B3/00;;A45B2200/1036,A45B3/00;;F04D25/08,135/16,0,0,,,,EXPIRED
146,CA,A,CA 673600 A,060-813-905-600-188,1963-11-05,1963,CA 673600D A,,CA 673600T A,,PICKLING ZIRCONIUM AND ZIRCONIUM BASE ALLOYS,,WESTINGHOUSE ELECTRIC CORP,WATKINS ROBERT M;;COHEN RONALD,,https://lens.org/060-813-905-600-188,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
147,US,A,US 3972731 A,075-024-154-745-628,1976-08-03,1976,US 54960075 A,1975-02-12,US 54960075 A,1975-02-12,Pressurized fuel cell power plant,"A fuel cell power plant for producing electricity uses pressurized reactants in the cells. The air is compressed by compressor apparatus which is powered by waste energy produced by the power plant in the form of a hot pressurized gaseous medium, such as the exhaust gases from the cathode side of the cells. For example, the compressor apparatus may comprise a compressor and a turbine which are operably connected. The exhaust gases from the cathode side of the cell are delivered into the turbine which drives the compressor for compressing the air delivered to the cells.",UNITED TECHNOLOGIES CORP,BLOOMFIELD DAVID P;;COHEN RONALD,,https://lens.org/075-024-154-745-628,Granted Patent,yes,7,83,8,38,0,F02C6/00;;F02C6/10;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;H01M8/0612;;Y02E60/50;;H01M8/0612;;H01M8/04014;;H01M8/04156;;H01M8/04007;;H01M8/04089;;F02C6/00;;F02C6/10;;H01M8/04029,F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,136 86R,0,0,,,,EXPIRED
148,US,A,US 2946820 A,183-714-327-399-190,1960-07-26,1960,US 14455450 A,1950-02-16,US 14455450 A,1950-02-16,High bulk density nitroguanidine,,HENRY RONALD A;;JOSEPH COHEN,HENRY RONALD A;;JOSEPH COHEN,,https://lens.org/183-714-327-399-190,Granted Patent,no,2,7,1,1,0,C07C279/36;;C07C277/08;;C07C279/36,,,0,0,,,,EXPIRED
149,US,B2,US 6796318 B2,163-563-236-215-113,2004-09-28,2004,US 33574503 A,2003-01-02,US 33574503 A;;US 19387902 A;;US 609701 A,2001-12-04,Fan assembly for an umbrella,"
    A fan assembly with a split collar clampable about a pole, the split collar including a drive ring support. A split motor housing is clampable about the split collar and the split motor housing includes a drive mechanism. A split drive ring is rotatably clampable about the split collar and supported by the drive ring support. The split drive ring includes a driven mechanism driven by the drive mechanism. A plurality of fan blades are coupled to the split drive ring. The fan assembly can be easily raised up or lowered down an umbrella pole. When the fan assembly is in the lowered position and the fan blades are removed, the umbrella can be easily stored away with the fan assembly still assembled about the umbrella pole. 
",NEW PRODUCTS TOO LLC,COHEN RONALD B;;WALLEN WAYNE,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;SUMMER BLAST LLC (2003-06-13),https://lens.org/163-563-236-215-113,Granted Patent,yes,18,21,2,12,0,A45B3/00;;A45B2200/1036;;F04D25/088;;F04D25/088;;A45B3/00;;A45B2200/1036,A45B3/00;;F04D25/08,135/16;;X416224 R,0,0,,,,EXPIRED
150,US,A1,US 2002/0096203 A1,060-410-275-726-82X,2002-07-25,2002,US 609701 A,2001-12-04,US 609701 A;;US 55018300 A,2000-04-14,Fan assembly for an umbrella,"
   A fan assembly for an umbrella including a first integrated sub-assembly clampable about an umbrella pole. The first integrated sub-assembly has a split collar surrounding the umbrella pole, a support housing on a lower end of the collar defining a drive ring support plate, and a motor housing enclosing a motor therein on an upper end of the collar spaced from the drive ring support plate. A second integrated sub-assembly is rotatably disposable about the collar and the umbrella pole and includes a drive ring having a lower surface which is supported by the drive ring support plate of the support housing, a drive ring drive mechanism, and a plurality of fan blades coupled to the drive ring. 
",COHEN RONALD B.;;WALLEN WAYNE,COHEN RONALD B;;WALLEN WAYNE,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;CONTINENTAL INDUSTRIES INC (2002-02-25);;SUMMER BLAST LLC (2002-09-24),https://lens.org/060-410-275-726-82X,Patent Application,yes,0,13,2,12,0,A45B3/00;;A45B2200/1036;;A45B2200/1063;;F04D25/088;;A45B3/00;;A45B2200/1063;;F04D25/088;;A45B2200/1036,A45B3/00;;F04D25/08,135/16;;417/313;;416/5,0,0,,,,EXPIRED
151,US,A,US 3704172 A,087-630-648-954-505,1972-11-28,1972,US 3704172D A,1971-03-29,US 12877471 A,1971-03-29,DUAL MODE FUEL CELL SYSTEM,,UNITED AIRCRAFT CORP,STEDMAN JAMES K;;COHEN RONALD,,https://lens.org/087-630-648-954-505,Granted Patent,no,0,21,4,4,0,H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04097;;H01M8/04119;;H01M8/04156;;Y02E60/50;;H01M8/04007;;H01M8/04156;;H01M8/04029;;H01M8/04097;;H01M8/04014;;H01M8/04119,H01M8/04,136 86   C,0,0,,,,EXPIRED
152,US,A1,US 2006/0266341 A1,079-103-483-253-166,2006-11-30,2006,US 13801705 A,2005-05-26,US 13801705 A,2005-05-26,Paint ball simulation toy,"A paint ball simulation toy including a number of darts, a launcher configured to propel the darts, and a number of stickers each carried by a dart and configured to simulate a paint ball strike.",HAMBRIGHT PERRY;;COHEN RONALD B,HAMBRIGHT PERRY;;COHEN RONALD B,NEW PRODUCTS LLC (2006-02-27);;NEW PRODUCTS TOO LLC (2005-05-20),https://lens.org/079-103-483-253-166,Patent Application,yes,7,10,1,1,0,F41B7/08;;F41B11/00;;F42B6/00;;F41B11/00;;F42B6/00;;F41B7/08,F41B7/08,124/16;;473/578,0,0,,,,DISCONTINUED
153,US,A1,US 2003/0102021 A1,073-964-724-904-502,2003-06-05,2003,US 19387902 A,2002-07-12,US 19387902 A;;US 609701 A,2001-12-04,Fan assembly for an umbrella,"
   A fan assembly with a split collar clampable about a pole, the split collar including a drive ring support. A split motor housing is clampable about the split collar and the split motor housing includes a drive mechanism. A split drive ring is rotatably clampable about the split collar and supported by the drive ring support. The split drive ring includes a driven mechanism driven by the drive mechanism. A plurality of fan blades are coupled to the split drive ring. 
",COHEN RONALD B.;;WALLEN WAYNE,COHEN RONALD B;;WALLEN WAYNE,GREAT IMPORTANCE LLC (2010-07-29);;NEW PRODUCTS TOO LLC (2004-03-02);;SUMMER BLAST LLC (2002-10-07),https://lens.org/073-964-724-904-502,Patent Application,yes,0,12,7,12,0,A45B3/00;;A45B3/00;;A45B2023/0012;;A45B2023/0012;;A45B2200/1036;;A45B2200/1036;;F04D25/088;;F04D25/088,A45B3/00;;F04D25/08,135/16,0,0,,,,EXPIRED
154,GB,A,GB 2406048 A,136-052-281-362-063,2005-03-23,2005,GB 0500573 A,2002-12-27,US 0241437 W;;US 19387902 A,2002-07-12,Fan assembly for an umbrella,"A fan assembly with a split collar (100) clampable about a pole (12), the split collar (100) including a drive ring support (106). A split motor housing (120) is clampable about the split collar (100) and the split motor housing (120) includes a drive mechanism (130). A split drive ring (140, 142) is rotatably clampable about the split collar (100) and supported by the drive ring support (106). The split drive ring (140, 142) includes a driven mechanism (144) driven by the drive mechanism (130). A plurality of fan blades (160) are coupled to the split drive ring (140, 142). The fan assembly can be easily raised up or lowered down an umbrella pole (12). When the fan assembly is in the lowered position and the fan blades (160) are removed, the umbrella (10) can be easily stored away with the fan assembly still assembled about the umbrella pole (12).",SUMMER BLAST LLC,COHEN RONALD B;;WALLEN WAYNE,,https://lens.org/136-052-281-362-063,Patent Application,no,5,0,7,12,0,A45B3/00;;A45B3/00;;A45B2023/0012;;A45B2023/0012;;A45B2200/1036;;A45B2200/1036;;F04D25/088;;F04D25/088,A45B3/00;;F04D25/08,A4P PAA           PAA230;;A4P P230          PAA230,0,0,,,,EXPIRED
155,CA,A,CA 1043861 A,145-359-982-422-981,1978-12-05,1978,CA 244683 A,1976-01-27,US 54960075 A,1975-02-12,PRESSURIZED FUEL CELL POWER PLANT,"PRESSURIZED FUEL CELL POWER PLANT A fuel cell power plant for producing electricity uses pressurized reactants in the cells. The air is compressed by compressor apparatus which is powered by waste energy produced by the power plant in the form of a hot pressurized gaseous medium, such as the exhaust gases from the cathode side of the cells. For example, the compressor apparatus may comprise a compressor and a turbine which are operably connected. The exhaust gases from the cathode side of the cell are delivered into the turbine which drives the compressor for compressing the air delivered to the cells.",UNITED TECHNOLOGIES CORP,BLOOMFIELD DAVID P;;COHEN RONALD,,https://lens.org/145-359-982-422-981,Granted Patent,no,0,0,8,38,0,F02C6/00;;F02C6/10;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;H01M8/0612;;Y02E60/50;;H01M8/0612;;H01M8/04014;;H01M8/04156;;H01M8/04007;;H01M8/04089;;F02C6/00;;F02C6/10;;H01M8/04029,F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,319-2,0,0,,,,EXPIRED
156,WO,A1,WO 2004/006711 A1,191-869-296-572-769,2004-01-22,2004,US 0241437 W,2002-12-27,US 19387902 A,2002-07-12,FAN ASSEMBLY FOR AN UMBRELLA,"A fan assembly with a split collar (100) clampable about a pole (12), the split collar (100) including a drive ring support (106). A split motor housing (120) is clampable about the split collar (100) and the split motor housing (120) includes a drive mechanism (130). A split drive ring (140, 142) is rotatably clampable about the split collar (100) and supported by the drive ring support (106). The split drive ring (140, 142) includes a driven mechanism (144) driven by the drive mechanism (130). A plurality of fan blades (160) are coupled to the split drive ring (140, 142). The fan assembly can be easily raised up or lowered down an umbrella pole (12). When the fan assembly is in the lowered position and the fan blades (160) are removed, the umbrella (10) can be easily stored away with the fan assembly still assembled about the umbrella pole (12).",SUMMER BLAST LLC,COHEN RONALD B;;WALLEN WAYNE,,https://lens.org/191-869-296-572-769,Patent Application,yes,5,1,7,12,0,A45B3/00;;A45B3/00;;A45B2023/0012;;A45B2023/0012;;A45B2200/1036;;A45B2200/1036;;F04D25/088;;F04D25/088,A45B3/00;;F04D25/08,,0,0,,,,PENDING
157,GB,B,GB 2406048 B,001-942-861-180-740,2005-10-05,2005,GB 0500573 A,2002-12-27,US 0241437 W;;US 19387902 A,2002-07-12,Fan assembly for an umbrella,,SUMMER BLAST LLC,COHEN RONALD B;;WALLEN WAYNE,,https://lens.org/001-942-861-180-740,Granted Patent,no,5,0,7,12,0,A45B3/00;;A45B3/00;;A45B2023/0012;;A45B2023/0012;;A45B2200/1036;;A45B2200/1036;;F04D25/088;;F04D25/088,A45B3/00;;F04D25/08,A4P PAA           PAA230;;A4P P230          PAA230,0,0,,,,EXPIRED
158,GB,A,GB 851637 A,064-511-965-929-905,1960-10-19,1960,GB 3009358 A,1958-09-19,GB 3009358 A,1958-09-19,Improvements in or relating to gas-filled electric discharge tubes,"851,637. Cold cathode discharge tubes. GENERAL ELECTRIC CO. Ltd. July 22, 1959 [Sept. 19, 1958], No. 30093/58. Class 39(1). A gas filled corona stabiliser tube comprises tubular cathode 2 and internally and coaxially disposed wire helical anode 3 extending along the whole length ofthe cathode, the anode-cathode spacing being larger than the diameter of the wire but smaller than the pitch of the helix. The electrodes are supported between ceramic members 4, 5, held in glass tubular envelope 1 by mica spacers 6, 7. Anode lead 12, cathode leads 10, 11 passing through the envelope. The anode wire may be of iron, nickel, molybdenum or tungsten and the cathode of iron or nickel. The gas filling is hydrogen at 55 cms. of mercury. The dimensions of the electrodes are given.",GEN ELECTRIC CO LTD,COHEN EDWARD;;JENKINS RONALD OSMOND,,https://lens.org/064-511-965-929-905,Granted Patent,no,0,0,1,1,0,H01J17/00;;H01J2893/0064,H01J17/00,H1D DG            GX;;H1D DGX           GX;;H1D D12B47Y       8E;;H1D D12B6         8E;;H1D D12C          8E;;H1D D17D          8E;;H1D D38           8E;;H1D D8X           8E,0,0,,,,EXPIRED
159,CA,C,CA 1299648 C,091-041-540-170-302,1992-04-28,1992,CA 574973 A,1988-08-17,US 9030387 A,1987-08-27,FUEL CELL POWER PLANT WITH INCREASED REACTANT PRESSURES,"Fuel Cell Power Plant with Increased Reactant Pressures The fuel cell power plant operates at higher reactant pressures, and thus higher power density (lower cost) and efficiency, by providing reactant reformer steam from a separate steam boiler. Instead of supplying coolant steam to the reformer, the coolant is operated in a closed loop apart from the reformer, and the coolant steam is used to drive a steam generator to produce additional electricity. A portion of the raw fuel is burned within the steam boiler and the remainder is passed through the reformer and thence to the fuel cells. Boiler exhaust is used to drive a turocompressor which pressurized the air used on the cathode side of the fuel cells. C-1521",INT FUEL CELLS CORP,COHEN RONALD;;BUSWELL RICHARD F,,https://lens.org/091-041-540-170-302,Granted Patent,no,0,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,D33190002    M;;3220035    S,0,0,,,,EXPIRED
160,EP,B1,EP 0304949 B1,187-672-216-012-603,1992-03-04,1992,EP 88113992 A,1988-08-26,US 9030387 A,1987-08-27,FUEL CELL POWER PLANT WITH INCREASED REACTANT PRESSURES,,INTERNATIONAL FUEL CELLS CORPORATION,"COHEN, RONALD;;BUSWELL, RICHARD F.",,https://lens.org/187-672-216-012-603,Granted Patent,yes,5,0,11,11,0,H01M8/0612;;Y02E60/50;;H01M8/0612,H01M8/04;;H01M8/06,,3,0,,,"PATENT ABSTRACTS OF JAPAN, vol. 11, no. 275 (E-537)[2722], 5th September 1987; & JP-A-62 76 163 (TOSHIBA CORP.) 08-04-1987;;PATENT ABSTRACTS OF JAPAN, vol. 7, no. 107 (E-174)[1252], 11th May 1983; & JP-A-58 28 176 (TOKYO SHIBAURA DENKI K.K.) 19-02-1983;;PATENT ABSTRACTS OF JAPAN, vol. 7, no. 76 (E-167)[1221], 30th March 1983; & JP-A-58 5974 (TOKYO SHIBAURA DENKI K.K.) 13-11-1983",EXPIRED
161,US,B2,US 9141714 B2,004-533-319-379-110,2015-09-22,2015,US 201414536412 A,2014-11-07,US 201414536412 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/004-533-319-379-110,Granted Patent,yes,109,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference On Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications In Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection In Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems For Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects In The Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features For Image Retrieval,"" IEEE Transactions On Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design And Implementation Of A Snapshot Based Method For Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision And Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility To Create Ubiquitous And Active Augmented Reality In Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target And Pose Recognition For 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens To Access, Manage and Share Bookmarks On The Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through The Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach To Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework For Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing A Natural User Interface For Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation And Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
162,US,A1,US 2014/0059580 A1,002-258-248-983-305,2014-02-27,2014,US 201314070642 A,2013-11-04,US 201314070642 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/002-258-248-983-305,Patent Application,yes,9,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N21/81;;H04N21/254;;H04N21/442,725/18;;725/19,0,0,,,,EXPIRED
163,US,A1,US 2014/0177916 A1,011-490-491-943-998,2014-06-26,2014,US 201414189015 A,2014-02-25,US 201414189015 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/011-490-491-943-998,Patent Application,yes,6,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/00,382/103,0,0,,,,EXPIRED
164,US,A1,US 2014/0064561 A1,011-771-238-289-030,2014-03-06,2014,US 201314073760 A,2013-11-06,US 201314073760 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/011-771-238-289-030,Patent Application,yes,9,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06K9/78,382/103,0,0,,,,EXPIRED
165,WO,A1,WO 1988/006700 A1,017-731-916-099-677,1988-09-07,1988,US 8800579 W,1988-02-23,US 1831787 A,1987-02-24,DOWNDRAFT WOODSTOVE,"A stove for burning solid fuel comprising a primary combustion chamber (20) for burning and gasifying said solid fuel and a secondary combustion chamber (120) positioned beneath said primary combustion chamber (20) for burning gases created in said primary combustion chamber during the burning and gasification of said solid fuel. A hollow floor (30) is positioned between the primary and secondary combustion chambers (20, 120) and an aperture (34) is provided in the floor (30) pneumatically coupling the primary combustion chamber (20) with the secondary combustion chamber (120). Atmospheric air for supporting the combustion of the solid fuel and gases produced during the combustion of the solid fuel is separately introduced into both the primary and secondary combustion chambers (20, 120). Gases generated during the combustion of the solid fuel in the primary chamber (20) are drawn downwardly from the primary combustion chamber (20) through the aperture (34) into the secondary combustion chamber (120) where the gases continue to burn. Residual combustible gases are mixed with air in the secondary combustion chamber (120) and are drawn out of the stove through a tertiary chamber (320). Optionally, a catalytic converter (344) may be installed in the tertiary chamber (320) for burning the gas/air mixture that is exhausted from the secondary combustion chamber (120).",COHEN & PECK INC;;PLAMEN,COHEN RONALD;;ALBERTSEN PETER;;HAJEK VIKTOR,,https://lens.org/017-731-916-099-677,Patent Application,yes,18,6,2,2,0,F24B5/04;;F24B1/006,F24B1/00;;F24B5/04,F4W W42B          W42B;;F4W W42C          W42B,0,0,,,,PENDING
166,US,A1,US 2011/0155148 A1,016-715-689-312-581,2011-06-30,2011,US 201113047688 A,2011-03-14,US 201113047688 A;;US 2010/0057286 W;;US 26250309 P;;US 29700110 P,2009-11-18,SHOULDER IMMOBILIZER AND FRACTURE STABILIZATION DEVICE,"A shoulder immobilizer ( 20 ) includes a semi-rigid or rigid orthosis, in the form of an arm support ( 22 ), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster ( 24 ) is positioned between the patient and the arm support ( 22 ). A body strap ( 26 ) extends around the patient and attaches to the arm support ( 22 ) and/or the bolster ( 24 ), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer ( 20 ) may utilize a shoulder strap ( 28 ), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",CRADLE MEDICAL INC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD,CRADLE MEDICAL INC (2011-03-08),https://lens.org/016-715-689-312-581,Patent Application,yes,33,19,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/37,128/878,0,0,,,,ACTIVE
167,US,A1,US 2014/0043500 A1,048-426-774-018-213,2014-02-13,2014,US 201314058287 A,2013-10-21,US 201314058287 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/048-426-774-018-213,Patent Application,yes,5,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/225,348/222.1,0,0,,,,EXPIRED
168,US,B2,US 9110925 B2,074-121-416-974-550,2015-08-18,2015,US 201414464587 A,2014-08-20,US 201414464587 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/074-121-416-974-550,Granted Patent,yes,107,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
169,US,B2,US 8488880 B2,096-138-770-621-095,2013-07-16,2013,US 201213410668 A,2012-03-02,US 201213410668 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/096-138-770-621-095,Granted Patent,yes,102,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
170,FR,A1,FR 2579838 A1,099-590-034-499-271,1986-10-03,1986,FR 8604253 A,1986-03-25,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,CONNECTEUR ELECTRIQUE POUR CABLE ELECTRIQUE,"<P>L'INVENTION CONCERNE UN CONNECTEUR ELECTRIQUE POUR CABLE AXIAL A DEUX CONDUCTEURS.</P><P>IL COMPREND UN PREMIER ASSEMBLAGE 4 CONSTITUE D'UNE COQUE EXTERIEURE CONDUCTRICE6, D'UN PREMIER CORPS DIELECTRIQUE8, D'UNE COQUE INTERIEURE CONDUCTRICE10 ET D'UN SECOND CORPS DIELECTRIQUE, ET UN SECOND ASSEMBLAGE60 DESTINE A ETRE INSERE DANS LA COQUE EXTERIEURE6 ET A ETABLIR UNE CONNEXION AVEC LA COQUE INTERIEURE10. CE SECOND ASSEMBLAGE COMPREND UN PREMIER CORPS CONDUCTEUR62, UNE VIROLE CONDUCTRICE64, UN TROISIEME CORPS DIELECTRIQUE, UN CONTACT ELECTRIQUE70 ET UN SECOND CORPS CONDUCTEUR72.</P><P>DOMAINE D'APPLICATION : CONNECTEURS POUR CABLES AXIAUX A DEUX CONDUCTEURS.</P>",AMP INC,LAUDIG RONALD;;SMITH DONALD;;COHEN THOMAS,,https://lens.org/099-590-034-499-271,Patent Application,no,4,0,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,,0,0,,,,EXPIRED
171,WO,A1,WO 2003/041000 A1,106-223-232-338-02X,2003-05-15,2003,US 0235407 W,2002-11-05,US 99294201 A,2001-11-05,IMAGE CAPTURE AND IDENTIFICATION SYSTEM AND PROCESS,A digital image of the object (16) is captured and the object is recognized from plurality of objects in a database (20). An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/106-223-232-338-02X,Patent Application,yes,4,0,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,,1,0,,,See also references of EP 1442417A4,PENDING
172,AU,A,AU 1998/068712 A,091-949-241-570-242,1998-10-20,1998,AU 1998/068712 A,1998-03-20,US 82819597 A;;US 9806065 W,1997-03-21,"Substrates useful in both aqueous and organic media, and associated methods of preparation and use",,CHIRON CORP,ZUCKERMANN RONALD N;;COHEN FRED E,,https://lens.org/091-949-241-570-242,Patent Application,no,0,0,2,2,0,C07H21/00;;C07K1/04;;C07K1/042;;C07K1/047,C07H21/00;;C07K1/04,,0,0,,,,PENDING
173,US,B2,US 10080686 B2,121-216-235-354-373,2018-09-25,2018,US 201715711118 A,2017-09-21,US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"A digital image segment of a human body part is captured and matched against a reference image segment. If the match score meets a threshold, the digital image segment is stored and the human body part is recognized as a target object. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object. If the match score does not meet a threshold, a second image containing a representation of the human body part is obtained.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/121-216-235-354-373,Granted Patent,yes,421,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/136;;G06T7/246;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,40,20,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Hang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive computing, LinzNienna, Austria, 6 pages.;;Uebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
174,US,B2,US 9014512 B2,132-686-841-492-149,2015-04-21,2015,US 201314024639 A,2013-09-12,US 201314024639 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/132-686-841-492-149,Granted Patent,yes,100,4,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/60;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00,382/305;;705/26.1,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
175,US,B2,US 9785651 B2,123-081-886-410-743,2017-10-10,2017,US 201615169948 A,2016-06-01,US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/123-081-886-410-743,Granted Patent,yes,410,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-211.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
176,US,B2,US 9324004 B2,128-682-669-706-850,2016-04-26,2016,US 201314100431 A,2013-12-09,US 201314100431 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/128-682-669-706-850,Granted Patent,yes,112,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
177,US,A1,US 2012/0230543 A1,161-053-517-429-027,2012-09-13,2012,US 201213477954 A,2012-05-22,US 201213477954 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/161-053-517-429-027,Patent Application,yes,1,9,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/103,0,0,,,,EXPIRED
178,US,A1,US 2006/0002607 A1,173-024-873-407-724,2006-01-05,2006,US 20490105 A,2005-08-15,US 20490105 A;;US 0235407 W;;US 49224304 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Use of image-derived information as search criteria for internet and other search engines,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/173-024-873-407-724,Patent Application,yes,20,216,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F17/30,382/165;;707/3,0,0,,,,EXPIRED
179,US,A1,US 2014/0032330 A1,189-823-377-800-801,2014-01-30,2014,US 201314041322 A,2013-09-30,US 201314041322 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/189-823-377-800-801,Patent Application,yes,6,7,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/02,705/14.64,0,0,,,,EXPIRED
180,US,B2,US 9342748 B2,175-146-601-052-868,2016-05-17,2016,US 201514721627 A,2015-05-26,US 201514721627 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/175-146-601-052-868,Granted Patent,yes,106,27,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference On Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications In Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection In Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems For Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects In The Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features For Image Retrieval,"" IEEE Transactions On Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design And Implementation Of A Snapshot Based Method For Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision And Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility To Create Ubiquitous And Active Augmented Reality In Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target And Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks On The Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through The Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach To Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework For Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing A Natural User Interface For Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation And Information Access With Mobile Computers,"" Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality, 2001, pp. 179-180.",EXPIRED
181,US,B2,US 9330326 B2,174-742-136-278-777,2016-05-03,2016,US 201414474254 A,2014-09-01,US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/174-742-136-278-777,Granted Patent,yes,114,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference On Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions On Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for A Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of A Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing A Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
182,JP,A,JP 2012194984 A,173-238-559-580-311,2012-10-11,2012,JP 2012108209 A,2012-05-10,US 34209406 A,2006-01-26,SYSTEM AND METHOD FOR ACQUIRING AND IDENTIFYING DATA,"PROBLEM TO BE SOLVED: To digitally identify an image captured without requiring change of an object.SOLUTION: An identification method uses characteristics of an image for specifying an object from a plurality of objects in a database device. In order to identify an actual object in a digital image, data is broken down into parameters, such as shape comparison, grayscale comparison, wavelet comparison, and color cube comparison with object data in one or more databases.",EVRYX TECH INC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/173-238-559-580-311,Patent Application,no,5,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06T1/00;;G06F17/30;;G06V10/56;;G06V30/142;;H04N7/173;;H04N21/278;;H04N21/845,,0,0,,,,DISCONTINUED
183,US,A1,US 2015/0066936 A1,175-115-789-980-25X,2015-03-05,2015,US 201414536684 A,2014-11-10,US 201414536684 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/175-115-789-980-25X,Patent Application,yes,6,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30,707/737,0,0,,,,EXPIRED
184,US,A1,US 2006/0181605 A1,197-853-689-926-400,2006-08-17,2006,US 34209406 A,2006-01-26,US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/197-853-689-926-400,Patent Application,yes,21,13,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,H04N7/14;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,348/14.01,0,0,,,,EXPIRED
185,US,A1,US 2015/0302385 A1,008-908-777-122-391,2015-10-22,2015,US 201414558643 A,2014-12-02,US 201414558643 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/008-908-777-122-391,Patent Application,yes,8,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q20/32;;G06Q20/20,,0,0,,,,EXPIRED
186,US,B2,US 9805063 B2,049-105-182-185-236,2017-10-31,2017,US 201615298671 A,2016-10-20,US 201615298671 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing de ice submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/049-105-182-185-236,Granted Patent,yes,412,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar, 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, ) pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content- Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
187,US,A1,US 2015/0199384 A1,062-966-593-395-903,2015-07-16,2015,US 201514668979 A,2015-03-25,US 201514668979 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/062-966-593-395-903,Patent Application,yes,10,16,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06K9/00;;G06K9/18;;G06K9/46;;G06K9/62,,0,0,,,,EXPIRED
188,US,B2,US 7016532 B2,074-719-159-722-323,2006-03-21,2006,US 99294201 A,2001-11-05,US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses image characteristics to identify an object from a plurality of objects in a database. The image is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-04);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/074-719-159-722-323,Granted Patent,yes,31,599,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,382/165;;382/305,3,1,067-825-083-591-587,10.1109/cvpr.2004.1315147,"Carswell et al., An Environment Mobile Context-Based Hypermedia Retriewval, IEEE 1529-4188/02.;;Yeh et al., Searching the Web with Mobile Images for location Recognition, IEEE 1063-6919/04.;;Fu et al., Visual information retrieval from large distributed online respositories, ACM, ISSN:0001-0782, pp. 64-71.",EXPIRED
189,US,B2,US 8588468 B2,076-369-549-476-880,2013-11-19,2013,US 13693983,2012-12-04,,,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,"Nant Holdings IP, LLC",Wayne C. Boncyk;;Ronald H. Cohen,,https://lens.org/076-369-549-476-880,Granted Patent,yes,9,0,1,1,0,,G06K9/00,382103,0,0,,,,UNKNOWN
190,US,A1,US 2019/0026314 A1,090-297-873-815-191,2019-01-24,2019,US 201816143257 A,2018-09-26,US 201816143257 A;;US 201715711326 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 36052402 P;;US 62552604 P,2000-11-06,Object Information Derived From Object Images,"A real-world object is recognized from image data based on derived image characteristics, which are used to derive search information to conduct a search. The search returns object information which is used to execute a software process by a mobile device.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/090-297-873-815-191,Patent Application,yes,7,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F3/01;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,0,0,,,,EXPIRED
191,US,B2,US 8885982 B2,102-199-807-633-810,2014-11-11,2014,US 201313965876 A,2013-08-13,US 201313965876 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/102-199-807-633-810,Granted Patent,yes,112,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06,382/305;;705/26.1,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
192,US,A,US 4220306 A,134-069-035-885-297,1980-09-02,1980,US 3003079 A,1979-04-13,US 3003079 A,1979-04-13,Adjustable hanging device,"An adjustable hanging device for hanging plants and the like having a cord with a hook at its upper end for suspending same, the cord extending downwardly through a bore at one end of a bar and returning upwardly to terminate at a second bore at the other end of the bar with a second hook positioned at the bend of the cord. An object suspended on the second hook such as a plant causes the bar to tilt downwardly and the cord to become crimped at the bar and thereby lock the cord in position. Upon pushing upwardly on the lower end of the tilted bar to a horizontal position by means of a pole, the position of the bar frees the cord and permits the height adjustment of the device.",COHEN ARTHUR N;;CUETO RONALD E,COHEN ARTHUR N;;CUETO RONALD E,,https://lens.org/134-069-035-885-297,Granted Patent,yes,11,17,1,1,0,A47G7/047;;A47G2007/003;;F16G11/14;;Y10T24/3916;;Y10T24/3916;;A47G7/047;;F16G11/14;;A47G2007/003,A47G7/00;;A47G7/04;;F16G11/14,248/328,0,0,,,,EXPIRED
193,US,A1,US 2015/0254279 A1,152-469-524-829-283,2015-09-10,2015,US 201514721627 A,2015-05-26,US 201514721627 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/152-469-524-829-283,Patent Application,yes,7,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06K9/46,,0,0,,,,EXPIRED
194,US,A1,US 2019/0008684 A1,150-376-655-153-708,2019-01-10,2019,US 201816116660 A,2018-08-29,US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image depicting a digital representation of a scene is captured by an image sensor of a vehicle. An identification system recognizes a real-world object from the digital image as a target object based on derived image characteristics and identifies object information about the target object based on the recognition. The identification provides the object information to the vehicle data system of the vehicle so that the vehicle data system can execute a control function of the vehicle based on the received object information.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/150-376-655-153-708,Patent Application,yes,0,2,4,173,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10;;G06Q30/04;;G06Q30/0635;;G06T7/10;;G06T7/194;;G06T7/73;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N1/00244;;H04N7/183;;G06V30/142;;G06V10/56;;G06V10/7515;;G06V10/462;;H04N21/44224;;H04N23/661;;G06F18/254;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23418;;H04N21/41407;;H04N21/6582;;H04N21/4782;;H04N21/4223;;H04N21/4722;;H04N21/23109;;A63F13/20;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06T7/136;;G06T7/194;;G06T7/10;;G06T7/11;;G06T7/246;;G06T7/73;;G06T7/13;;G06T7/33;;G06T7/337;;G06F16/51;;G06F16/5866;;G06F16/50;;G06F40/134;;A63F13/00;;G06Q20/102;;G06Q20/14;;G06Q20/202;;G06Q20/208;;G06Q20/24;;G06Q20/327;;G06Q20/3567;;G06Q20/40145;;G06Q30/04;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G09B21/006;;H04L67/02;;H04N1/00244;;H04N5/91;;H04N7/183;;H04N7/185;;H04N21/254;;H04N21/4781;;H04N21/47815;;H04N21/812;;H04N21/8126;;H04N21/8173;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;H04N21/44224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F18/254;;G06F2218/12;;H04N23/00;;H04N23/64;;H04N23/80;;H04N23/661;;A61F9/08;;G06F3/0482;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10,A63F13/00;;A61F9/08;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G06V10/56;;G06V30/142;;G06V30/224;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,0,0,,,,EXPIRED
195,US,B2,US 8331679 B2,155-693-638-943-573,2012-12-11,2012,US 201113207211 A,2011-08-10,US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/155-693-638-943-573,Granted Patent,yes,103,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/181,0,0,,,,EXPIRED
196,US,A1,US 2014/0328513 A1,179-284-750-285-279,2014-11-06,2014,US 201414332216 A,2014-07-15,US 201414332216 A;;US 201314073760 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/179-284-750-285-279,Patent Application,yes,3,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F17/30,382/103,0,0,,,,EXPIRED
197,US,B2,US 9014514 B2,173-564-464-370-745,2015-04-21,2015,US 201414170079 A,2014-01-31,US 201414170079 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/173-564-464-370-745,Granted Patent,yes,100,13,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/60;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Enviroments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
198,US,A1,US 2013/0266183 A1,197-463-690-070-124,2013-10-10,2013,US 201313907842 A,2013-05-31,US 201313907842 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/197-463-690-070-124,Patent Application,yes,6,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/78,382/103,0,0,,,,EXPIRED
199,US,B2,US 8712193 B2,188-956-731-792-553,2014-04-29,2014,US 201213693983 A,2012-12-04,US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/188-956-731-792-553,Granted Patent,yes,111,30,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/34,382/305,33,18,032-705-158-397-206;;104-793-026-621-862;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;051-045-047-582-773;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;030-846-937-028-967;;013-901-391-839-508;;088-865-239-067-73X;;187-572-604-127-113;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/mmcs.1999.778638;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1145/354666.354669;;10.1145/215585.215639;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402,"Arai, T. et al., ""PaperLink: A Technique for Hyperlinking From Real Paper to Electronic Content,"" CHI1997, Conference On Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997; pp. 327-334.;;Bulman, J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, vol. 22, No. 3, Jul. 2004; pp. 84-94.;;Chang, W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia 1997, Seattle, Washington, Nov. 9-13, 1997; pp. 203-213.;;Diverdi, S. et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12; University of California Santa Barbara, May 2003; 7 pages.;;Diverdi, S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004 (IEEE/ACM Int'l Symp on Mixed and Augmented Reality), Arlington, Virginia, Nov. 2-5, 2004; 2 pages.;;Feiner, S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1(4), 1997; pp. 208-217.;;Fernandez, F., ""Responsive Environments: Digital Objects In The Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba; Mar. 2004; 124 pages.;;Geiger, C., et al., ""Mobile AR4ALL,"" Proceedings Of the IEEE and ACM Int'l Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; 2 pages.;;Gevers, T., et al., ""PicToSeek: Combining Color and Shape Invariant Features For Image Retrieval,"" IEEE Transactions On Image Processing, vol. 9, No. 1, Jan. 2000; pp. 102-119.;;Haritaoglu, I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp 2001; Lecture Notes in Computer Science, vol. 2201; pp. 247-255.;;Hollerer, T., et al., ""Chapter Nine: Mobile Augmented Reality,"" Telegeoinformatics: Location Based Computing and Services. H. Karimi and A. Hammad (eds.), Taylor & Francis Books, Ltd., Jan. 2004; 39 pages.;;Iwamoto, T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive2004 Advances in Pervasive Computing, LinzNienna, Austria, (2004).;;Iwaoka, T., et al., ""Digital Safari Guidebook With Image Retrieval,"" ICMCS, vol. 2, p. 1011-1012. (1999).;;Jebara, T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" ISWC, pp. 138-145. IEEE Computer Society, (1997).;;Kangas, K. et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, Aug. 15-20, 1999, Seattle, Washington; pp. 48-58.;;Kato, H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Int'l Workshop on Augmented Reality, Oct. 20-21, 1999, San Francisco, California; pp. 85-94.;;Klinker, G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,"" ISAR, p. 124-136. IEEE Computer Society, (2001).;;Levine, J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis,. EECS Dept., MIT, 1997.;;Ljungstrand, P., et al., ""WebStickers: Using Physical Tokens To Access, Manage and Share Bookmarks On The Web,"" ; Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingor, Denmark; Apr. 2000; pp 23-31.;;Rekimoto, J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology (1995), pp. 29-36.;;Rekimoto, J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, 1998, Second International Symposium, Oct. 19-20, 1998, Pittsburgh, Pennsylvania; pp. 68-75.;;Rekimoto, J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingor, Denmark: Apr. 2000; pp. 1-10.;;Rekimoto, J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" from the book Fundamentals Of Wearable Computers And Augmented Reality, Barfield and Caudell (Eds.), Jun. 6, 2001; pp. 353-377.;;Rohs, M., et al., ""A Conceptual Framework For Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 171-189.;;Siltanen, S., et al., ""Implementing A Natural User Interface For Camera Phones Using Visual Tags,"" AUIC '06 Proceedings of the 7th Australasian User interface conference-vol. 50; pp. 113-116.;;Smailagic, A, et al., ""Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith, J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, Multimedia '96, ACM New York, New York, pp. 87-98.;;Starner, T., et al., ""Augmented Reality Through Wearable Computing,"" 1997; Presence: Teleoper. Virtual Environ. 6, 4.;;Suzuki, G., et al., ""u-Photo: Interacting With Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science vol. 3468, 2005, pp. 190-207.;;Toye, E., et al., ""Interacting With Mobile Services: An Evaluation Of Camera-Phones And Visual Tags,"" Personal and Ubiquitous Computing; vol. 11, Issue 2, Jan. 2007; pp. 97-106.;;Wagner, D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, 2003. Oct. 18-21, 2003; 9 pages.;;Yang, J., et al., ""Smart Sight: A Tourist Assistant System,"" Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California; Digest of Papers, pp. 73-78.;;Zhang, X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation And Information Access With Mobile Computers,"" Proceedings Of the IEEE and ACM Int'l Symposium On Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; pp. 179-180.",EXPIRED
200,US,A1,US 2014/0177918 A1,027-970-864-396-805,2014-06-26,2014,US 201414191355 A,2014-02-26,US 201414191355 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/027-970-864-396-805,Patent Application,yes,1,5,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06T7/00,382/103,0,0,,,,EXPIRED
201,US,B2,US 9613284 B2,033-263-887-998-678,2017-04-04,2017,US 201414558643 A,2014-12-02,US 201414558643 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/033-263-887-998-678,Granted Patent,yes,399,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;A63F13/45;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” the Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
202,US,A1,US 2013/0316800 A1,031-325-986-312-481,2013-11-28,2013,US 201313954920 A,2013-07-30,US 201313954920 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/031-325-986-312-481,Patent Application,yes,7,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A63F13/12,463/25;;463/29,0,0,,,,EXPIRED
203,JP,A,JP 2015007992 A,041-030-119-300-102,2015-01-15,2015,JP 2014162208 A,2014-08-08,US 34209406 A,2006-01-26,SYSTEM AND METHOD FOR ACQUIRING AND IDENTIFYING DATA,"PROBLEM TO BE SOLVED: To digitally identify an image captured without requiring change of an object.SOLUTION: An identification method uses characteristics of an image for specifying an object from a plurality of objects in a database device. In order to identify an actual object in a digital image, data is broken down into parameters, such as shape comparison, grayscale comparison, wavelet comparison, and color cube comparison with object data in one or more databases.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/041-030-119-300-102,Patent Application,no,7,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06K7/00;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,PENDING
204,US,A1,US 2017/0039224 A1,059-732-793-302-687,2017-02-09,2017,US 201615298671 A,2016-10-20,US 201615298671 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing de ice submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/059-732-793-302-687,Patent Application,yes,10,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/62;;G06Q30/06;;H04N5/232,,0,0,,,,EXPIRED
205,US,B2,US 8218874 B2,062-088-187-063-261,2012-07-10,2012,US 201113069134 A,2011-03-22,US 201113069134 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/062-088-187-063-261,Granted Patent,yes,105,49,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/181,0,0,,,,EXPIRED
206,EP,A1,EP 0020605 A1,112-615-290-540-576,1981-01-07,1981,EP 79901585 A,1980-05-20,US 95780178 A,1978-11-06,MODIFIED POLYESTER COMPOSITIONS.,"Des compositions polyester thermoplastiques modifiees comprennent (a) une resine de poly(1,4-terephthalate de butylene) ou un copolymere de polyesters et, eventuellement, une resine de poly(terephthalate d'ethylene) et (b) un modificateur comprenant une combinaison d'une resine de polyacrylate et un polycarbonate aromatique et, eventuellement, (c) un remplisseur et/ou un agent de renforcement et/ou (d) un retardateur d'inflammation. Le modificateur (b) presente une resistance accrue a la rupture par impact, une resistance accrue a la deformation a la chaleur des articles moules a partir de ces compositions.",GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/112-615-290-540-576,Patent Application,yes,0,2,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,,0,0,,,,EXPIRED
207,US,B2,US 10772765 B2,117-354-243-805-390,2020-09-15,2020,US 201916575260 A,2019-09-18,US 201916575260 A;;US 201916264454 A;;US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"A computing platform that analyzes a captured video stream to identify a document depicted in the video stream, validates identification information corresponding to the document to display an information address associated with the document, and that initiates a transaction based on the validation of the identification information associated with the document.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/117-354-243-805-390,Granted Patent,yes,450,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/00;;A61F9/08;;A63F13/00;;A63F13/20;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06F40/134;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,43,23,157-015-151-956-874;;078-957-418-810-926;;032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151;;10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Kohtake et al., InfoStick: An Interaction Device for Inter-Appliance Computing, Hans-W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www.infoworld.com, Aug. 21, 2000 Infoworld, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages.;;Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content- Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
208,AU,A,AU 1971/034414 A,133-434-353-052-270,1973-04-19,1973,AU 1971/034414 A,1971-10-11,US 9147770 A,1970-11-20,HEAT EXCHANGE DEVICE,,BAXTER LABORATORIES INC,LEONARD RONALD JAMES;;COHEN FRED MICHAEL,,https://lens.org/133-434-353-052-270,Patent Application,no,0,0,17,17,0,A61M5/44;;A61M5/44;;A61M2205/366;;A61M2205/366;;F28D9/0025;;F28D9/0025;;Y10S165/399;;Y10S165/399,A61M5/44;;F28D9/00,,0,0,,,,EXPIRED
209,US,A9,US 2017/0046369 A9,189-850-431-208-416,2017-02-16,2017,US 201615169948 A,2016-06-01,US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/189-850-431-208-416,Amended Application,yes,10,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/46;;H04N5/44,,0,0,,,,EXPIRED
210,US,B2,US 9154695 B2,198-037-798-352-259,2015-10-06,2015,US 201414536689 A,2014-11-10,US 201414536689 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/198-037-798-352-259,Granted Patent,yes,110,13,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
211,US,A1,US 2014/0081747 A1,023-369-853-323-456,2014-03-20,2014,US 201314083210 A,2013-11-18,US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/023-369-853-323-456,Patent Application,yes,12,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/02,705/14.51,0,0,,,,EXPIRED
212,MX,A,MX 152445 A,054-015-703-053-450,1985-07-16,1985,MX 17991979 A,1979-11-06,US 95780178 A,1978-11-06,UNA COMPOSICION DE POLIESTER MODIFICADA MEJORADA PARA MOLDEADOS RESISTENTES AL IMPACTO,,GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/054-015-703-053-450,Granted Patent,no,0,0,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,09-4,0,0,,,,EXPIRED
213,US,A1,US 2018/0021174 A1,045-366-593-801-267,2018-01-25,2018,US 201715711118 A,2017-09-21,US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,"A digital image segment of a human body part is captured and matched against a reference image segment. If the match score meets a threshold, the digital image segment is stored and the human body part is recognized as a target object. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object. If the match score does not meet a threshold, a second image containing a representation of the human body part is obtained.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/045-366-593-801-267,Patent Application,yes,7,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A61F9/08;;A63F13/00;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,0,0,,,,EXPIRED
214,US,A1,US 2012/0296754 A1,064-102-829-168-542,2012-11-22,2012,US 201213523491 A,2012-06-14,US 201213523491 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/064-102-829-168-542,Patent Application,yes,5,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/78;;G06Q30/06,705/26.1;;382/103,0,0,,,,EXPIRED
215,US,B2,US 9135355 B2,072-212-465-015-971,2015-09-15,2015,US 201414170047 A,2014-01-31,US 201414170047 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/072-212-465-015-971,Granted Patent,yes,107,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
216,US,B2,US 9020305 B2,085-701-223-186-590,2015-04-28,2015,US 201414170123 A,2014-01-31,US 201414170123 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/085-701-223-186-590,Granted Patent,yes,105,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/60;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in The Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on The Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
217,JP,A,JP 2012043447 A,078-739-311-283-93X,2012-03-01,2012,JP 2011204795 A,2011-09-20,US 99294201 A,2001-11-05,IMAGE CAPTURE AND IDENTIFICATION SYSTEM AND METHOD,"PROBLEM TO BE SOLVED: To provide a system and a method for capturing and identifying an image without the need of changing an object.SOLUTION: A device 14 captures a digital image 18 of an object 16, a server 20 analyzes image characteristics of the digital image 18, and the object 16 is recognized from a plurality of objects in a database. Then, an information address corresponding to the object 16 is provided to position and supply information on the object 16 or to initiate communication pertinent to the object 16.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/078-739-311-283-93X,Patent Application,no,4,1,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06Q30/02;;G06Q10/00;;G06T7/00;;G06V10/56;;H04N1/00,,0,0,,,,INACTIVE
218,US,B2,US 9031290 B2,075-507-865-613-708,2015-05-12,2015,US 201414160263 A,2014-01-21,US 201414160263 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/075-507-865-613-708,Granted Patent,yes,108,9,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F3/01;;G06F17/30;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,382/118;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
219,US,B2,US 9536168 B2,112-427-372-689-851,2017-01-03,2017,US 201514683953 A,2015-04-10,US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYCK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/112-427-372-689-851,Granted Patent,yes,108,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;A63F13/45;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHYF Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
220,US,A1,US 2013/0311503 A1,101-802-703-877-025,2013-11-21,2013,US 201313952421 A,2013-07-26,US 201313952421 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/101-802-703-877-025,Patent Application,yes,13,13,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30,707/758,0,0,,,,EXPIRED
221,US,A,US 4317035 A,094-937-039-528-754,1982-02-23,1982,US 10561979 A,1979-12-20,US 10561979 A,1979-12-20,Gold monitoring procedure,A gold plating process is described in which gold concentration is monitored by a radioactive excitation procedure. This procedure for measuring gold concentration requires no chemical manipulation and yields immediate results. The procedure can be adapted to continuous concentration measurement for use in automatic control of gold concentration in a gold plating procedure.,WESTERN ELECTRIC CO,COHEN RICHARD L;;MEEK RONALD L,AT & T TECHNOLOGIES INC. (1983-12-29),https://lens.org/094-937-039-528-754,Granted Patent,yes,3,14,1,1,0,G01N23/223;;G01N23/223;;G01N2223/076;;G01N2223/076,G01N23/223,250/272,0,0,,,,EXPIRED
222,US,A1,US 2012/0163667 A1,122-023-042-183-753,2012-06-28,2012,US 201213410668 A,2012-03-02,US 201213410668 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/122-023-042-183-753,Patent Application,yes,3,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/103,0,0,,,,EXPIRED
223,US,B2,US 8824738 B2,115-594-507-064-523,2014-09-02,2014,US 201313968666 A,2013-08-16,US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/115-594-507-064-523,Granted Patent,yes,103,34,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/103;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
224,US,A1,US 2013/0232076 A1,170-242-829-843-920,2013-09-05,2013,US 201313856197 A,2013-04-03,US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/170-242-829-843-920,Patent Application,yes,11,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q20/40,705/44,0,0,,,,EXPIRED
225,US,B2,US 8885983 B2,182-478-878-359-410,2014-11-11,2014,US 201314041322 A,2013-09-30,US 201314041322 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/182-478-878-359-410,Granted Patent,yes,108,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/40;;G06Q30/02;;G06Q30/06;;H04N5/225;;H04N5/232;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
226,US,B2,US 9046930 B2,172-392-212-567-264,2015-06-02,2015,US 201414332216 A,2014-07-15,US 201414332216 A;;US 201314073760 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/172-392-212-567-264,Granted Patent,yes,106,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F3/01;;G06F17/30;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference On Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications In Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection In Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level Of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems For Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects In The Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features For Image Retrieval,"" IEEE Transactions On Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design And Implementation Of A Snapshot Based Method For Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision And Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility To Create Ubiquitous And Active Augmented Reality In Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target And Pose Recognition For 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens To Access, Manage and Share Bookmarks On The Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through The Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach To Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework For Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing A Natural User Interface For Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation And Information Access With Mobile Computers,"" Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality, 2001, pp. 179-180.",EXPIRED
227,US,A1,US 2011/0258057 A1,175-381-885-094-305,2011-10-20,2011,US 201113092017 A,2011-04-21,US 201113092017 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/175-381-885-094-305,Patent Application,yes,0,7,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/00;;G06K9/00,705/14.73;;382/103;;705/26.61,0,0,,,,EXPIRED
228,US,B2,US 8948460 B2,187-638-547-401-217,2015-02-03,2015,US 201314032509 A,2013-09-20,US 201314032509 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/187-638-547-401-217,Granted Patent,yes,102,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N5/232;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/103;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007102010, mailed on Nov. 16, 2007, 5 pages.;;Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in The Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
229,US,A1,US 2013/0246684 A1,002-701-888-243-747,2013-09-19,2013,US 201213421401 A,2012-03-15,US 201213421401 A,2012-03-15,SYSTEM AND METHOD FOR COMMUNICATING WITH A PLURALITY OF DEVICES,"A system and method that permits a monitoring unit to communicate with any one of several Serial Peripheral Interface (SPI) devices on an input/output (IO) module using a single device select line. The monitoring unit sends a data message with an identifier code to the IO module, which includes a router to selectively activate a corresponding circuit to the selected SPI device based on the identifier code.",COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD;;GEN ELECTRIC,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD,GENERAL ELECTRIC COMPANY (2012-03-12),https://lens.org/002-701-888-243-747,Patent Application,yes,7,4,5,5,0,G06F13/4282;;G05B19/4185;;Y02P90/02;;G06F13/4282;;G05B19/4185;;Y02P90/02,G06F13/00,710/316,1,0,,,"Dallas Semiconductor - ""Serial-Control Multiplexer Expands SPI Chip Selects""; 2 pages, Dated July 1, 2001.",DISCONTINUED
230,US,B2,US 8948459 B2,030-010-976-227-969,2015-02-03,2015,US 201314016628 A,2013-09-03,US 201314016628 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/030-010-976-227-969,Granted Patent,yes,112,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
231,US,B2,US 8798322 B2,061-854-001-476-572,2014-08-05,2014,US 201313971758 A,2013-08-20,US 201313971758 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/061-854-001-476-572,Granted Patent,yes,118,25,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/103,38,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications In Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on The Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
232,US,A1,US 2013/0332317 A1,055-632-865-014-163,2013-12-12,2013,US 201313965876 A,2013-08-13,US 201313965876 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/055-632-865-014-163,Patent Application,yes,13,18,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06Q30/06,705/26.62,0,0,,,,EXPIRED
233,US,A1,US 2011/0228126 A1,088-074-063-219-320,2011-09-22,2011,US 201113069124 A,2011-03-22,US 201113069124 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/088-074-063-219-320,Patent Application,yes,99,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/228,348/222.1;;X348E05031,0,0,,,,EXPIRED
234,US,A1,US 2012/0269396 A1,096-190-299-959-817,2012-10-25,2012,US 201213538915 A,2012-06-29,US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/096-190-299-959-817,Patent Application,yes,1,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/103,0,0,,,,EXPIRED
235,US,B2,US 9036949 B2,090-581-926-630-341,2015-05-19,2015,US 201314073760 A,2013-11-06,US 201314073760 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/090-581-926-630-341,Granted Patent,yes,108,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54;;G06F3/01;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
236,US,B2,US 8867839 B2,133-078-297-632-749,2014-10-21,2014,US 201313860967 A,2013-04-11,US 201313860967 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/133-078-297-632-749,Granted Patent,yes,110,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/181;;348/207.1,40,20,041-034-977-263-043;;067-825-083-591-587;;032-705-158-397-206;;104-793-026-621-862;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;051-045-047-582-773;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;030-846-937-028-967;;013-901-391-839-508;;088-865-239-067-73X;;187-572-604-127-113;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619,10.1145/265563.265573;;10.1109/cvpr.2004.1315147;;10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/mmcs.1999.778638;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1145/354666.354669;;10.1145/215585.215639;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402,"Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Arai, T. et al., ""PaperLink: A Technique for Hyperlinking From Real Paper to Electronic Content,"" CHI1997, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997; pp. 327-334.;;Bulman, J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, vol. 22, No. 3, Jul. 2004; pp. 84-94.;;Chang, W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia 1997, Seattle, Washington, Nov. 9-13, 1997; pp. 203-213.;;Diverdi, S. et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003; University of California Santa Barbara, May 2003; 7 pages.;;Diverdi, S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004 (IEEE/ACM Intl Symp on Mixed and Augmented Reality), Arlington, Virginia, Nov. 2-5, 2004; 2 pages.;;Feiner, S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1(4), 1997; pp. 208-217.;;Fernandez, F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba; Mar., 2004; 124 pages.;;Geiger, C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; 2 pages.;;Gevers, T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, vol. 9, No. 1, Jan. 2000; pp. 102-119.;;Haritaoglu, I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp 2001; Lecture Notes in Computer Science, vol. 2201; pp. 247-255.;;Hollerer, T., et al., ""Chapter Nine: Mobile Augmented Reality,"" Telegeoinformatics: Location Based Computing and Services. H. Karimi and A. Hammad (eds.), Taylor & Francis Books, Ltd., Jan. 2004; 39 pages.;;Iwamoto, T., et al., ""u-Photo: A Design And Implementation Of A Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive2004 Advances in Pervasive Computing, Linz/Vienna, Austria, (2004).;;Iwaoka, T., et al., ""Digital Safari Guidebook With Image Retrieval,"" ICMCS, vol. 2, pp. 1011-1012. (1999).;;Jebara, T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision and Wearable Computers,"" ISWC, pp. 138-145. IEEE Computer Society, (1997).;;Kangas, K. et al., ""Using Code Mobility to Create Ubiquitous And Active Augmented Reality in Mobile Computing,"" Mobicom, Aug. 15-20, 1999, Seattle, Washington; pp. 48-58.;;Kato, H., et al., ""Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Int'l Workshop on Augmented Reality, Oct. 20-21, 1999, San Francisco, California; pp. 85-94.;;Klinker, G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study of a Mobile AR System,"" ISAR, pp. 124-136. IEEE Computer Society, (2001).;;Levine, J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis,. EECS Dept., MIT, 1997.;;Ljungstrand, P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" ; Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingçr, Denmark; Apr., 2000; pp -23-31.;;Rekimoto, J., et al., ""The World Through The Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology (1995), pp. 29-36.;;Rekimoto, J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, 1998, Second International Symposium, Oct. 19-20, 1998, Pittsburgh, Pennsylvania; pp. 68-75.;;Rekimoto, J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (Dare 2000), Helsingør, Denmark: Apr. 2000; pp. 1-10.;;Rekimoto, J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" from the book Fundamentals Of Wearable Computers And Augmented Reality, Barfield and Caudell (Eds.), Jun. 6, 2001; pp. 353-377.;;Rohs, M., et al., ""A Conceptual Framework For Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 171-189.;;Siltanen, S., et al., ""Implementing A Natural User Interface for Camera Phones Using Visual Tags,"" AUIC '06 Proceedings of the 7th Australasian User interface conference-vol. 50; pp. 113-116.;;Smailagic, A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith, J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, MULTIMEDIA '96, ACM New York, New York, pp. 87-98.;;Starner, T., et al., ""Augmented Reality Through Wearable Computing,"" 1997; Presence: Teleoper. Virtual Environ. 6, 4.;;Suzuki, G., et al., ""u-Photo: Interacting With Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science vol. 3468, 2005, pp. 190-207.;;Toye, E., et al., ""Interacting With Mobile Services: An Evaluation of Camera-Phones And Visual Tags,"" Personal and Ubiquitous Computing; vol. 11, Issue 2, Jan. 2007; pp. 97-106.;;Wagner, D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, 2003. Oct. 18-21, 2003; 9 pages.;;Yang, J., et al., ""Smart Sight: A Tourist Assistant System,"" Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California; Digest of Papers, pp. 73-78.;;Zhang, X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Int'l Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
237,WO,A2,WO 2007/021996 A2,141-115-693-371-333,2007-02-22,2007,US 2006/0031485 W,2006-08-10,US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC;;BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/141-115-693-371-333,Patent Application,yes,0,47,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F17/30,,0,0,,,,PENDING
238,US,A1,US 2014/0355894 A1,156-445-866-132-311,2014-12-04,2014,US 201414463526 A,2014-08-19,US 201414463526 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/156-445-866-132-311,Patent Application,yes,0,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;G06F17/30,382/224,0,0,,,,EXPIRED
239,US,B2,US 9330328 B2,154-444-942-119-50X,2016-05-03,2016,US 201414574391 A,2014-12-18,US 201414574391 A;;US 201313908081 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/154-444-942-119-50X,Granted Patent,yes,106,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
240,US,A9,US 2016/0048591 A9,168-142-180-294-110,2016-02-18,2016,US 201414569763 A,2014-12-14,US 201414569763 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,OBJECT INFORMATION DERIVED FROM OBJECT IMAGES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/168-142-180-294-110,Amended Application,yes,0,2,3,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F3/04842;;G06F16/532;;G06F16/583;;G06F16/5854;;G06F16/9537;;G06F3/017;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06Q30/0623;;G06Q30/0625;;G06V20/20;;H04N23/80;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5838;;G06F16/5854;;G06F16/7335;;G06F16/9537;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F3/04842;;G06V20/10;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V20/20;;G06F2218/08;;H04N23/80;;G06F16/5846;;G06F16/9538;;G06F3/017;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06Q30/0623;;G06Q30/0625;;G06T7/00,G06F17/30,,0,0,,,,EXPIRED
241,US,B2,US 8463030 B2,013-868-555-974-967,2013-06-11,2013,US 201113069124 A,2011-03-22,US 201113069124 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/013-868-555-974-967,Granted Patent,yes,100,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
242,US,B2,US 8218873 B2,021-120-518-685-525,2012-07-10,2012,US 201113037330 A,2011-02-28,US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/021-120-518-685-525,Granted Patent,yes,100,70,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/181,0,0,,,,EXPIRED
243,US,B2,US 9014513 B2,025-946-853-451-669,2015-04-21,2015,US 201314058287 A,2013-10-21,US 201314058287 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/025-946-853-451-669,Granted Patent,yes,104,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/60;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing A Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
244,US,B2,US 9036862 B2,051-461-506-420-881,2015-05-19,2015,US 201414195768 A,2014-03-03,US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/051-461-506-420-881,Granted Patent,yes,110,11,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F3/01;;G06F17/30;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,382/100;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-2012, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
245,US,A1,US 2020/0155807 A1,063-695-007-655-683,2020-05-21,2020,US 201916434158 A,2019-06-06,US 201916434158 A;;US 201962834933 P;;US 201862681727 P,2018-06-07,"SMALL DIAMETER CATHETER FOR INTRODUCTION INTO THE TRACHEA AND OTHER ORIFICES, AS WELL AS INTO PASSAGES THAT ARE DIFFICULT TO INTUBATE OR ACCESS","A catheter includes: a tubular member having a first end, a second end, a body extending between the first end and the second end, and a first lumen in the body; a first flexible line having at least a segment located in the first lumen of the body; and a first anchor at an end of the first flexible line, the first anchor having a cross sectional dimension that is larger than a cross sectional dimension of the first lumen; wherein the first anchor is configured to apply a compression force against an exterior surface at the first end of the tubular member in response to tension applied through the first flexible line.",UNIV LELAND STANFORD JUNIOR,COHEN RONALD S;;WALTERSPIEL JUAN N,,https://lens.org/063-695-007-655-683,Patent Application,yes,5,2,1,1,0,A61B10/02;;A61M2240/00;;A61M16/0488;;A61M16/0418;;A61M25/04;;A61M25/04;;A61M27/00;;A61M25/0026;;A61M25/0054;;A61M25/0041;;A61M25/003;;A61M2240/00;;A61M16/0486;;A61M2210/1085;;A61M2210/101;;A61M2210/122;;A61M2210/1017;;A61B10/02,A61M25/04;;A61B10/02;;A61M16/04;;A61M25/00;;A61M27/00,,0,0,,,,DISCONTINUED
246,US,A1,US 2011/0150292 A1,077-800-978-070-506,2011-06-23,2011,US 201113037330 A,2011-02-28,US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/077-800-978-070-506,Patent Application,yes,99,31,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/64;;G06K9/00,382/116;;382/217;;382/115,0,0,,,,EXPIRED
247,US,B2,US 7899252 B2,065-100-033-617-311,2011-03-01,2011,US 56813009 A,2009-09-28,US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/065-100-033-617-311,Granted Patent,yes,29,117,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06K9/54,382/181;;382/305,0,0,,,,EXPIRED
248,US,A1,US 2014/0361075 A1,081-313-081-137-418,2014-12-11,2014,US 201414467189 A,2014-08-25,US 201414467189 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/081-313-081-137-418,Patent Application,yes,16,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06Q90/00,235/379;;235/375;;235/385,0,0,,,,EXPIRED
249,US,B2,US 10509821 B2,091-313-795-549-02X,2019-12-17,2019,US 201816154547 A,2018-10-08,US 201816154547 A;;US 201715818312 A;;US 201615392935 A;;US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"A mobile system that performs object recognition, identifying real-world objects in a scene from captured digital data of the scene. The mobile system identifies the real-world objects based on derived salient characteristics from the digital data, and retrieves stored object information corresponding to the identified object such that a CPU can execute a software process based on the retrieved object information about the real-world object.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/091-313-795-549-02X,Granted Patent,yes,446,1,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F16/583;;G06F16/21;;G06F16/2457;;G06F16/248;;G06F16/51;;G06F16/58;;G06V10/56;;G06V30/142;;H04L29/08;;H04M1/02;;H04N21/278;;H04N21/845,,43,22,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587;;157-015-151-956-874;;078-957-418-810-926,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147;;10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive computing, LinzNienna, Austria, 6 pages.;;Uebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of be 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;Kohtake et al, InfoStick: An Interaction Device for Inter-Appliance Computing, Hans- W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www.infoworld.com, Aug. 21, 2000 Infoworld, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages. Date not available.",EXPIRED
250,US,B2,US 7477780 B2,096-619-360-674-933,2009-01-13,2009,US 49224304 A,2004-05-20,US 49224304 A;;US 99294201 A;;US 0235407 W,2001-11-05,Image capture and identification system and process,The invention is a method by which information and communication pertinent to an object is provided based on imagery of the object. A digital image of the object is captured and the object is recognized from a plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-04-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/096-619-360-674-933,Granted Patent,yes,20,401,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,382/165;;382/305,0,0,,,,ACTIVE
251,US,A1,US 2012/0263351 A1,101-874-663-055-707,2012-10-18,2012,US 201213535216 A,2012-06-27,US 201213535216 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/101-874-663-055-707,Patent Application,yes,1,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/103,0,0,,,,EXPIRED
252,US,B2,US 8588527 B2,106-498-232-639-386,2013-11-19,2013,US 201213686851 A,2012-11-27,US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/106-498-232-639-386,Granted Patent,yes,103,36,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/181,0,0,,,,EXPIRED
253,US,B2,US 9244943 B2,107-912-816-615-684,2016-01-26,2016,US 201314083210 A,2013-11-18,US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/107-912-816-615-684,Granted Patent,yes,111,13,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
254,US,B2,US 9311553 B2,121-321-151-667-318,2016-04-12,2016,US 201414467189 A,2014-08-25,US 201414467189 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/121-321-151-667-318,Granted Patent,yes,115,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings Of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
255,US,A1,US 2017/0046570 A1,135-064-048-948-254,2017-02-16,2017,US 201615335849 A,2016-10-27,US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/135-064-048-948-254,Patent Application,yes,13,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;G06K9/18;;G06K9/22;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q20/14;;G06Q30/06;;G06T7/00;;G07F17/32;;H04N1/00;;H04N21/231;;H04N21/234;;H04N21/414;;H04N21/4223;;H04N21/478,,0,0,,,,EXPIRED
256,US,B2,US 8224077 B2,150-345-149-097-449,2012-07-17,2012,US 201113005716 A,2011-01-13,US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/150-345-149-097-449,Granted Patent,yes,98,69,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/165,0,0,,,,EXPIRED
257,US,A1,US 2013/0230210 A1,152-904-960-812-22X,2013-09-05,2013,US 201313858897 A,2013-04-08,US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/152-904-960-812-22X,Patent Application,yes,14,4,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/00,382/103,0,0,,,,EXPIRED
258,US,A1,US 2011/0268317 A1,162-418-423-218-54X,2011-11-03,2011,US 201113005716 A,2011-01-13,US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/162-418-423-218-54X,Patent Application,yes,1,4,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/103,0,0,,,,EXPIRED
259,US,B2,US 9844466 B2,191-131-169-369-548,2017-12-19,2017,US 201615299584 A,2016-10-21,US 201615299584 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/191-131-169-369-548,Granted Patent,yes,405,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors In Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 34-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level Of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems For Exploring The Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects In The Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features For Image Retrieval,” IEEE Transactions On Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design And Implementation Of A Snapshot Based Method For Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision And Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility To Create Ubiquitous And Active Augmented Reality In Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target And Pose Recognition For 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens To Access, Manage and Share Bookmarks On The Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through The Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach To Augmented Reality,” Fundamentals of Wearable computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework For Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing A Natural User Interface For Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content- Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation And Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium On Augmented Reality, 2001, pp. 179-180.",EXPIRED
260,US,B2,US 9844467 B2,187-797-169-834-32X,2017-12-19,2017,US 201615299597 A,2016-10-21,US 201615299597 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/187-797-169-834-32X,Granted Patent,yes,406,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
261,US,B2,US 9844468 B2,194-557-436-193-290,2017-12-19,2017,US 201615299604 A,2016-10-21,US 201615299604 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/194-557-436-193-290,Granted Patent,yes,403,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in The Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on The Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through The Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing A Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
262,US,B2,US 9235600 B2,195-589-237-337-952,2016-01-12,2016,US 201414463526 A,2014-08-19,US 201414463526 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/195-589-237-337-952,Granted Patent,yes,109,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
263,US,A1,US 2017/0036112 A1,018-733-038-650-626,2017-02-09,2017,US 201615299584 A,2016-10-21,US 201615299584 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/018-733-038-650-626,Patent Application,yes,11,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A63F13/65;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/792;;A63F13/92;;G06F17/30;;G06Q30/04;;G06T7/00;;G07F17/32,,0,0,,,,EXPIRED
264,US,B2,US 9360945 B2,018-538-530-561-912,2016-06-07,2016,US 201414569766 A,2014-12-14,US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P;;US 0235407 W,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/018-538-530-561-912,Granted Patent,yes,106,34,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
265,CA,A1,CA 2619497 A1,047-596-844-110-257,2007-02-22,2007,CA 2619497 A,2006-08-10,US 20490105 A;;US 2006/0031485 W,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of t he resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/047-596-844-110-257,Patent Application,no,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,DISCONTINUED
266,US,B2,US 8437544 B2,058-860-251-464-454,2013-05-07,2013,US 201213441370 A,2012-04-06,US 201213441370 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/058-860-251-464-454,Granted Patent,yes,102,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165;;382/305,0,0,,,,EXPIRED
267,DK,A,DK 201370152 A,108-706-350-502-651,2013-09-16,2013,DK PA201370152 A,2013-03-14,US 201213421401 A,2012-03-15,SYSTEM AND METHOD FOR COMMUNICATING WITH A PLURALITY OF DEVICES,"A system and method that permits a monitoring unit to communicate with any one of several Serial Peripheral Interface (SPI) devices on an input/output (10) module using a single device select line. The monitoring unit sends a data message with an identifier code to the 10 module, which includes a router to selectively activate a corresponding circuit to the selected SPI device based on the identifier code.",GEN ELECTRIC,DEAN COHEN MITCHELL;;RONALD NIKKELS ROBERT,,https://lens.org/108-706-350-502-651,Unknown,no,0,0,5,5,0,G06F13/4282;;G05B19/4185;;Y02P90/02;;G06F13/4282;;G05B19/4185;;Y02P90/02,G06F13/00,,0,0,,,,DISCONTINUED
268,US,A1,US 2014/0177922 A1,090-573-781-998-70X,2014-06-26,2014,US 201414195768 A,2014-03-03,US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/090-573-781-998-70X,Patent Application,yes,11,5,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/00;;G06K9/78;;G06Q20/10;;G06Q30/06,382/103,0,0,,,,EXPIRED
269,US,B2,US 9311554 B2,124-082-273-012-065,2016-04-12,2016,US 201414468304 A,2014-08-25,US 201414468304 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/124-082-273-012-065,Granted Patent,yes,114,16,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
270,US,A1,US 2014/0368674 A1,149-594-587-732-352,2014-12-18,2014,US 201414474254 A,2014-09-01,US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/149-594-587-732-352,Patent Application,yes,15,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/232,348/207.1,0,0,,,,EXPIRED
271,US,B2,US 9330327 B2,180-795-141-489-655,2016-05-03,2016,US 201414569709 A,2014-12-14,US 201414569709 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/180-795-141-489-655,Granted Patent,yes,106,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 23, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
272,US,A,US 4373047 A,020-029-784-187-314,1983-02-08,1983,US 21086680 A,1980-11-26,US 21086680 A;;US 1168079 A,1979-02-12,Flame retardant thermoplastic compositions with reduced bloom,"Normally flammable polyester resins (a) are rendered flame-retardant with reduced blooming or plate out tendencies and without loss in toughness or other properties in combination with (b) a flame retardant amount of decabromodiphenyl ether and (c) a flame-retardant synergist compound, by including a small amount of (d) an olefin polymer and/or an olefin copolymer. The compositions, which are useful per se for molding, extrusion, and the like, are, in addition, described in impact modified resin compositions and filled and/or reinforced modifications.",GEN ELECTRIC,COHEN STUART C;;DIECK RONALD L,,https://lens.org/020-029-784-187-314,Granted Patent,yes,11,11,1,9,0,C08K5/06;;C08K5/06;;C08L67/02;;C08L67/02,C08K5/06;;C08L67/02,524/371;;524/406;;524/412;;524/437;;524/449;;524/451;;524/508;;524/513;;524/523;;524/526;;525/173;;525/174;;525/176;;525/177,0,0,,,,EXPIRED
273,US,B2,US 8923563 B2,031-073-861-191-518,2014-12-30,2014,US 201313954920 A,2013-07-30,US 201313954920 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/031-073-861-191-518,Granted Patent,yes,106,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N5/232;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/103,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSeek: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
274,US,A1,US 2019/0042599 A1,047-288-829-425-408,2019-02-07,2019,US 201816154547 A,2018-10-08,US 201816154547 A;;US 201715818312 A;;US 201615392935 A;;US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"A mobile system that performs object recognition, identifying real-world objects in a scene from captured digital data of the scene. The mobile system identifies the real-world objects based on derived salient characteristics from the digital data, and retrieves stored object information corresponding to the identified object such that a CPU can execute a software process based on the retrieved object information about the real-world object.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/047-288-829-425-408,Patent Application,yes,5,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04L29/08;;H04M1/02;;H04N21/278;;H04N21/845,,0,0,,,,EXPIRED
275,US,B2,US 8498484 B2,071-629-946-611-00X,2013-07-30,2013,US 201213407432 A,2012-02-28,US 201213407432 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGAS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/071-629-946-611-00X,Granted Patent,yes,102,1,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/181,0,0,,,,EXPIRED
276,US,B2,US 10095712 B2,082-430-505-159-987,2018-10-09,2018,US 201715818312 A,2017-11-20,US 201715818312 A;;US 201615392935 A;;US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,NANT HOLDINGS IP LLC (2011-05-16);;EVYRX TECHNOLOGIES INC (2009-03-09);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/082-430-505-159-987,Granted Patent,yes,414,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06Q30/00;;G06V10/56;;G06V30/142;;H04L29/08;;H04M1/02;;H04N21/278;;H04N21/845,,40,20,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Uebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
277,US,A1,US 2002/0090132 A1,092-755-538-451-341,2002-07-11,2002,US 99294201 A,2001-11-05,US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"
   An identification method and process for objects from digitally captured images thereof that uses image characteristics to identify an object from a plurality of objects in a database. The image is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image. 
",BONCYK WAYNE C.;;COHEN RONALD H.,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-04);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/092-755-538-451-341,Patent Application,yes,29,181,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,382/154;;382/165;;382/167;;382/305;;707/104.1;;382/209,0,0,,,,EXPIRED
278,US,A1,US 2014/0229306 A1,095-465-415-864-174,2014-08-14,2014,US 201414223876 A,2014-03-24,US 201414223876 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/095-465-415-864-174,Patent Application,yes,9,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q20/34;;G06Q20/24,705/17;;705/39;;705/43,0,0,,,,EXPIRED
279,AU,A,AU 1979/052346 A,098-582-331-512-528,1980-05-15,1980,AU 1979/052346 A,1979-10-31,US 95780178 A,1978-11-06,MODIFIED POLYESTER COMPOSITIONS,,GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/098-582-331-512-528,Patent Application,no,0,0,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,,0,0,,,,EXPIRED
280,US,A1,US 2014/0133712 A1,110-024-371-537-654,2014-05-15,2014,US 201414160263 A,2014-01-21,US 201414160263 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/110-024-371-537-654,Patent Application,yes,9,13,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/117;;382/118,0,0,,,,EXPIRED
281,US,B2,US 8948544 B2,114-035-068-296-367,2015-02-03,2015,US 201414170236 A,2014-01-31,US 201414170236 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/114-035-068-296-367,Granted Patent,yes,112,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
282,US,A1,US 2015/0302266 A1,128-979-384-667-269,2015-10-22,2015,US 201414574391 A,2014-12-18,US 201414574391 A;;US 201313908081 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/128-979-384-667-269,Patent Application,yes,0,8,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;G06F17/30;;G06K9/62;;G06Q30/02,,0,0,,,,EXPIRED
283,US,B2,US 10639199 B2,136-378-503-572-593,2020-05-05,2020,US 201916577910 A,2019-09-20,US 201916577910 A;;US 201916264454 A;;US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"An image-based transaction system includes a mobile device with an image sensor that is programmed to capture, via the image sensor, a video stream of a scene. The mobile device identifies a document using image characteristics from the video stream and acquires an image of at least a part of the document, and then identifies symbols in the image based on locations within the image of the document. The symbols can include alphanumeric symbols. The mobile device processes the symbols according to their type to obtain an address related to the document and the symbols and initiates a transaction associated with the identified document.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/136-378-503-572-593,Granted Patent,yes,450,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F16/51;;A61F9/08;;A63F13/00;;A63F13/20;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,43,23,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587;;157-015-151-956-874;;078-957-418-810-926,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147;;10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, p. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-211.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content—Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;Kohtake et al., InfoStick: An Interaction Device for Inter-Appliance Computing, Hans-W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www.infoworld.com, Aug. 21, 2000 INFOWORLD, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages.",EXPIRED
284,US,B2,US 10617568 B2,139-090-331-529-391,2020-04-14,2020,US 201816116660 A,2018-08-29,US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image depicting a digital representation of a scene is captured by an image sensor of a vehicle. An identification system recognizes a real-world object from the digital image as a target object based on derived image characteristics and identifies object information about the target object based on the recognition. The identification provides the object information to the vehicle data system of the vehicle so that the vehicle data system can execute a control function of the vehicle based on the received object information.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/139-090-331-529-391,Granted Patent,yes,446,0,4,173,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10;;G06Q30/04;;G06Q30/0635;;G06T7/10;;G06T7/194;;G06T7/73;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N1/00244;;H04N7/183;;G06V30/142;;G06V10/56;;G06V10/7515;;G06V10/462;;H04N21/44224;;H04N23/661;;G06F18/254;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23418;;H04N21/41407;;H04N21/6582;;H04N21/4782;;H04N21/4223;;H04N21/4722;;H04N21/23109;;A63F13/20;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06T7/136;;G06T7/194;;G06T7/10;;G06T7/11;;G06T7/246;;G06T7/73;;G06T7/13;;G06T7/33;;G06T7/337;;G06F16/51;;G06F16/5866;;G06F16/50;;G06F40/134;;A63F13/00;;G06Q20/102;;G06Q20/14;;G06Q20/202;;G06Q20/208;;G06Q20/24;;G06Q20/327;;G06Q20/3567;;G06Q20/40145;;G06Q30/04;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G09B21/006;;H04L67/02;;H04N1/00244;;H04N5/91;;H04N7/183;;H04N7/185;;H04N21/254;;H04N21/4781;;H04N21/47815;;H04N21/812;;H04N21/8126;;H04N21/8173;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;H04N21/44224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F18/254;;G06F2218/12;;H04N23/00;;H04N23/64;;H04N23/80;;H04N23/661;;A61F9/08;;G06F3/0482;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10,A61F9/08;;A63F13/00;;A63F13/20;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G06V10/56;;G06V30/142;;G06V30/224;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,43,23,157-015-151-956-874;;078-957-418-810-926;;032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151;;10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Kohtake et al., InfoStick: An Interaction Device for Inter-Appliance Computing, Hans- W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www.infoworld.com, Aug. 21, 2000 INFOWORLD, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages.;;Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188102, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-211.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook with Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments with Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction with Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
285,US,B2,US 8467600 B2,147-448-868-292-076,2013-06-18,2013,US 201113092009 A,2011-04-21,US 201113092009 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/147-448-868-292-076,Granted Patent,yes,102,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
286,US,A1,US 2004/0208372 A1,168-743-108-606-072,2004-10-21,2004,US 49224304 A,2004-05-20,US 49224304 A;;US 99294201 A;;US 0235407 W,2001-11-05,Image capture and identification system and process,"
   The invention is a method by which information and communication pertinent to an object is provided based on imagery of the object. A digital image of the object is captured and the object is recognized from a plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object. 
",BONCYK WAYNE C.;;COHEN RONALD H.,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-04-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/168-743-108-606-072,Patent Application,yes,18,236,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,382/181;;707/104.1,0,0,,,,EXPIRED
287,US,A1,US 2019/0167479 A1,012-845-188-629-222,2019-06-06,2019,US 201916264454 A,2019-01-31,US 201916264454 A;;US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,IMAGE CAPTURE AND IDENTIFICATION SYSTEM AND PROCESS,A digital image of the object is captured and the object is recognized from plurality of objects in a database as part of a computer-based game. An information address corresponding to the object is then used to access content information associated with the identified object and interact with the game based on the content information.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/012-845-188-629-222,Patent Application,yes,13,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A61F9/08;;A63F13/00;;A63F13/20;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06F17/22;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,0,0,,,,EXPIRED
288,US,A1,US 2013/0274013 A1,019-272-900-173-695,2013-10-17,2013,US 201313912396 A,2013-06-07,US 201313912396 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/019-272-900-173-695,Patent Application,yes,13,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A63F13/00,463/31,0,0,,,,EXPIRED
289,US,A1,US 2013/0336533 A1,023-036-931-001-204,2013-12-19,2013,US 201313971758 A,2013-08-20,US 201313971758 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDLINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/023-036-931-001-204,Patent Application,yes,19,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,382/103,0,0,,,,EXPIRED
290,CN,A,CN 103309299 A,066-833-157-923-913,2013-09-18,2013,CN 201310083201 A,2013-03-15,US 201213421401 A,2012-03-15,System and method for communicating with a plurality of devices,"The title of the invention is system and method for communicating with a plurality of devices. A system and method that permits a monitoring unit to communicate with any one of several Serial Peripheral Interface (SPI) devices on an input/output (IO) module using a single device select line. The monitoring unit sends a data message with an identifier code to the IO module, which includes a router to selectively activate a corresponding circuit to the selected SPI device based on the identifier code.",GEN ELECTRIC,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD,,https://lens.org/066-833-157-923-913,Patent Application,no,0,0,5,5,0,G06F13/4282;;G05B19/4185;;Y02P90/02;;G06F13/4282;;G05B19/4185;;Y02P90/02,G05B19/418,,0,0,,,,DISCONTINUED
291,WO,A1,WO 1998/042730 A1,059-728-509-797-60X,1998-10-01,1998,US 9806065 W,1998-03-20,US 82819597 A,1997-03-21,"SUBSTRATES USEFUL IN BOTH AQUEOUS AND ORGANIC MEDIA, AND ASSOCIATED METHODS OF PREPARATION AND USE","Novel functionalized substrates are provided having a surface which is hydrophilic in a first state and hydrophobic in a second state, so that the substrate can be used in either aqueous or organic media. The substrate surface contains a plurality of hydrophilic sites which can be readily protected and deprotected. In use, generally, a fraction of the sites are protected, leaving the remainder available for participating in organic synthetic processes to be conducted using organic reagents and solvents, e.g., solid phase organic synthesis of ligands which may or may not be oligomeric. Following synthesis, the protected hydrophilic sites are deprotected, regenerating the substrate surface in hydrophilic form for use with aqueous reagents, e.g., in screening and/or separation procedures to be conducted in aqueous media.",CHIRON CORP,ZUCKERMANN RONALD N;;COHEN FRED E,,https://lens.org/059-728-509-797-60X,Patent Application,yes,1,5,2,2,0,C07H21/00;;C07K1/04;;C07K1/042;;C07K1/047,C07H21/00;;C07K1/04,,3,1,040-934-438-052-076,10.1002/pola.1992.080300823,"R ARSHADY & F FALLAH: ""Amphiphilic gels for peptide synthesis"", JOURNAL OF POLYMER SCIENCE, POLYMER CHEMISTRY EDITION., vol. 30, no. 8, 1992, NEW YORK US, pages 1705 - 1716, XP000286978;;CHEMICAL ABSTRACTS, vol. 123, no. 13, 25 September 1995, Columbus, Ohio, US; abstract no. 170151, XP002074984;;CHEMICAL ABSTRACTS, vol. 102, no. 6, 11 February 1985, Columbus, Ohio, US; abstract no. 46635, R ARSHADY: ""A new synthetic approach for the preparation of polymer supports based on beaded copolymers of styren and 2,4,5-trichlorophenyl acrylate: synthesis and swelling behavior off poly(styrene-co-acrylamide) resins"" XP002074985",PENDING
292,EP,A2,EP 1915709 A2,076-936-510-879-357,2008-04-30,2008,EP 06801326 A,2006-08-10,US 2006/0031485 W;;US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,,EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,"NANT HOLDINGS IP, LLC (2011-11-16)",https://lens.org/076-936-510-879-357,Patent Application,yes,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,DISCONTINUED
293,US,A1,US 2014/0012705 A1,077-329-535-289-312,2014-01-09,2014,US 201314024639 A,2013-09-12,US 201314024639 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,OBJECT INFORMATION DERIVED FROM OBJECT IMAGES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/077-329-535-289-312,Patent Application,yes,1,4,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06Q30/06,705/26.61;;705/26.1,0,0,,,,EXPIRED
294,JP,A,JP 2013196691 A,093-677-362-108-536,2013-09-30,2013,JP 2013042479 A,2013-03-05,US 201213421401 A,2012-03-15,SYSTEM AND METHOD FOR COMMUNICATING WITH PLURAL DEVICES,PROBLEM TO BE SOLVED: To provide a system and method that permits a monitoring unit to communicate with any one of several Serial Peripheral Interface (SPI) devices on an input/output (IO) module by use of a single device select line.SOLUTION: A monitoring unit 110 sends a data message including an identifier code to an IO module 200 by use of a single device select line. The IO module includes a router to selectively activate a circuit corresponding to a selected SPI device on the basis of the identifier code.,GEN ELECTRIC,MITCHELL DEAN COHEN;;ROBERT RONALD NIKKELS,,https://lens.org/093-677-362-108-536,Patent Application,no,0,0,5,5,0,G06F13/4282;;G05B19/4185;;Y02P90/02;;G06F13/4282;;G05B19/4185;;Y02P90/02,G06F13/14,,0,0,,,,PENDING
295,US,A1,US 2012/0219187 A1,083-355-475-581-317,2012-08-30,2012,US 201213464410 A,2012-05-04,US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/083-355-475-581-317,Patent Application,yes,1,3,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/103,0,0,,,,EXPIRED
296,US,A1,US 2013/0279754 A1,109-055-506-983-042,2013-10-24,2013,US 201313923260 A,2013-06-20,US 201313923260 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/109-055-506-983-042,Patent Application,yes,17,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/32,382/103,0,0,,,,EXPIRED
297,US,A1,US 2010/0034468 A1,111-212-111-166-003,2010-02-11,2010,US 56813009 A,2009-09-28,US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/111-212-111-166-003,Patent Application,yes,27,47,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/68;;G06F7/10;;G06F17/30;;G06K7/10;;G06Q30/00,382/217;;707/3;;705/27;;235/462.11;;X707E17108;;X707E17019;;707/10,0,0,,,,EXPIRED
298,US,A1,US 2017/0036113 A1,121-224-857-659-243,2017-02-09,2017,US 201615299597 A,2016-10-21,US 201615299597 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/121-224-857-659-243,Patent Application,yes,13,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A63F13/65;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/792;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/78;;G06T7/00;;G07F17/32;;H04N1/00;;H04N21/231;;H04N21/234;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/81,,0,0,,,,EXPIRED
299,US,A1,US 2010/0011058 A1,123-215-104-871-176,2010-01-14,2010,US 50571409 A,2009-07-20,US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/123-215-104-871-176,Patent Application,yes,9,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F15/16;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,709/203;;709/219;;707/104.1,0,0,,,,EXPIRED
300,US,A1,US 2020/0008978 A1,112-162-604-189-426,2020-01-09,2020,US 201916575260 A,2019-09-18,US 201916575260 A;;US 201916264454 A;;US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,IMAGE CAPTURE AND IDENTIFICATION SYSTEM AND PROCESS,"A computing platform that analyzes a captured video stream to identify a document depicted in the video stream, validates identification information corresponding to the document to display an information address associated with the document, and that initiates a transaction based on the validation of the identification information associated with the document.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/112-162-604-189-426,Patent Application,yes,0,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A61F9/08;;A63F13/00;;A63F13/20;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,0,0,,,,EXPIRED
301,US,B2,US 9317769 B2,126-542-875-802-109,2016-04-19,2016,US 201514668979 A,2015-03-25,US 201514668979 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/126-542-875-802-109,Granted Patent,yes,109,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
302,US,B2,US 8457395 B2,128-112-899-021-895,2013-06-04,2013,US 201213493953 A,2012-06-11,US 201213493953 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/128-112-899-021-895,Granted Patent,yes,104,16,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
303,US,B2,US 7565008 B2,139-672-433-106-867,2009-07-21,2009,US 34209406 A,2006-01-26,US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/139-672-433-106-867,Granted Patent,yes,23,130,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/165;;382/305,0,0,,,,EXPIRED
304,US,A1,US 2011/0295742 A1,161-852-816-445-730,2011-12-01,2011,US 201113207230 A,2011-08-10,US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/161-852-816-445-730,Patent Application,yes,7,9,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06Q40/00,705/39;;235/379,0,0,,,,EXPIRED
305,US,B2,US 10500097 B2,145-811-339-458-166,2019-12-10,2019,US 201916264454 A,2019-01-31,US 201916264454 A;;US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database as part of a computer-based game. An information address corresponding to the object is then used to access content information associated with the identified object and interact with the game based on the content information.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/145-811-339-458-166,Granted Patent,yes,448,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A63F13/00;;A61F9/08;;A63F13/20;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06F17/22;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,43,23,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587;;157-015-151-956-874;;078-957-418-810-926,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147;;10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;Kohtake et al., InfoStick: An Interaction Device for Inter-Appliance Computing, Hans-W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www.infoworld.com, Aug. 21, 2000 Infoworld, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages. Date not available.",EXPIRED
306,US,A1,US 2006/0110034 A1,006-523-975-139-936,2006-05-25,2006,US 29497105 A,2005-12-05,US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses image characteristics to identify an object from a plurality of objects in a database. The image is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/006-523-975-139-936,Patent Application,yes,15,9,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04L9/32;;H04N1/00,382/165;;340/5.74,0,0,,,,EXPIRED
307,US,B2,US 7881529 B2,035-427-012-996-865,2011-02-01,2011,US 50571409 A,2009-07-20,US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/035-427-012-996-865,Granted Patent,yes,9,78,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/165,0,0,,,,EXPIRED
308,US,A1,US 2014/0340532 A1,059-057-328-137-456,2014-11-20,2014,US 201414173671 A,2014-02-05,US 201414173671 A;;US 201313860967 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/059-057-328-137-456,Patent Application,yes,7,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/91;;G06Q30/06;;H04N1/00;;H04N5/232,348/207.1;;705/26.1,0,0,,,,EXPIRED
309,US,A1,US 2011/0173100 A1,060-335-430-175-734,2011-07-14,2011,US 201113069134 A,2011-03-22,US 201113069134 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/060-335-430-175-734,Patent Application,yes,99,41,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06Q30/00;;H04L29/06;;H04M1/66,705/27.1;;455/414.3;;455/411;;705/26.1,0,0,,,,EXPIRED
310,US,A,US 2810550 A,062-392-561-165-177,1957-10-22,1957,US 27972452 A,1952-04-01,US 27972452 A,1952-04-01,Earth boring machine,,ISIDORE COHEN MARK;;JAMES GULLY RONALD,ISIDORE COHEN MARK;;JAMES GULLY RONALD,,https://lens.org/062-392-561-165-177,Granted Patent,no,8,14,1,1,0,E21B7/021;;E21B7/021,E21B7/02,,0,0,,,,EXPIRED
311,US,B2,US 7403652 B2,069-847-052-423-871,2008-07-22,2008,US 29497105 A,2005-12-05,US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses image characteristics to identify an object from a plurality of objects in a database. The image is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/069-847-052-423-871,Granted Patent,yes,17,93,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,382/165,0,0,,,,EXPIRED
312,US,A1,US 2013/0097043 A1,066-374-132-771-095,2013-04-18,2013,US 201213645439 A,2012-10-04,US 201213645439 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/066-374-132-771-095,Patent Application,yes,0,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/78,705/26.1;;382/103,0,0,,,,EXPIRED
313,US,A1,US 2019/0134509 A1,074-916-474-605-445,2019-05-09,2019,US 201916238434 A,2019-01-02,US 201916238434 A;;US 201615254802 A;;US 201213406720 A;;US 51000906 A;;US 29497105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 71259005 P,2000-11-06,INTERACTIVITY WITH A MIXED REALITY VIA REAL-WORLD OBJECT RECOGNITION,"An identification method and process for objects from digitally captured images thereof that uses image characteristics to identify an object from a plurality of objects in a database. The image is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image. The inventive subject matter also includes systems and methods of interacting with a virtual space, in which a mobile device is used to electronically capture image data of a real-world object, the image data is used to identify information related to the real-world object, which enables the mobile device to execute processes that include interaction with the object.",NANT HOLDINGS IP LLC,COHEN RONALD H;;BONCYK WAYNE C,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/074-916-474-605-445,Patent Application,yes,16,0,3,173,0,G06F16/29;;G06F16/51;;A63F13/216;;A63F13/35;;A63F13/655;;A63F13/92;;A63F2300/8082;;G06V20/20;;G06V30/142;;G06V10/245;;G06V10/56;;G06V10/462;;G06V10/7515;;G06F16/29;;G06F16/51;;G06V10/56;;G06V10/245;;G06V10/462;;G06V10/7515;;G06V20/20;;G06V30/142;;G06F18/22;;G06F18/24;;A63F13/216;;A63F13/25;;A63F13/335;;A63F13/35;;A63F13/655;;A63F13/92;;A63F2300/8082;;G06T19/006,A63F13/655;;A63F13/216;;A63F13/25;;A63F13/335;;A63F13/35;;G06F16/29;;G06F16/51;;G06T19/00;;G06V10/56,,0,0,,,,DISCONTINUED
314,AU,A,AU 1980/055418 A,088-374-608-869-118,1980-08-21,1980,AU 1980/055418 A,1980-02-11,US 1168079 A,1979-02-12,FLAME RETARDANT THERMOPLASTIC COMPOSITIONS WITH REDUCED BLOOMS,,GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/088-374-608-869-118,Patent Application,no,0,0,8,9,0,C08K5/06;;C08L67/02;;C08K5/03;;C08L23/00,C08L67/00;;C08K5/06;;C08K7/14;;C08L7/00;;C08L21/00;;C08L23/00;;C08L33/00;;C08L33/02;;C08L51/00;;C08L51/02;;C08L67/02;;C08L77/00;;C08L101/00,,0,0,,,,DISCONTINUED
315,US,A1,US 2015/0063712 A1,110-029-720-640-485,2015-03-05,2015,US 201414536412 A,2014-11-07,US 201414536412 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/110-029-720-640-485,Patent Application,yes,10,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;G06F17/30,382/224,0,0,,,,EXPIRED
316,US,B2,US 9785859 B2,139-942-597-437-248,2017-10-10,2017,US 201615291934 A,2016-10-12,US 201615291934 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/139-942-597-437-248,Granted Patent,yes,396,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/70;;G06F17/30;;G06K9/62;;G06Q20/10;;G09B21/00,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
317,US,B2,US 8938096 B2,144-711-176-738-635,2015-01-20,2015,US 201313907819 A,2013-05-31,US 201313907819 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/144-711-176-738-635,Granted Patent,yes,105,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N5/232;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/103,40,9,041-034-977-263-043;;067-825-083-591-587;;084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206,10.1145/265563.265573;;10.1109/cvpr.2004.1315147;;10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782,"Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer-Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: Situated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; Play: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.",EXPIRED
318,JP,A,JP 2007200275 A,160-689-907-422-493,2007-08-09,2007,JP 2006225644 A,2006-08-22,US 34209406 A,2006-01-26,SYSTEM AND METHOD FOR ACQUIRING AND IDENTIFYING DATA,"<P>PROBLEM TO BE SOLVED: To digitally identify an image captured without changing the object. <P>SOLUTION: An identification method uses characteristics of an image for specifying an object from a plurality of objects in a database. In order to identify an actual object in a digital image, data is broken down into parameters, such as a shape comparison, grayscale comparison, wavelet comparison, and color cube comparison with object data in one or more databases. <P>COPYRIGHT: (C)2007,JPO&INPIT",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/160-689-907-422-493,Patent Application,no,2,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06T1/00;;G06F17/30;;G06V10/56;;G06V30/142;;H04N5/225;;H04N7/173;;H04N21/278;;H04N21/845,,0,0,,,,DISCONTINUED
319,US,A1,US 2011/0292204 A1,191-742-778-693-91X,2011-12-01,2011,US 201113207211 A,2011-08-10,US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/191-742-778-693-91X,Patent Application,yes,4,9,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,H04N7/18,348/135;;X348E05048,0,0,,,,EXPIRED
320,US,A1,US 2015/0063645 A1,190-661-515-673-852,2015-03-05,2015,US 201414536689 A,2014-11-10,US 201414536689 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/190-661-515-673-852,Patent Application,yes,2,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;G06F17/30;;G06K9/22;;G06K9/78;;G06Q30/02;;G06Q30/06;;H04N21/81,382/103,0,0,,,,EXPIRED
321,US,A1,US 2012/0250942 A1,192-517-959-969-458,2012-10-04,2012,US 201213493953 A,2012-06-11,US 201213493953 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/192-517-959-969-458,Patent Application,yes,5,9,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/103,0,0,,,,EXPIRED
322,US,A1,US 2014/0330677 A1,002-501-014-004-263,2014-11-06,2014,US 201414335559 A,2014-07-18,US 201414335559 A;;US 201314073760 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/002-501-014-004-263,Patent Application,yes,6,44,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06Q30/06,705/26.61,0,0,,,,EXPIRED
323,US,A1,US 2014/0177921 A1,015-311-294-806-539,2014-06-26,2014,US 201414195759 A,2014-03-03,US 201414195759 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/015-311-294-806-539,Patent Application,yes,8,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06K9/46,382/103,0,0,,,,EXPIRED
324,US,A1,US 2020/0016003 A1,018-118-003-924-311,2020-01-16,2020,US 201916577910 A,2019-09-20,US 201916577910 A;;US 201916264454 A;;US 201816116660 A;;US 201715711118 A;;US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,IMAGE CAPTURE AND IDENTIFICATION SYSTEM AND PROCESS,"An image-based transaction system includes a mobile device with an image sensor that is programmed to capture, via the image sensor, a video stream of a scene. The mobile device identifies a document using image characteristics from the video stream and acquires an image of at least a part of the document, and then identifies symbols in the image based on locations within the image of the document. The symbols can include alphanumeric symbols. The mobile device processes the symbols according to their type to obtain an address related to the document and the symbols and initiates a transaction associated with the identified document.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/018-118-003-924-311,Patent Application,yes,0,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A61F9/08;;A63F13/00;;A63F13/20;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/58;;G06F16/583;;G06F16/93;;G06F16/955;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/10;;G06T7/11;;G06T7/13;;G06T7/136;;G06T7/194;;G06T7/246;;G06T7/33;;G06T7/73;;G07F17/32;;G09B21/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,0,0,,,,EXPIRED
325,JP,A,JP 2014241151 A,025-632-752-442-454,2014-12-25,2014,JP 2014157409 A,2014-08-01,US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"PROBLEM TO BE SOLVED: To provide a system and a process for identifying digitally captured images without requiring modification to an object.SOLUTION: Search terms are derived automatically from images captured by a camera-equipped cell phone, a PDA or other image capturing devices, and submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,WAYNE C BONCYK;;COHEN RONALD H,,https://lens.org/025-632-752-442-454,Patent Application,no,3,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,PENDING
326,US,A1,US 2017/0124119 A1,038-147-572-580-991,2017-05-04,2017,US 201615392935 A,2016-12-28,US 201615392935 A;;US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture And Identification System And Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/038-147-572-580-991,Patent Application,yes,0,3,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,EXPIRED
327,US,A1,US 2013/0238412 A1,045-106-421-710-691,2013-09-12,2013,US 201313859183 A,2013-04-09,US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/045-106-421-710-691,Patent Application,yes,0,39,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/02,705/14.23;;705/14.51,0,0,,,,EXPIRED
328,AU,B2,AU 533834 B2,076-234-241-498-321,1983-12-15,1983,AU 1979/052346 A,1979-10-31,US 95780178 A,1978-11-06,MODIFIED POLYESTER COMPOSITIONS,,GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/076-234-241-498-321,Granted Patent,no,0,1,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,,0,0,,,,EXPIRED
329,US,A1,US 2014/0331184 A1,088-896-613-154-289,2014-11-06,2014,US 201414332354 A,2014-07-15,US 201414332354 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/088-896-613-154-289,Patent Application,yes,2,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;G06F3/0482,715/835;;382/103,0,0,,,,EXPIRED
330,US,B2,US 10089329 B2,094-845-407-247-553,2018-10-02,2018,US 201715711326 A,2017-09-21,US 201715711326 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"An object is recognized from image data as a target object and linked to a user based on an interaction by the user, information about the target object is obtained and a purchase of the target object is initiated.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/094-845-407-247-553,Granted Patent,yes,415,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
331,US,A1,US 2014/0172575 A1,093-593-348-181-018,2014-06-19,2014,US 201414187717 A,2014-02-24,US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/093-593-348-181-018,Patent Application,yes,8,8,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06Q30/02;;G06K9/32,705/14.58;;705/14.64,0,0,,,,EXPIRED
332,US,B2,US 9014516 B2,095-724-632-844-245,2015-04-21,2015,US 201414191355 A,2014-02-26,US 201414191355 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/095-724-632-844-245,Granted Patent,yes,100,6,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/60;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-a Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007102010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: a Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
333,US,A1,US 2014/0368431 A1,097-516-359-224-366,2014-12-18,2014,US 201414474245 A,2014-09-01,US 201414474245 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/097-516-359-224-366,Patent Application,yes,3,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F3/01,345/156,0,0,,,,EXPIRED
334,US,A1,US 2015/0302087 A1,114-679-401-051-149,2015-10-22,2015,US 201414569766 A,2014-12-14,US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P;;US 0235407 W,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/114-679-401-051-149,Patent Application,yes,0,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/00,,0,0,,,,EXPIRED
335,US,A1,US 2020/0012679 A1,117-935-833-980-119,2020-01-09,2020,US 201916578231 A,2019-09-20,US 201916578231 A;;US 201816143257 A;;US 201715711326 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived From Object Images,"An image-based transaction system includes a mobile device with an image sensor that is programmed to capture, via the image sensor, a digital images of a scene. The mobile device identifies a document using image characteristics from the captured images and acquires an image of at least a part of the document, and then identifies symbols in the image based on locations within the image of the document. The symbols can include alphanumeric symbols. The mobile device processes the symbols according to their type to obtain an address related to the document and the symbols and initiates a transaction associated with the identified document.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/117-935-833-980-119,Patent Application,yes,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F16/583;;G06F3/01;;G06F16/22;;G06F16/2455;;G06F16/50;;G06F16/532;;G06F16/58;;G06F16/732;;G06F16/904;;G06F16/951;;G06F16/9537;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,0,0,,,,EXPIRED
336,US,B2,US 8792750 B2,113-180-973-541-726,2014-07-29,2014,US 201313858897 A,2013-04-08,US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/113-180-973-541-726,Granted Patent,yes,113,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54,382/305,38,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
337,US,A1,US 2017/0036114 A1,125-498-308-113-84X,2017-02-09,2017,US 201615299604 A,2016-10-21,US 201615299604 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/125-498-308-113-84X,Patent Application,yes,11,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A63F13/65;;A63F13/213;;A63F13/335;;A63F13/792;;A63F13/92;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06T7/00;;G07F17/32;;H04N1/00;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/4722;;H04N21/478;;H04N21/81,,0,0,,,,EXPIRED
338,US,B2,US 9148562 B2,120-934-761-431-092,2015-09-29,2015,US 201414536432 A,2014-11-07,US 201414536432 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/120-934-761-431-092,Granted Patent,yes,110,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/232;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
339,US,A1,US 2013/0276004 A1,125-596-609-658-340,2013-10-17,2013,US 201313908081 A,2013-06-03,US 201313908081 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/125-596-609-658-340,Patent Application,yes,5,44,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N21/81,725/5;;725/60;;725/23;;725/1,0,0,,,,EXPIRED
340,US,B2,US 8478037 B2,153-270-028-382-791,2013-07-02,2013,US 201213538915 A,2012-06-29,US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/153-270-028-382-791,Granted Patent,yes,100,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
341,US,B2,US 8478036 B2,168-271-984-621-51X,2013-07-02,2013,US 201213410577 A,2012-03-02,US 201213410577 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/168-271-984-621-51X,Granted Patent,yes,102,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
342,US,B2,US 8798368 B2,179-645-438-367-537,2014-08-05,2014,US 201313856197 A,2013-04-03,US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/179-645-438-367-537,Granted Patent,yes,110,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;G06Q20/40,382/181;;705/42,38,20,041-034-977-263-043;;067-825-083-591-587;;032-705-158-397-206;;104-793-026-621-862;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;051-045-047-582-773;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;030-846-937-028-967;;013-901-391-839-508;;088-865-239-067-73X;;187-572-604-127-113;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619,10.1145/265563.265573;;10.1109/cvpr.2004.1315147;;10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/mmcs.1999.778638;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1145/354666.354669;;10.1145/215585.215639;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402,"Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Arai, T. et al., ""PaperLink: A Technique for Hyperlinking From Real Paper to Electronic Content,"" CHI1997, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997; pp. 327-334.;;Bulman, J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, vol. 22, No. 3, Jul. 2004; pp. 84-94.;;Chang, W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia 1997, Seattle, Washington, Nov. 9-13, 1997; pp. 203-213.;;Diverdi, S. et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12; University of California Santa Barbara, May 2003; 7 pages.;;Diverdi, S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004 (IEEE/ACM Int'l Symp on Mixed and Augmented Reality), Arlington, Virginia, Nov. 2-5, 2004; 2 pages.;;Feiner, S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,"" Personal Technologies, 1(4), 1997; pp. 208-217.;;Fernandez, F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba; Mar. 2004; 124 pages.;;Geiger, C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Int'l Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; 2 pages.;;Gevers, T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, vol. 9, No. 1, Jan. 2000; pp. 102-119.;;Haritaoglu, I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp 2001; Lecture Notes in Computer Science, vol. 2201; pp. 247-255.;;Hollerer, T., et al., ""Chapter Nine: Mobile Augmented Reality,"" Telegeoinformatics: Location Based Computing and Services. H. Karimi and A. Hammad (eds.), Taylor & Francis Books, Ltd., Jan. 2004; 39 pages.;;Iwamoto, T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive2004 Advances in Pervasive Computing, Linz/Vienna, Austria, (2004).;;Iwaoka, T., et al., ""Digital Safari Guidebook With Image Retrieval,"" ICMCS, vol. 2, p. 1011-1012. (1999).;;Jebara, T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision and Wearable Computers,"" ISWC, p. 138-145. IEEE Computer Society, (1997).;;Kangas, K. et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, Aug. 15-20, 1999, Seattle, Washington; p. 48-58.;;Kato, H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Int'l Workshop on Augmented Reality, Oct. 20-21, 1999, San Francisco, California; pp. 85-94.;;Klinker, G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" ISAR, p. 124-136. IEEE Computer Society, (2001).;;Levine, J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis,. EECS Dept., MIT, 1997.;;Ljungstrand, P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" ; Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingør, Denmark; Apr. 2000; pp. 23-31.;;Rekimoto, J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology (1995), pp. 29-36.;;Rekimoto, J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, 1998, Second International Symposium, Oct. 19-20, 1998, Pittsburgh, Pennsylvania; pp. 68-75.;;Rekimoto, J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingør, Denmark: Apr. 2000; pp. 1-10.;;Rekimoto, J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" from the book Fundamentals of Wearable Computers and Augmented Reality, Barfield and Caudell (Eds.), Jun. 6, 2001; pp. 353-377.;;Rohs, M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 171-189.;;Siltanen, S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" AUIC '06 Proceedings of the 7th Australasian User interface conference-vol. 50; pp. 113-116.;;Smailagic, A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith, J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, Multimedia '96, ACM New York, New York, pp. 87-98.;;Starner, T., et al., ""Augmented Reality Through Wearable Computing,"" 1997; Presence: Teleoper. Virtual Environ. 6, 4.;;Suzuki, G., et al., ""u-Photo: Interacting With Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science vol. 3468, 2005, pp. 190-207.;;Toye, E., et al., ""Interacting With Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" Personal and Ubiquitous Computing; vol. 11, Issue 2, Jan. 2007; pp. 97-106.;;Wagner, D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, 2003. Oct. 18-21, 2003; 9 pages.;;Yang, J., et al., ""Smart Sight: A Tourist Assistant System,"" Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California; Digest of Papers, pp. 73-78.;;Zhang, X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Int'l Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; pp. 179-180.",EXPIRED
343,US,A1,US 2013/0030961 A1,188-510-606-108-39X,2013-01-31,2013,US 201213633808 A,2012-10-02,US 201213633808 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/188-510-606-108-39X,Patent Application,yes,6,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/06,705/27.2,0,0,,,,EXPIRED
344,US,B2,US 8548278 B2,006-408-871-796-460,2013-10-01,2013,US 201213633808 A,2012-10-02,US 201213633808 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/006-408-871-796-460,Granted Patent,yes,105,20,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/60,382/305;;705/27.2,0,0,,,,EXPIRED
345,EP,B1,EP 0020605 B1,001-876-123-673-719,1985-01-09,1985,EP 79901585 A,1980-05-20,US 95780178 A,1978-11-06,MODIFIED POLYESTER COMPOSITIONS,,GENERAL ELECTRIC COMPANY,"COHEN, STUART COLIN;;DIECK, RONALD LEE",,https://lens.org/001-876-123-673-719,Granted Patent,yes,0,0,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,,0,0,,,,EXPIRED
346,US,B2,US 8503787 B2,008-864-376-065-11X,2013-08-06,2013,US 201113207112 A,2011-08-10,US 201113207112 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/008-864-376-065-11X,Granted Patent,yes,105,14,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/181,0,0,,,,EXPIRED
347,US,B2,US 8718410 B2,035-175-168-260-151,2014-05-06,2014,US 201213693892 A,2012-12-04,US 201213693892 A;;US 201113091994 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/035-175-168-260-151,Granted Patent,yes,115,21,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54,382/305,38,20,032-705-158-397-206;;104-793-026-621-862;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;051-045-047-582-773;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;030-846-937-028-967;;013-901-391-839-508;;088-865-239-067-73X;;187-572-604-127-113;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;041-034-977-263-043;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/mmcs.1999.778638;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1145/354666.354669;;10.1145/215585.215639;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1145/265563.265573;;10.1109/cvpr.2004.1315147,"Arai, T. et al., ""PaperLink: A Technique for Hyperlinking From Real Paper to Electronic Content,"" CHI1997, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997; pp. 327-334.;;Bulman, J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, vol. 22, No. 3, Jul. 2004; pp. 84-94.;;Chang, W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia 1997, Seattle, Washington, Nov. 9-13, 1997; pp. 203-213.;;Diverdi, S. et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12; University of California Santa Barbara, May 2003; 7 pages.;;Diverdi, S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004 (IEEE/ACM Int'l Symp on Mixed and Augmented Reality), Arlington, Virginia, Nov. 2-5, 2004; 2 pages.;;Feiner, S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1(4), 1997; pp. 208-217.;;Fernandez, F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba; Mar. 2004; 124 pages.;;Geiger, C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; 2 pages.;;Gevers, T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, vol. 9, No. 1, Jan. 2000; pp. 102-119.;;Haritaoglu, I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp 2001; Lecture Notes in Computer Science, vol. 2201; pp. 247-255.;;Hollerer, T., et al., ""Chapter Nine: Mobile Augmented Reality,"" Telegeoinformatics: Location Based Computing and Services. H. Karimi and a. Hammad (eds.), Taylor & Francis Books, Ltd., Jan. 2004; 39 pages.;;Iwamoto, T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive2004 Advances in Pervasive Computing, Linz/Vienna, Austria, (2004).;;Iwaoka, T., et al., ""Digital Safari Guidebook With Image Retrieval,"" ICMCS, vol. 2, p. 1011-1012. (1999).;;Jebara, T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" ISWC, p. 138-145. IEEE Computer Society, (1997).;;Kangas, K. et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, Aug. 15-20, 1999, Seattle, Washington; p. 48-58.;;Kato, H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Int'l Workshop on Augmented Reality, Oct. 20-21, 1999, San Francisco, California; pp. 85-94.;;Klinker, G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study of a Mobile AR System,"" ISAR, p. 124-136. IEEE Computer Society, (2001).;;Levine, J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis,. EECS Dept., MIT, 1997.;;Ljungstrand, P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" ; Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingor, Denmark; Apr. 2000; pp. 23-31.;;Rekimoto, J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology (1995), pp. 29-36.;;Rekimoto, J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, 1998, Second International Symposium, Oct. 19-20, 1998, Pittsburgh, Pennsylvania; pp. 68-75.;;Rekimoto, J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingor, Denmark: Apr. 2000; pp. 1-10,.;;Rekimoto, J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" from the book Fundamentals of Wearable Computers and Augmented Reality, Barfield and Caudell (Eds.), Jun. 6, 2001; pp. 353-377.;;Rohs, M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 171-189.;;Siltanen, S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" AUIC '06 Proceedings of the 7th Australasian User interface conference-vol. 50; pp. 113-116.;;Smailagic, A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith, J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, Multimedia '96, ACM New York, New York, pp. 87-98.;;Starner, T., et al., ""Augmented Reality Through Wearable Computing,"" 1997; Presence: Teleoper. Virtual Environ. 6, 4.;;Suzuki, G., et al., ""u-Photo: Interacting With Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science vol. 3468, 2005, pp. 190-207.;;Toye, E., et al., ""Interacting With Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" Personal and Ubiquitous Computing; vol. 11, Issue 2, Jan. 2007; pp. 97-106.;;Wagner, D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, 2003. Oct. 18-21, 2003; 9 pages.;;Yang, J., et al., ""Smart Sight: A Tourist Assistant System,"" Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California; Digest of Papers, pp. 73-78.;;Zhang, X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Int'l Symposium On Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; pp. 179-180.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.",EXPIRED
348,KR,A,KR 20080033538 A,046-480-182-419-210,2008-04-16,2008,KR 20087005802 A,2008-03-10,US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/046-480-182-419-210,Patent Application,no,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;H04Q7/24,,0,0,,,,DISCONTINUED
349,US,B2,US 7899243 B2,044-896-444-244-796,2011-03-01,2011,US 33363008 A,2008-12-12,US 33363008 A;;US 49224304 A;;US 99294201 A;;US 0235407 W;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object ( 16 ) is captured and the object is recognized from plurality of objects in a database ( 20 ). An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/044-896-444-244-796,Granted Patent,yes,25,96,4,173,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10;;G06Q30/04;;G06Q30/0635;;G06T7/10;;G06T7/194;;G06T7/73;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N1/00244;;H04N7/183;;G06V30/142;;G06V10/56;;G06V10/7515;;G06V10/462;;H04N21/44224;;H04N23/661;;G06F18/254;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23418;;H04N21/41407;;H04N21/6582;;H04N21/4782;;H04N21/4223;;H04N21/4722;;H04N21/23109;;A63F13/20;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06T7/136;;G06T7/194;;G06T7/10;;G06T7/11;;G06T7/246;;G06T7/73;;G06T7/13;;G06T7/33;;G06T7/337;;G06F16/51;;G06F16/5866;;G06F16/50;;G06F40/134;;A63F13/00;;G06Q20/102;;G06Q20/14;;G06Q20/202;;G06Q20/208;;G06Q20/24;;G06Q20/327;;G06Q20/3567;;G06Q20/40145;;G06Q30/04;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G09B21/006;;H04L67/02;;H04N1/00244;;H04N5/91;;H04N7/183;;H04N7/185;;H04N21/254;;H04N21/4781;;H04N21/47815;;H04N21/812;;H04N21/8126;;H04N21/8173;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;H04N21/44224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F18/254;;G06F2218/12;;H04N23/00;;H04N23/64;;H04N23/80;;H04N23/661;;A61F9/08;;G06F3/0482;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10,G06V10/56;;G06V30/142;;G06V30/224,382/165;;382/305,0,0,,,,EXPIRED
350,US,A1,US 2012/0195467 A1,043-547-997-696-352,2012-08-02,2012,US 201213407432 A,2012-02-28,US 201213407432 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/043-547-997-696-352,Patent Application,yes,3,1,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/62,382/103,0,0,,,,EXPIRED
351,US,A1,US 2013/0336530 A1,049-782-786-068-127,2013-12-19,2013,US 201313968666 A,2013-08-16,US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/049-782-786-068-127,Patent Application,yes,4,2,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/103,0,0,,,,EXPIRED
352,DK,B,DK 138162 B,072-448-751-984-985,1978-07-24,1978,DK 568171 A,1971-11-19,US 9147770 A,1970-11-20,Varmeveksler.,,BAXTER TRAVENOL LAB,LEONARD RONALD JAMES;;COHEN FRED MICHAEL,,https://lens.org/072-448-751-984-985,Patent Application,no,0,0,17,17,0,A61M5/44;;A61M5/44;;A61M2205/366;;A61M2205/366;;F28D9/0025;;F28D9/0025;;Y10S165/399;;Y10S165/399,A61M5/44;;F28D9/00,,0,0,,,,EXPIRED
353,US,A1,US 2016/0275115 A1,093-061-422-626-031,2016-09-22,2016,US 201615169948 A,2016-06-01,US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 0235407 W;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/093-061-422-626-031,Patent Application,yes,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/46;;H04N5/44,,0,0,,,,EXPIRED
354,US,B2,US 9578107 B2,108-310-110-679-537,2017-02-21,2017,US 201514615162 A,2015-02-05,US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/108-310-110-679-537,Granted Patent,yes,108,19,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04L29/08;;H04N21/278;;H04N21/845,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
355,US,B2,US 7680324 B2,106-096-003-004-414,2010-03-16,2010,US 20490105 A,2005-08-15,US 20490105 A;;US 0235407 W;;US 49224304 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Use of image-derived information as search criteria for internet and other search engines,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/106-096-003-004-414,Granted Patent,yes,20,209,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06K9/54,382/165;;382/305,0,0,,,,ACTIVE
356,US,A1,US 2015/0205868 A1,108-489-727-845-462,2015-07-23,2015,US 201414569763 A,2014-12-14,US 201414569763 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/108-489-727-845-462,Patent Application,yes,7,7,3,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F3/04842;;G06F16/532;;G06F16/583;;G06F16/5854;;G06F16/9537;;G06F3/017;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06Q30/0623;;G06Q30/0625;;G06V20/20;;H04N23/80;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5838;;G06F16/5854;;G06F16/7335;;G06F16/9537;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F3/04842;;G06V20/10;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V20/20;;G06F2218/08;;H04N23/80;;G06F16/5846;;G06F16/9538;;G06F3/017;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06Q30/0623;;G06Q30/0625;;G06T7/00,G06F17/30,,0,0,,,,EXPIRED
357,US,B2,US 8520897 B2,112-439-042-451-339,2013-08-27,2013,US 201213705071 A,2012-12-04,US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/112-439-042-451-339,Granted Patent,yes,9,4,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/103,0,0,,,,EXPIRED
358,US,B2,US 8224078 B2,119-274-870-773-626,2012-07-17,2012,US 201113037317 A,2011-02-28,US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/119-274-870-773-626,Granted Patent,yes,100,94,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
359,ZA,B,ZA 817630 B,113-195-897-642-315,1982-10-27,1982,ZA 817630 A,1981-11-04,ZA 817630 A;;ZA 812591 A,1981-04-21,PROP OR OTHER ELONGATE SUPPORT,,DERGLEN PTY LTD,PRETORIUS WILLEM JOHANNES;;COHEN RONALD RAYMOND,,https://lens.org/113-195-897-642-315,Granted Patent,no,0,0,1,1,0,,E21D/,,0,0,,,,EXPIRED
360,US,A1,US 2013/0246256 A1,127-038-174-793-434,2013-09-19,2013,US 201313872032 A,2013-04-26,US 201313872032 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/127-038-174-793-434,Patent Application,yes,11,9,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/72,705/39;;382/103,0,0,,,,EXPIRED
361,US,A,US 4257937 A,121-858-550-644-893,1981-03-24,1981,US 95780178 A,1978-11-06,US 95780178 A,1978-11-06,Modified polyester compositions,"Modified thermoplastic polyester compositions are provided which comprise (a) a poly(1,4-butylene terephthalate) resin or polyester compolymer and, optionally, a poly(ethylene terephthalate) resin and (b) a modifier therefor comprising a combination of a polyacrylate resin and an aromatic polycarbonate, and, optionally (c) filler and/or reinforcing agent and/or (d) a flame retardant. Modifier (b) provides enhanced resistance to impact fracture, increased strength and improved resistance to heat distortion in articles molded from the compositions.",GEN ELECTRIC,COHEN STUART C;;DIECK RONALD L,,https://lens.org/121-858-550-644-893,Granted Patent,yes,8,65,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,260 40R,0,0,,,,EXPIRED
362,US,B2,US 9025814 B2,125-620-537-235-409,2015-05-05,2015,US 201414195759 A,2014-03-03,US 201414195759 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/125-620-537-235-409,Granted Patent,yes,107,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/100;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
363,US,A1,US 2018/0011877 A1,123-112-900-707-033,2018-01-11,2018,US 201715711326 A,2017-09-21,US 201715711326 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"An object is recognized from image data as a target object and linked to a user based on an interaction by the user, information about the target object is obtained and a purchase of the target object is initiated.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/123-112-900-707-033,Patent Application,yes,9,4,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,0,0,,,,EXPIRED
364,US,B2,US 8855423 B2,143-989-851-958-018,2014-10-07,2014,US 201313912396 A,2013-06-07,US 201313912396 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/143-989-851-958-018,Granted Patent,yes,112,51,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/181,40,9,084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206;;041-034-977-263-043;;067-825-083-591-587,10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782;;10.1145/265563.265573;;10.1109/cvpr.2004.1315147,"Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer-Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: Situated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; PLAY: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
365,CA,A,CA 554390 A,147-024-578-833-947,1958-03-18,1958,CA 554390D A,,CA 554390T A,,EARTH BORING MACHINE,,COHEN MARK I;;GULLY RONALD J,GULLY RONALD J;;COHEN MARK I,,https://lens.org/147-024-578-833-947,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
366,US,B2,US 8326031 B2,144-414-312-322-394,2012-12-04,2012,US 201113069112 A,2011-03-22,US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/144-414-312-322-394,Granted Patent,yes,105,36,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
367,EP,A1,EP 0128964 A1,136-300-797-083-663,1984-12-27,1984,EP 83105803 A,1983-06-14,EP 83105803 A,1983-06-14,Mine props.,"A prop of the type used to support the hanging wall in underground mining operations includes a substantially cylindrical timber pole, one end of which is tapered in a frusto-conical manner and is located within a complementary shaped metal sleeve.",STOPE INTERNATIONAL INC,COHEN RONALD RAYMOND;;PRETORIUS WILLEM JOHANNES,,https://lens.org/136-300-797-083-663,Patent Application,yes,5,8,1,1,0,E21D15/02,E21D15/02,,0,0,,,,DISCONTINUED
368,US,B2,US 9824099 B2,148-235-305-883-099,2017-11-21,2017,US 201615392935 A,2016-12-28,US 201615392935 A;;US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/148-235-305-883-099,Granted Patent,yes,412,9,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04L29/08;;H04M1/02;;H04N21/278;;H04N21/845,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in The Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/U52007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 35-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content—Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
369,US,B2,US 9170654 B2,182-514-293-381-757,2015-10-27,2015,US 201414474245 A,2014-09-01,US 201414474245 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/182-514-293-381-757,Granted Patent,yes,112,34,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F3/01;;G06F17/30;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
370,AU,A,AU 1983/016837 A,018-824-124-568-067,1985-01-17,1985,AU 1983/016837 A,1983-07-14,AU 1983/016837 A,1983-07-14,NON-REUSABLE TIMBER PROP WITH SLEEVED END,,STOPE INTERNATIONAL INC,COHEN RONALD RAYMOND;;PRETORIUS WILLEM JOHANNES,,https://lens.org/018-824-124-568-067,Patent Application,no,0,0,1,1,0,E21D15/55;;E21D15/02,E21D15/02;;E21D15/55,,0,0,,,,DISCONTINUED
371,CA,A,CA 1123534 A,034-459-775-472-912,1982-05-11,1982,CA 343121 A,1980-01-07,CA 343121 A,1980-01-07,MODIFIED POLYESTER COMPOSITIONS,"Modified thermoplastic polyester compositions are provided which comprise (a) a poly-(1,4-butylene terephthalate) resin or polyester copolymer and, optionally, a poly(ethylene terephthalate) resin and (b) a modifier therefor comprising a combination of a polyacrylate resin and an aromatic polycarbonate, and, optionally (c) filler and/or reinforcing agent and/or (d) a flame retardant. Modifier (b) provides enhanced resistance to impact fracture, increased strength and improved resistance to heat distortion in articles molded from the compositions.",GEN ELECTRIC,COHEN STUART C;;DIECK RONALD L,,https://lens.org/034-459-775-472-912,Granted Patent,no,0,0,1,1,0,,C08L33/08;;C08L67/02;;C08L69/00,400-86,0,0,,,,EXPIRED
372,US,A1,US 2009/0141986 A1,024-092-108-568-426,2009-06-04,2009,US 33363008 A,2008-12-12,US 33363008 A;;US 49224304 A;;US 99294201 A;;US 0235407 W;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object ( 16 ) is captured and the object is recognized from plurality of objects in a database ( 20 ). An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/024-092-108-568-426,Patent Application,yes,23,42,4,173,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10;;G06Q30/04;;G06Q30/0635;;G06T7/10;;G06T7/194;;G06T7/73;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N1/00244;;H04N7/183;;G06V30/142;;G06V10/56;;G06V10/7515;;G06V10/462;;H04N21/44224;;H04N23/661;;G06F18/254;;A63F13/655;;A63F13/213;;G06F16/24;;G06F16/29;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23418;;H04N21/41407;;H04N21/6582;;H04N21/4782;;H04N21/4223;;H04N21/4722;;H04N21/23109;;A63F13/20;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/70;;A63F13/792;;A63F13/92;;G06T7/136;;G06T7/194;;G06T7/10;;G06T7/11;;G06T7/246;;G06T7/73;;G06T7/13;;G06T7/33;;G06T7/337;;G06F16/51;;G06F16/5866;;G06F16/50;;G06F40/134;;A63F13/00;;G06Q20/102;;G06Q20/14;;G06Q20/202;;G06Q20/208;;G06Q20/24;;G06Q20/327;;G06Q20/3567;;G06Q20/40145;;G06Q30/04;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G09B21/006;;H04L67/02;;H04N1/00244;;H04N5/91;;H04N7/183;;H04N7/185;;H04N21/254;;H04N21/4781;;H04N21/47815;;H04N21/812;;H04N21/8126;;H04N21/8173;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;H04N21/44224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F18/254;;G06F2218/12;;H04N23/00;;H04N23/64;;H04N23/80;;H04N23/661;;A61F9/08;;G06F3/0482;;G06Q10/02;;G06Q30/0217;;G06Q30/0241;;G06Q30/0253;;G06Q30/0257;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06Q30/0601;;G06Q90/00;;H04L67/10,G06V10/56;;G06V30/142;;G06V30/224,382/209,0,0,,,,EXPIRED
373,US,A1,US 2013/0094708 A1,045-298-682-587-168,2013-04-18,2013,US 201213705071 A,2012-12-04,US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/045-298-682-587-168,Patent Application,yes,9,5,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/103,0,0,,,,EXPIRED
374,FR,B1,FR 2579838 B1,057-131-797-542-753,1989-04-07,1989,FR 8604253 A,1986-03-25,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,CONNECTEUR ELECTRIQUE POUR CABLE ELECTRIQUE,,AMP INC,LAUDIG RONALD;;SMITH DONALD;;COHEN THOMAS,,https://lens.org/057-131-797-542-753,Granted Patent,no,0,0,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,,0,0,,,,EXPIRED
375,US,A1,US 2013/0083207 A1,067-881-312-987-961,2013-04-04,2013,US 201213686851 A,2012-11-27,US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/067-881-312-987-961,Patent Application,yes,0,8,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/78,348/207.1,0,0,,,,EXPIRED
376,US,A1,US 2014/0223022 A1,066-734-997-670-951,2014-08-07,2014,US 201414251480 A,2014-04-11,US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/066-734-997-670-951,Patent Application,yes,2,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,H04L29/08;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,709/228,0,0,,,,EXPIRED
377,US,A1,US 2013/0034267 A1,064-724-164-772-329,2013-02-07,2013,US 201213633533 A,2012-10-02,US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/064-724-164-772-329,Patent Application,yes,1,2,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/103,0,0,,,,EXPIRED
378,US,B2,US 9036948 B2,087-780-014-940-674,2015-05-19,2015,US 201314070642 A,2013-11-04,US 201314070642 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/087-780-014-940-674,Granted Patent,yes,108,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
379,US,B2,US 9262440 B2,095-297-893-813-291,2016-02-16,2016,US 201414223876 A,2014-03-24,US 201414223876 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/095-297-893-813-291,Granted Patent,yes,108,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
380,US,B2,US 8483484 B2,092-331-237-341-633,2013-07-09,2013,US 201113207174 A,2011-08-10,US 201113207174 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/092-331-237-341-633,Granted Patent,yes,107,12,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/181,0,0,,,,EXPIRED
381,WO,A3,WO 2007/021996 A3,097-255-132-202-717,2007-10-25,2007,US 2006/0031485 W,2006-08-10,US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",EVRYX TECHNOLOGIES INC;;BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/097-255-132-202-717,Search Report,yes,1,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,PENDING
382,US,B2,US 9104916 B2,102-050-025-657-177,2015-08-11,2015,US 201414189015 A,2014-02-25,US 201414189015 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/102-050-025-657-177,Granted Patent,yes,105,3,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54;;G06F3/01;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P, et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
383,US,B2,US 9310892 B2,118-009-539-753-605,2016-04-12,2016,US 201414569763 A,2014-12-14,US 201414569763 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/118-009-539-753-605,Granted Patent,yes,106,1,3,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F3/04842;;G06F16/532;;G06F16/583;;G06F16/5854;;G06F16/9537;;G06F3/017;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06Q30/0623;;G06Q30/0625;;G06V20/20;;H04N23/80;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5838;;G06F16/5854;;G06F16/7335;;G06F16/9537;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F3/04842;;G06V20/10;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V20/20;;G06F2218/08;;H04N23/80;;G06F16/5846;;G06F16/9538;;G06F3/017;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06Q30/0623;;G06Q30/0625;;G06T7/00,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
384,US,A,US 4008343 A,112-896-242-132-029,1977-02-15,1977,US 60506875 A,1975-08-15,US 60506875 A,1975-08-15,Process for electroless plating using colloid sensitization and acid rinse,"A process is described for the electroless deposition of metals on nonmetallic surfaces. The process involves pretreatment of the nonmetallic surface so as to obtain a surface finish suitable for deposition of colloidal sensitizers which catalyze electroless metallic deposition. The nonmetallic surface is then exposed to a colloidal catalyst solution (typically SnCl.sub.2 /PdCl.sub.2) followed by an acid rinse. On completion of this surface activation procedure, the surface is exposed to a bath for the electroless deposition of metal. This procedure, which differs from that traditionally used, insures more reliable catalysis for electroless deposition of metals with shorter initiation times and is simpler in procedure and lower in cost.",BELL TELEPHONE LABOR INC,COHEN RICHARD LEWIS;;MEEK RONALD LEE,,https://lens.org/112-896-242-132-029,Granted Patent,yes,4,27,2,2,0,C23C18/28;;C23C18/405;;H05K3/181;;C23C18/405;;H05K3/181;;C23C18/28,C23C18/28;;C23C18/40;;H05K3/18,427/305,0,0,,,,EXPIRED
385,US,A1,US 2011/0295714 A1,126-294-934-667-745,2011-12-01,2011,US 201113207174 A,2011-08-10,US 201113207174 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/126-294-934-667-745,Patent Application,yes,8,5,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06Q30/00,705/26.41,0,0,,,,EXPIRED
386,US,B2,US 8849069 B2,133-801-000-305-326,2014-09-30,2014,US 201313872032 A,2013-04-26,US 201313872032 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/133-801-000-305-326,Granted Patent,yes,116,5,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54;;G06F17/30;;G06K9/00;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/00;;G06Q30/06,382/305;;705/26.1,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
387,US,B2,US 8224079 B2,133-344-047-992-96X,2012-07-17,2012,US 201113092017 A,2011-04-21,US 201113092017 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/133-344-047-992-96X,Granted Patent,yes,101,14,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
388,DE,A1,DE 3004943 A1,137-530-585-013-532,1980-08-21,1980,DE 3004943 A,1980-02-09,US 1168079 A,1979-02-12,FLAMMHEMMENDE THERMOPLASTISCHE ZUSAMMENSETZUNGEN MIT VERMINDERTER AUSBLUEHNEIGUNG,,GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/137-530-585-013-532,Patent Application,no,0,1,8,9,0,C08K5/06;;C08L67/02;;C08K5/03;;C08L23/00,C08L67/00;;C08K5/06;;C08K7/14;;C08L7/00;;C08L21/00;;C08L23/00;;C08L33/00;;C08L33/02;;C08L51/00;;C08L51/02;;C08L67/02;;C08L77/00;;C08L101/00,,0,0,,,,DISCONTINUED
389,US,B2,US 9288271 B2,159-860-106-072-800,2016-03-15,2016,US 201414251480 A,2014-04-11,US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/159-860-106-072-800,Granted Patent,yes,107,10,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04L29/08;;H04N21/278;;H04N21/845,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring The Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand R, et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
390,US,A,US 4042730 A,165-025-236-634-355,1977-08-16,1977,US 67103476 A,1976-03-29,US 67103476 A,1976-03-29,Process for electroless plating using separate sensitization and activation steps,"A process is described for the electroless deposition of metals on nonmetallic surfaces. After pretreatment of the nonmetallic surface so as to obtain a finish suitable for deposition of sensitizers and activators, the nonmetallic surface is exposed to a sensitizing solution and thereafter in a separate step to an activation solution. The surface is then washed with an aqueous alkaline solution prior to immersion in the electroless plating solution. The separate sensitization and activation steps are particularly suitable where the sensitizing step is also used for pattern generation. The inclusion of the aqueous alkaline wash after the activation step both protects the electroless plating bath from contamination with sensitizer and activator, and also insures a short initition time. Short initiation times are highly desirable especially in the production of electronic circuits because highly uniform metal platings are insured, manufacturing time is considerably reduced and reliability is increased.",BELL TELEPHONE LABOR INC,COHEN RICHARD LEWIS;;MEEK RONALD LEE,,https://lens.org/165-025-236-634-355,Granted Patent,yes,3,22,1,1,0,C23C18/28;;C23C18/28;;H05K3/181;;H05K3/181,C23C18/28;;H05K3/18,427/305,4,1,098-050-305-796-013,10.1149/1.2402361,"Goldie, Metallic Coating of Plastics, Electrochemical Pub. Ltd., 1968, vol. 1, Chapter 5.;;McDermott, Plating of Plastics with Metals, Noyes Data Corp., 1974, Chapter 1.;;Journal of Electrochemical Soc., vol. 122, p. 1478, 1975, vol. 120, p. 1241, 1973.;;Lowenheim, Moder Electroplating, 3rd Ed., 1974, p. 645.",EXPIRED
391,BR,A2,BR PI0614864 A2,163-186-682-838-619,2011-04-19,2011,BR PI0614864 A,2006-08-10,US 20490105 A;;US 2006/0031485 W,2005-08-15,uso de informação derivada de imagem como critérios de busca para internet e outros agentes de busca,"USO DE INFORMAçãO DERIVADA DE IMAGEM COMO CRITéRIOS DE BUSCA PARA INTERNET E OUTROS AGENTES DE BUSCA.Termos de busca são derivados automaticamente a partir de imagens capturadas por um telefone celular equipado com câmera, um PDA ou um outro dispositivo de captura de imagem, submetidos a um agente de busca para a obtenção de uma informação de interesse, e pelo menos uma porção da informação resultante é transmitida de volta localmente para ou próximo do dispositivo que capturou a imagem.",EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/163-186-682-838-619,Patent Application,no,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,DISCONTINUED
392,US,A1,US 2014/0368691 A1,165-594-674-986-262,2014-12-18,2014,US 201414470784 A,2014-08-27,US 201414470784 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 99264201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P;;US 31754101 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/165-594-674-986-262,Patent Application,yes,0,3,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06K9/00;;H04N5/232,348/222.1,0,0,,,,EXPIRED
393,US,A1,US 2012/0002872 A1,164-542-888-135-550,2012-01-05,2012,US 201113069112 A,2011-03-22,US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/164-542-888-135-550,Patent Application,yes,6,24,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
394,EP,A4,EP 1915709 A4,164-177-059-460-61X,2008-09-10,2008,EP 06801326 A,2006-08-10,US 2006/0031485 W;;US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,,EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,"NANT HOLDINGS IP, LLC (2011-11-16)",https://lens.org/164-177-059-460-61X,Search Report,no,5,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,DISCONTINUED
395,US,A9,US 2015/0316992 A9,194-682-599-023-31X,2015-11-05,2015,US 201414474245 A,2014-09-01,US 201414474245 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,OBJECT INFORMATION DERIVED FROM OBJECT IMAGES,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/194-682-599-023-31X,Amended Application,yes,0,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F3/01,,0,0,,,,EXPIRED
396,AU,A,AU 1988/014217 A,190-926-059-176-000,1988-09-26,1988,AU 1988/014217 A,1988-02-23,US 1831787 A,1987-02-24,DOWNDRAFT WOODSTOVE,,COHEN & PECK INC,COHEN RONALD;;ALBERTSEN PETER;;HAJEK VIKTOR,,https://lens.org/190-926-059-176-000,Patent Application,no,0,0,2,2,0,F24B5/04;;F24B1/006,F24B1/00;;F24B5/04,,0,0,,,,DISCONTINUED
397,US,A1,US 2013/0265435 A1,191-720-082-311-728,2013-10-10,2013,US 201313907819 A,2013-05-31,US 201313907819 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/191-720-082-311-728,Patent Application,yes,6,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N7/18,348/158,0,0,,,,EXPIRED
398,CA,A,CA 942291 A,195-152-909-964-51X,1974-02-19,1974,CA 124923 A,1971-10-12,US 9147770 A,1970-11-20,HEAT EXCHANGE DEVICE WITH CONVOLUTED HEAT TRANSFER WALL,,BAXTER LABORATORIES INC,LEONARD RONALD J;;COHEN FRED M,,https://lens.org/195-152-909-964-51X,Granted Patent,no,0,0,17,17,0,A61M5/44;;A61M5/44;;A61M2205/366;;A61M2205/366;;F28D9/0025;;F28D9/0025;;Y10S165/399;;Y10S165/399,A61M5/44;;F28D9/00,257-15,0,0,,,,EXPIRED
399,US,A1,US 2014/0023234 A1,000-828-071-500-337,2014-01-23,2014,US 201314032509 A,2013-09-20,US 201314032509 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDING IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/000-828-071-500-337,Patent Application,yes,3,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/103,0,0,,,,EXPIRED
400,US,B2,US 8842941 B2,000-687-384-598-64X,2014-09-23,2014,US 201313952421 A,2013-07-26,US 201313952421 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/000-687-384-598-64X,Granted Patent,yes,112,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,9,041-034-977-263-043;;067-825-083-591-587;;084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206,10.1145/265563.265573;;10.1109/cvpr.2004.1315147;;10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782,"Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer-Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: SItuated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; PLAY: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
401,US,B2,US 8861859 B2,013-454-353-743-044,2014-10-14,2014,US 201313859183 A,2013-04-09,US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/013-454-353-743-044,Granted Patent,yes,110,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q20/40;;G06Q30/00;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/181,40,20,041-034-977-263-043;;067-825-083-591-587;;032-705-158-397-206;;104-793-026-621-862;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;051-045-047-582-773;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;030-846-937-028-967;;013-901-391-839-508;;088-865-239-067-73X;;187-572-604-127-113;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619,10.1145/265563.265573;;10.1109/cvpr.2004.1315147;;10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/mmcs.1999.778638;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1145/354666.354669;;10.1145/215585.215639;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402,"Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Arai, T. et al., ""PaperLink: A Technique for Hyperlinking From Real Paper to Electronic Content,"" CHI1997, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997; pp. 327-334.;;Bulman, J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, vol. 22, No. 3, Jul. 2004; pp. 84-94.;;Chang, W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia 1997, Seattle, Washington, Nov. 9-13, 1997; pp. 203-213.;;Diverdi, S. et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003; University of California Santa Barbara, May 2003; 7 pages.;;Diverdi, S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004 (IEEE/ACM Int'l Symp on Mixed and Augmented Reality), Arlington, Virginia, Nov. 2-5, 2004; 2 pages.;;Feiner, S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1(4), 1997; pp. 208-217.;;Fernandez, F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba; Mar. 2004; 124 pages.;;Geiger, C., et al., ""Mobile AR4ALL,"" Proceedings Of the IEEE and ACM Int'l Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; 2 pages.;;Gevers, T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, vol. 9, No. 1, Jan. 2000; pp. 102-119.;;Haritaoglu, I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp 2001; Lecture Notes in Computer Science, vol. 2201; pp. 247-255.;;Hollerer, T., et al., ""Chapter Nine: Mobile Augmented Reality,"" Telegeoinformatics: Location Based Computing and Services. H. Karimi and A. Hammad (eds.), Taylor & Francis Books, Ltd., Jan. 2004; 39 pages.;;Iwamoto, T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive2004 Advances in Pervasive Computing, Linz/Vienna, Austria, (2004).;;Iwaoka, T., et al., ""Digital Safari Guidebook With Image Retrieval,"" ICMCS, vol. 2, p. 1011-1012. (1999).;;Jebara, T., et al., ""Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision And Wearable Computers,"" ISWC, p. 138-145. IEEE Computer Society, (1997).;;Kangas, K. et al., ""Using Code Mobility To Create Ubiquitous And Active Augmented Reality In Mobile Computing,"" Mobicom, Aug. 15-20, 1999, Seattle, Washington; p. 48-58.;;Kato, H., et al., ""Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Int'l Workshop on Augmented Reality, Oct. 20-21, 1999, San Francisco, California; pp. 85-94.;;Klinker, G., ""Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,"" ISAR, p. 124-136. IEEE Computer Society, (2001).;;Levine, J.M., ""Real-Time Target And Pose Recognition For 3-D Graphical Overlay,"" Master's thesis,. EECS Dept., MIT, 1997.;;Ljungstrand, P., et al., ""WebStickers: Using Physical Tokens To Access, Manage and Share Bookmarks On The Web,""; Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingor, Denmark; Apr. 2000; pp. 23-31.;;Rekimoto, J., et al., ""The World Through The Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology (1995), pp. 29-36.;;Rekimoto, J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, 1998, Second International Symposium, Oct. 19-20, 1998, Pittsburgh, Pennsylvania; pp. 68-75.;;Rekimoto, J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), Helsingør, Denmark: Apr. 2000; pp. 1-10.;;Rekimoto, J., ""NaviCam: A Palmtop Device Approach To Augmented Reality,"" from the book Fundamentals Of Wearable Computers And Augmented Reality, Barfield and Caudell (Eds.), Jun. 6, 2001; pp. 353-377.;;Rohs, M., et al., ""A Conceptual Framework For Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 171-189.;;Siltanen, S., et al., ""Implementing A Natural User Interface For Camera Phones Using Visual Tags,"" AUIC '06 Proceedings of the 7th Australasian User interface conference-vol. 50; pp. 113-116.;;Smailagic, A, et al., ""Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith, J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, MULTIMEDIA '96, ACM New York, New York, pp. 87-98.;;Starner, T., et al., ""Augmented Reality Through Wearable Computing,"" 1997; Presence: Teleoper. Virtual Environ. 6, 4.;;Suzuki, G., et al., ""u-Photo: Interacting With Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science vol. 3468, 2005, pp. 190-207.;;Toye, E., et al., ""Interacting With Mobile Services: An Evaluation Of Camera-Phones And Visual Tags,"" Personal and Ubiquitous Computing; vol. 11, Issue 2, Jan. 2007; pp. 97-106.;;Wagner, D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, 2003. Oct. 18-21, 2003; 9 pages.;;Yang, J., et al., ""Smart Sight: A Tourist Assistant System,"" Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California; Digest of Papers, pp. 73-78.;;Zhang, X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Int'l Symposium on Augmented Reality (ISAR'01); Oct. 29-30, 2001; Columbia University, New York; pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
402,US,B2,US 8582817 B2,019-166-065-033-488,2013-11-12,2013,US 201213633533 A,2012-10-02,US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/019-166-065-033-488,Granted Patent,yes,98,13,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/103,0,0,,,,EXPIRED
403,US,B2,US 9152864 B2,016-341-009-511-437,2015-10-06,2015,US 201414187717 A,2014-02-24,US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/016-341-009-511-437,Granted Patent,yes,107,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00;;G06F3/01;;G06F17/30;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: a Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
404,US,B2,US 8109273 B2,039-808-252-818-675,2012-02-07,2012,US 201113047688 A,2011-03-14,US 201113047688 A;;US 2010/0057286 W;;US 26250309 P;;US 29700110 P,2009-11-18,Shoulder immobilizer and fracture stabilization device,"A shoulder immobilizer ( 20 ) includes a semi-rigid or rigid orthosis, in the form of an arm support ( 22 ), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster ( 24 ) is positioned between the patient and the arm support ( 22 ). A body strap ( 26 ) extends around the patient and attaches to the arm support ( 22 ) and/or the bolster ( 24 ), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer ( 20 ) may utilize a shoulder strap ( 28 ), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;CRADLE MEDICAL INC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD,CRADLE MEDICAL INC (2011-03-08),https://lens.org/039-808-252-818-675,Granted Patent,yes,41,34,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/37;;A47B7/00;;A47C17/86;;A61B19/00;;A61F5/00;;A61F5/56,128/878;;128/846;;128/869;;128/876;;602/4;;602/5;;602/12;;602/20;;5/623;;5/646,1,0,,,"Corflex Inc., ""Ultra Cubital Tunnel Splint,"" [online], [retrieved on Sep. 25, 2006], retrieved from the internet: .",ACTIVE
405,US,A1,US 2014/0101690 A1,057-880-465-460-274,2014-04-10,2014,US 201314042839 A,2013-10-01,US 201314042839 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/057-880-465-460-274,Patent Application,yes,6,47,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N21/81,725/32,0,0,,,,EXPIRED
406,WO,B1,WO 2007/021996 B1,051-164-057-746-366,2007-12-21,2007,US 2006/0031485 W,2006-08-10,US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"Search terms are derived automatically from images captured by a camera equipped cell phone, P",EVRYX TECHNOLOGIES INC;;BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/051-164-057-746-366,Patent Application,no,0,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,PENDING
407,CH,A,CH 538658 A,063-522-017-662-486,1973-06-30,1973,CH 1650171 A,1971-11-11,US 9147770 A,1970-11-20,"Wärmeaustauscher, insbesondere zum Wärmeaustausch zwischen Blut und einem Wärme- oder Kälteträger",,BAXTER LABORATORIES INC,RONALD JAMES LEONARD;;FRED MICHAEL COHEN,,https://lens.org/063-522-017-662-486,Granted Patent,no,0,0,17,17,0,A61M5/44;;A61M5/44;;A61M2205/366;;A61M2205/366;;F28D9/0025;;F28D9/0025;;Y10S165/399;;Y10S165/399,A61M5/44;;F28D9/00,,0,0,,,,EXPIRED
408,JP,A,JP 2008090838 A,067-824-119-875-65X,2008-04-17,2008,JP 2007246850 A,2007-09-25,US 99294201 A,2001-11-05,SYSTEM AND METHOD FOR IMAGE CAPTURE AND IDENTIFICATION,"<P>PROBLEM TO BE SOLVED: To provide a system and a method for image capture and identification. <P>SOLUTION: In this system, a digital image of an object 16 is captured, and the object is recognized from a plurality of objects in a server 20. Information address corresponding to the object is then used to access information and initiate communication pertinent to the object. <P>COPYRIGHT: (C)2008,JPO&INPIT",BONCYK WAYNE C;;COHEN RONALD H;;EVRYX TECHNOLOGIES INC,BONCYK WAYNE C;;COHEN RONALD H,,https://lens.org/067-824-119-875-65X,Patent Application,no,13,0,13,173,0,H04N1/00002;;H04N1/00005;;H04N1/00031;;H04N1/00045;;H04N1/00068;;H04N1/00082;;H04N1/00827;;H04N2201/3225;;G06F16/5838;;G06V10/95;;G06V30/142;;G06V10/56;;G06V10/7515;;H04N1/00068;;H04N1/00045;;H04N1/00005;;H04N1/00031;;H04N1/00002;;H04N2201/3225;;H04N1/00827;;H04N1/00082;;G06F16/5838;;G06V10/95;;G06V10/56;;G06V10/7515;;G06V30/142,G06F13/00;;G06F17/30;;G06T7/00;;G06V10/56;;H04N1/00,,0,0,,,,DISCONTINUED
409,US,A1,US 2014/0003668 A1,090-520-994-652-156,2014-01-02,2014,US 201314016628 A,2013-09-03,US 201314016628 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/090-520-994-652-156,Patent Application,yes,13,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/103,0,0,,,,EXPIRED
410,US,B2,US 8494264 B2,109-313-759-803-299,2013-07-23,2013,US 201213464410 A,2012-05-04,US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data capture and identification system and process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/109-313-759-803-299,Granted Patent,yes,102,15,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,382/165,0,0,,,,EXPIRED
411,US,B2,US 8837868 B2,136-643-209-735-683,2014-09-16,2014,US 201313911240 A,2013-06-06,US 201313911240 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/136-643-209-735-683,Granted Patent,yes,112,17,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305;;705/26.1,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Repositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
412,US,B2,US 9154694 B2,122-737-163-124-64X,2015-10-06,2015,US 201414332354 A,2014-07-15,US 201414332354 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/122-737-163-124-64X,Granted Patent,yes,108,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and Hmd Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
413,CN,A,CN 1220488 A,128-628-513-310-801,1999-06-23,1999,CN 98109600 A,1998-06-10,US 88205697 A,1997-06-25,Improved silica stain test structures and methods therefor,,SIEMENS AG,ARNDT RUSS;;COHEN SUSAN;;HOYER RONALD,,https://lens.org/128-628-513-310-801,Patent Application,no,0,0,9,9,0,H01L21/02;;H01L22/34;;H01L22/34,G01N21/88;;G01N21/93;;G01N21/956;;H01L21/304;;H01L21/306;;H01L21/66;;H01L23/544;;H01L27/10,,0,0,,,,EXPIRED
414,US,A1,US 2011/0255744 A1,174-541-449-863-140,2011-10-20,2011,US 201113091994 A,2011-04-21,US 201113091994 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/174-541-449-863-140,Patent Application,yes,7,7,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,0,0,,,,EXPIRED
415,US,A1,US 2016/0012077 A1,179-583-804-936-39X,2016-01-14,2016,US 201514615162 A,2015-02-05,US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture and Identification System and Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2009-03-09);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/179-583-804-936-39X,Patent Application,yes,3,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04N21/278;;H04N21/845,,0,0,,,,EXPIRED
416,US,B2,US 9269015 B2,189-351-850-262-146,2016-02-23,2016,US 201414536684 A,2014-11-10,US 201414536684 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/189-351-850-262-146,Granted Patent,yes,54,27,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,0,0,,,,EXPIRED
417,US,A1,US 2014/0177920 A1,000-067-619-448-180,2014-06-26,2014,US 201414194619 A,2014-02-28,US 201414194619 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/000-067-619-448-180,Patent Application,yes,9,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06K9/62;;G06K9/78,382/103,0,0,,,,EXPIRED
418,US,B2,US 9031278 B2,017-055-527-100-75X,2015-05-12,2015,US 201414194619 A,2014-02-28,US 201414194619 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/017-055-527-100-75X,Granted Patent,yes,108,14,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/100;;382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P. et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
419,CA,A,CA 1047331 A,008-699-795-976-632,1979-01-30,1979,CA 251548 A,1976-04-30,US 60506875 A,1975-08-15,COLLOID SENSITIZATION FOLLOWED BY ACID RINSE FOR ELECTROLESS PLATING OF NONMETAL,"PROCESS FOR ELECTROLESS PLATING USING COLLOID SENSITIZATION A process is described for the electroless deposition of metals on nonmetallic surfaces. The process involves pretreatment of the nonmetallic surface so as to obtain a surface finish suitable for deposition of colloidal sensitizers which catalyze electroless metallic deposition. The nonmetallic surface is then exposed to a colloidal catalyst solution (typically SnCl2/PdCl2) followed by an acid rinse. On completion of this surface activation procedure, the surface is exposed to a bath for the electroless deposition of metal. This procedure, which differs from that traditionally used, insures more reliable catalyst for electroless deposition of metals with shorter initiation times and is simpler in procedure and lower in cost. - i",WESTERN ELECTRIC CO,COHEN RICHARD L;;MEEK RONALD L,,https://lens.org/008-699-795-976-632,Granted Patent,no,0,0,2,2,0,C23C18/28;;C23C18/405;;H05K3/181;;C23C18/405;;H05K3/181;;C23C18/28,C23C18/28;;C23C18/40;;H05K3/18,117-77,0,0,,,,EXPIRED
420,US,A1,US 2015/0003747 A1,037-754-112-585-079,2015-01-01,2015,US 201414464587 A,2014-08-20,US 201414464587 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/037-754-112-585-079,Patent Application,yes,8,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62;;G06F17/30;;H04L29/08,382/218,0,0,,,,EXPIRED
421,US,A1,US 2017/0132486 A1,048-763-032-776-266,2017-05-11,2017,US 201615291934 A,2016-10-12,US 201615291934 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/048-763-032-776-266,Patent Application,yes,10,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/70;;G06F17/30;;G06K9/62;;G06Q20/10;;G09B21/00,,0,0,,,,EXPIRED
422,US,A1,US 2011/0211760 A1,061-456-771-123-278,2011-09-01,2011,US 201113037317 A,2011-02-28,US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/061-456-771-123-278,Patent Application,yes,99,90,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;G06K9/68,382/190;;382/218;;705/27.2;;705/35;;705/1.1,0,0,,,,EXPIRED
423,US,A1,US 2013/0170702 A1,065-792-455-340-113,2013-07-04,2013,US 201213693892 A,2012-12-04,US 201213693892 A;;US 201113091994 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/065-792-455-340-113,Patent Application,yes,7,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,0,0,,,,EXPIRED
424,US,B2,US 9087240 B2,088-032-787-199-083,2015-07-21,2015,US 201414335559 A,2014-07-18,US 201414335559 A;;US 201314073760 A;;US 201213686851 A;;US 201113207211 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/088-032-787-199-083,Granted Patent,yes,110,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/54;;G06F3/01;;G06F17/30;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-55.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
425,US,B2,US 10635714 B2,094-312-029-519-504,2020-04-28,2020,US 201916578231 A,2019-09-20,US 201916578231 A;;US 201816143257 A;;US 201715711326 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"An image-based transaction system includes a mobile device with an image sensor that is programmed to capture, via the image sensor, a digital images of a scene. The mobile device identifies a document using image characteristics from the captured images and acquires an image of at least a part of the document, and then identifies symbols in the image based on locations within the image of the document. The symbols can include alphanumeric symbols. The mobile device processes the symbols according to their type to obtain an address related to the document and the symbols and initiates a transaction associated with the identified document.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/094-312-029-519-504,Granted Patent,yes,450,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F16/583;;G06F3/01;;G06F16/22;;G06F16/2455;;G06F16/50;;G06F16/532;;G06F16/58;;G06F16/732;;G06F16/904;;G06F16/951;;G06F16/9537;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,43,23,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587;;157-015-151-956-874;;078-957-418-810-926,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147;;10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection In Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level Of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems For Exploring The Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-211.;;Fernandez F., “Responsive Environments: Digital Objects In The Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features For Image Retrieval,” IEEE Transactions On Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design And Implementation Of A Snapshot Based Method For Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting The Billiards Experience With Probabilistic Vision And Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility To Create Ubiquitous And Active Augmented Reality In Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration For A Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance Of Powerplants: A Prototyping Case Study Of A Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target And Pose Recognition For 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens To Access, Manage and Share Bookmarks On The Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through The Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach To Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework For Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing A Natural User Interface For Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing And Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation And Information Access With Mobile Computers,” Proceedings Of the IEEE and ACM Intl Symposium On Augmented Reality, 2001, pp. 179-180.;;Kohtake et al., InfoStick: An Interaction Device for Inter-Appliance Computing, Hans-W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www.infoworld.com, Aug. 21, 2000 INFOWORLD, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages.",EXPIRED
426,DE,D1,DE 2967353 D1,088-309-899-825-404,1985-02-21,1985,DE 2967353 T,1979-10-23,US 95780178 A;;US 7900880 W,1978-11-06,MODIFIED POLYESTER COMPOSITIONS,,GEN ELECTRIC,COHEN STUART COLIN;;DIECK RONALD LEE,,https://lens.org/088-309-899-825-404,Granted Patent,no,0,0,12,13,0,C08L67/02;;C08L67/02,C08K5/03;;C08K7/14;;C08L33/08;;C08L67/00;;C08L67/02;;C08L69/00,,0,0,,,,EXPIRED
427,US,B2,US 9036947 B2,104-891-821-921-564,2015-05-19,2015,US 201314042839 A,2013-10-01,US 201314042839 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/104-891-821-921-564,Granted Patent,yes,105,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
428,US,A1,US 2012/0195468 A1,110-085-087-613-583,2012-08-02,2012,US 201213442660 A,2012-04-09,US 201213442660 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/110-085-087-613-583,Patent Application,yes,3,3,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/103,0,0,,,,EXPIRED
429,US,B2,US 8548245 B2,125-947-622-208-565,2013-10-01,2013,US 201213645439 A,2012-10-04,US 201213645439 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/125-947-622-208-565,Granted Patent,yes,102,12,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/181;;705/26.1,0,0,,,,EXPIRED
430,US,A1,US 2013/0265400 A1,112-083-067-028-858,2013-10-10,2013,US 201313907780 A,2013-05-31,US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/112-083-067-028-858,Patent Application,yes,5,8,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,A61F9/08,348/62,0,0,,,,EXPIRED
431,US,A1,US 2013/0268407 A1,116-634-313-837-866,2013-10-10,2013,US 201313911240 A,2013-06-06,US 201313911240 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/116-634-313-837-866,Patent Application,yes,13,7,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/06,705/26.61,0,0,,,,EXPIRED
432,US,A1,US 2011/0317873 A1,113-530-101-222-573,2011-12-29,2011,US 201113092009 A,2011-04-21,US 201113092009 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/113-530-101-222-573,Patent Application,yes,3,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,0,0,,,,EXPIRED
433,US,B2,US 8873891 B2,113-445-187-956-271,2014-10-28,2014,US 201313907842 A,2013-05-31,US 201313907842 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/113-445-187-956-271,Granted Patent,yes,105,13,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/54;;A61F9/08;;A63F13/00;;A63F13/30;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;H04N5/225;;H04N5/232;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,9,084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206;;041-034-977-263-043;;067-825-083-591-587,10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782;;10.1145/265563.265573;;10.1109/cvpr.2004.1315147,"Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer-Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: SItuated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; PLAY: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
434,US,B2,US 8774463 B2,122-712-680-088-703,2014-07-08,2014,US 201313923260 A,2013-06-20,US 201313923260 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/122-712-680-088-703,Granted Patent,yes,116,30,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,38,9,041-034-977-263-043;;067-825-083-591-587;;084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206,10.1145/265563.265573;;10.1109/cvpr.2004.1315147;;10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782,"Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer-Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: Situated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; PLAY: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.",EXPIRED
435,US,A1,US 2017/0024714 A1,136-532-453-833-697,2017-01-26,2017,US 201615287516 A,2016-10-06,US 201615287516 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,"An object is recognized from plurality of objects in a database based on a digital representation of a scene containing the object. An information address corresponding to the object is then used to present an item to a user, who may obtain the item via a transaction.",NANT HOLDINGS IP LLC,BONCYCK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/136-532-453-833-697,Patent Application,yes,10,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q20/10;;G06K9/00;;G06K9/62,,0,0,,,,EXPIRED
436,US,B2,US 8520942 B2,147-382-697-254-163,2013-08-27,2013,US 201213535216 A,2012-06-27,US 201213535216 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/147-382-697-254-163,Granted Patent,yes,104,16,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
437,US,B2,US 9336453 B2,144-916-802-554-657,2016-05-10,2016,US 201414574399 A,2014-12-18,US 201414574399 A;;US 201313908081 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/144-916-802-554-657,Granted Patent,yes,106,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
438,US,A1,US 2018/0081907 A1,173-954-395-162-531,2018-03-22,2018,US 201715818312 A,2017-11-20,US 201715818312 A;;US 201615392935 A;;US 201514615162 A;;US 201414251480 A;;US 201313968666 A;;US 201213633533 A;;US 201213464410 A;;US 201113005716 A;;US 50571409 A;;US 34209406 A;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Data Capture And Identification System And Process,"An identification method and process for objects from digitally captured images thereof that uses data characteristics to identify an object from a plurality of objects in a database. The data is broken down into parameters such as a Shape Comparison, Grayscale Comparison, Wavelet Comparison, and Color Cube Comparison with object data in one or more databases to identify the actual object of a digital image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,NANT HOLDINGS IP LLC (2011-05-16);;EVYRX TECHNOLOGIES INC (2009-03-09);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/173-954-395-162-531,Patent Application,yes,0,0,29,173,0,G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V30/142;;G06V10/7515;;G06V10/56;;G06F16/5838;;G06F16/21;;G06F16/51;;G06F16/248;;G06F16/5866;;G06F16/24578;;G06V10/56;;G06V10/7515;;G06V30/142;;G06F18/00;;G06V10/462;;G06F16/5854;;H04L67/141;;H04M1/0202,G06F17/30;;G06V10/56;;G06V30/142;;H04L29/08;;H04M1/02;;H04N21/278;;H04N21/845,,0,0,,,,EXPIRED
439,US,A1,US 2015/0302267 A1,176-333-057-952-992,2015-10-22,2015,US 201414574399 A,2014-12-18,US 201414574399 A;;US 201313908081 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/176-333-057-952-992,Patent Application,yes,0,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;G06F17/30;;G06Q30/02;;G06T7/00,,0,0,,,,EXPIRED
440,US,B2,US 8335351 B2,191-948-230-759-948,2012-12-18,2012,US 201113091994 A,2011-04-21,US 201113091994 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/191-948-230-759-948,Granted Patent,yes,106,33,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,0,0,,,,EXPIRED
441,US,A1,US 2012/0294488 A1,187-999-251-228-164,2012-11-22,2012,US 201213535185 A,2012-06-27,US 201213535185 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/187-999-251-228-164,Patent Application,yes,2,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62;;G06F17/30,382/103;;235/375,0,0,,,,EXPIRED
442,US,B2,US 9182828 B2,006-629-713-926-759,2015-11-10,2015,US 201414470784 A,2014-08-27,US 201414470784 A;;US 201414195768 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 49224304 A;;US 99264201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P;;US 31754101 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/006-629-713-926-759,Granted Patent,yes,109,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30;;G06F3/01;;G06K9/00;;G06K9/32;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
443,US,A1,US 2013/0229536 A1,008-707-381-408-966,2013-09-05,2013,US 201313860967 A,2013-04-11,US 201313860967 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/008-707-381-408-966,Patent Application,yes,11,9,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/225,348/207.1,0,0,,,,EXPIRED
444,US,B2,US 9116920 B2,028-874-320-412-869,2015-08-25,2015,US 201414173671 A,2014-02-05,US 201414173671 A;;US 201313860967 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/028-874-320-412-869,Granted Patent,yes,106,15,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content- Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
445,US,A1,US 2011/0295829 A1,023-718-199-925-948,2011-12-01,2011,US 201113207112 A,2011-08-10,US 201113207112 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object Information Derived from Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/023-718-199-925-948,Patent Application,yes,2,19,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,707/706;;X707E17108,0,0,,,,EXPIRED
446,JP,A,JP 2012133790 A,019-768-501-529-016,2012-07-12,2012,JP 2012012682 A,2012-01-25,US 20490105 A,2005-08-15,USE OF IMAGE-DERIVED INFORMATION AS SEARCH CRITERIA FOR INTERNET AND OTHER SEARCH ENGINES,"PROBLEM TO BE SOLVED: To provide a system and process for identifying digitally captured images without requiring modification to the object.SOLUTION: Search terms are derived automatically from images captured by a camera-equipped cell phone, PDA or other image capturing devices, and submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,WAYNE C BONCYK;;COHEN RONALD H,,https://lens.org/019-768-501-529-016,Patent Application,no,8,1,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F17/30,,0,0,,,,DISCONTINUED
447,US,A,US 4143648 A,047-910-312-807-240,1979-03-13,1979,US 78706477 A,1977-04-13,US 78706477 A,1977-04-13,Portable therapeutic apparatus having patient responsive feedback means,A portable therapeutic instrument includes a microphone to be secured to a patient's throat for monitoring voice level or to a patient's nose for monitoring nasal sounds. An input amplifier includes an automatic gain circuit which essentially flattens the gain curve. An adjustable level detector includes a solid state level detector to generate a square wave signal connected to a logic switching circuit for turning a tone oscillator or other stimulus unit wholly on or off. A second similar channel connected to the input amplifier detects total voiced speech. A switch means connects the oscillator to only the first channel to detect speech above a selected level or to both channels to detect speech only below a selected level. The several channels include time delay circuits permitting normal speech attack and decay. The microphone may also be connected to the patient's nose to monitor nasal sounds.,BEHAVIORAL CONTROLS INC,COHEN RONALD S;;DAWLEY JAMES M,,https://lens.org/047-910-312-807-240,Granted Patent,yes,13,50,1,1,0,A61F5/58;;A61F5/58;;Y10S128/905,A61F5/58,128  1R,0,0,,,,EXPIRED
448,US,B2,US 8478047 B2,054-827-305-896-35X,2013-07-02,2013,US 201213442660 A,2012-04-09,US 201213442660 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/054-827-305-896-35X,Granted Patent,yes,102,0,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/181,0,0,,,,EXPIRED
449,US,B2,US 9311552 B2,059-335-945-719-029,2016-04-12,2016,US 201313907780 A,2013-05-31,US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/059-335-945-719-029,Granted Patent,yes,104,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/4782;;H04N21/658;;H04N21/81,,40,9,084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206;;041-034-977-263-043;;067-825-083-591-587,10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782;;10.1145/265563.265573;;10.1109/cvpr.2004.1315147,"Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer-Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: Situated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; Play: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.",EXPIRED
450,US,A1,US 2016/0012308 A1,077-454-407-448-940,2016-01-14,2016,US 201514683953 A,2015-04-10,US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/077-454-407-448-940,Patent Application,yes,3,3,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/46;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/62;;G06K9/78;;H04N1/00;;H04N5/232;;H04N7/18,,0,0,,,,EXPIRED
451,US,B2,US 8463031 B2,078-867-415-876-20X,2013-06-11,2013,US 201213523491 A,2012-06-14,US 201213523491 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/078-867-415-876-20X,Granted Patent,yes,104,16,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
452,US,A1,US 2014/0363092 A1,087-262-435-795-479,2014-12-11,2014,US 201414468304 A,2014-08-25,US 201414468304 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/087-262-435-795-479,Patent Application,yes,6,6,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06K9/64,382/218,0,0,,,,EXPIRED
453,US,B2,US 9025813 B2,113-634-544-242-465,2015-05-05,2015,US 201313908081 A,2013-06-03,US 201313908081 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/113-634-544-242-465,Granted Patent,yes,110,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/100;;382/305,40,9,084-111-378-111-079;;187-572-604-127-113;;008-326-799-368-325;;031-355-417-899-97X;;199-996-296-181-277;;001-154-350-168-291;;032-705-158-397-206;;041-034-977-263-043;;067-825-083-591-587,10.1109/iswc.1997.629927;;10.1145/354666.354667;;10.1007/3-540-45427-6_21;;10.1109/83.817602;;18255376;;10.1109/isar.2001.970532;;10.1007/bf01682023;;10.1145/258549.258782;;10.1145/265563.265573;;10.1109/cvpr.2004.1315147,"European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Levine, Jeffrey M; Real-Time Target and Pose Recognition for 3-D Graphical Overlay; Massachusetts Institute of Technology, Jun. 1997.;;Yang, Jie et al; Smart Sight: A Tourist Assistant System; Interactive Systems Laboratories, Carnegie Melon University.;;Zhang, Xiang et al; Taking AR into Large Scale Industrial Environments: Navigation and Information Access with Mobile Computers.;;Wagner, Daniel et al; First Steps Towards Handheld Augmented Reality; Vienna University of Technology; Favoritensrt. 9-11/118/2; A1040 Vienna, Austria.;;Toye, Eleanor et al; Interacting with Mobile Services; An Evaluation of Camera-Phones and Visual Tags; Springer Verlag, London Limited 2006.;;Suzuki, Genta et al; u-Photo: Interacting with Pervasive Services using Digital Still Images; Graduate School of Media and Governance, Keio University; Japan.;;Starner, Jennifer et al; Augmented Reality Through Wearable Computing; Massachusetts Institute of Technology.;;Smith, John R. et al; Visual SEEk: a Fully Automated Content-Based Image Query System; Center for Image Technology for New Media, Columbia University, New York, New York.;;Smailagic, Asim et al; Metronaut: A Wearable Computer with Sensing and Global Communication Capabilities; Carnegie Mellon University; Pittsburg, PA.;;Siltanen, Sanni et al; Implementing a Natural User Interface for Camera Phones Using Visual Rags; VTT Information Technology.;;Rohs, Michael et al; A Conceptual Framework for Camera Phone-based Interaction Techniques; Institute for Pervasive Computing, Department of Computer Science, Swiss Federal Institute of Technology; Zurich, CH.;;Rekimoto, Jun; NaviCam: A Palmtop Device APproach to Augmented Reality; Sony Computer Science Laboratory , Inc.;;Rekimoto, Jun et al; CyberCode: Designing Augmented Reality Environments with Visual Tags; Interaction Laboratory, Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Rekimoto, Jun et al; Augmented-able Reality: Situated COmmunication through Physical and Digital Spaces; ony Computer Science Laboratory, Sony Corporation Informaiton Technology Laboratories and Department of Informaiton Science, Tokyo Institute of Technology; Tokyo, JP.;;Rekimoto, Jun et al; The World Through the Computer: Computer Augmented Interactions with Real World Environments; Sony Computer Science Laboratory , Inc.; Tokyo, JP.;;Ljungstrand, Peter et al; WebStickers: Using Physical Tokens to Acces, Manage and Share Bookmarks to the Web; PLAY: Applied research on art and technology; Interactive Institute c/o Viktoria Institute; Goteborg, SE.;;Klinker, Gudrun et al; Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System; Tescnische Universitat Munchen; Munchen, DE.;;Kato, Hirokazu et al; Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System; Faculty of Information Sciences, Hiroshima City University and Human Interface Technology Laboratory, University of Washington.;;Kangas, Kari et al; Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing; University of Oulu, Department of Electrical Engineering, Computer Engineering Laboratory; Oulu, Finland.;;Jebara, Tony et al; Stochasticks: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Conputers; Media Laboratory; Massachusetts Institute of Technology.;;Iwaoka, Toshiyuki et al; Digital Safari Guidebook with Image Retrieval; OMRON Corporation, Information Technology Research Center; Kyoto, JP.;;Iwamoto, Takeshi et al; u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information; Graduate School of Medial Governance, Keio University.;;Holler, Tobias H. et al; Mobile Augmented Reality; Chapter Nine; Telegeoinformatics: Location-Based Computing and Services; H. Karimi and A. Hammad (eds.); Taylor & Francis Books Ltd; Jan. 2004.;;Haritaoglu, Ismail; InfoScope: Link from Real World Digital Information Space; IBM Almaden Research; San Jose, CA.;;Gevers, Theo et al; PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval; IEEE Transactions on Inage Processing, vol. 9, No. 1; Jan. 2000.;;Geiger, Christian et al; Mobile AR4ALL; C-Lab; Paderborn, DE.;;Fernandez, Francisco; Responsive Environments: Digital Objects in the Landscape; Department of Landscape Architecture; University of Manitoba; Winnipeg, Manitoba; Mar. 2004.;;Feiner, Steven et al; A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment; Department of Computer Science; Columbia University and Graduate School of Architecture, Planning and Preservation; Columbia University; Personal Technologies, 1(4), 1997, pp. 208-217.;;Diverdi, Stephen et al; Level of Detail Interfaces; Department of Computer Science, University of California, Santa Barbara; IEEE/ACM Intl. Symp. on Mixed and Augmented Reality; Arlington, VA; Nov. 2-5, 2004.;;Diverdi, Stephen et al; ARWin-A Desktop Augmented Reality Window Manager; Department of Computer Science, University of California, Santa Barbara; May 2003.;;Arai; Toshifumi et al; PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content; CHI 97, Mar. 22-27, 1997.;;Bulman, J. et al; Mixed Reality Applicaitons in Urban Environments; BT Technology Journal; vol. 22, No. 3; Jul. 2004.;;Chang, Wendy et al; Efficient Resource Selection in Distributed Visual Information Systems; Department of Computer Science, State University of New York at Buffalo; Buffalo, NY.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.",EXPIRED
454,US,B2,US 8326038 B2,111-784-760-321-433,2012-12-04,2012,US 201113207230 A,2011-08-10,US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 63052404 P;;US 62552604 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/111-784-760-321-433,Granted Patent,yes,106,2,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/181,0,0,,,,EXPIRED
455,US,A1,US 2012/0163722 A1,105-871-884-710-017,2012-06-28,2012,US 201213410577 A,2012-03-02,US 201213410577 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 24629500 P;;US 31752101 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/105-871-884-710-017,Patent Application,yes,3,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/68,382/218,0,0,,,,EXPIRED
456,US,A1,US 2015/0302271 A1,104-899-745-601-070,2015-10-22,2015,US 201414569709 A,2014-12-14,US 201414569709 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/104-899-745-601-070,Patent Application,yes,0,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62;;G06F17/22;;G06F17/30;;G06K9/46;;H04L29/08,,0,0,,,,EXPIRED
457,US,B2,US 10509820 B2,123-137-585-930-024,2019-12-17,2019,US 201816143257 A,2018-09-26,US 201816143257 A;;US 201715711326 A;;US 201615169948 A;;US 201414569766 A;;US 201414187717 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 31752101 P;;US 24629500 P;;US 36052402 P;;US 62552604 P,2000-11-06,Object information derived from object images,"A real-world object is recognized from image data based on derived image characteristics, which are used to derive search information to conduct a search. The search returns object information which is used to execute a software process by a mobile device.",NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/123-137-585-930-024,Granted Patent,yes,447,0,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06F16/583;;G06F3/01;;G06F16/22;;G06F16/2455;;G06F16/50;;G06F16/532;;G06F16/58;;G06F16/732;;G06F16/904;;G06F16/951;;G06F16/9537;;G06K9/00;;G06K9/20;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/72;;G06K9/78;;G06Q20/10;;G06Q30/02;;G06Q30/06;;G06T7/00;;H04N5/232;;H04N5/44,,43,23,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587;;157-015-151-956-874;;078-957-418-810-926,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147;;10.1007/3-540-48157-5_23;;10.1109/apchi.1998.704151,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwaoka T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: a Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.;;Kohtake et al., InfoStick: An Interaction Device for Inter-Appliance Computing, Hans- W. Gellerson (Ed.): HUC'99, LNCS 1707, pp. 246-258, 1999.;;Schwartz, Wireless world takes James Bond-like twist with wearable digital jewelry, Enterprise Networking, www. infoworld.com, Aug. 21, 2000 Infoworld, 2 pages.;;Rekimoto, Matrix: A Realtime Object Identificaitn and Registration Method for Augmented Reality, Sony Computer Science Laboratory Inc., http://www.csl.sony.co.jp/person/rekimoto.html, 6 pages.",EXPIRED
458,DE,A1,DE 102013102626 A1,138-796-102-472-684,2013-09-19,2013,DE 102013102626 A,2013-03-14,US 201213421401 A,2012-03-15,System und Verfahren zur Kommunikation mit mehreren Elementen,"Ein System und ein Verfahren, das einer Überwachungseinheit ermöglicht, mit einem beliebigen von mehreren Serial Peripheral Interface (SPI) Elementen auf einem Eingabe/Ausgabe-(IO)-Modul unter Verwendung einer einzigen Elementauswahlleitung zu kommunizieren, werden bereitgestellt. Die Überwachungseinheit sendet eine Datennachricht mit einem Kennungscode an das IO-Modul, welches einen Router enthält, um selektiv eine entsprechende Schaltung auf dem ausgewählten SPI-Element auf der Basis des Kennungscodes zu aktivieren.",GEN ELECTRIC,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD,,https://lens.org/138-796-102-472-684,Patent Application,no,0,0,5,5,0,G06F13/4282;;G05B19/4185;;Y02P90/02;;G06F13/4282;;G05B19/4185;;Y02P90/02,G08C19/16;;H04L12/40,,0,0,,,,DISCONTINUED
459,US,B2,US 9808376 B2,135-783-474-333-560,2017-11-07,2017,US 201615287516 A,2016-10-06,US 201615287516 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,"An object is recognized from plurality of objects in a database based on a digital representation of a scene containing the object. An information address corresponding to the object is then used to present an item to a user, who may obtain the item via a transaction.",NANT HOLDINGS IP LLC,BONCYCK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/135-783-474-333-560,Granted Patent,yes,412,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q30/00;;A61F9/08;;A63F13/00;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06F17/30;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,40,20,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswel J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-211.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;ntemational Search Report and Written Opinion for Application No. PCT/US2007/02010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World nvironments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content—Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Nearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
460,US,B2,US 9844469 B2,149-453-863-741-708,2017-12-19,2017,US 201615335849 A,2016-10-27,US 201615335849 A;;US 201514683953 A;;US 201314083210 A;;US 201313856197 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES INC (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/149-453-863-741-708,Granted Patent,yes,406,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;A61F9/08;;A63F13/00;;A63F13/213;;A63F13/30;;A63F13/335;;A63F13/35;;A63F13/45;;A63F13/65;;A63F13/792;;A63F13/92;;G06F3/0482;;G06F17/22;;G06K9/00;;G06K9/18;;G06K9/22;;G06K9/32;;G06K9/34;;G06K9/46;;G06K9/62;;G06K9/64;;G06K9/78;;G06Q10/02;;G06Q20/10;;G06Q20/14;;G06Q20/20;;G06Q20/24;;G06Q20/32;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/04;;G06Q30/06;;G06Q40/00;;G06Q90/00;;G06T7/00;;G07F17/32;;H04L29/08;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/231;;H04N21/234;;H04N21/254;;H04N21/414;;H04N21/4223;;H04N21/442;;H04N21/4722;;H04N21/478;;H04N21/4782;;H04N21/658;;H04N21/81,,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., “PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,” CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., “Mixed Reality Applications in Urban Environments,” BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., “An Environment for Mobile Context-Based Hypermedia Retrieval,” IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., “Visual Information Retrieval from Large Distributed Online Respositories,” Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., “Efficient Resource Selection in Distributed Visual Information Systems,” ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., “ARWin—A Desktop Augmented Reality Window Manager,” UCSB Tech Report Dec. 2003, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., “Level of Detail Interfaces,” Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, dated Oct. 30, 2008, 2 pages.;;Feiner S., et al., “A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,” Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., “Responsive Environments: Digital Objects in the Landscape,” Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., “Mobile AR4ALL,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., “PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,” IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., “InfoScope: Link from Real World to Digital Information Space,” IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., “Chapter Nine: Mobile Augmented Reality,” in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007/02010, dated Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., “Digital Safari Guidebook With Image Retrieval,” International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., “u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,” The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., “Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,” International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., “Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,” Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,” Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., “Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,” International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., “Real-Time Target and Pose Recognition for 3-D Graphical Overlay,” Master's thesis, 1997, 48 pages.;;Ljungstrand P., et al., “WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., “Augment-able Reality: Situated Communication Through Physical and Digital Spaces,” Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., “CyberCode: Designing Augmented Reality Environments With Visual Tags,” Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., “The World Through the Computer: Computer Augmented Interaction With Real World Environments,” ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., “NaviCam: A Palmtop Device Approach to Augmented Reality,” Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., “A Conceptual Framework for Camera Phone-Based Interaction Techniques,” Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., “Implementing a Natural User Interface for Camera Phones Using Visual Tags,” Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., “Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,” First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., “VisualSEEk: A Fully Automated Content-Based Image Query System,” Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., “Augmented Reality Through Wearable Computing,” Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, dated May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, dated Aug. 12, 2008, 8 pages.;;Suzuki G., et al., “u-Photo: Interacting with Pervasive Services Using Digital Still Images,” Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., “Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,” in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., “First Steps Towards Handheld Augmented Reality,” Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., “Smart Sight: A Tourist Assistant System,” Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., “Searching the Web with Mobile Images for location Recognition,” IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., “Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,” Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
461,US,A1,US 2013/0121532 A1,144-359-384-869-103,2013-05-16,2013,US 201213693983 A,2012-12-04,US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/144-359-384-869-103,Patent Application,yes,3,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/78,382/103,0,0,,,,EXPIRED
462,US,A1,US 2012/0207352 A1,155-386-912-515-345,2012-08-16,2012,US 201213441370 A,2012-04-06,US 201213441370 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/155-386-912-515-345,Patent Application,yes,3,5,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,0,0,,,,EXPIRED
463,US,A1,US 2015/0063644 A1,177-210-546-784-252,2015-03-05,2015,US 201414536432 A,2014-11-07,US 201414536432 A;;US 201414474254 A;;US 201313859183 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/177-210-546-784-252,Patent Application,yes,2,0,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06F17/30;;G06K9/62,382/103,0,0,,,,EXPIRED
464,US,B2,US 8494271 B2,170-535-747-884-12X,2013-07-23,2013,US 201213477954 A,2012-05-22,US 201213477954 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object information derived from object images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2005-08-12);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/170-535-747-884-12X,Granted Patent,yes,104,5,10,173,0,G06F16/583;;G06F16/583;;G06F16/5854;;G06F16/5854;;G06F16/9537;;G06F16/9537;;G06Q30/0601;;G06Q30/0601;;G06Q30/0641;;G06Q30/0641,G06K9/00,382/181,0,0,,,,EXPIRED
465,US,B2,US 8467602 B2,179-781-934-053-146,2013-06-18,2013,US 201213535185 A,2012-06-27,US 201213535185 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/179-781-934-053-146,Granted Patent,yes,101,11,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/165,0,0,,,,EXPIRED
466,US,A1,US 2014/0098993 A1,198-831-870-400-082,2014-04-10,2014,US 201314100431 A,2013-12-09,US 201314100431 A;;US 201313907780 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,BONCYK WAYNE C;;COHEN RONALD H;;NANT HOLDINGS IP LLC,BONCYK WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/198-831-870-400-082,Patent Application,yes,13,5,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/00,382/103,0,0,,,,EXPIRED
467,US,A1,US 2014/0211996 A1,017-148-676-208-089,2014-07-31,2014,US 201414170123 A,2014-01-31,US 201414170123 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK V WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/017-148-676-208-089,Patent Application,yes,6,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62;;G06F17/30;;G06K9/78,382/103,0,0,,,,EXPIRED
468,US,A1,US 2016/0019617 A1,100-107-106-160-754,2016-01-21,2016,US 201514853845 A,2015-09-14,US 201514853845 A;;US 201313840044 A,2013-03-15,METHODS AND APPARATUS FOR FACILITATION OF ORDERS OF FOOD ITEMS,"Embodiments of the invention provide techniques which aid in correctly capturing what a restaurant customer intends to order, and may enhance the customer's satisfaction with the ordering and dining process overall. For example, an interface may be provided through which a customer may specify an order, and the interface may clearly convey such information as each ordered item's ingredients and nutritional content. The interface may enable the customer to customize ordered items, and may clearly convey any changes that the customer has made, allowing the customer to make informed choices about the items included in an order. The interface may embody a design which enables the customer to quickly and easily customize items, and/or to re-order previously customized items.",PANERA LLC,HURST BLAINE E;;SHAICH RONALD;;COHEN DANIEL,PANERA LLC (2015-08-07),https://lens.org/100-107-106-160-754,Patent Application,yes,0,4,8,8,0,G06Q30/0621;;G06Q30/0621;;G06Q30/0633;;G06Q30/0633;;G06Q30/0641;;G06Q30/0641;;G06Q30/0643;;G06Q30/0643;;G06Q50/12;;G06Q50/12,G06Q30/06;;G06Q50/12,,0,0,,,,ACTIVE
469,US,A1,US 2014/0149154 A1,037-661-799-736-079,2014-05-29,2014,US 201414170047 A,2014-01-31,US 201414170047 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK V WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/037-661-799-736-079,Patent Application,yes,8,2,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06Q10/02,705/5,0,0,,,,EXPIRED
470,US,B2,US 10089669 B2,128-080-748-100-146,2018-10-02,2018,US 201514853845 A,2015-09-14,US 201514853845 A;;US 201313840044 A,2013-03-15,Methods and apparatus for facilitation of orders of food items,"Embodiments of the invention provide techniques which aid in correctly capturing what a restaurant customer intends to order, and may enhance the customer's satisfaction with the ordering and dining process overall. For example, an interface may be provided through which a customer may specify an order, and the interface may clearly convey such information as each ordered item's ingredients and nutritional content. The interface may enable the customer to customize ordered items, and may clearly convey any changes that the customer has made, allowing the customer to make informed choices about the items included in an order. The interface may embody a design which enables the customer to quickly and easily customize items, and/or to re-order previously customized items.",PANERA LLC,HURST BLAINE E;;SHAICH RONALD;;COHEN DANIEL,PANERA LLC (2015-08-07),https://lens.org/128-080-748-100-146,Granted Patent,yes,458,7,8,8,0,G06Q30/0621;;G06Q30/0621;;G06Q30/0633;;G06Q30/0633;;G06Q30/0641;;G06Q30/0641;;G06Q30/0643;;G06Q30/0643;;G06Q50/12;;G06Q50/12,G06Q50/12;;G06Q30/06,,10,0,,,"U.S. Appl. No. 14/850,837, filed Sep. 10, 2015, Hurst et al.;;U.S. Appl. No. 13/838,155, filed Mar. 15, 2013, Hurst et al.;;U.S. Appl. No. 13/838,312, filed Mar. 15, 2013, Hurst et al.;;U.S. Appl. No. 13/838,457, filed Mar. 15, 2013, Ronald Shaich.;;U.S. Appl. No. 13/839,256, filed Mar. 15, 2013, Blaine E. Hurst.;;U.S. Appl. No. 13/839,424, filed Mar. 15, 2013, Hurst et al.;;U.S. Appl. No. 13/839,609, filed Mar. 15, 2013, Ronald Shaich.;;U.S. Appl. No. 13/839,495, filed Mar. 15, 2013, Hurst et al.;;U.S. Appl. No. 13/839,298, filed Mar. 15, 2013, Hurst et al.;;U.S. Appl. No. 13/850,837, filed Sep. 10, 2015, Hurst et al.",ACTIVE
471,US,A1,US 2014/0152855 A1,065-366-417-111-203,2014-06-05,2014,US 201414173195 A,2014-02-05,US 201414173195 A;;US 201313860967 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK V WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/065-366-417-111-203,Patent Application,yes,6,1,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,H04N5/232,348/207.1,0,0,,,,EXPIRED
472,US,A1,US 2023/0190225 A1,100-257-697-313-604,2023-06-22,2023,US 202218082303 A,2022-12-15,US 202218082303 A;;US 202163290688 P,2021-12-17,"INTRAVASCULAR IMAGING ASSESSMENT OF STENT DEPLOYMENT AND ASSOCIATED SYSTEMS, DEVICES, AND METHODS",A system includes a processor circuit that receives intraluminal images of a body lumen. The processor circuit identifies a stent edge within the intraluminal images and calculates a distance between the stent edge and the vessel wall. The processor circuit additionally compares the distance between the stent edge and the vessel for the intraluminal images to a threshold distance and identifies which intraluminal images correspond to a distance exceeding the threshold. The processor circuit further outputs to a display a longitudinal view of the body lumen identifying locations along the stent at which the distance between the stent and the vessel wall exceeds the threshold distance.,PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD,PHILIPS IMAGE GUIDED THERAPY CORPORATION (2022-12-07),https://lens.org/100-257-697-313-604,Patent Application,yes,0,0,2,2,0,G16H30/40;;G16H20/40;;A61B8/12;;G06V2201/034;;G06V10/44;;A61B8/0841;;A61B8/12;;A61B8/463;;G06T7/60;;G06T11/00;;G06T2207/30101;;G06T2210/41,A61B8/08;;A61B8/00;;A61B8/12;;G06T7/60;;G06T11/00;;G06V10/44,,0,0,,,,PENDING
473,US,B2,US 9014515 B2,147-380-252-233-360,2015-04-21,2015,US 201414173195 A,2014-02-05,US 201414173195 A;;US 201313860967 A;;US 201213538915 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image capture and identification system and process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK V WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/147-380-252-233-360,Granted Patent,yes,105,10,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/60;;A61F9/08;;A63F13/00;;A63F13/30;;G06F3/0482;;G06F17/30;;G06K9/00;;G06K9/22;;G06K9/32;;G06K9/46;;G06K9/62;;G06K9/78;;G06Q10/02;;G06Q20/24;;G06Q20/34;;G06Q20/40;;G06Q30/02;;G06Q30/06;;G06Q40/00;;G06Q90/00;;H04N1/00;;H04N5/225;;H04N5/232;;H04N5/91;;H04N7/18;;H04N21/254;;H04N21/442;;H04N21/81,382/305,40,21,032-705-158-397-206;;104-793-026-621-862;;041-034-977-263-043;;001-154-350-168-291;;031-355-417-899-97X;;008-326-799-368-325;;031-722-294-321-407;;128-214-933-277-42X;;151-790-631-478-110;;066-347-463-670-762;;030-846-937-028-967;;088-865-239-067-73X;;187-572-604-127-113;;013-901-391-839-508;;075-323-994-501-589;;084-111-378-111-079;;005-593-570-469-117;;001-707-518-497-898;;152-227-401-630-619;;104-390-025-879-216;;067-825-083-591-587,10.1145/258549.258782;;10.1023/b:bttj.0000047123.94280.3a;;10.1145/265563.265573;;10.1007/bf01682023;;10.1109/83.817602;;18255376;;10.1007/3-540-45427-6_21;;10.1109/iswc.1997.629930;;10.1145/313451.313467;;10.1109/iwar.1999.803809;;10.1109/isar.2001.970522;;10.1145/354666.354669;;10.1109/iswc.1998.729531;;10.1145/354666.354667;;10.1145/215585.215639;;10.1007/11428572_11;;10.1109/iswc.1997.629927;;10.1145/244130.244151;;10.1007/11428572_12;;10.1109/iswc.2003.1241402;;10.1109/iswc.1999.806662;;10.1109/cvpr.2004.1315147,"Arai T., et al., ""PaperLink: A Technique for Hyperlinking from Real Paper to Electronic Content,"" CHI 97 Electronic Publications: Papers, Conference on Human Factors in Computer Systems, Atlanta, Georgia, Mar. 22-27, 1997, pp. 327-334.;;Bulman J., et al., ""Mixed Reality Applications in Urban Environments,"" BT Technology Journal, 2004, vol. 22 (3), pp. 84-94.;;Carswell J.D., et al., ""An Environment for Mobile Context-Based Hypermedia Retrieval,"" IEEE: Proceedings of the 13th International Workshop on Database and Expert Systems Applications, 1529-4188/02, 2002, 5 pages.;;Chang S.F., et al., ""Visual Information Retrieval from Large Distributed Online Respositories,"" Communication of Association for Computing Machinery, ISSN:0001-0782, 1997, vol. 40 (12), pp. 64-71.;;Chang W., et al., ""Efficient Resource Selection in Distributed Visual Information Systems,"" ACM Multimedia, 1997, pp. 203-213.;;Diverdi S., et al., ""ARWin-A Desktop Augmented Reality Window Manager,"" UCSB Tech Report 2003-12, University of California Santa Barbara, May 2003, 7 pages.;;Diverdi S., et al., ""Level of Detail Interfaces,"" Proc. ISMAR 2004, IEEE/ACM IHyf Symp on Mixed and Augmented Reality, Arlington, Virginia, 2004, 2 pages.;;European Search Report for Application No. EP06018047, mailed on Oct. 30, 2008, 2 pages.;;Feiner S., et al., ""A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment,"" Personal Technologies, 1997, vol. 1 (4), pp. 208-217.;;Fernandez F., ""Responsive Environments: Digital Objects in the Landscape,"" Thesis submitted to Department of Landscape Architecture, University of Manitoba, Winnipeg, Manitoba, Mar. 2004, 124 pages.;;Geiger C., et al., ""Mobile AR4ALL,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality (ISAR'01), Oct. 29-30, 2001, Columbia University, New York, 2 pages.;;Gevers T., et al., ""PicToSeek: Combining Color and Shape Invariant Features for Image Retrieval,"" IEEE Transactions on Image Processing, 2000, vol. 9 (1), pp. 102-119.;;Haritaoglu I., ""InfoScope: Link from Real World to Digital Information Space,"" IBM Almaden Research, UbiComp, Lecture Notes in Computer Science, 2001, vol. 2201, pp. 247-255.;;Hollerer T., et al., ""Chapter Nine: Mobile Augmented Reality,"" in: Telegeoinformatics: Location Based Computing and Services, Karimi H., eds., Taylor & Francis Books, Ltd., 2004, Chapter 9, 39 pages.;;International Search Report and Written Opinion for Application No. PCT/US2007102010, mailed on Nov. 16, 2007, 5 pages.;;Iwamoto T., et al., ""Digital Safari Guidebook With Image Retrieval,"" International Conference on Advances in Mathematical Computations and Statistical Computing, 1999, vol. 2, pp. 1011-1012.;;Iwamoto T., et al., ""u-Photo: A Design and Implementation of a Snapshot Based Method for Capturing Contextual Information,"" The Second International Conference on Pervasive Computing Pervasive, 2004, Advances in Pervasive Computing, LinzNienna, Austria, 6 pages.;;Jebara T., et al., ""Stochasticks: Augmenting the Billiards Experience With Probabilistic Vision and Wearable Computers,"" International Symposium on Wearable Computers, 1997, IEEE Computer Society, pp. 138-145.;;Kangas K., et al., ""Using Code Mobility to Create Ubiquitous and Active Augmented Reality in Mobile Computing,"" Mobicom, 1999, Seattle, Washington, pp. 48-58.;;Kato H., et al., ""Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System,"" Proceedings of the 2nd IEEE and ACM Intl Workshop on Augmented Reality, San Francisco, California, 1999, pp. 85-94.;;Klinker G., ""Augmented Maintenance of Powerplants: A Prototyping Case Study of a Mobile AR System,"" International Symposium on Augmented Reality, 2001, IEEE Computer Society, pp. 124-136.;;Levine J.M., ""Real-Time Target and Pose Recognition for 3-D Graphical Overlay,"" Master's thesis, 1997, 48 pages.;;Ljungstrand R, et al., ""WebStickers: Using Physical Tokens to Access, Manage and Share Bookmarks on the Web,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments (DARE 2000), 2000, pp. 23-31.;;Rekimoto J., et al., ""Augment-able Reality: Situated Communication Through Physical and Digital Spaces,"" Wearable Computers, Second International Symposium, 1998, pp. 68-75.;;Rekimoto J., et al., ""CyberCode: Designing Augmented Reality Environments With Visual Tags,"" Proceedings of the 2000 ACM Conference on Designing Augmented Reality Environments, 2000, pp. 1-10.;;Rekimoto J., et al., ""The World Through the Computer: Computer Augmented Interaction With Real World Environments,"" ACM Symposium on User Interface Software and Technology, 1995, pp. 29-36.;;Rekimoto J., ""NaviCam: A Palmtop Device Approach to Augmented Reality,"" Fundamentals of Wearable Computers and Augmented Reality, 2001, Barfield and Caudell, Eds., pp. 353-377.;;Rohs M., et al., ""A Conceptual Framework for Camera Phone-Based Interaction Techniques,"" Pervasive Computing. Lecture Notes in Computer Science, 2005, vol. 3468, pp. 171-189.;;Siltanen S., et al., ""Implementing a Natural User Interface for Camera Phones Using Visual Tags,"" Proceedings of the 7th Australasian User interface conference, 2006, vol. 50, pp. 113-116.;;Smailagic A, et al., ""Metronaut: A Wearable Computer With Sensing and Global Communication Capabilities,"" First International Symposium on Wearable Computers, Oct. 13-14, 1997, Cambridge, Massachusetts; Digest of Papers, pp. 116-122.;;Smith J.R., et al., ""VisualSEEk: A Fully Automated Content-Based Image Query System,"" Proceedings of the fourth ACM international conference on Multimedia, ACM New York, 1996, pp. 87-98.;;Starner T., et al., ""Augmented Reality Through Wearable Computing,"" Presence: Teleoper. Virtual Environ. 6, 4, Massachusetts Institute of Technology, 1997, 24 pages.;;Supplementary European Search Report for Application No. EP02778730, mailed on May 14, 2007, 3 pages.;;Supplementary European Search Report for Application No. EP06801326, mailed on Aug. 12, 2008, 8 pages.;;Suzuki G., et al., ""u-Photo: Interacting with Pervasive Services Using Digital Still Images,"" Pervasive Computing. Lecture Notes in Computer Science, vol. 3468, 2005, pp. 190-207.;;Toye E., et al., ""Interacting with Mobile Services: An Evaluation of Camera-Phones and Visual Tags,"" in: Personal and Ubiquitous Computing, vol. 11 (2), Springer-Verlag, London Limited, 2007, pp. 97-106.;;Wagner D., et al., ""First Steps Towards Handheld Augmented Reality,"" Vienna University of Technology, Proceedings of Seventh IEEE International Symposium on Wearable Computers, Oct. 18-21, 2003, 9 pages.;;Yang J., et al., ""Smart Sight: A Tourist Assistant System,"" Digest of Papers, Third International Symposium on Wearable Computers, Oct. 18-19, 1999, San Francisco, California, pp. 73-78.;;Yeh T., et al., ""Searching the Web with Mobile Images for location Recognition,"" IEEE: Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'04), 1063-6919/04, 2004, 6 pages.;;Zhang X., et al., ""Taking AR Into Large Scale Industrial Environments: Navigation and Information Access With Mobile Computers,"" Proceedings of the IEEE and ACM Intl Symposium on Augmented Reality, 2001, pp. 179-180.",EXPIRED
474,WO,A1,WO 2023/110594 A1,055-249-925-808-351,2023-06-22,2023,EP 2022084862 W,2022-12-07,US 202163290688 P,2021-12-17,"INTRAVASCULAR IMAGING ASSESSMENT OF STENT DEPLOYMENT AND ASSOCIATED SYSTEMS, DEVICES, AND METHODS",A system includes a processor circuit that receives intraluminal images of a body lumen. The processor circuit identifies a stent edge within the intraluminal images and calculates a distance between the stent edge and the vessel wall. The processor circuit additionally compares the distance between the stent edge and the vessel for the intraluminal images to a threshold distance and identifies which intraluminal images correspond to a distance exceeding the threshold. The processor circuit further outputs to a display a longitudinal view of the body lumen identifying locations along the stent at which the distance between the stent and the vessel wall exceeds the threshold distance.,PHILIPS IMAGE GUIDED THERAPY CORP;;KONINKLIJKE PHILIPS NV,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD,,https://lens.org/055-249-925-808-351,Patent Application,yes,11,0,2,2,0,G16H30/40;;G16H20/40;;A61B8/12;;G06V2201/034;;G06V10/44;;A61B8/0841;;A61B8/12;;A61B8/463;;G06T7/60;;G06T11/00;;G06T2207/30101;;G06T2210/41,G16H20/40;;G16H30/40,,0,0,,,,PENDING
475,US,A1,US 2023/0196569 A1,161-431-735-005-965,2023-06-22,2023,US 202218082482 A,2022-12-15,US 202218082482 A;;US 202163292521 P,2021-12-22,"CALCIUM ARC OF BLOOD VESSEL WITHIN INTRAVASCULAR IMAGE AND ASSOCIATED SYSTEMS, DEVICES, AND METHODS",A system includes a processor circuit in communication with an intraluminal imaging device. The processor circuit is configured to receive an intraluminal image obtained by the intraluminal imaging device while the intraluminal imaging device is positioned within a body lumen of a patient. The processor circuit also receive a user input selecting one location within the intraluminal image and another user input selecting another location within the intraluminal image. These two locations within the intraluminal image define boundaries of a sector of the intraluminal image associated with a tissue type. The processor circuit determines an angle of the sector defined by the two locations. The intraluminal image and a visual representation of the angle are displayed on a screen display.,PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD,PHILIPS IMAGE GUIDED THERAPY CORPORATION (2022-12-08),https://lens.org/161-431-735-005-965,Patent Application,yes,0,0,2,2,0,A61B5/0066;;A61B5/0084;;A61B8/12;;A61B5/02007;;A61B6/12;;A61B8/0891;;A61B8/4416;;A61B8/5261;;A61B8/468;;A61B8/463;;A61B5/107;;G16H30/40;;G06T7/64;;G06F3/04883;;G06F3/14;;G06T7/0012;;G06T2207/20101;;G06T2207/30101,G06T7/00;;G06F3/04883;;G06F3/14;;G06T7/64,,0,0,,,,PENDING
476,US,A1,US 2014/0147053 A1,196-540-448-046-791,2014-05-29,2014,US 201414170079 A,2014-01-31,US 201414170079 A;;US 201213693983 A;;US 201113069112 A;;US 201113037317 A;;US 33363008 A;;US 49224304 A;;US 0235407 W;;US 99294201 A;;US 31752101 P;;US 24629500 P,2000-11-06,Image Capture and Identification System and Process,A digital image of the object is captured and the object is recognized from plurality of objects in a database. An information address corresponding to the object is then used to access information and initiate communication pertinent to the object.,NANT HOLDINGS IP LLC,BONCYK V WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/196-540-448-046-791,Patent Application,yes,1,4,146,146,0,G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F16/5838;;G06F16/5854;;G06Q30/0241;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;G06Q30/04;;G06Q30/0601;;G06Q30/0253;;G06Q10/02;;G06Q30/0217;;H04N1/00244;;G06Q90/00;;G06Q30/0257;;H04N7/183;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;G06V30/142;;G06V10/56;;G06V10/462;;G06V10/7515;;H04N23/60;;H04N23/661;;G06F16/24;;G06F16/29;;G06F16/50;;G06F16/51;;G06F16/94;;G06F16/583;;G06F16/5838;;G06F16/5846;;G06F16/5854;;G06F16/5866;;G06F16/9554;;G06F16/9558;;G06Q30/0277;;G06Q30/0623;;G06Q30/0643;;G06Q40/00;;H04N21/23109;;H04N21/23418;;H04N21/41407;;H04N21/4223;;H04N21/4722;;H04N21/4782;;H04N21/6582;;G06T7/73;;G06T7/10;;G06T7/194;;G06F40/134;;G06V10/56;;G06V10/462;;G06V10/7515;;G06V20/10;;G06V20/20;;G06V30/142;;G06V30/224;;G06F18/22;;G06F18/23;;G06F18/217;;G06F2218/12;;H04N23/00;;H04N23/60;;H04N23/64;;H04N23/80;;G06Q30/0601;;G06Q20/40145;;G06Q30/0257;;A61F9/08;;H04N7/183;;A63F13/00;;H04N21/8173;;G06Q30/0267;;G06Q30/0268;;G06Q30/0269;;H04N21/254;;H04N21/8126;;G06Q30/0253;;H04N21/812;;G06Q10/02;;G06Q20/24;;G06Q20/3567;;G06Q30/0217;;G06F3/0482;;H04N1/00244;;H04N5/91;;H04N2201/3253;;H04N2201/3254;;H04N2201/3274;;G06Q90/00;;H04L67/10;;G06Q30/0241;;H04L67/02;;G06Q20/202;;G06Q20/208;;G06Q20/327;;H04N7/185;;A63F13/45;;G06Q20/102;;G06Q20/14;;G06Q30/0635;;G07F17/3206;;G07F17/3241;;G07F17/3244;;H04N21/4781;;A63F13/213;;A63F13/335;;A63F13/35;;A63F13/65;;A63F13/792;;A63F13/92;;G06Q30/04;;H04N21/47815;;G06T7/13;;G06T7/33;;A63F13/70;;G09B21/006;;G06T7/11;;G06T7/337;;G06T7/136;;G06T7/246;;A63F13/20,G06K9/62,382/218,0,0,,,,EXPIRED
477,US,B1,US 7460035 B1,153-412-983-153-63X,2008-12-02,2008,US 77318107 A,2007-07-03,US 77318107 A,2007-07-03,Balanced code with opportunistically reduced transitions,"Embodiments of an encoding circuit to communicate a sequence of words are described. This encoding circuit includes an encoding module that is configured to receive a first sequence of words and to generate a DC-balanced second sequence of words based on the first sequence of words, where communicating the second sequence of words consumes less energy than communicating a third sequence of words that includes words in the first sequence of words alternating with words in the inverse of the first sequence of words. In addition, the second sequence of words includes substantially twice as many words as the first sequence of words.",SUN MICROSYSTEMS INC,HO RONALD;;COHEN DANNY;;DROST ROBERT J,SUN MICROSYSTEMS INC (2007-06-05);;ORACLE AMERICA INC (2010-02-12),https://lens.org/153-412-983-153-63X,Granted Patent,yes,2,4,1,1,0,H03M5/12;;H03M5/12,H03M5/00,341/58;;341/50,0,0,,,,ACTIVE
478,US,A1,US 2014/0147006 A1,049-564-631-644-067,2014-05-29,2014,US 201414170236 A,2014-01-31,US 201414170236 A;;US 201313858897 A;;US 201213705071 A;;US 201113207230 A;;US 201113037330 A;;US 56813009 A;;US 20490105 A;;US 99294201 A;;US 63052404 P;;US 62552604 P;;US 31752101 P;;US 24629500 P,2000-11-06,Object Information Derived From Object Images,"Search terms are derived automatically from images captured by a camera equipped cell phone, PDA, or other image capturing device, submitted to a search engine to obtain information of interest, and at least a portion of the resulting information is transmitted back locally to, or nearby, the device that captured the image.",NANT HOLDINGS IP LLC,BONCYK V WAYNE C;;COHEN RONALD H,EVRYX TECHNOLOGIES (2004-03-14);;NANT HOLDINGS IP LLC (2011-05-16);;EVRYX ACQUISITION LLC (2011-02-23),https://lens.org/049-564-631-644-067,Patent Application,yes,0,3,74,173,0,G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q30/0635;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;G06Q30/0625;;G06Q30/0623;;G06V40/16;;G06V20/80;;G06V40/18;;G06V20/00;;G06V20/20;;G06V20/46;;G06V20/10;;G06V10/255;;G06V10/768;;G06V10/10;;H04N23/80;;G06F2218/08;;H04W88/18;;G06F16/5838;;G06F16/22;;G06F16/50;;G06F16/532;;G06F16/583;;G06F16/904;;G06F16/951;;G06F16/5854;;G06F16/5866;;G06F16/7335;;G06F16/9537;;G06F16/24554;;G06Q20/10;;G06Q30/0601;;G06Q30/0613;;G06V10/10;;G06V10/255;;G06V10/768;;G06V20/00;;G06V20/10;;G06V20/20;;G06V20/46;;G06V20/80;;G06V40/16;;G06V40/18;;G06V2201/07;;G06F18/25;;G06F2218/08;;H04N23/80;;G06F16/9538;;G06Q30/0625;;G06Q30/0623;;G06Q30/0261;;G06Q30/0267;;G06Q30/0269;;G06T7/00;;G06F3/017;;H04N5/44;;G06Q30/0635,G06K9/00,382/103,0,0,,,,EXPIRED
479,US,A,US 4591496 A,192-643-276-024-663,1986-05-27,1986,US 57100784 A,1984-01-16,US 57100784 A,1984-01-16,Process for making systems for the controlled release of macromolecules,"A new method for making polymeric systems for the sustained release of macromolecular drugs is described. The method consists of mixing drug and polymer, e.g. ethylene-vinyl acetate copolymer powders below the glass transition temperature of the polymer, and compressing the mixture at a temperature above the glass transition point. The macromolecule is not exposed to organic solvent during the fabrication process. The sustained release and bioactivity of macromolecules is unchanged throughout the pressure casting and release processes.",MASSACHUSETTS INST TECHNOLOGY,COHEN JONATHAN M;;SIEGEL RONALD;;LANGER ROBERT,MASSACHUSETTS INSTITUTE OF TECHNOLOGY (1983-12-30);;MASSACHUSETTS INSTITUTE OF TECHNOLOGY 77 MASS AVE A MA CORP (1984-01-13),https://lens.org/192-643-276-024-663,Granted Patent,yes,8,70,1,1,0,A61K9/2027;;A61K9/2027,A61K9/20,424/15;;264/109;;264/123;;264/125;;424/14;;424/16;;424/19;;424/22;;424/78,1,0,,,"Little et al., Tablet Making, 2nd ed. (1963), Northern Pub. Co., Liverpool, England, pp. 11 23, 29 33.",EXPIRED
480,WO,A1,WO 2023/104599 A1,007-212-261-894-321,2023-06-15,2023,EP 2022083771 W,2022-11-30,US 202163288554 P,2021-12-11,AUTOMATIC SEGMENTATION AND TREATMENT PLANNING FOR A VESSEL WITH COREGISTRATION OF PHYSIOLOGY DATA AND EXTRALUMINAL DATA,A system includes a processor circuit that receives physiology measurements obtained by an intraluminal physiology measurement device within a body lumen. The processor circuit automatically segments the body lumen into a plurality of segments based on the physiology measurements. The processor circuit then determines a change in the physiology measurements corresponding to each segment and determines a recommended position for a treatment device within the body lumen based on the change for each segment. The processor circuit provides an output associated with the recommended position on a display.,KONINKLIJKE PHILIPS NV;;PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN,,https://lens.org/007-212-261-894-321,Patent Application,yes,8,0,2,2,0,A61B5/0215;;G16H30/40;;A61B6/5247;;A61B8/5261;;A61B2090/364;;A61B34/25;;A61B34/10;;A61B2034/105;;A61B2034/102;;A61B2034/104;;A61B2034/107;;A61B6/032;;A61B6/4417;;A61B6/4225;;A61B6/504;;A61B6/12;;A61B6/5217;;A61B6/481;;A61B8/12;;A61B8/0891;;G16H20/40;;G16H40/63;;G16H50/20;;A61B2017/00022;;A61B2034/108;;A61B8/0891;;A61B8/12,A61B6/00;;A61B5/0215;;A61B8/08;;A61B34/00;;A61B34/10;;A61B90/00;;G16H30/40,,0,0,,,,PENDING
481,US,A1,US 2017/0042721 A1,044-009-650-858-031,2017-02-16,2017,US 201615340735 A,2016-11-01,US 201615340735 A;;US 201213473531 A;;US 2010/0057286 W;;US 29700110 P;;US 26250309 P,2009-11-18,SHOULDER IMMOBILIZER AND FRACTURE STABILIZATION DEVICE,"A shoulder immobilizer ( 20 ) includes a semi-rigid or rigid orthosis, in the form of an arm support ( 22 ), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster ( 24 ) is positioned between the patient and the arm support ( 22 ). A body strap ( 26 ) extends around the patient and attaches to the arm support ( 22 ) and/or the bolster ( 24 ), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer ( 20 ) may utilize a shoulder strap ( 28 ), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",DJO LLC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,DJO LLC (2017-01-26),https://lens.org/044-009-650-858-031,Patent Application,yes,6,1,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/37;;A61F5/05;;A61F5/32;;A61F7/02,,0,0,,,,ACTIVE
482,EP,A2,EP 0887852 A2,104-778-504-582-728,1998-12-30,1998,EP 98305008 A,1998-06-25,US 88205697 A,1997-06-25,silica stain monitoring method,"A method for forming silica stain on a substrate to facilitate monitoring of the silica stain during integrated circuit manufacture. The method includes providing a silica stain test structure which has a silicon substrate, a hydrophilic silicon dioxide containing layer disposed above the silicon substrate, and a plurality of cavities formed in the silicon dioxide containing layer. The cavities have hydrophobic sidewalls. The method also includes exposing the silica stain test structure to deionized water, and drying the silica stain test structure to form the silica stain on the silicon dioxide containing layer.",SIEMENS AG;;IBM,ARNDT RUSS;;HOYER RONALD;;COHEN SUSAN;;SNAVELY COLLEEN,INFINEON TECHNOLOGIES AG (2003-06-11);;INTERNATIONAL BUSINESS MACHINESCORPORATION (2003-06-11),https://lens.org/104-778-504-582-728,Patent Application,yes,0,0,9,9,0,H01L21/02;;H01L22/34;;H01L22/34,G01N21/88;;G01N21/93;;G01N21/956;;H01L21/304;;H01L21/306;;H01L21/66;;H01L23/544;;H01L27/10,,0,0,,,,DISCONTINUED
483,US,A,US 3073731 A,075-309-903-337-891,1963-01-15,1963,US 57493956 A,1956-03-29,US 57493956 A,1956-03-29,Plasticizing agents for nitrocellulose,,JOSEPH COHEN;;FINNEGAN WILLIAM G;;HENRY RONALD A,JOSEPH COHEN;;FINNEGAN WILLIAM G;;HENRY RONALD A,,https://lens.org/075-309-903-337-891,Granted Patent,no,1,9,1,1,0,C06B43/00;;C06B43/00;;C06B25/18;;C06B25/18,C06B25/18;;C06B43/00,,0,0,,,,EXPIRED
484,WO,A1,WO 2011/063155 A1,010-969-764-394-399,2011-05-26,2011,US 2010/0057286 W,2010-11-18,US 26250309 P;;US 29700110 P,2009-11-18,SHOULDER IMMOBILIZER AND FRACTURE STABILIZATION DEVICE,"A shoulder immobilizer (20) includes a semi-rigid or rigid orthosis, in the form of an arm support (22), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster (24) is positioned between the patient and the arm support (22). A body strap (26) extends around the patient and attaches to the arm support (22) and/or the bolster (24), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer (20) may utilize a shoulder strap (28), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",CRADLE MEDICAL INC;;GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,,https://lens.org/010-969-764-394-399,Patent Application,yes,5,6,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/00,,1,0,,,See also references of EP 2501345A4,PENDING
485,JP,A,JP H1174327 A,084-834-059-721-047,1999-03-16,1999,JP 17754198 A,1998-06-24,US 88205697 A,1997-06-25,"METHOD FOR FORMING SILICA STAIN ON SUBSTRATE, AND FOR PREPARING TESTING STRUCTURE THEREOF","PROBLEM TO BE SOLVED: To facilitate monitoring of silica stain, by providing a plurality of cavities in a silicon substrate through a hydrophilic silicon dioxide containing layer and a silicon dioxide containing layer on the silicon substrate, making their side walls hydrophobic, exposing them to deionized water and then drying them. SOLUTION: A silicon substrate is prepared (502), and a hydrophilic carbon dioxide (SiO2 ) containing layer is formed entirely on the substrate (504). Then, a plurality of cavities are formed by etching through the SiO2 layer into the substrate (506). Side wall surfaces of the cavities are made to be hydrophobic by HF liquid (508), the substrate is washed in deionized aqueous solution (510), and this is dried to remove the deionized water (512). The drying and/or cleaning process extracts silica containing solution to a surface from the cavities with a high aspect ratio. Thus, silica stain can be formed thick and/or large, thereby improving accuracy in automatic stain detection.",SIEMENS AG;;IBM,ARNDT RUSS;;COHEN SUSAN;;HOYER RONALD;;SNAVELY COLLEEN,,https://lens.org/084-834-059-721-047,Patent Application,no,0,0,9,9,0,H01L22/34;;H01L21/02;;H01L22/34,G01N21/88;;G01N21/93;;G01N21/956;;H01L21/304;;H01L21/306;;H01L21/66;;H01L23/544;;H01L27/10,,0,0,,,,PENDING
486,US,A,US 5899701 A,077-347-306-963-712,1999-05-04,1999,US 88205697 A,1997-06-25,US 88205697 A,1997-06-25,Method for making silica strain test structures,"A method for forming silica stain on a substrate to facilitate monitoring of the silica stain during integrated circuit manufacture. The method includes providing a silica stain test structure which has a silicon substrate, a hydrophilic silicon dioxide containing layer disposed above the silicon substrate, and a plurality of cavities formed in the silicon substrate through the silicon dioxide containing layer. The cavities have hydrophobic sidewalls. The method also includes exposing the silica stain test structure to deionized water, and drying the silica stain test structure to form the silica stain on the silicon dioxide containing layer.",SIEMENS AG;;IBM,ARNDT RUSS;;COHEN SUSAN;;HOYER RONALD;;SNAVELY COLLEEN,SIEMENS AKTIENGESELLSCHAFT (1998-04-16);;QIMONDA AG (2006-04-25);;SIEMENS MICROELECTRONICS INC (1998-02-09);;INFINEON TECHNOLOGIES AG (2014-10-09);;INTERNATIONAL BUSINESS MACHINES CORPORATION (1997-11-20),https://lens.org/077-347-306-963-712,Granted Patent,yes,3,2,9,9,0,H01L21/02;;H01L22/34;;H01L22/34,G01N21/88;;G01N21/93;;G01N21/956;;H01L21/304;;H01L21/306;;H01L21/66;;H01L23/544;;H01L27/10,438/12;;438/8,2,1,090-643-732-197-595,10.1149/1.2044235,"Jin Goo Park et al., Effects of Drying and Wettability of Silicon on the Formation of Water Marks in Semiconductor Processing, Jun. 1995, J. Electrochem. Soc ., vol. 142, No. 6, pp. 2028 2031.;;Scott Mackinnon, Water Spot Formation on Hydrophobic Silicon Surfaces, 1994, Microcontamination Conference Proceedings Sematech, pp. 173 184.",EXPIRED
487,TW,B,TW 389951 B,156-184-899-765-462,2000-05-11,2000,TW 87110243 A,1998-06-25,US 88205697 A,1997-06-25,Improved silica stain test structures and methods therefor,"A method for forming silica stain on a substrate to facilitate monitoring of the silica stain during integrated circuit manufacture. The method includes providing a silica stain test structure which has a silicon substrate, a hydrophilic silicon dioxide containing layer disposed above the silicon substrate, and a plurality of cavities formed in the silicon substrate through the silicon dioxide containing layer. The cavities have hydrophobic sidewalls. The method also includes exposing the silica stain test structure to deionized water, and drying the silica stain test structure to form the silica stain on the silicon dioxide containing layer.",INTERNAT BUSINESSN MACHINES CO;;SIEMENS AG,ARNDT RUSS;;COHEN SUSAN;;HOYER RONALD;;SNAVELY COLLEEN,,https://lens.org/156-184-899-765-462,Granted Patent,no,0,0,9,9,0,H01L21/02;;H01L22/34;;H01L22/34,G01N21/88;;G01N21/93;;G01N21/956;;H01L21/304;;H01L21/306;;H01L21/66;;H01L23/544;;H01L27/10,,0,0,,,,EXPIRED
488,US,A,US 4797318 A,086-611-140-253-230,1989-01-10,1989,US 89252986 A,1986-07-31,US 89252986 A,1986-07-31,"Active particle-containing nonwoven material, method of formation thereof, and uses thereof","Particle-laden meltblown material, methods for forming such material, composite laminate fabrics using such material as a layer of the laminate, and uses of such material and/or laminate thereof are disclosed. The particle-laden meltblown material is a coform of the particles and meltblown fibers, consolidated into a meltblown material. The meltblown fibers are made of polymeric materials such that the fibers are tacky after extrusion from the meltblowing die and prior to consolidation as meltblown material; active particles (such as active carbon) are incorporated in the stream of meltblown fibers, as the fibers pass from the die to the consolidation surface, at a location where the fibers are tacky, so that the particles adhere to the surface of the fibers. The polymeric materials forming the meltblown fibers can be elastomeric materials, and/or blends of polymers. The formed meltblown material can be used as a layer of a laminate, with other layers of the laminate providing abrasion resistance and mechanical strength. The meltblown material, and/or laminate including the meltblown material, can be used for gas/vapor filtering and/or adsorbing, and specifically can be used for disposable vacuum cleaner bags and the like.",KIMBERLY CLARK CO,BROOKER RONALD W;;COHEN BERNARD;;JACKSON DAVID M,KIMBERLY-CLARK CORPORATION (1986-07-31),https://lens.org/086-611-140-253-230,Granted Patent,yes,23,139,6,7,0,B01D39/1623;;B01D2239/0407;;B01D2239/0622;;B01D2239/0636;;B01D2239/065;;B01D2239/0681;;B01D2239/10;;Y10S428/903;;A61F13/53;;A61F13/15658;;A61F2013/15967;;A61F2013/530496;;D04H1/56;;Y10T442/673;;Y10T442/626;;Y10T442/699;;Y10T442/66;;Y10T442/619;;B32B17/04;;Y10T442/673;;Y10T442/626;;Y10T442/699;;Y10T442/66;;Y10T442/619;;B01D39/1623;;B01D2239/0622;;B01D2239/0636;;B01D2239/10;;B01D2239/065;;B01D2239/0681;;B01D2239/0407;;Y10S428/903;;A61F2013/530496;;A61F13/15658;;A61F2013/15967;;A61F13/53;;D04H1/56,B01D39/08;;D04H1/40;;B01D39/16;;D04H1/56;;D04H3/16,428/283;;428/286;;428/288;;428/296;;428/903,0,0,,,,EXPIRED
489,AU,A,AU 1987/076233 A,091-059-222-208-251,1988-02-04,1988,AU 1987/076233 A,1987-07-29,US 89252986 A,1986-07-31,ACTIVE PARTICLE CONTAINING NONWOVEN MATERIAL,,KIMBERLY CLARK CO,JACKSON DAVID M;;COHEN BERNARD;;BROOKER RONALD W,,https://lens.org/091-059-222-208-251,Patent Application,no,0,0,6,7,0,B01D39/1623;;B01D2239/0407;;B01D2239/0622;;B01D2239/0636;;B01D2239/065;;B01D2239/0681;;B01D2239/10;;Y10S428/903;;A61F13/53;;A61F13/15658;;A61F2013/15967;;A61F2013/530496;;D04H1/56;;Y10T442/673;;Y10T442/626;;Y10T442/699;;Y10T442/66;;Y10T442/619;;B32B17/04;;Y10T442/673;;Y10T442/626;;Y10T442/699;;Y10T442/66;;Y10T442/619;;B01D39/1623;;B01D2239/0622;;B01D2239/0636;;B01D2239/10;;B01D2239/065;;B01D2239/0681;;B01D2239/0407;;Y10S428/903;;A61F2013/530496;;A61F13/15658;;A61F2013/15967;;A61F13/53;;D04H1/56,D04H1/40;;B01D39/08;;B01D39/16;;D04H1/56;;D04H3/16,,0,0,,,,DISCONTINUED
490,WO,A1,WO 2023/117822 A1,100-202-754-319-853,2023-06-29,2023,EP 2022086522 W,2022-12-17,US 202163292521 P,2021-12-22,"CALCIUM ARC OF BLOOD VESSEL WITHIN INTRAVASCULAR IMAGE AND ASSOCIATED DEVICES, SYSTEMS, AND METHODS",A system includes a processor circuit in communication with an intraluminal imaging device. The processor circuit is configured to receive an intraluminal image obtained by the intraluminal imaging device while the intraluminal imaging device is positioned within a body lumen of a patient. The processor circuit also receive a user input selecting one location within the intraluminal image and another user input selecting another location within the intraluminal image. These two locations within the intraluminal image define boundaries of a sector of the intraluminal image associated with a tissue type. The processor circuit determines an angle of the sector defined by the two locations. The intraluminal image and a visual representation of the angle are displayed on a screen display.,KONINKLIJKE PHILIPS NV,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN,,https://lens.org/100-202-754-319-853,Patent Application,yes,4,0,2,2,0,A61B5/0066;;A61B5/0084;;A61B8/12;;A61B5/02007;;A61B6/12;;A61B8/0891;;A61B8/4416;;A61B8/5261;;A61B8/468;;A61B8/463;;A61B5/107;;G16H30/40;;G06T7/64;;G06F3/04883;;G06F3/14;;G06T7/0012;;G06T2207/20101;;G06T2207/30101,A61B5/00;;A61B5/02;;A61B8/00;;A61B8/08;;A61B8/12;;G16H40/63,,1,1,055-674-141-785-662,11300468;;10.1016/s0735-1097(01)01175-5,"MINTZ G S ET AL: ""American College of Cardiology clinical expert consensus document on standards for acquisition, measurement and reporting of intravascular ultrasound studies (ivus)"", JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY, ELSEVIER, AMSTERDAM, NL, vol. 37, no. 5, 1 April 2001 (2001-04-01), pages 1478 - 1492, XP027372566, ISSN: 0735-1097, [retrieved on 20010401]",PENDING
491,CA,A,CA 667997 A,151-951-718-237-453,1963-08-06,1963,CA 667997D A,,CA 667997T A,,PLASTICIZING AGENTS FOR NITROCELLULOSE,,US GOV SEC NAVY,COHEN JOSEPH;;HENRY RONALD A;;FINNEGAN WILLIAM G,,https://lens.org/151-951-718-237-453,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
492,US,B2,US 9492303 B2,011-208-851-140-389,2016-11-15,2016,US 201213473531 A,2012-05-16,US 201213473531 A;;US 2010/0057286 W;;US 26250309 P;;US 29700110 P,2009-11-18,Shoulder immobilizer and fracture stabilization device,"A shoulder immobilizer ( 20 ) includes a semi-rigid or rigid orthosis, in the form of an arm support ( 22 ), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster ( 24 ) is positioned between the patient and the arm support ( 22 ). A body strap ( 26 ) extends around the patient and attaches to the arm support ( 22 ) and/or the bolster ( 24 ), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer ( 20 ) may utilize a shoulder strap ( 28 ), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC;;DJO LLC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,DJO LLC (2013-11-13);;CRADLE MEDICAL LLC (2012-12-31),https://lens.org/011-208-851-140-389,Granted Patent,yes,86,1,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/02;;A41D13/00;;A41D13/05;;A41D13/08;;A41D27/26;;A61F5/00;;A61F5/01;;A61F5/04;;A61F5/05;;A61F5/058;;A61F5/37;;A61F7/00;;A61F13/00;;A61F13/06,,11,1,048-100-174-544-746,10.2106/00004623-200105000-00003;;11379734,"Canale, S. Terry and James H. Beaty, Campbell's operative orthopaedics, 11th Edition. Philadelphia, Pennsylvania, Mosby, Inc., 2008. pp. 2694-2695.;;Corflex, Inc. ""Ultra Cubital Tunnel Splint."" [online] , [retrieved on Sep. 25, 2006]. Retrieved from the Internet: .;;International Search Report and Written Opinon mailed Jan. 31, 2011 in Application No. PCT/US10/57286 filed Nov. 18, 2010.;;ltoi et al., ""Position of Immobilization After Dislocation of the Glenohumeral Joint, The Journal of Bone and Joint Surgery"", May 2001, pp. 661-667, vol. 83-A, No. 5.;;Breg, Inc., Product Brochure, Neutral Wedge, date unknown, 2 pages.;;Scott Kober, Upper Extremity-Patients Immobilized in External Rotation Avoid Recurrent Dislocations, Orthopedics Today-Online Newspaper, Mar. 2003, 3 pages.;;Upper Extremity Bracing depicting the Slingshot, Adjustable Sling and Shoulder Abduction Pillow, Breg � Product Catalog 2002, 1 page.;;DonJoy Shoulder Stabilizer Developed with Dr. Tom Sawa, DonJoyTM advertisement, 2 pages (front and back), Feb. 2002.;;Quadrant by DonJoy shoulder brace, Smith & Nephew DonJoy, Inc. catalog, 2 pages, Mar. 1995.;;Humeral Stabilizing System, Smith & Nephew DonJoy, Inc. catalog, 2 pages, Mar. 1992.;;The S.C.O.I. Shoulder Brace, Smith & Nephew DonJoy, Inc. catalog, 1 page, Jun. 1990.",ACTIVE
493,US,A1,US 2023/0190227 A1,019-715-894-224-651,2023-06-22,2023,US 202218075561 A,2022-12-06,US 202218075561 A;;US 202163290483 P,2021-12-16,PLAQUE BURDEN INDICATION ON LONGITUDINAL INTRALUMINAL IMAGE AND X-RAY IMAGE,"A system includes a processor circuit that receives a plurality of intraluminal images obtained by an intraluminal imaging device. The processor circuit determines a plaque burden for each of the plurality of intraluminal images and identifies a region of the body lumen within an image of the body lumen. The processor circuit then outputs to a display the image of the body lumen, a first plaque burden value corresponding to a distal end of the region, and a second plaque burden value corresponding to a proximal end of the region.",PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN,PHILIPS IMAGE GUIDED THERAPY CORPORATION (2022-12-01),https://lens.org/019-715-894-224-651,Patent Application,yes,0,0,2,2,0,G06T7/0012;;G06T2207/10101;;G06T2207/30101;;G06T2207/10132;;G06T7/60;;G06T2200/24;;G06T2207/10116;;G06T2207/10121;;A61B8/4416;;A61B8/12;;A61B6/12;;A61B8/0891;;A61B8/5223;;A61B8/0891;;A61B8/12;;A61B8/5207,A61B8/12;;A61B8/08,,0,0,,,,PENDING
494,CH,A5,CH 600598 A5,176-182-110-979-866,1978-06-30,1978,CH 128776 A,1976-02-02,US 54959875 A;;US 54960075 A;;US 54960175 A,1975-02-12,Power station using pressurised fuel oxidn. cells as energy source,"Power station using pressurised fuel oxidn. cells as energy source has stacks, compressors, conditioners, condenser, boiler, air distribution and electrodes",KORBER HANS,LANDAU MICHAEL BERNARD;;COHEN RONALD;;BLOOMFIELD DAVID PETER,,https://lens.org/176-182-110-979-866,Granted Patent,no,0,2,16,38,0,F02C6/00;;F02C6/10;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;H01M8/0612;;Y02T10/12;;Y02E60/50,F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
495,EP,A4,EP 2501345 A4,042-447-650-302-76X,2017-12-06,2017,EP 10832207 A,2010-11-18,US 26250309 P;;US 29700110 P;;US 2010/0057286 W,2009-11-18,SHOULDER IMMOBILIZER AND FRACTURE STABILIZATION DEVICE,,CRADLE MEDICAL INC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,,https://lens.org/042-447-650-302-76X,Search Report,no,8,0,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/00,,1,0,,,See also references of WO 2011063155A1,DISCONTINUED
496,US,A1,US 2023/0181156 A1,061-892-884-249-986,2023-06-15,2023,US 202218076459 A,2022-12-07,US 202218076459 A;;US 202163288554 P,2021-12-11,AUTOMATIC SEGMENTATION AND TREATMENT PLANNING FOR A VESSEL WITH COREGISTRATION OF PHYSIOLOGY DATA AND EXTRALUMINAL DATA,A system includes a processor circuit that receives physiology measurements obtained by an intraluminal physiology measurement device within a body lumen. The processor circuit automatically segments the body lumen into a plurality of segments based on the physiology measurements. The processor circuit then determines a change in the physiology measurements corresponding to each segment and determines a recommended position for a treatment device within the body lumen based on the change for each segment. The processor circuit provides an output associated with the recommended position on a display.,PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN,PHILIPS IMAGE GUIDED THERAPY CORPORATION (2022-12-01),https://lens.org/061-892-884-249-986,Patent Application,yes,0,0,2,2,0,A61B5/0215;;G16H30/40;;A61B6/5247;;A61B8/5261;;A61B2090/364;;A61B34/25;;A61B34/10;;A61B2034/105;;A61B2034/102;;A61B2034/104;;A61B2034/107;;A61B6/032;;A61B6/4417;;A61B6/4225;;A61B6/504;;A61B6/12;;A61B6/5217;;A61B6/481;;A61B8/12;;A61B8/0891;;G16H20/40;;G16H40/63;;G16H50/20;;A61B2017/00022;;A61B2034/108;;A61B8/0891;;A61B8/12,A61B8/12;;A61B8/08,,0,0,,,,PENDING
497,US,A,US 4176003 A,069-935-492-313-887,1979-11-27,1979,US 87993378 A,1978-02-22,US 87993378 A,1978-02-22,Method for enhancing the adhesion of photoresist to polysilicon,"An adhesion-enhancing technique for preparing the surface of a polycrystalline silicon body to receive organic photoresist. In an exemplary procedure, the polysilicon is placed in an oxygen plasma chamber operating under rf power of about 90 milliwatts per cubic centimeter of chamber volume and a pressure of approximately 1 torr for 10 minutes to form an adhesion-enhancing oxide monolayer on the polysilicon.",NCR CO,BROWER RONALD W;;CHEN PETER C;;COHEN JEROME,HYUNDAI ELECTRONICS AMERICA (1995-02-15);;SYMBIOS INC (1995-08-18),https://lens.org/069-935-492-313-887,Granted Patent,yes,5,54,1,1,0,H01L21/32105;;Y10S148/053;;Y10S148/143;;Y10S438/948;;H01L21/02118;;H01L21/312;;H01L21/32105,H01L21/312;;H01L21/321,H1K KJAX          JAX,1,0,,,"Ligenza, J. R., ""Silicon . . . Microwaves"" Journal of Applied Sciences, vol. 36, No. 9 (Sep. 65), pp. 2703-2707.",EXPIRED
498,US,A1,US 2013/0131568 A1,008-138-346-718-902,2013-05-23,2013,US 201213473531 A,2012-05-16,US 201213473531 A;;US 2010/0057286 W;;US 26250309 P;;US 29700110 P,2009-11-18,SHOULDER IMMOBILIZER AND FRACTURE STABILIZATION DEVICE,"A shoulder immobilizer ( 20 ) includes a semi-rigid or rigid orthosis, in the form of an arm support ( 22 ), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster ( 24 ) is positioned between the patient and the arm support ( 22 ). A body strap ( 26 ) extends around the patient and attaches to the arm support ( 22 ) and/or the bolster ( 24 ), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer ( 20 ) may utilize a shoulder strap ( 28 ), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC;;CRADLE MEDICAL INC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,DJO LLC (2013-11-13);;CRADLE MEDICAL LLC (2012-12-31),https://lens.org/008-138-346-718-902,Patent Application,yes,3,5,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/01,602/20,0,0,,,,ACTIVE
499,US,B1,US 6829764 B1,100-315-049-305-529,2004-12-07,2004,US 88061697 A,1997-06-23,US 88061697 A,1997-06-23,System and method for maximizing usage of computer resources in scheduling of application tasks,"
    A task schedule is enforced among multiple processes by setting process priorities based upon which tasks are running on which processes and based upon the task schedule. The task scheduling may be provided by a local or global scheduler which uses application information to prioritize tasks. The task schedule, or priority list, is provided at Local Activity Schedulers which schedule the activities for their local execution elements/nodes. Execution of activities locally are performed by any number of processes that reside in each execution element. These processes are assigned operating system priorities by the respective Local Activity Scheduler based on their assigned activities for execution and the task schedule. 
",IBM,COHEN MITCHELL ADAM;;JHINGRAN ANANT DEEP;;MRAZ RONALD,STANLEY AVIATION CORPORATION (1995-11-21);;IBM CORPORATION (1997-06-20),https://lens.org/100-315-049-305-529,Granted Patent,yes,14,56,2,2,0,G06F9/4881;;G06F9/5066;;G06F9/4881;;G06F9/5066,G06F9/00;;G06F9/46;;G06F9/48;;G06F9/50,718/103;;718/107,3,0,,,"IBM TDB, ""Service Management"", Dec. 1973, pp. 2330-2338.*;;Custer, ""Inside WIndows NT"", Microsoft Press, Chapter 4 pp. 83-97, Dec. 1993.*;;Ripps, ""The Multitasking Mindset Meets the Operating System,"" EDN, v35, n20, p115(9), pp. 1-13, Oct. 1990.",EXPIRED
500,US,B2,US 10918513 B2,198-393-081-232-808,2021-02-16,2021,US 201615340735 A,2016-11-01,US 201615340735 A;;US 201213473531 A;;US 2010/0057286 W;;US 29700110 P;;US 26250309 P,2009-11-18,Shoulder immobilizer and fracture stabilization device,"A shoulder immobilizer ( 20 ) includes a semi-rigid or rigid orthosis, in the form of an arm support ( 22 ), which supports the upper arm, elbow, forearm and wrist of a patient. A bolster ( 24 ) is positioned between the patient and the arm support ( 22 ). A body strap ( 26 ) extends around the patient and attaches to the arm support ( 22 ) and/or the bolster ( 24 ), holding the arm support and bolster in position against the body of the patient. In embodiments, the shoulder immobilizer ( 20 ) may utilize a shoulder strap ( 28 ), but such a shoulder strap is not necessary for shoulder immobilization of the patient.",DJO LLC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,DJO LLC (2017-01-26),https://lens.org/198-393-081-232-808,Granted Patent,yes,96,4,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/37;;A41D13/00;;A41D13/05;;A41D13/08;;A61F5/00;;A61F5/01;;A61F5/04;;A61F5/05;;A61F5/058;;A61F5/32;;A61F7/00;;A61F7/02,,13,1,048-100-174-544-746,10.2106/00004623-200105000-00003;;11379734,"WO-03071994-A2 machine translation (Year: 2003).;;“Upper Extremity Bracing depicting the Slingshot, Adjustable Sling and Shoulder Abduction Pillow,” Breg (c) Product Catalog 2002, 1 page.;;DonJoy Shoulder Stabilizer Developed with Dr. Tom Sawa, DonJoyTMadvertisement, Feb. 2002, 2 pages.;;“Quadrant by DonJoy shoulder brace,” Smith & Nephew Don.Toy, Inc. catalog, Mar. 1995, 2 pages.;;“Humeral Stabilizing System,” Smith & Nephew DonJoy, Inc. catalog, Mar. 1992, 2 pages.;;“Donjoy Brings its Technology to the Shoulder. The S.C.O.I. Shoulder Brace,” Smith & Nephew DonJoy, Inc. catalog, Jun. 1990, 1 page.;;Toi et al., “Position of Immobilization After Dislocation of the Glenohumeral Joint, The Journal of Bone and Joint Surgery”, May 2001, vol. 83-A, No. 5, pp. 661-667.;;Breg, Inc., Product Brochure, Neutral Wedge, date unknown, 2 pages.;;Scott Kober, “Upper Extremity—Patients Immobilized in External Rotation Avoid Recurrent Dislocations,” Orthopedics Today—Online Newspaper, Mar. 2003, 3 pages.;;Canale et al., Campbell's operative orthopaedics, 11th Edition. Philadelphia, Pennsylvania, Mosby, Inc., 2008. pp. 2694-2695.;;Corflex, Inc. “Ultra Cubital Tunnel Splint.” [online] , [retrieved on Sep. 25, 2006]. Retrieved from the Internet: <URL: http://www.corflex.com/>.;;International Search Report and Written Opinion dated Jan. 31, 2011 in Application No. PCT/US10/57286 filed Nov. 18, 2010.;;Extended European Search Report dated Nov. 7, 2017 for EP Application No. 10832207.4.",ACTIVE
501,GB,A,GB 2194255 A,171-550-970-994-622,1988-03-02,1988,GB 8718148 A,1987-07-31,US 89252986 A,1986-07-31,"ACTIVE PARTICLE-CONTAINING NONWOVEN MATERIAL, METHOD OF FORMATION THEREOF, AND USES THEREOF",,KIMBERLY CLARK CO,JACKSON DAVID M;;COHEN BERNARD;;BROOKER RONALD W,,https://lens.org/171-550-970-994-622,Patent Application,no,7,18,6,7,0,B01D39/1623;;B01D2239/0407;;B01D2239/0622;;B01D2239/0636;;B01D2239/065;;B01D2239/0681;;B01D2239/10;;Y10S428/903;;A61F13/53;;A61F13/15658;;A61F2013/15967;;A61F2013/530496;;D04H1/56;;Y10T442/673;;Y10T442/626;;Y10T442/699;;Y10T442/66;;Y10T442/619;;B32B17/04;;Y10T442/673;;Y10T442/626;;Y10T442/699;;Y10T442/66;;Y10T442/619;;B01D39/1623;;B01D2239/0622;;B01D2239/0636;;B01D2239/10;;B01D2239/065;;B01D2239/0681;;B01D2239/0407;;Y10S428/903;;A61F2013/530496;;A61F13/15658;;A61F2013/15967;;A61F13/53;;D04H1/56,D04H1/40;;B01D39/08;;B01D39/16;;D04H1/56;;D04H3/16,D1R RBF           RBF;;D1R R105          RBF;;D1R R151          RBF;;D1R R306          RBF;;D1R R310          RBF;;D1R R311          RBF;;D1R R319          RBF;;D1R R461          RBF;;D1R R519          RBF;;D1R R562          RBF;;D1R R601          RBF;;D1R R602          RBF;;D1R R603          RBF;;D1R R604          RBF;;U1S S1133,0,0,,,,DISCONTINUED
502,EP,A1,EP 2501345 A1,189-223-595-641-109,2012-09-26,2012,EP 10832207 A,2010-11-18,US 26250309 P;;US 29700110 P;;US 2010/0057286 W,2009-11-18,SHOULDER IMMOBILIZER AND FRACTURE STABILIZATION DEVICE,,CRADLE MEDICAL INC,GOLDEN STEVE;;COHEN NATHANIEL;;JOSEPH RONALD;;SAFRAN MARC,,https://lens.org/189-223-595-641-109,Patent Application,yes,0,0,9,9,0,A61F5/3738;;A61F5/3738;;A41D13/00;;A41D13/05;;A41D13/0512;;A41D13/08;;A61F5/00;;A61F5/00;;A61F5/01;;A61F5/01;;A61F5/0118;;A61F5/0118;;A61F5/013;;A61F5/013;;A61F5/04;;A61F5/04;;A61F5/05;;A61F5/05;;A61F5/05841;;A61F5/05841;;A61F5/05858;;A61F5/05858;;A61F5/32;;A61F5/32;;A61F5/37;;A61F5/37;;A61F5/3715;;A61F5/3715;;A61F5/373;;A61F5/373;;A61F5/3746;;A61F5/3746;;A61F5/3753;;A61F5/3753;;A61F7/00;;A61F7/02;;A61F2007/003;;A61F2007/0231,A61F5/00,,0,0,,,,DISCONTINUED
503,WO,A1,WO 2023/110556 A1,181-507-280-315-716,2023-06-22,2023,EP 2022084691 W,2022-12-07,US 202163290483 P,2021-12-16,PLAQUE BURDEN INDICATION ON LONGITUDINAL INTRALUMINAL IMAGE AND X-RAY IMAGE,"A system includes a processor circuit that receives a plurality of intraluminal images obtained by an intraluminal imaging device. The processor circuit determines a plaque burden for each of the plurality of intraluminal images and identifies a region of the body lumen within an image of the body lumen. The processor circuit then outputs to a display the image of the body lumen, a first plaque burden value corresponding to a distal end of the region, and a second plaque burden value corresponding to a proximal end of the region.",KONINKLIJKE PHILIPS NV;;PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN,,https://lens.org/181-507-280-315-716,Patent Application,yes,24,0,2,2,0,G06T7/0012;;G06T2207/10101;;G06T2207/30101;;G06T2207/10132;;G06T7/60;;G06T2200/24;;G06T2207/10116;;G06T2207/10121;;A61B8/4416;;A61B8/12;;A61B6/12;;A61B8/0891;;A61B8/5223;;A61B8/0891;;A61B8/12;;A61B8/5207,G06T7/00;;A61B8/00;;G06T7/60,,0,0,,,,PENDING
504,US,A,US 4087284 A,186-705-794-840-840,1978-05-02,1978,US 69316076 A,1976-06-07,US 69316076 A,1976-06-07,Color-developer coating for use in copy systems,"A process for preparing color-developer coatings in which an oily solution of an acidic, organic material is emulsified in water and an insoluble, particulate, oil-adsorbent material is dispersed in the emulsion. The resulting emulsion-dispersion may be coated onto a receptor such as a paper substrate or other receiving surface and dried. The product resulting from the process is an enhanced color-developer coating for use in pressure-sensitive copy systems.",CHAMPION INT CORP,GOLDEN RONALD;;COHEN ALLAN H;;EBY DAVID G,,https://lens.org/186-705-794-840-840,Granted Patent,yes,3,17,1,1,0,B41M5/155;;B41M5/155;;Y10S428/914,B41M5/155,106/21,0,0,,,,EXPIRED
505,TW,B,TW 406242 B,127-062-467-885-535,2000-09-21,2000,TW 87103448 A,1998-03-10,US 88061697 A,1997-06-23,System and method for maximizing usage of computer resources in scheduling of application tasks,"A task schedule is enforced among multiple processes by setting process priorities based upon which tasks are running on which processes and based upon the task schedule. The task scheduling may be provided by a local or global scheduler which uses application information to prioritize tasks. The task schedule, or priority list, is provided at Local Activity Schedulers which schedule the activities for their local execution element/nodes. Execution of activities locally are performed by any number of processes that reside in each execution element. These processes are assigned operating system priorities by the respective Local Activity Scheduler based on their assigned activities for execution and the task schedule.",IBM,COHEN MITCHELL ADAM;;JHINGRAN ANANT DEEP;;MRAZ RONALD,,https://lens.org/127-062-467-885-535,Granted Patent,no,0,1,2,2,0,G06F9/4881;;G06F9/5066;;G06F9/4881;;G06F9/5066,G06F9/00;;G06F9/46;;G06F9/48;;G06F9/50,,0,0,,,,EXPIRED
506,EP,A3,EP 0887852 A3,058-974-586-601-401,1999-07-14,1999,EP 98305008 A,1998-06-25,US 88205697 A,1997-06-25,Improved silica stain test structures and methods therefor,"A method for forming silica stain on a substrate to facilitate monitoring of the silica stain during integrated circuit manufacture. The method includes providing a silica stain test structure which has a silicon substrate, a hydrophilic silicon dioxide containing layer disposed above the silicon substrate, and a plurality of cavities formed in the silicon dioxide containing layer. The cavities have hydrophobic sidewalls. The method also includes exposing the silica stain test structure to deionized water, and drying the silica stain test structure to form the silica stain on the silicon dioxide containing layer.",SIEMENS AG;;IBM,ARNDT RUSS;;HOYER RONALD;;COHEN SUSAN;;SNAVELY COLLEEN,INFINEON TECHNOLOGIES AG (2003-06-11);;INTERNATIONAL BUSINESS MACHINESCORPORATION (2003-06-11),https://lens.org/058-974-586-601-401,Search Report,yes,0,0,9,9,0,H01L21/02;;H01L22/34;;H01L22/34,G01N21/88;;G01N21/93;;G01N21/956;;H01L21/304;;H01L21/306;;H01L21/66;;H01L23/544;;H01L27/10,,2,0,,,"PATENT ABSTRACTS OF JAPAN vol. 018, no. 372 (E - 1577) 13 July 1994 (1994-07-13);;""Improvements to Surface Characteristics of SiIicon Wafers"", IBM TECHNICAL DISCLOSURE BULLETIN., vol. 26, no. 12, May 1984 (1984-05-01), NEW YORK US, pages 6456 - 6457, XP002102754",DISCONTINUED
507,GB,A,GB 2175150 A,194-640-828-027-766,1986-11-19,1986,GB 8604891 A,1986-02-27,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,Coaxial electrical connector for an electrical cable,"An electrical connector 1 for twin axial cable 100 comprises; a first assembly 4 comprised of a conductive outer shell 6, a first dielectric body 8, a conductive inner shell 10, and a second dielectric body 12; and a second assembly (fig. 3) 60 for insertion in the first assembly and for electrical connection with the inner shell 10, comprises a first conductive body 62, a conductive ferrule 64 on the first conductive body 62 for connection with a corresponding electrical conductor 104, a third dielectric body 66, an electrical contact 70 for connection with a corresponding electrical conductor 102 of a twin axial cable 100, and a second conductive body 72 for establishing electrical connection of a conductive sheath 106 of a twin axial cable 100 and a barrier 108 in the outer shell 6 for limiting displacement of the conductive sheath 106 along the outer shell 6. The second assembly is connected to a cable before insertion into the first assembly. <IMAGE>",AMP INC,COHEN THOMAS SHACKNEY;;LAUDIG RONALD CLAIR;;SMITH DONALD LEE,,https://lens.org/194-640-828-027-766,Patent Application,no,0,7,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,H2E ECBB          ECBB,0,0,,,,EXPIRED
508,US,A1,US 2007/0260463 A1,027-246-945-114-796,2007-11-08,2007,US 59514506 A,2006-11-09,US 59514506 A;;US 83938801 A,2001-04-20,Method and apparatus to provision a network appliance,A method and apparatus to provision a network node such as a network appliance is described.,INTEL CORP,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,,https://lens.org/027-246-945-114-796,Patent Application,yes,1,0,4,4,0,H04L41/00;;H04L41/00,H04L12/24;;G10L11/00,704/275,0,0,,,,EXPIRED
509,US,B2,US 7181400 B2,048-569-798-088-249,2007-02-20,2007,US 83938801 A,2001-04-20,US 83938801 A,2001-04-20,Method and apparatus to provision a network appliance,A method and apparatus to provision a network node such as a network appliance is described.,INTEL CORP,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-05-11),https://lens.org/048-569-798-088-249,Granted Patent,yes,5,5,4,4,0,H04L41/00;;H04L41/00,G10L11/00;;H04L12/24,704/275;;381/110;;367/198,0,0,,,,INACTIVE
510,US,A,US 3565978 A,061-315-853-598-796,1971-02-23,1971,US 3565978D A,1967-09-11,US 66661767 A,1967-09-11,REPLICATION OF SURFACE DEFORMATION IMAGES,,XEROX CORP,FOLGER WILLIAM F;;COHEN RONALD H;;URBACH JOHN C,,https://lens.org/061-315-853-598-796,Granted Patent,no,0,88,7,7,0,B41C3/00;;B41C3/08;;G03G5/022;;G03H1/02;;G03H1/0244;;G03H1/0486;;G03H1/18;;G03H1/182;;G03H2001/0284;;G03H2001/0288;;G03H2001/0296;;G03H2260/53;;B41C3/08;;G03H1/182;;B41C3/00;;G03H1/18;;G03G5/022;;G03H1/02;;G03H2001/0288;;G03H1/0244;;G03H2001/0296;;G03H1/0486;;G03H2001/0284;;G03H2260/53,B41C3/00;;B41C3/08;;G03G5/022;;G03H1/02;;G03H1/18,264/1,0,0,,,,EXPIRED
511,DK,A,DK 201370153 A,165-609-706-268-230,2013-09-16,2013,DK PA201370153 A,2013-03-14,US 201213421452 A,2012-03-15,SYSTEM AND METHOD FOR DETECTING IMPROPER WIRING OR CONFIGURATION IN A MONITORING SYSTEM,"A system and method for detecting improper wiring or configuration in a monitoring system. The improper wiring or configuration is detected by measuring the value of an electric al property (e.g., voltage or current) of an electric al signal received from a first set of wiring terminals to which a transducer is connected and comparing that value to a predetermined value or range of values of the electrical property based on values that would be expected for the electrical signal if the transducer was the type configured to be monitored by the monitoring unit.",GEN ELECTRIC,DEAN COHEN MITCHELL;;ALAN TART MICHAEL;;RONALD NIKKELS ROBERT,,https://lens.org/165-609-706-268-230,Unknown,no,0,0,5,5,0,G01R31/2829;;G01R31/2829,G01R31/00,,0,0,,,,DISCONTINUED
512,WO,A1,WO 2005/087929 A1,172-308-826-852-049,2005-09-22,2005,AU 2005/000355 W,2005-03-15,AU 2004/901359 A;;US 61268804 P,2004-03-15,INFECTIOUS AETIOLOGY OF PROSTATIC DISEASE AND METHODS TO IDENTIFY CAUSATIVE AGENTS,"The present invention relates to a method of diagnosing, or predicting risk of, prostate disease in a subject. More particularly, the invention relates to a method of diagnosing the presence of, or the predisposition to develop, prostate disease in a subject, the method comprising analysing a test sample from the subject for the presence of P. acnes infection of the prostate gland. The present invention further relates to reagents for use in this method and to methods of prevention or treatment of prostate disease.",TISSUGEN PTY LTD;;COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLEY ANNE,COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLEY ANNE,,https://lens.org/172-308-826-852-049,Patent Application,yes,1,3,5,7,0,C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/136;;C12Q2600/156;;A61P13/08;;A61P31/04;;C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/156;;C12Q2600/136,C07K14/195;;C12N15/31;;C12Q1/68,,4,0,,,"DATABASE GENBANK [online] XP008092884, Database accession no. (AE017283);;DATABASE MEDLINE [online] XP008093103, Database accession no. (9920982);;DATABASE MEDLINE [online] XP008093131, Database accession no. (15125499);;See also references of EP 1725662A4",PENDING
513,US,S,US D0624971 S,029-825-393-039-431,2010-10-05,2010,US 34867910 F,2010-01-28,US 34867910 F,2010-01-28,Toy rocket ship convertible into a table and chair set,,KIDS ONLY INC,COHEN RONALD B;;PAGANO ROBERT J;;WECKSTEIN LAWRENCE ALAN,KID'S ONLY INC (2010-01-27),https://lens.org/029-825-393-039-431,Design Right,no,0,13,1,1,0,,,2101;;D21/452;;D6/337,0,0,,,,ACTIVE
514,AU,B2,AU 2005/221729 B2,032-994-672-681-991,2009-09-24,2009,AU 2005/221729 A,2005-03-15,US 61268804 P;;AU 2004/901359 A;;AU 2005/000355 W;;AU 2005/221729 A,2004-03-15,Infectious aetiology of prostatic disease and methods to identify causative agents,,TISSUGEN PTY LTD,COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLEY ANNE,,https://lens.org/032-994-672-681-991,Granted Patent,no,1,0,2,7,0,,C12N15/31;;C07K14/195;;C12Q1/68,,7,3,018-163-556-262-066;;022-573-589-162-682;;002-323-390-714-147,10.1002/path.1243;;12434425;;15286373;;10.1126/science.1100330;;10.1111/j.1365-4632.2004.01887.x;;15125499,"Yamada, T. et al., J. PATHOL., 2002, vol. 198, no. 4, pages 541-547;;Bruggemann, H. et al., SCIENCE, 2004, vol. 305, no. 5684, pages 671 - 673;;DATABASE GENBANK [Online] XP008092884 Database accession no. AE017283;;Kurokawa, I. et al EURO J. DERMATOL., 1999, vol. 9, no. 1, pages 25 - 28 and;;DATABASE MEDLINE [Online] XP008093103 Database accession no. 9920982;;Higaki, S. et al., INT. J. DERMATOL., 2004, vol. 43, no. 2, pages 103 - 107 and;;DATABASE MEDLINE [Online] XP008093131 Database accession no. 15125499",INACTIVE
515,US,A1,US 2002/0156636 A1,047-990-713-278-856,2002-10-24,2002,US 83938801 A,2001-04-20,US 83938801 A,2001-04-20,Method and apparatus to provision a network appliance,"
   A method and apparatus to provision a network node such as a network appliance is described. 
",COHEN PAUL M.;;MEREDITH CHRISTOPHER A.;;CHILD RONALD J.,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-05-11),https://lens.org/047-990-713-278-856,Patent Application,yes,5,1,4,4,0,H04L41/00;;H04L41/00,H04L12/24,704/275,0,0,,,,EXPIRED
516,JP,A,JP H08213461 A,077-875-591-293-875,1996-08-20,1996,JP 30098895 A,1995-11-20,US 34509994 A,1994-11-28,INSULATING MATERIAL FOR INTEGRATED CIRCUIT AND ITS MANUFACTURE,"PROBLEM TO BE SOLVED: To obtain insulator having low permitivity and gap filling capability, by annealing a curing flowable oxide layer in an atmosphere of hydrogen and aluminum, diffusing hydrogen in the flowable oxide layer, and specifying the permittivity. SOLUTION: This insulator is used for covering interconnection wiring level 3 in the semiconductor substrate surface containing a semiconductor device, provided with a first flowable oxide layer 1 for covering the interconnection wiring level 3, and cures the oxide layer 1. The flowable oxide layer 1 is annealed in an atmosphere of hydrogen and aluminum. Hydrogen is diffused in the flowable oxide layer 1, and its permitivity is reduced to be less than 3.2. As the flowable oxide layer 1, cured hydrogensilsesquioxane is contained. Thereby special insulator having comparatively low permitivity less than 3.2 and excellent gap filling capability can be obtained.",IBM,COHEN STEPHEN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT,,https://lens.org/077-875-591-293-875,Patent Application,no,0,3,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,,0,0,,,,EXPIRED
517,EP,A2,EP 0715354 A2,117-587-829-228-049,1996-06-05,1996,EP 95117118 A,1995-10-31,US 34509994 A,1994-11-28,Insulator for integrated circuits and process,"An insulator for covering an interconnection wiring level in a surface thereof on a semiconductor substrate containing semiconductor devices formed by curing a flowable oxide layer and annealing. The annealing is carried out in the presence of hydrogen and aluminum to obtain a dielectric constant of the oxide layer to a value below 3.2. Also provided is electrical insulation between neighboring devices using the flowable oxide which is cured and annealed. In this case, the annealing can be carried out in hydrogen with or without the presence of aluminum.",IBM,COHEN STEPHAN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT,,https://lens.org/117-587-829-228-049,Patent Application,yes,1,4,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,,0,0,,,,DISCONTINUED
518,GB,B,GB 2175150 B,171-654-615-030-593,1988-06-08,1988,GB 8604891 A,1986-02-27,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,COAXIAL ELECTRICAL CONNECTOR FOR AN ELECTRICAL CABLE,,AMP INC,COHEN THOMAS SHACKNEY;;LAUDIG RONALD CLAIR;;SMITH DONALD LEE,,https://lens.org/171-654-615-030-593,Granted Patent,no,0,0,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,H2ECBB,0,0,,,,EXPIRED
519,EP,A1,EP 1725662 A1,163-137-478-566-037,2006-11-29,2006,EP 05714228 A,2005-03-15,AU 2005/000355 W;;AU 2004/901359 A;;US 61268804 P,2004-03-15,INFECTIOUS AETIOLOGY OF PROSTATIC DISEASE AND METHODS TO IDENTIFY CAUSATIVE AGENTS,,TISSUGEN PTY LTD,COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLEY ANNE,,https://lens.org/163-137-478-566-037,Patent Application,yes,0,0,5,7,52,C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/136;;C12Q2600/156;;A61P13/08;;A61P31/04;;C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/156;;C12Q2600/136,C12N15/31;;C07K14/195;;C12Q1/68;;G01N33/50,,0,0,,,,PENDING
520,EP,A4,EP 1725662 A4,014-937-841-357-970,2008-03-05,2008,EP 05714228 A,2005-03-15,AU 2005/000355 W;;AU 2004/901359 A;;US 61268804 P,2004-03-15,INFECTIOUS AETIOLOGY OF PROSTATIC DISEASE AND METHODS TO IDENTIFY CAUSATIVE AGENTS,,TISSUGEN PTY LTD,COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLEY ANNE,,https://lens.org/014-937-841-357-970,Search Report,no,0,0,5,7,0,C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/136;;C12Q2600/156;;A61P13/08;;A61P31/04;;C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/156;;C12Q2600/136,C12N15/31;;C07K14/195;;C12Q1/68;;G01N33/50,,16,2,019-093-662-175-236;;077-788-756-659-033,12637783;;10.1159/000069030;;10.1097/01.ju.0000158161.15277.78;;15879794,"DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 45 from Patent WO0181581."", XP002462325, retrieved from EBI accession no. EMBL:CQ363762 Database accession no. CQ363762;;DATABASE Geneseq [online] 17 October 2003 (2003-10-17), ""Propionibacterium acnes DNA contig sequence #45."", XP002462326, retrieved from EBI accession no. GSN:ACF64479 Database accession no. ACF64479;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 24 from Patent WO0181581."", XP002462327, retrieved from EBI accession no. EMBL:CQ363741 Database accession no. CQ363741;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 43 from Patent WO0181581."", XP002462328, retrieved from EBI accession no. EMBL:CQ363760 Database accession no. CQ363760;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 151 from Patent WO0181581."", XP002462329, retrieved from EBI accession no. EMBL:CQ363868 Database accession no. CQ363868;;DATABASE Geneseq [online] 13 February 2002 (2002-02-13), ""Propionibacterium acnes immunogenic protein encoding DNA #151."", XP002462330, retrieved from EBI accession no. GSN:AAS59656 Database accession no. AAS59656;;DATABASE Geneseq [online] 17 October 2003 (2003-10-17), ""Propionibacterium acnes DNA contig sequence #43."", XP002462331, retrieved from EBI accession no. GSN:ACF64477 Database accession no. ACF64477;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 46 from Patent WO0181581."", XP002462332, retrieved from EBI accession no. EMBL:CQ363763 Database accession no. CQ363763;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 33 from Patent WO0181581."", XP002462333, retrieved from EBI accession no. EMBL:CQ363750 Database accession no. CQ363750;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 123 from Patent WO0181581."", XP002462334, retrieved from EBI accession no. EMBL:CQ363840 Database accession no. CQ363840;;DATABASE EMBL [online] 30 January 2004 (2004-01-30), ""Sequence 8293 from Patent WO0192523."", XP002462335, retrieved from EBI accession no. EMBL:CQ442533 Database accession no. CQ442533;;DATABASE EMBL [online] 23 January 2004 (2004-01-23), ""Sequence 238 from Patent WO0181581."", XP002462336, retrieved from EBI accession no. EMBL:CQ363955 Database accession no. CQ363955;;DATABASE Geneseq [online] 8 July 2002 (2002-07-08), ""Human ORF49 cDNA, SEQ ID NO:97."", XP002462337, retrieved from EBI accession no. GSN:ABN75102 Database accession no. ABN75102;;NAM C ET AL: ""Anti-acne effects of Oriental herb extracts: A novel screening method to select anti-acne agents"", BIOSIS, March 2003 (2003-03-01), XP002435514;;COHEN ET AL: ""PROPIONIBACTERIUM ACNES ASSOCIATED WITH INFLAMMATION IN RADICAL PROSTATECTOMY SPECIMENS: A POSSIBLE LINK TO CANCER EVOLUTION?"", JOURNAL OF UROLOGY, BALTIMORE, MD, US, vol. 173, no. 6, June 2005 (2005-06-01), pages 1969 - 1974, XP005530125, ISSN: 0022-5347;;See also references of WO 2005087929A1",PENDING
521,CH,A5,CH 691847 A5,044-415-045-808-558,2001-11-15,2001,CH 251297 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Utilisation de raloxifène dans la prophylaxie du cancer du sein.,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH,,https://lens.org/044-415-045-808-558,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
522,CH,A5,CH 693820 A5,101-028-193-114-721,2004-02-27,2004,CH 251197 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Utilisation de raloxifen pour la prévention du cancer du sein.,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH,ELI LILLY & COMPANY (2007-10-30),https://lens.org/101-028-193-114-721,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
523,US,B2,US 6512682 B2,102-497-687-490-450,2003-01-28,2003,US 82373001 A,2001-03-29,US 82373001 A,2001-03-29,Power supply with interface to determine power requirements of devices coupled thereto,"
    Intelligent power supplies to provide power to electronic devices in a manner the avoids causing a power supply circuit fuse to blow or breaker to trip are disclosed. The power supply circuit includes a power supply control device that determines whether supplying power to an additional electronic device would exceed the capacity of the circuit and cause the fuse to blow or the breaker to trip. The power supply control device communicates with electronic devices via a power control interface to determine the power requirements of the electronic devices. Power is supplied to the devices that can be supplied without causing the fuse to blow or the breaker to trip. Power is not supplied to the devices that would cause the fuse to blow or the breaker to trip. 
",INTEL CORP,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-05-11),https://lens.org/102-497-687-490-450,Granted Patent,yes,4,81,2,2,0,H02H11/00;;H02J3/14;;Y02B70/3225;;Y04S20/222;;H02J2310/52;;H02J3/14;;H02H11/00;;Y02B70/3225;;Y04S20/222,H02H11/00;;H02J3/14,363/146,0,0,,,,EXPIRED
524,WO,A1,WO 2016/022694 A1,157-904-984-267-635,2016-02-11,2016,US 2015/0043821 W,2015-08-05,US 201462033526 P,2014-08-05,"MODULATION OF LAMININ ALPHA-4 IN THE PREVENTION, TREATMENT, AND MANAGEMENT OF METABOLIC SYNDROMES","The disclosure provides methods of preventing or treating metabolic syndrome in a subject by administering an effective amount of an inhibitor of laminin α4 expression, laminin α4 activity, or both.",UNIV CHICAGO;;ILLINOIS TECHNOLOGY INST,VAICIK MARCELLA K;;COHEN RONALD N;;BREY ERIC M,,https://lens.org/157-904-984-267-635,Patent Application,yes,1,0,2,2,4,C07K16/18;;A61K2039/505;;A61K38/39;;C07K16/18;;A61K2039/505;;A61K38/39;;C07K2317/76,C07K16/18;;A61K39/395;;C12P21/08,,2,2,027-543-923-656-835;;048-672-850-386-16X,pmc3587258;;23388637;;10.1073/pnas.1215236110;;18067585;;10.1111/j.1440-169x.2007.00979.x,"QIAN, SW ET AL.: ""BMP4-mediated brown fat-like changes in white adipose tissue alter glucose and energy homeostasis."", PUBLICATIONS OF THE NATIONAL ACADEMY OF SCIENCES., vol. 110, no. 9, 6 February 2013 (2013-02-06), pages E798 - E807;;YAMASHITA, H.: ""Blackwell Publishing Asia Cryptic fragment a4 LG4-5 derived from laminin a4 chain inhibits de novo adipogenesis by modulating the effect of fibroblast growth factor-2;"", DEVELOPMENT GROWTH AND REGENERATION, vol. 50, no. 2, March 2008 (2008-03-01), pages 97 - 107",PENDING
525,AU,A1,AU 2005/221729 A1,056-101-690-166-336,2005-09-22,2005,AU 2005/221729 A,2005-03-15,US 61268804 P;;AU 2004/901359 A;;AU 2005/000355 W;;AU 2005/221729 A,2004-03-15,Infectious aetiology of prostatic disease and methods to identify causative agents,,TISSUGEN PTY LTD,COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLEY ANNE,,https://lens.org/056-101-690-166-336,Patent Application,no,0,0,2,7,0,,C12N15/31,,0,0,,,,INACTIVE
526,IT,A0,IT 8619856 A0,070-850-201-766-02X,1986-03-25,1986,IT 1985686 A,1986-03-25,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,CONNETTORE ELETTRICO PER UN CAVO ELETTRICO.,,AMP INC,COHEN THOMAS SHCKNEY;;LAUDIG RONALD CLAIR;;SMITH DONALD LEE,,https://lens.org/070-850-201-766-02X,Patent Application,no,0,0,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,,0,0,,,,EXPIRED
527,CA,A1,CA 2162189 A1,079-310-350-571-824,1996-05-29,1996,CA 2162189 A,1995-11-06,US 34509994 A,1994-11-28,INSULATOR FOR INTEGRATED CIRCUITS AND PROCESS INSULATOR FOR INTEGRATED CIRCUITS AND PROCESS,"An insulator for covering an interconnection wiring level in a surface thereof on a semiconductor substrate containing semiconductor devices formed by curing a flowable oxide layer and annealing. The annealing is carried out in the presence of hydrogen and aluminum to obtain a dielectric constant of the oxide layer to a value below 3.2. Also provided is electrical insulation between neighboring devices using the flowable oxide which is cured and annealed. In this case, the annealing can be carried out in hydrogen with or without the presence of aluminum.",IBM,COHEN STEPHAN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT,,https://lens.org/079-310-350-571-824,Patent Application,no,0,0,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,,0,0,,,,EXPIRED
528,JP,A,JP 2013195425 A,177-897-632-038-700,2013-09-30,2013,JP 2013050201 A,2013-03-13,US 201213421452 A,2012-03-15,SYSTEM AND METHOD FOR DETECTING IMPROPER WIRING OR CONFIGURATION IN MONITORING SYSTEM,"PROBLEM TO BE SOLVED: To provide a system and a method for detecting improper wiring or configuration in a monitoring system.SOLUTION: The improper wiring or configuration is detected by: measuring the value of an electrical property (e.g., voltage or current) of an electrical signal received from a first set of wiring terminals 211 to which a transducer 161 is connected; and comparing that value to a predetermined value or range of values of the electrical property based on values that would be expected if the transducer 161 was the type configured to be monitored by the monitoring unit 110.",GEN ELECTRIC,MITCHELL DEAN COHEN;;TART MICHAEL ALAN;;ROBERT RONALD NIKKELS,,https://lens.org/177-897-632-038-700,Patent Application,no,0,0,5,5,0,G01R31/2829;;G01R31/2829,G01R31/02,,0,0,,,,PENDING
529,DE,A1,DE 3610092 A1,037-823-796-039-285,1986-10-30,1986,DE 3610092 A,1986-03-25,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,ELEKTRISCHER VERBINDER FUER EIN ELEKTRISCHES KABEL,,AMP INC,COHEN THOMAS SHACKNEY;;LAUDIG RONALD CLAIR;;SMITH DONALD LEE,,https://lens.org/037-823-796-039-285,Patent Application,no,2,4,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,,0,0,,,,DISCONTINUED
530,US,A1,US 2008/0255252 A1,109-554-172-686-502,2008-10-16,2008,US 59257905 A,2005-03-15,US 59257905 A;;AU 2004/901359 A;;US 61268804 P;;AU 2005/000355 W,2004-03-15,Infectious Aetiology of Prostatic Disease and Methods to Identify Causative Agents,"The present invention relates to a method of diagnosing, or predicting risk of, prostate disease in a subject. More particularly, the invention relates to a method of diagnosing the presence of, or the predisposition to develop, prostate disease in a subject, the method comprising analysing a test sample from the subject for the presence of P. acnes infection of the prostate gland. The present invention further relates to reagents for use in this method and to methods of prevention or treatment of prostate disease.",TISSUGEN PTY LTD,COHEN RONALD JOSEPH;;GARRETT KERRYN LEE;;SHANNON BEVERLY ANNE,TISSUGEN PTY LTD (2006-11-14),https://lens.org/109-554-172-686-502,Patent Application,yes,1,4,5,7,52,C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/136;;C12Q2600/156;;A61P13/08;;A61P31/04;;C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/156;;C12Q2600/136,A61K45/00;;A61P13/08;;A61P31/04;;C07K14/195;;C12N1/20;;C12N15/31;;C12Q1/68,514/789;;536/23.7;;536/24.33;;536/24.32;;435/6;;435/252.1,0,0,,,,DISCONTINUED
531,US,A1,US 2013/0294036 A1,171-464-262-307-94X,2013-11-07,2013,US 201213462568 A,2012-05-02,US 201213462568 A,2012-05-02,MODULE FOR USE WITH A MONITORING SYSTEM AND METHOD OF ASSEMBLING SAME,A module for use with a monitoring system is provided. The module includes a circuit board that includes a plurality of ground planes. At least two of the plurality of ground planes are coupled using a plurality of vias. The module further includes a copper pour coupled to the circuit board adjacent to the plurality of vias. The module further includes a housing that includes a dam wall that is coupled to the copper pour.,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD;;SUMMERS SEAN KELLY,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD;;SUMMERS SEAN KELLY,BAKER HUGHES HOLDINGS LLC (2017-07-03);;GENERAL ELECTRIC COMPANY (2012-05-01),https://lens.org/171-464-262-307-94X,Patent Application,yes,4,0,2,2,0,H05K1/0218;;H05K1/0218;;H05K1/0215;;H05K1/0215;;Y10T29/49117;;Y10T29/49117;;Y10T29/49147;;Y10T29/49147,H05K1/14;;H05K3/30;;H05K7/00;;H05K13/04,361/736;;361/728;;29/825;;29/842,0,0,,,,ACTIVE
532,US,A1,US 2003/0005339 A1,158-147-982-535-932,2003-01-02,2003,US 89398101 A,2001-06-29,US 89398101 A,2001-06-29,Power control for a computer system,"
   A system for and a process of controlling power supplied to a group of computers. The power available is determined, and the total power requirement of the group of computers is monitored. When an additional computer joins the group, the new total power requirement is determined. If this exceeds the power available, but the existing group of computers can operate with reduced power and the additional computer can operate with less power than indicated in the request for power, reduced power is provided to each computer of the existing group of computers, and the additional computer is provided with less power than indicated in the request for power. When the existing group of computers or the additional computer can not operate with this reduced power, the total power requirement of the existing plurality of computers is continued to be provided, and only standby power is provided to the additional computer. 
",COHEN PAUL M.;;MEREDITH CHRISTOPHER A.;;CHILD RONALD J.,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-10-18),https://lens.org/158-147-982-535-932,Patent Application,yes,8,97,2,2,0,G06F1/26;;G06F1/28;;G06F1/26;;G06F1/28,G06F1/26;;G06F1/28,7133,0,0,,,,EXPIRED
533,US,A1,US 2002/0194517 A1,106-170-347-134-389,2002-12-19,2002,US 85243201 A,2001-05-09,US 85243201 A,2001-05-09,Method and apparatus to modify power requirements for a system,"
   A method and apparatus to modify power levels for devices in a system in response to changes in power conditions is described. 
",COHEN PAUL M.;;MEREDITH CHRISTOPHER A.;;CHILD RONALD J.,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-06-07),https://lens.org/106-170-347-134-389,Patent Application,yes,12,66,2,2,0,G06F1/26;;G06F1/26,G06F1/26,71334,0,0,,,,EXPIRED
534,US,B2,US 9095056 B2,122-172-540-844-402,2015-07-28,2015,US 201213462568 A,2012-05-02,US 201213462568 A,2012-05-02,Module for use with a monitoring system and method of assembling same,A module for use with a monitoring system is provided. The module includes a circuit board that includes a plurality of ground planes. At least two of the plurality of ground planes are coupled using a plurality of vias. The module further includes a copper pour coupled to the circuit board adjacent to the plurality of vias. The module further includes a housing that includes a dam wall that is coupled to the copper pour.,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD;;SUMMERS SEAN KELLY;;GEN ELECTRIC,COHEN MITCHELL DEAN;;NIKKELS ROBERT RONALD;;SUMMERS SEAN KELLY,BAKER HUGHES HOLDINGS LLC (2017-07-03);;GENERAL ELECTRIC COMPANY (2012-05-01),https://lens.org/122-172-540-844-402,Granted Patent,yes,13,0,2,2,0,H05K1/0218;;H05K1/0218;;H05K1/0215;;H05K1/0215;;Y10T29/49117;;Y10T29/49117;;Y10T29/49147;;Y10T29/49147,H05K1/14;;H05K1/02,,0,0,,,,ACTIVE
535,WO,A1,WO 1990/012539 A1,163-256-069-193-534,1990-11-01,1990,US 9000620 W,1990-02-02,US 34340489 A,1989-04-25,METHOD AND APPARATUS FOR PHYSIOLOGIC SYSTEM IDENTIFICATION,"A computer (310) generates a series of audio-pulses (312), which are spaced in time randomly in a given distribution. When subject (308) hears an audio-cue, the subject inhales and exhales. The instantaneous lung volume (324) is measured using a two-belt, chest-abdomen inductance plethysmograph (314) and recorded by a 8-channel FM tape recorder (326). The heart rate (322) is determined by a surface electrocardiogram device (320) and recorded by the 8-channel FM tape recorder (326). The blood pressure (318) is similarly measured (316) using an intra-arterial catheter or continuous non-invasive blood pressure transducer and recorded. The data is then analyzed using a computer (328).",MASSACHUSETTS INST TECHNOLOGY,COHEN RICHARD J;;APPEL MARVIN L;;BERGER RONALD D,,https://lens.org/163-256-069-193-534,Patent Application,yes,4,0,2,2,0,A61B5/0205;;A61B5/7257;;A61B5/0205;;A61B5/7257,A61B5/0205;;G06F17/00,,0,0,,,,PENDING
536,IT,B,IT 1204843 B,198-740-672-541-382,1989-03-10,1989,IT 1985686 A,1986-03-25,US 71607585 A;;US 74691985 A;;US 83833586 A,1985-03-26,CONNETTORE ELETTRICO PER UN CAVO ELETTRICO,,AMP INC,COHEN THOMAS SHOKNEY;;LAUDIG RONALD CLAIR;;SMITH DONALD LEE,,https://lens.org/198-740-672-541-382,Granted Patent,no,0,0,8,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R13/65915,H01R13/646;;H01R13/658,,0,0,,,,EXPIRED
537,CA,A1,CA 2559390 A1,102-612-052-806-432,2005-09-22,2005,CA 2559390 A,2005-03-15,AU 2004/901359 A;;US 61268804 P;;AU 2005/000355 W,2004-03-15,INFECTIOUS AETIOLOGY OF PROSTATIC DISEASE AND METHODS TO IDENTIFY CAUSATIVE AGENTS,,TISSUGEN PTY LTD,SHANNON BEVERLEY ANNE;;COHEN RONALD JOSEPH;;GARRETT KERRYN LEE,,https://lens.org/102-612-052-806-432,Patent Application,no,0,0,5,7,0,C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/136;;C12Q2600/156;;A61P13/08;;A61P31/04;;C07K14/195;;C12Q1/6883;;C12Q1/689;;C12Q2600/156;;C12Q2600/136,C12N15/31;;C07K14/195;;C12Q1/68,,0,0,,,,DISCONTINUED
538,DE,A1,DE 102013102627 A1,115-367-260-962-750,2013-09-19,2013,DE 102013102627 A,2013-03-14,US 201213421452 A,2012-03-15,System und Verfahren zum Erkennen einer falschen Verdrahtung oder Konfiguration in einem Überwachungssystem,"System und Verfahren zum Erkennen einer falschen Verdrahtung oder Konfiguration in einem Überwachungssystem. Die falsche Verdrahtung oder Konfiguration wird durch Messen des Wertes einer elektrischen Eigenschaft (z.B. Spannung oder Strom) eines elektrischen Signals erkannt, das von einem ersten Satz Anschlussklemmen empfangen wird, an die ein Aufnehmer angeschlossen ist, und durch Vergleichen dieses Werts mit einem vorbestimmten Wert oder Wertebereich der elektrischen Eigenschaft auf Basis von Werten, die für das elektrische Signal erwartet würden, wenn der Aufnehmer von dem Aufnehmertyp wäre, der zur Überwachung durch die Überwachungseinheit konfiguriert ist.",GEN ELECTRIC,COHEN MITCHELL DEAN;;TART MICHAEL ALAN;;NIKKELS ROBERT RONALD,,https://lens.org/115-367-260-962-750,Patent Application,no,0,0,5,5,0,G01R31/2829;;G01R31/2829,G01R31/02,,0,0,,,,DISCONTINUED
539,CA,A,CA 879916 A,164-935-365-278-517,1971-08-31,1971,CA 879916D A,,CA 879916T A,,DEFORMATION IMAGE REPRODUCTION SYSTEM,,XEROX CORP,FOLGER WILLIAM F;;URBACH JOHN C;;COHEN RONALD H,,https://lens.org/164-935-365-278-517,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
540,US,B2,US 7664648 B2,177-799-912-660-298,2010-02-16,2010,US 59514506 A,2006-11-09,US 59514506 A;;US 83938801 A,2001-04-20,Method and apparatus to provision a network appliance,A method and apparatus to provision a network node such as a network appliance is described.,INTEL CORP,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,,https://lens.org/177-799-912-660-298,Granted Patent,yes,1,0,4,4,0,H04L41/00;;H04L41/00,H03G3/20;;G10L11/00;;H04L12/24,704/275;;381/100;;367/198,0,0,,,,EXPIRED
541,US,S,US D0631105 S,014-808-234-264-376,2011-01-18,2011,US 34856710 F,2010-01-20,US 34856710 F,2010-01-20,Toy castle convertible into a table and chair set,,KIDS ONLY INC,COHEN RONALD B;;PAGANO ROBERT J;;WECKSTEIN LAWRENCE ALAN,KID'S ONLY INC (2010-01-19),https://lens.org/014-808-234-264-376,Design Right,no,0,7,1,1,0,,,2101;;D21/510;;D6/337,0,0,,,,ACTIVE
542,US,A1,US 2013/0241734 A1,075-667-032-328-059,2013-09-19,2013,US 201213421452 A,2012-03-15,US 201213421452 A,2012-03-15,SYSTEM AND METHOD FOR DETECTING IMPROPER WIRING OR CONFIGURATION IN A MONITORING SYSTEM,"A system and method for detecting improper wiring or configuration in a monitoring system. The improper wiring or configuration is detected by measuring the value of an electrical property (e.g., voltage or current) of an electrical signal received from a first set of wiring terminals to which a transducer is connected and comparing that value to a predetermined value or range of values of the electrical property based on values that would be expected for the electrical signal if the transducer was the type configured to be monitored by the monitoring unit.",COHEN MITCHELL DEAN;;TART MICHAEL ALAN;;NIKKELS ROBERT RONALD;;GEN ELECTRIC,COHEN MITCHELL DEAN;;TART MICHAEL ALAN;;NIKKELS ROBERT RONALD,GENERAL ELECTRIC COMPANY (2012-03-13),https://lens.org/075-667-032-328-059,Patent Application,yes,5,2,5,5,0,G01R31/2829;;G01R31/2829,G08B21/00;;G01R31/00;;G06F19/00,340/635;;702/58,0,0,,,,DISCONTINUED
543,KR,B1,KR 0160830 B1,108-376-496-281-258,1999-02-01,1999,KR 19950043859 A,1995-11-27,US 34509994 A,1994-11-28,INSULATOR FOR INTEGRATED CIRCUIT AND PROCESS,"반도체 디바이스를 포함하는 반도체 기판 상의 표면 내의 상호 접속 와이어링 레벨을 피복하는 절연층은 유동성 산화물층의 경화 및 어닐링에 의해 형성된다. 이 어닐링은 산화물층의 유전 상수가 3.2 이하가 되도록 하기 위해 수소 및 알루미늄의 존재시에 실행된다. 또한, 경화되고 어닐링된 유동성 산화물을 사용하여 인접한 디바이스간을 전기적으로 절연한다. 이 경우에, 어닐링은 수소의 존재시 알루미늄의 존재 또는 부재시에 실행될 수 있다.",IBM,COHEN STEPHAN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT,,https://lens.org/108-376-496-281-258,Granted Patent,no,0,0,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,,0,0,,,,EXPIRED
544,EP,A3,EP 0715354 A3,129-361-053-008-826,1998-07-15,1998,EP 95117118 A,1995-10-31,US 34509994 A,1994-11-28,Insulator for integrated circuits and process,,IBM,COHEN STEPHAN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT,,https://lens.org/129-361-053-008-826,Search Report,no,8,0,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,,0,0,,,,DISCONTINUED
545,US,B2,US 7203852 B2,011-900-248-669-166,2007-04-10,2007,US 89398101 A,2001-06-29,US 89398101 A,2001-06-29,System and process for making power readily available to newly added computers,"A system for and a process of controlling power supplied to a group of computers. The power available is determined, and the total power requirement of the group of computers is monitored. When an additional computer joins the group, the new total power requirement is determined. If this exceeds the power available, but the existing group of computers can operate with reduced power and the additional computer can operate with less power than indicated in the request for power, reduced power is provided to each computer of the existing group of computers, and the additional computer is provided with less power than indicated in the request for power. When the existing group of computers or the additional computer can not operate with this reduced power, the total power requirement of the existing plurality of computers is continued to be provided, and only standby power is provided to the additional computer.",INTEL CORP,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-10-18),https://lens.org/011-900-248-669-166,Granted Patent,yes,8,26,2,2,0,G06F1/26;;G06F1/28;;G06F1/26;;G06F1/28,G06F1/32;;G06F1/26;;G06F1/28;;G06F11/30;;H04Q7/20,713/320;;713/340;;455/522,0,0,,,,EXPIRED
546,US,A1,US 2010/0184350 A1,016-476-563-442-967,2010-07-22,2010,US 65738810 A,2010-01-20,US 65738810 A;;US 20555209 P,2009-01-21,Reconfigurable child's toy,"A reconfigurable child's toy features a first configuration including a table with a top and a supporting pedestal and chairs about the table. A second configuration includes two or more of the chairs stacked on each other and the table top and supporting pedestal interlocked with the stacked chairs forming a play structure such as a tower, a rocket ship, or other round or square play structure.",COHEN RONALD B;;PAGANO ROBERT J;;WECKSTEIN LAWRENCE ALAN,COHEN RONALD B;;PAGANO ROBERT J;;WECKSTEIN LAWRENCE ALAN,JAKKS PACIFIC INC (2012-12-11);;KIDS ONLY INC (2010-03-03),https://lens.org/016-476-563-442-967,Patent Application,yes,7,3,1,1,0,A47D3/00;;A47D3/00;;A47D1/00;;A47D1/00;;A63H33/008;;A63H33/008;;A63H33/044;;A63H33/044,A63H33/08;;A47C13/00;;A63H33/42,446/71;;446/124,2,0,,,"Freshome, Stackable Furniture Ideal for Small Places, 3/19/08, <https://web.archive.org/web20080319005536/http:// freshome.com/2008/03/17/stackable-furniture-ideal-for-small-places/> page 2.;;Freshome, Stackable Furniture Ideal for Small Places, 3/19/08, <https://web.archive.org/web20080319005536/http:// freshome.com/2008/O3/17/stackable-furniture-ideal-for-small-places/> page 2.",DISCONTINUED
547,US,B1,US 7263558 B1,111-447-844-317-231,2007-08-28,2007,US 39749199 A,1999-09-15,US 39749199 A,1999-09-15,Method and apparatus for providing additional information in response to an application server request,"A method and apparatus are disclosed for providing additional information, such as advertisements, to a client device via the response signal to an application (or web) server request. A client device is in communication with a server device, and sends a request for information to the server via a network connection. A device is associated with the network connection that detects and analyzes the signals being exchanged. The device would likely be associated with a point-of-presence to an Internet connection, for an ISP or the like. The associated device sends an appropriately timed reset signal to the server device that prevents the server device from further responding to signals subsequently received from the client device. The associated device sends, in response to the web server request, a response signal to the client device. The response signal provides additional information, along with the originally requested web server material. The additional information, along with the originally requested server materials, might then be displayed in appropriate windows or frames on a client browser. The additional information can be made to reside on a separate server. The associated device might also be used to revoke requests made to certain types of web servers, with a revocation response being provided, or a re-direction being provided to a site containing revocation information.",NARUS INC,KHIRMAN STANISLAV;;STONE MARK RONALD;;ARIAL OREN;;COHEN ORI,NARUS INC (1999-09-02),https://lens.org/111-447-844-317-231,Granted Patent,yes,76,30,1,1,0,G06Q30/00;;G06Q30/00,G06F15/16;;G06F11/00,709/229;;714/100,39,9,129-814-341-979-60X;;073-324-340-290-278;;061-478-809-158-124;;055-329-378-386-507;;055-756-552-074-477;;097-207-088-347-225;;100-375-954-445-251;;184-832-257-771-99X;;163-165-789-113-826,10.3998/3336451.0002.102;;10.1145/99508.99562;;10.1145/41457.37505;;10.1145/52324.52345;;10.1109/lcn.1988.10251;;10.1109/90.929851;;10.1145/347057.347555;;10.17487/rfc1319;;10.17487/rfc1321,"Jeffrey K. MacKie-Mason and Hal R. Varian. ""Some FAQs about Usage-Based Pricing"". Sep. 14, 1994. <http://www-personal.umich.edu/~jmm/papers/useF,AQs/useFAQs.pdf>.;;Jeffrey K. MacKie-Mason and Hal R. Varian. ""Pricing the Internet"". Feb. 10, 1994. <http://www-personal.umich.edu/~jmm/papers/Pricing<SUB>-</SUB>the<SUB>-</SUB>Internet.pdf>.;;Jeffrey K. MacKie-Mason and Hal R. Varian. ""Economic FAQs About the Internet"". Jun. 1, 1996. <http://www-personal.umich.edu/~jmm/papers/FAQs/econ-faqs-mit96-net.pdf>.;;Parker, Tim. ""Teach Yourself TCP/IP in 14 Days"", Second Edition, Sams Publishing, published Apr. 4, 1996, pp. 18-20, 44-45, 49, and 64-72.;;Howe, Denis. ""fault tolerance"", Free On-Line Dictionary of Computing, posted Apr. 6, 1995, <http://foldoc.doc.ic.ac.uk/foldoc/foldoc.cgi?fault+tolerance>, 1 page.;;Bay Networks, Chapter 2: SNMP, RMON, GOOTP, DHCP and RARP Concepts, Mar. 1997, 8 pages, http://www.baynetworks.com/library/pubs/html/routers.;;Tim Wilson, Sniffer Meets RMON At N+1, http://www.internetwk.com/news1098/news102298-2.thm.;;Teresa C. Mann et a., Network Design: Management and Technical Perspectives, CRC Press, Aug. 1998, 9 pages.;;Cisco Systems, Inc.: ""NetFlow FlowCollector Installation and User Guide,"" Chapter 5, pp. 5-1-5-8, undated.;;Cisco Systems, Inc.: ""NetFlow FlowCollector Installation and User Guide,"" Chapter 6, pp. 6-1-6-28, undated.;;Blaze, M.: ""NFS Tracing by Passive Network Monitoring"", Department of Computer Science, Princeton University, undated.;;AG Group, Inc.: ""WatchPoint 1.0 Manual"", May 1999.;;Network General Corporation: ""Managing WAN Technologies for Maximum Internetwork Performance, a Network Visibility Guide"", Copyright 1996.;;Network General Corporation: ""An Introduction to the Total Network Visibility Architecture, a Network Visibility Guide"", Copyright 1995.;;Network Associates, Inc.: ""SnifferPRO 98 by Network Associates, Expert Network Analysis for Optimal Performance"", Copyright 1998.;;NetScout Systems, Inc.: ""NetScout Intelligent Probes, End-to-End Monitoring of LANs, WANs, and Switched LANs for Distributed Networks"", Copyright 1997.;;Precision Guesswork Product Page: ""LANWatch32 Network Analyzer for Windows 95/NT, Unlocking the Complexity of Network Analysis"", Jun. 4, 1998 Update.;;Check Point Software Technologies Ltd.: ""Check Point FireWall-1 Technical Overview, Version 4.0"", Apr. 1999.;;Enger and Reynolds, RFC 1470, http://ftp.cised.unima.it/pub/docs/rfc-unsorted/rfc 1470.txt, pp. 65, 70, 93, 95, 102, 103, 128, 135, 146 and 160, Jun. 1993.;;Novell NetWare, Network Computer Products: ""LANalyzer for Windows 2.1 User's Guide, Chapter 5"", pp. 75-103, Mar. 1994.;;Network General: ""Expert Sniffer Network Analyzer Operations, Release 4.5"", pp. 1-3 through 1-7, 7-3 through 7-26, 6-62 through 6-75, Jan. 1995.;;Cisco Systems, Inc.: ""Overview of the NetFlow FlowAnalyzer"", Copyright 1989-1998.;;Cisco Systems, Inc.: ""NetFlow FlowCollector Overview, Chapter 1"", undated.;;Cisco Systems, Inc.: ""Release Notes for NetFlow FlowCollector, Release 1.0"", Sep. 1997.;;Cisco Systems, Inc.: ""FlowCollector Overview, Chapter 2"", undated.;;Cisco Systems, Inc.: ""Using the FlowAnalyzer Display Module, Chapter 3"", undated.;;Jeffrey C. Mogul, ""Efficient Use of Workstations for Passive Monitoring of Local Area Networks"" (1990) SIGCOMM '90 Symposium, Communications, Architectures & Protocols, Philadelphia, Pennsylvania, pp. 253-263.;;Jeffrey C. Mogul, et al., ""The Packet Filter: An Efficient Mechanism for User-Level Network Code"" (1987) Operating Systems Review, vol. 21, No. 5, Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, Austin, Texas, pp. 39-51.;;Robert T. Braden, ""A Pseudo-Machine for Packet Monitoring and Statistics"" (1988) SIGCOMM '88 Symposium, Communications, Architectures & Protocols, Stanford, California, pp. 200-209.;;J. Scott Haugdahl, ""Benchmarking LAN Protocol Analyzers"" (1988) IEEE Proceedings, 13<SUP>th </SUP>Conference on Local Computer Networks, Minneapolis, Minnesota, pp. 375-384.;;""Sniffer Network Analyzer Ethernet(R)-Seven-Layer Expert Analysis of 10/100 Mbps Ethernet Segments"", Network Associates, Inc., http://www.nai.com/products/network<SUB>-</SUB>visitibility/sniffer<SUB>-</SUB>lan/s<SUB>-</SUB>nae.asp.;;Rachel Emma Silverman, ""Intrusion Detection Systems Sniff Out Digital Attack"" (Feb. 4, 1999) Wall Street Journal.;;N. Michael Minnich, ""A Packet Capture System for LAN Software Development"" (1986) IEEE Proceedings, 11<SUP>th </SUP>Conference on Local Computer Networks, Minneapolis, Minnesota, pp. 68-76.;;Duffield, N.G., and Grossglauser, M., ""Trajectory Sampling for Direct Traffic Observation,"" AT&T Labs-Research, pp. 1-14, 2001.;;Duffield, N.G., and Grossglauser, M., ""Trajectory Sampling for Direct Traffic Observation,"" AT&T Labs-Research, pp. 1-12, 2000.;;Kaliski, B., ""The MD2 Message-Digest Algorithm,"" RSA Laboratories, Network Working Group, Apr. 1992.;;Minnich, N. Michael, ""A Packet Capture System for LAN Software Development"" (1986) IEEE Proceedings, 11<SUP>th </SUP>Conference on Local Computer Networks, Minneapolis, Minnesota, pp. 68-76.;;Rivest, R., ""The MD5 Message-Digest Algorithm,"" MIT Laboratory for Computer Science and RSA Data Security, Inc., Apr. 1992.;;Robshaw, M.J.B., ""On Recent Results for MD2, MD4, and MD5,"" RSA Laboratories' Bulletin, No. 4, Nov. 12, 1996.",EXPIRED
548,CN,A,CN 103308814 A,176-810-633-346-026,2013-09-18,2013,CN 201310083130 A,2013-03-15,US 201213421452 A,2012-03-15,System and method for detecting improper wiring or configuration in a monitoring system,"A system and method for detecting improper wiring or configuration in a monitoring system. The improper wiring or configuration is detected by measuring the value of an electrical property (e.g., voltage or current) of an electrical signal received from a first set of wiring terminals to which a transducer is connected and comparing that value to a predetermined value or range of values of the electrical property based on values that would be expected for the electrical signal if the transducer was the type configured to be monitored by the monitoring unit.",GEN ELECTRIC,DEAN COHEN MITCHELL;;ALAN TART MICHAEL;;RONALD NIKKELS ROBERT,,https://lens.org/176-810-633-346-026,Patent Application,no,5,5,5,5,0,G01R31/2829;;G01R31/2829,G01R31/02,,0,0,,,,DISCONTINUED
549,US,A1,US 2002/0141217 A1,119-369-320-700-774,2002-10-03,2002,US 82373001 A,2001-03-29,US 82373001 A,2001-03-29,POWER SUPPLY WITH INTERFACE TO DETERMINE POWER REQUIREMENTS OF DEVICES COUPLED THERETO,"
   Intelligent power supplies to provide power to electronic devices in a manner the avoids causing a power supply circuit fuse to blow or breaker to trip are disclosed. The power supply circuit includes a power supply control device that determines whether supplying power to an additional electronic device would exceed the capacity of the circuit and cause the fuse to blow or the breaker to trip. The power supply control device communicates with electronic devices via a power control interface to determine the power requirements of the electronic devices. Power is supplied to the devices that can be supplied without causing the fuse to blow or the breaker to trip. Power is not supplied to the devices that would cause the fuse to blow or the breaker to trip. 
",COHEN PAUL M.;;MEREDITH CHRISTOPHER A.;;CHILD RONALD J.,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-05-11),https://lens.org/119-369-320-700-774,Patent Application,yes,0,9,2,2,0,H02H11/00;;H02J3/14;;Y02B70/3225;;Y04S20/222;;H02J2310/52;;H02J3/14;;H02H11/00;;Y02B70/3225;;Y04S20/222,H02H11/00;;H02J3/14,363/146,0,0,,,,EXPIRED
550,US,A,US 4930517 A,015-135-121-070-674,1990-06-05,1990,US 34340489 A,1989-04-25,US 34340489 A,1989-04-25,Method and apparatus for physiologic system identification,"A method and apparatus for estimating transfer functions among multiple physiologic or biologic signals in the presence of feedback. The invention comprises the injection of broad band purturbation into one or more of the subsystems under study, and measuring signals from the subsystems. These signals are transformed to generate a new set of n signals. Casual transfer functions between the signals and additive noise sources are used to represent the relationships between the n signals. Parametric system identification techniques are then used to characterize quantitatively at least two casual transfer functions and noise sources. This method and apparatus provides a powerful tool with which to characterize the interactions of subsystems in the presence of feedback.",MASSACHUSETTS INST TECHNOLOGY,COHEN RICHARD J;;APPEL MARVIN L;;BERGER RONALD D,MASSACHUSETTS INSTITUTE OF TECHNOLOGY A MASSACHUSETTS CORP (1989-05-09),https://lens.org/015-135-121-070-674,Granted Patent,yes,3,100,2,2,0,A61B5/0205;;A61B5/7257;;A61B5/0205;;A61B5/7257,A61B5/0205;;G06F17/00,128/671;;128/695;;364/413.03,10,4,075-303-483-410-177;;055-483-795-028-925;;144-632-369-246-463;;034-782-080-711-438,10.1109/10.8688;;3220497;;2912176;;10.1152/ajpheart.1989.256.1.h142;;10.1177/014233128200400404;;10.1152/ajpheart.1989.256.1.h153;;2912177,"R. O. Kenet, Closed Loop Identification of Hemodynamic Control Systems , Ph.D. Thesis, Yale University, Jun. 1983.;;G. Baselli et al, IEEE Transactions on Biomedical Engineering, Cardiovascular Variability Signals: Towards the Identification of a Closed Loop Model of the Neural Control Mechanisms , vol. 35, No. 12, Dec. 1988, pp. 1033 1046.;;S. Kalli et al., Proceedings of the Third International Conference on Measurement in Clinical Medicine, Applying a Multivariate Autoregressive Model to Describe Interactions Between Blood Pressure and Heart Rate , Edinburgh, 1986, pp. 77 82.;;S. Kalli et al, Computers in Cardiology, Proceedings IEEE Computer Society, Analysis of Blood Pressure and Heart Rate Variability Using Multivariate Autoregressive Modelling , 1986, p. 4.;;R. D. Berger et al., American Journ. of Physiology, Transfer Function Analysis of Autonomic Regulation , vol. 256, Heart and Circulatory Physiology, vol. 25, pp. H142 H152 (1989).;;R. I. Kitney et al., Transactions of the Institute of Measurement and Control, System Identification of the Blood Pressure Control System by Low Frequency Neural Stimulation , vol. 4, No. 4, Oct. Dec. 1982, p. 202 203.;;J. P. Saul et al., American Journ. of Physiology, Transfer Function Analysis of Autonomic Regulation II. Respiratory Sinus Arrhythmia , vol. 256, Heart Circ. Physiology, vol. 25, 1989, pp. H153 H161.;;B. K. Walker et al, IFAC Symposium on Identification and System Parameter Estimation, Parameter Identification and Adaptive Control for Blood Pressure , Washington, D.C., 1982, pp. 1413 1418.;;B. C. McInnis et al., IFAC Symposium on Identification and System Parameter Estimation, Adaptive Pole Assignment Control of Blood Pressure Using Bilinear Models , York, 1985, pp. 1209 1212.;;D. A. Linkens, IFAC Symposium on Identification and System Parameter Estimation, Identification of Respiratory and Cardiovascular Systems , York, 1985, pp. 55 57.",EXPIRED
551,US,A,US 4688878 A,021-748-520-888-229,1987-08-25,1987,US 83833586 A,1986-01-22,US 83833586 A;;US 71607585 A,1985-03-26,Electrical connector for an electrical cable,"An electrical connector (1, 2) for twin axial cable (100,100) comprises; a first assembly (4,4) comprised of a conductive outer shell (6,6), a first dielectric body (8,8), a conductive inner shell (10,10), and a second dielectric body (12,12); a second assembly (60,60) for insertion in the outer shell (6,6) and for electrical connection with the inner shell (10,10) comprises a first conductive body (62,62) a conductive ferrule (64,64) on the first conductive body (62,62) for connection with a corresponding electrical conductor (104,104), a third dielectric body (66,66), an electrical contact (70,70) for connection with a corresponding electrical conductor (102,102) of a twin axial cable (100,100), and a second conductive body (72,72) for establishing electrical connection of a conductive sheath (106,106) of a twin axial cable (100,100) and a barrier (108,108) in the outer shell (6,6) for limiting displacement of the conductive sheath (106,106) along the outer shell (6,6).",AMP INC,COHEN THOMAS S;;LAUDIG RONALD C;;SMITH DONALD L,,https://lens.org/021-748-520-888-229,Granted Patent,yes,15,77,1,9,0,H01R24/562;;H01R2105/00;;H01R13/6593;;H01R24/562;;H01R2105/00;;H01R13/6593,H01R13/6593;;H01R24/56,439/585,0,0,,,,EXPIRED
552,US,B2,US 7155625 B2,056-905-497-116-357,2006-12-26,2006,US 85243201 A,2001-05-09,US 85243201 A,2001-05-09,Method and apparatus to modify power requirements for a system,"A method and apparatus to modify power levels for devices in a system in response to changes in power conditions is described. A power level of a power supply providing power to a plurality of devices is monitored. A change in the power level of the power supply is detected, a modification signal is created to modify the operating power level of at least one of the plurality of devices and the modification signal is sent to the device.",INTEL CORP,COHEN PAUL M;;MEREDITH CHRISTOPHER A;;CHILD RONALD J,INTEL CORPORATION (2001-06-07),https://lens.org/056-905-497-116-357,Granted Patent,yes,14,15,2,2,0,G06F1/26;;G06F1/26,G06F1/28;;G06F1/26,713/340;;713/322;;713/323,0,0,,,,EXPIRED
553,US,A1,US 2006/0161630 A1,091-537-190-267-380,2006-07-20,2006,US 3977605 A,2005-01-18,US 3977605 A,2005-01-18,Apparatus and method controlling use of individual segments of instant messaging content,"An apparatus and method is provided for a configuration of client work stations for instant messaging, wherein a participant intending to send a particular segment of chat content can elect to send the segment in an “off the record” mode. Content sent in this mode can be viewed but cannot be copied or saved by other instant messaging participants. The apparatus usefully includes a mode select device operable by the participant at a given station to designate each of a succession of chat content segments generated at the given station to be either for unrestricted use, or for off the record use, selectively. The apparatus further includes a component for applying a first use control message to each of the off the records segments sent from the given station to one or more of the other stations. A content control device located at a station receiving the off the record segments is responsive to the applied first use control messages to prevent the receiving station from retaining or otherwise propagating any of the received off the record segments.",IBM,COHEN GABRIEL A;;CRAIG RONALD E;;MITCHELL GERALD L JR,INTERNATIONAL BUSINESS MACHINES CORPORATION (2005-01-07);;TWITTER INC (2013-12-30),https://lens.org/091-537-190-267-380,Patent Application,yes,13,3,2,2,0,H04L12/1831;;H04L51/04;;H04L51/04;;H04L12/1831,G06F15/16,709/206,0,0,,,,ACTIVE
554,US,A,US 5750076 A,126-711-262-154-799,1998-05-12,1998,US 58007895 A,1995-12-20,US 58007895 A;;US 29365394 A,1994-08-22,Apparatus for the two-stage selective oxidation of carbon monoxide in a hydrogen-containing gas mixture,"An apparatus for the two-stage selective oxidation of carbon monoxide to carbon dioxide in a fuel stream comprising hydrogen and carbon monoxide. The apparatus includes primary and secondary reaction chambers, which deliver a hydrogen-rich outlet gas stream having a carbon monoxide concentration of less than about 5 ppm. When an increase in the carbon monoxide concentration in the outlet stream of the primary reaction chamber is detected, then the flow through the primary reaction chamber is reversed. The selective oxidizer employs a temperature-based control strategy as an oxygen-containing gas stream flow rate adjustment around the flow rate initially set in direct proportion to the fuel gas stream flow rate. The control strategy regulates the amount of oxygen-containing gas mixed with the gaseous fuel stream as a function of the difference between the temperature at a location at or near the end of the primary reaction chamber and the temperature at the outlet of the primary reaction chamber.",BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;COHEN RONALD;;MCNEILLY LEONARD;;WATKINS DAVID S,NUCELLSYS GMBH (2005-08-31);;BALLARD POWER SYSTEMS INC (2008-01-31);;BALLARD POWER SYSTEMS AG (2002-02-26);;FUEL CELL SYSTEMS GMBH (2005-07-29);;BALLARD POWER SYSTEMS INC. (CANADIAN CORP. NO. 7076991) (2009-05-27),https://lens.org/126-711-262-154-799,Granted Patent,yes,13,22,6,6,0,B01D53/864;;B01J8/0446;;C01B3/583;;C01B2203/044;;C01B2203/047;;B01D53/864;;C01B2203/044;;C01B3/583;;B01J8/0446;;C01B2203/047,B01D53/86;;B01J8/04;;C01B3/58,422/115;;422/173;;422/177,0,0,,,,EXPIRED
555,DE,T2,DE 69429332 T2,025-048-033-370-041,2002-08-22,2002,DE 69429332 T,1994-08-05,US 11007693 A;;US 9409025 W,1993-08-20,"VERFAHREN ZUR ERZEUGUNG ELEKTRISCHER ENERGIE MITTELS FESTSTOFFPOLYMERZELLEN, GESPEIST MIT KOHLENWASSERSTOFF",,BALLARD POWER SYSTEMS,BUSWELL F;;CLAUSI V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS S,,https://lens.org/025-048-033-370-041,Granted Patent,no,0,5,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
556,CA,C,CA 2029672 C,141-126-950-904-57X,1998-01-20,1998,CA 2029672 A,1990-11-09,CA 2029672 A,1990-11-09,BAG WITH AUXILIARY POCKET AND VIEWING WINDOW,"There is disclosed herein a bag which is constructed to form a primary loading compartment and an auxiliary load-carrying or promotional-item-carrying pocket. The bag includes front, back, side and bottom panels and a compartment forming partition panel. The partition panel is secured to the front panel so as to define primary and auxiliary load-carrying compartments. The auxiliary compartment is formed by the front panel and partition panel. The front panel may be apertured and overlaid with a transparent film so as to form a window. The partition is adhered to the front panel so as to form a pocket in which the contents are positioned for viewing through the window.",BAGCRAFT CORP,COHEN ALDEN M;;FALTYNEK MARK;;MARSIK RONALD;;RISEMAN DAVID A,,https://lens.org/141-126-950-904-57X,Granted Patent,no,0,0,2,2,0,,B65D33/04,D42200005    M,0,0,,,,EXPIRED
557,WO,A1,WO 2023/110555 A1,181-205-813-936-942,2023-06-22,2023,EP 2022084690 W,2022-12-07,US 202163290694 P;;US 202263331299 P,2021-12-17,"SYSTEMS, DEVICES, AND METHODS FOR COREGISTRATION OF INTRAVASCULAR DATA TO ENHANCED STENT DEPLOYMENT X-RAY IMAGES","A system includes a processor circuit in communication with an extraluminal imaging device and an intraluminal imaging device. The processor circuit obtains an enhanced stent deployment extraluminal image and a plurality of intraluminal images. The enhanced stent deployment extraluminal image and the each of the plurality of intraluminal images are associated with locations along a pathway. The pathway is overlaid over an extraluminal image. Based on the locations of the pathway, the processor circuit coregisters the plurality of intraluminal images to the enhanced stent deployment extraluminal image and outputs a screen display of one of the plurality of intraluminal images and the enhanced stent deployment extraluminal image with an indicator identifying the location at which the displayed intraluminal image was obtained. The processor circuit may also determine an expansion score for intraluminal images depicting the stent and identify regions of the stent corresponding to an expansions score below a threshold.",KONINKLIJKE PHILIPS NV;;PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN;;NACHTOMY EHUD,,https://lens.org/181-205-813-936-942,Patent Application,yes,27,0,2,2,0,A61B8/12;;A61B8/463;;A61B8/4416;;A61B6/12;;A61B6/4417;;A61B6/463;;A61B6/481;;A61B6/487;;A61B8/0891;;A61B8/12;;A61B8/463,A61B6/00;;A61B8/12;;A61B6/12;;A61B8/00,,0,0,,,,PENDING
558,US,B2,US 8856223 B2,019-240-333-925-603,2014-10-07,2014,US 3832305 A,2005-01-18,US 3832305 A,2005-01-18,Limiting access to instant messaging content on a display screen,A technique that reduces the possibility that a message received at a computer terminal during an instant messaging conversation will become accessible to unintended viewers. One embodiment is directed to an arrangement wherein a computer terminal at a first client work station is disposed to receive chat messages from a second client work station during an instant messaging conversation. An apparatus associated with the computer terminal for limiting access to the received chat messages includes a device for attaching a security identifier to each received chat message. A display device at the computer terminal generates a window that selectively provides a specified one of the chat messages in viewable form. A concealment device coupled to the display device is operable to make the specified chat message unviewable on the display device. A component connected to the concealment device activates the concealment device when a prespecified event occurs.,COHEN GABRIEL AARON;;CRAIG RONALD EUGENE;;MITCHELL JR GERALD LAVERTE;;IBM,COHEN GABRIEL AARON;;CRAIG RONALD EUGENE;;MITCHELL JR GERALD LAVERTE,INTERNATIONAL BUSINESS MACHINES CORORATION (2005-01-07),https://lens.org/019-240-333-925-603,Granted Patent,yes,16,1,2,2,0,G06F21/84;;G06F21/84;;H04L51/04;;H04L51/04,G06F15/16;;G06F21/84;;H04L12/58,709/204;;709/206;;709/229,4,0,,,"U.S. Appl. No. 10/735,9651, Karstens, Methods and Systems of Instant Message Secure Client Control, filed Dec. 15, 2003.;;U.S. Appl. No. 10/411,468, Hamilton et al., User Control of Off-Line Messaging, filed Apr. 10, 2003.;;Cohen et al., Apparatus and Method for Controlling Use of Instant Messaging Content, Jan. 18, 2005.;;Cohen et al., Apparatus and Method for Controlling Use of Individual Segments of Instant Messaging Content, Jan. 18, 2005.",ACTIVE
559,US,A1,US 2023/0190228 A1,110-100-572-055-741,2023-06-22,2023,US 202218082405 A,2022-12-15,US 202218082405 A;;US 202163290694 P;;US 202263331299 P,2021-12-17,"SYSTEMS, DEVICES, AND METHODS FOR COREGISTRATION OF INTRAVASCULAR DATA TO ENHANCED STENT DEPLOYMENT X-RAY IMAGES","A system includes a processor circuit in communication with an extraluminal imaging device and an intraluminal imaging device. The processor circuit obtains an enhanced stent deployment extraluminal image and a plurality of intraluminal images. The enhanced stent deployment extraluminal image and the each of the plurality of intraluminal images are associated with locations along a pathway. The pathway is overlaid over an extraluminal image. Based on the locations of the pathway, the processor circuit coregisters the plurality of intraluminal images to the enhanced stent deployment extraluminal image and outputs a screen display of one of the plurality of intraluminal images and the enhanced stent deployment extraluminal image with an indicator identifying the location at which the displayed intraluminal image was obtained. The processor circuit may also determine an expansion score for intraluminal images depicting the stent and identify regions of the stent corresponding to an expansions score below a threshold.",PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN;;NACHTOMY EHUD,PHILIPS IMAGE GUIDED THERAPY CORPORATION (2022-07-12),https://lens.org/110-100-572-055-741,Patent Application,yes,0,0,2,2,0,A61B8/12;;A61B8/463;;A61B8/4416;;A61B6/12;;A61B6/4417;;A61B6/463;;A61B6/481;;A61B6/487;;A61B8/0891;;A61B8/12;;A61B8/463,A61B8/12;;A61B8/08,,0,0,,,,PENDING
560,US,A,US 4991980 A,102-682-164-007-030,1991-02-12,1991,US 39082389 A,1989-08-08,US 39082389 A,1989-08-08,Bag with auxiliary pocket and viewing window,"There is disclosed herein a bag which is constructed to form a primary loading compartment and an auxiliary load-carrying or promotional-item-carrying pocket. The bag includes front, back, side and bottom panels and a compartment forming partition panel. The partition panel is secured to the front panel so as to define primary and auxiliary load-carrying compartments. The auxiliary compartment is formed by the front panel and partition panel. The front panel may be apertured and overlaid with a transparent film so as to form a window. The partition is adhered to the front panel so as to form a pocket in which the contents are positioned for viewing through the window.",BAGCRAFT CORP,COHEN ALDEN M;;FALTYNEK MARK;;MARSIK RONALD;;RISEMAN DAVID A,BAGCRAFT PACKAGING L.L.C (1999-04-01);;BAGCRAFT CORPORATION OF AMERICA A CORP. OF IL (1989-07-24);;BAGCRAFT ACQUISITION L.L.C (1998-11-20);;PACKAGING DYNAMICS L.L.C (2000-04-26);;PDOC LLC (2003-09-29),https://lens.org/102-682-164-007-030,Granted Patent,yes,38,76,4,4,0,B65D33/04;;B65D33/04;;B65D31/12;;B65D31/12,B65D30/22;;B65D33/04,383/40;;383/104;;383/106;;383/120;;229/71;;229/72,0,0,,,,EXPIRED
561,WO,A1,WO 1996/006387 A1,185-054-022-666-763,1996-02-29,1996,US 9510504 W,1995-08-18,US 29365394 A,1994-08-22,METHOD AND APPARATUS FOR THE OXIDATION OF CARBON MONOXIDE,"An apparatus and method are provided for the two-stage selective oxidation of carbon monoxide to carbon dioxide in a fuel stream comprising hydrogen and carbon monoxide (21). The apparatus includes primary (11) and secondary (12) reaction chambers, which deliver a hydrogen-rich outlet gas stream having a carbon monoxide concentration of less than about 5 ppm. When an increase in the carbon monoxide concentration in the outlet stream of the primary reaction chamber (11) is detected, then the flow through the primary reaction chamber is reversed. The selective oxidizer (10) employs a temperature-based control strategy (30) as an oxygen-containing gas stream flow rate adjustment around the flow rate initially set in direct proportion to the fuel gas stream flow rate. The control strategy regulates the amount of oxygen-containing gas mixed with the gaseous fuel stream as a function of the difference between the temperature at a location at or near the end of the primary reaction chamber and the temperature at the outlet of the primary reaction chamber.",BALLARD POWER SYSTEMS;;MCNEILLY LEONARD;;WATKINS DAVID S;;BUSWELL RICHARD F;;COHEN RONALD,MCNEILLY LEONARD;;WATKINS DAVID S;;BUSWELL RICHARD F;;COHEN RONALD,,https://lens.org/185-054-022-666-763,Patent Application,yes,10,1,6,6,0,B01D53/864;;B01J8/0446;;C01B3/583;;C01B2203/044;;C01B2203/047;;B01D53/864;;C01B2203/044;;C01B3/583;;B01J8/0446;;C01B2203/047,B01D53/86;;B01J8/04;;C01B3/58,,0,0,,,,PENDING
562,DE,D1,DE 69429332 D1,093-868-253-613-113,2002-01-17,2002,DE 69429332 T,1994-08-05,US 11007693 A;;US 9409025 W,1993-08-20,"VERFAHREN ZUR ERZEUGUNG ELEKTRISCHER ENERGIE MITTELS FESTSTOFFPOLYMERZELLEN, GESPEIST MIT KOHLENWASSERSTOFF",,BALLARD POWER SYSTEMS,BUSWELL F;;CLAUSI V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS S,,https://lens.org/093-868-253-613-113,Granted Patent,no,0,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
563,US,B2,US 7689653 B2,182-462-526-523-831,2010-03-30,2010,US 3977605 A,2005-01-18,US 3977605 A,2005-01-18,Apparatus and method controlling use of individual segments of instant messaging content,"An apparatus and method is provided for a configuration of client work stations for instant messaging, wherein a participant intending to send a particular segment of chat content can elect to send the segment in an “off the record” mode. Content sent in this mode can be viewed but cannot be copied or saved by other instant messaging participants. The apparatus usefully includes a mode select device operable by the participant at a given station to designate each of a succession of chat content segments generated at the given station to be either for unrestricted use, or for off the record use, selectively. The apparatus further includes a component for applying a first use control message to each of the off the records segments sent from the given station to one or more of the other stations. A content control device located at a station receiving the off the record segments is responsive to the applied first use control messages to prevent the receiving station from retaining or otherwise propagating any of the received off the record segments.",IBM,COHEN GABRIEL AARON;;CRAIG RONALD EUGENE;;MITCHELL JR GERALD LAVERTE,INTERNATIONAL BUSINESS MACHINES CORPORATION (2005-01-07);;TWITTER INC (2013-12-30),https://lens.org/182-462-526-523-831,Granted Patent,yes,15,12,2,2,0,H04L12/1831;;H04L51/04;;H04L51/04;;H04L12/1831,G06F15/16,709/206;;709/228,4,0,,,"U.S. Appl. No. 10/735,965, Karstens, Methods and Systems of Instant Message Secure Client Control, filed Dec. 15, 2003.;;U.S. Appl. No. 10/411,468, Hamilton et al., User Control of Off-Line Messaging, filed Apr. 10, 2003.;;Cohen et al., Apparatus and Method for Controlling Use of Instant Messaging Content, filed Jan. 18, 2005.;;Cohen et al., Apparatus and Method for Limiting Access to Instant Messaging Content on a Display Screen, filed Jan. 18, 2005.",ACTIVE
564,US,A1,US 2023/0181140 A1,037-357-558-870-836,2023-06-15,2023,US 202218075518 A,2022-12-06,US 202218075518 A;;US 202163288553 P;;US 202163292529 P,2021-12-11,REGISTRATION OF INTRALUMINAL PHYSIOLOGICAL DATA TO LONGITUDINAL IMAGE BODY LUMEN USING EXTRALUMINAL IMAGING DATA,"A system includes a processor circuit that receives intravascular imaging data from an intravascular imaging catheter, an x-ray image from an x-ray imaging device, and intravascular pressure data from an intravascular pressure-sensing guidewire. The processor circuit correlates the intravascular imaging data and the intravascular pressure data to locations along a body lumen shown in the x-ray image. The processor circuit generates a longitudinal view of the body lumen based on the intravascular imaging data and outputs a screen display including the longitudinal view of the body lumen with an overlaid graphical representation corresponding to the intravascular pressure measurements.",PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN;;PREISLER EFRAT,PHILIPS IMAGE GUIDED THERAPY CORPORATION (2022-12-01),https://lens.org/037-357-558-870-836,Patent Application,yes,0,0,2,4,0,A61B8/12;;A61B8/5253;;A61B8/5261;;A61B8/463;;A61B6/12;;A61B8/04;;G06T7/30;;A61B5/0215;;A61B6/12;;A61B6/463;;A61B6/5247;;A61B8/12;;G06T7/0012;;G06T7/20;;G06T11/00;;G06T2207/10116;;G06T2207/30104;;G06T2210/41,A61B6/00;;A61B6/12;;A61B8/12;;G06T7/00;;G06T7/20;;G06T7/30;;G06T11/00,,0,0,,,,PENDING
565,US,A1,US 2006/0161629 A1,132-433-235-440-749,2006-07-20,2006,US 3832305 A,2005-01-18,US 3832305 A,2005-01-18,Apparatus and method for limiting access to instant messaging content on a display screen,An apparatus and method is provided for substantially reducing the possibility that a message received at a computer terminal during an instant messaging conversation will become accessible to unintended viewers. A useful embodiment is directed to an arrangement wherein a computer terminal at a first client work station is disposed to receive chat messages from a second client work station during an instant messaging conversation. Apparatus associated with the computer terminal for limiting access to the received chat messages includes a device for attaching a security identifier to each received chat message. A display device at the computer terminal generates a window that selectively provides a specified one of the chat messages in viewable form. A concealment device coupled to the display device is-operable to make the specified chat message unviewable on the display device. A component connected to the concealment device activates the concealment device when a prespecified event occurs.,IBM,COHEN GABRIEL A;;CRAIG RONALD E;;MITCHELL GERALD L JR,INTERNATIONAL BUSINESS MACHINES CORORATION (2005-01-07),https://lens.org/132-433-235-440-749,Patent Application,yes,14,32,2,2,0,G06F21/84;;G06F21/84;;H04L51/04;;H04L51/04,G06F15/16,709/206;;709/229,0,0,,,,ACTIVE
566,US,A1,US 2006/0161666 A1,076-445-666-585-981,2006-07-20,2006,US 3972705 A,2005-01-18,US 3972705 A,2005-01-18,Apparatus and method for controlling use of instant messaging content,"An apparatus and method is provided for use in instant messaging or chat conversations between participants at client computer terminals or work stations. When a participant wants to save some or all of the chat transcript, the participant actively requests consent from all other participants. The consent request includes the specific content to be saved, and provides a variety of options for responding to the request, such as to approve, disapprove, or delete selected text. In a useful embodiment, apparatus for controlling use of chat content includes a content control device located at least at a first one of the client stations, the control device connected to regulate use by a first station of specified chat content received from at least a second station. A content request device operable at the first station sends a message requesting permission to selectively use the specified chat content, and a request response device at the second station sends a response request message to either prevent the first station from propagating the specified chat content, or else approving selective use by the first station of at least a portion of the specified content.",IBM,COHEN GABRIEL A;;CRAIG RONALD E;;MITCHELL GERALD L JR,INTERNATIONAL BUSINESS MACHINES CORPORATION (2005-01-07),https://lens.org/076-445-666-585-981,Patent Application,yes,19,23,1,1,0,H04L12/1831;;H04L51/04;;H04L51/212;;H04L12/1831;;H04L51/04;;H04L51/212,G06K9/00;;G06F15/16;;H04L9/32,709/229;;726/4,0,0,,,,DISCONTINUED
567,US,B1,US 6385308 B1,081-367-355-016-271,2002-05-07,2002,US 98067097 A,1997-12-01,US 98067097 A,1997-12-01,Telephone system and method for personalized announcements,"
    A telephone system provides personalized announcements to calling parties in support of branded products and services of the system and others during call processing to called parties. A processor coupled to the system includes a database of designated calling parties receiving personal announcements. Record means stored in the processor for each designated calling party define the parameters for each personalized announcement. Call processing means responsive to the processor initiate a call from the calling party to a called party according to the parameters for the calling party defined in the record means. In one form, audio means under control of the processor play the personalized announcement to the calling party during the pre-answer period of the call or until the call is abandoned or the line is busy. 
",AT & T CORP,COHEN STEVEN L;;DAVITT MICHAEL;;MCGRATH A HELEN;;NEMETH RONALD,AT&T CORP (1997-11-13),https://lens.org/081-367-355-016-271,Granted Patent,yes,19,94,1,1,0,H04M1/642;;H04M3/42017;;H04M3/42059;;H04M3/4878;;H04M3/53366;;H04M15/00;;H04M2242/22;;H04M3/42017;;H04M15/00;;H04M3/4878;;H04M1/642;;H04M3/42059;;H04M3/53366;;H04M2242/22,H04M1/64;;H04M3/487;;H04M3/533,379/88.23;;379/67.1;;379/76;;379/209;;379/221,0,0,,,,EXPIRED
568,GB,B,GB 2234735 B,103-810-055-341-507,1993-08-18,1993,GB 9012384 A,1990-06-04,US 39082389 A,1989-08-08,BAG WITH AUXILIARY POCKET AND VIEWING WINDOW,,BAGCRAFT CORP,COHEN ALDEN M;;FALTYNEK MARK;;MARSIK RONALD;;RISEMAN DAVID A,,https://lens.org/103-810-055-341-507,Granted Patent,no,7,0,4,4,0,B65D33/04;;B65D33/04;;B65D31/12;;B65D31/12,B65D30/22;;B65D33/04,B8K KXX           KXX;;B8K K2E           KXX;;B8K K2G1          KXX;;B8K K2K2          KXX;;B8K K2K3          KXX;;B8K K2K4          KXX;;B8K K2M           KXX,0,0,,,,EXPIRED
569,US,A,US 5518705 A,180-130-018-158-125,1996-05-21,1996,US 29365394 A,1994-08-22,US 29365394 A,1994-08-22,Method and apparatus for the two-stage selective oxidation of carbon monoxide in a hydrogen-containing gas mixture,"An apparatus and method are provided for the two-stage selective oxidation of carbon monoxide to carbon dioxide in a fuel stream comprising hydrogen and carbon monoxide. The apparatus includes primary and secondary reaction chambers, which deliver a hydrogen-rich outlet gas stream having a carbon monoxide concentration of less than about 5 ppm. When an increase in the carbon monoxide concentration in the outlet stream of the primary reaction chamber is detected, then the flow through the primary reaction chamber is reversed. The selective oxidizer employs a temperature-based control strategy as an oxygen-containing gas stream flow rate adjustment around the flow rate initially set in direct proportion to the fuel gas stream flow rate. The control strategy regulates the amount of oxygen-containing gas mixed with the gaseous fuel stream as a function of the difference between the temperature at a location at or near the end of the primary reaction chamber and the temperature at the outlet of the primary reaction chamber.",BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;COHEN RONALD;;MCNEILLY LEONARD;;WATKINS DAVID S,NUCELLSYS GMBH (2005-08-31);;BALLARD POWER SYSTEMS INC (2008-01-31);;BALLARD POWER SYSTEMS AG (2002-02-26);;FUEL CELL SYSTEMS GMBH (2005-07-29);;BALLARD POWER SYSTEMS INC. (CANADIAN CORP. NO. 7076991) (2009-05-27),https://lens.org/180-130-018-158-125,Granted Patent,yes,9,80,6,6,0,B01D53/864;;B01J8/0446;;C01B3/583;;C01B2203/044;;C01B2203/047;;B01D53/864;;C01B2203/044;;C01B3/583;;B01J8/0446;;C01B2203/047,B01D53/86;;B01J8/04;;C01B3/58,423437M;;423/247;;429/13;;429/24,0,0,,,,EXPIRED
570,CA,A1,CA 2197863 A1,144-393-985-958-506,1996-02-29,1996,CA 2197863 A,1995-08-18,US 29365394 A;;US 9510504 W,1994-08-22,Method and Apparatus for the Oxidation of Carbon Monoxide,,BALLARD POWER SYSTEM INC,MCNEILLY LEONARD;;WATKINS DAVID S;;BUSWELL RICHARD F;;COHEN RONALD,,https://lens.org/144-393-985-958-506,Patent Application,no,0,0,6,6,0,B01D53/864;;B01J8/0446;;C01B3/583;;C01B2203/044;;C01B2203/047;;B01D53/864;;C01B2203/044;;C01B3/583;;B01J8/0446;;C01B2203/047,B01D53/86;;B01J8/04;;C01B3/58,,0,0,,,,EXPIRED
571,CA,C,CA 2197863 C,032-555-446-621-064,2000-04-18,2000,CA 2197863 A,1995-08-18,US 29365394 A;;US 9510504 W,1994-08-22,METHOD AND APPARATUS FOR THE OXIDATION OF CARBON MONOXIDE,"An apparatus and method are provided for the two-stage selective oxidation of carbon monoxide to carbon dioxide in a fuel stream comprising hydrogen and carbon monoxide (21). The apparatus includes primary (11) and secondary (12) reaction chambers, which deliver a hydrogen-rich outlet gas stream having a carbon monoxide concentration of less than about 5 ppm. When an increase in the carbon monoxide concentration in the outlet stream of the primary reaction chamber (11) is detected, then the flow through the primary reaction chamber is reversed. The selective oxidizer (10) employs a temperature-based control strategy (30) as an oxygen-containing gas stream flow rate adjustment around the flow rate initially set in direct proportion to the fuel gas stream flow rate. The control strategy regulates the amount of oxygen-containing gas mixed with the gaseous fuel stream as a function of the difference between the temperature at a location at or near the end of the primary reaction chamber and the temperature at the outlet of the primary reaction chamber.",BALLARD POWER SYSTEMS,COHEN RONALD;;BUSWELL RICHARD F;;MCNEILLY LEONARD;;WATKINS DAVID S,,https://lens.org/032-555-446-621-064,Granted Patent,no,0,0,6,6,0,B01D53/864;;B01J8/0446;;C01B3/583;;C01B2203/044;;C01B2203/047;;B01D53/864;;C01B2203/044;;C01B3/583;;B01J8/0446;;C01B2203/047,B01D53/86;;B01J8/04;;C01B3/58,,0,0,,,,EXPIRED
572,GB,A,GB 2234735 A,123-206-913-510-632,1991-02-13,1991,GB 9012384 A,1990-06-04,US 39082389 A,1989-08-08,BAG WITH AUXILIARY POCKET AND VIEWING WINDOW,,BAGCRAFT CORP,COHEN ALDEN M;;FALTYNEK MARK;;MARSIK RONALD;;RISEMAN DAVID A,,https://lens.org/123-206-913-510-632,Patent Application,no,7,1,4,4,0,B65D33/04;;B65D33/04;;B65D31/12;;B65D31/12,B65D30/22;;B65D33/04,B8K KXX           KXX;;B8K K2E           KXX;;B8K K2G1          KXX;;B8K K2K2          KXX;;B8K K2K3          KXX;;B8K K2K4          KXX;;B8K K2M           KXX,0,0,,,,EXPIRED
573,CA,A1,CA 2029672 A1,081-706-704-253-675,1992-05-10,1992,CA 2029672 A,1990-11-09,CA 2029672 A,1990-11-09,BAG WITH AUXILIARY POCKET AND VIEWING WINDOW,,BAGCRAFT CORP,COHEN ALDEN M;;FALTYNEK MARK;;MARSIK RONALD;;RISEMAN DAVID A,,https://lens.org/081-706-704-253-675,Patent Application,no,0,0,2,2,0,,B65D33/04,D42200005    M,0,0,,,,EXPIRED
574,AU,A,AU 1995/034082 A,039-936-091-942-566,1996-03-14,1996,AU 1995/034082 A,1995-08-18,US 29365394 A;;US 9510504 W,1994-08-22,Method and apparatus for the oxidation of carbon monoxide,,BALLARD POWER SYSTEMS,MCNEILLY LEONARD;;WATKINS DAVID S;;BUSWELL RICHARD F;;COHEN RONALD,,https://lens.org/039-936-091-942-566,Patent Application,no,0,0,6,6,0,B01D53/864;;B01J8/0446;;C01B3/583;;C01B2203/044;;C01B2203/047;;B01D53/864;;C01B2203/044;;C01B3/583;;B01J8/0446;;C01B2203/047,B01D53/86;;B01J8/04;;C01B3/58,,0,0,,,,PENDING
575,WO,A1,WO 2023/104841 A1,080-678-433-802-983,2023-06-15,2023,EP 2022084684 W,2022-12-07,US 202163288553 P;;US 202163292529 P,2021-12-11,REGISTRATION OF INTRALUMINAL PHYSIOLOGICAL DATA TO LONGITUDINAL IMAGE OF BODY LUMEN USING EXTRALUMINAL IMAGING DATA,"A system includes a processor circuit that receives intravascular imaging data from an intravascular imaging catheter, an x-ray image from an x-ray imaging device, and intravascular pressure data from an intravascular pressure-sensing guidewire. The processor circuit correlates the intravascular imaging data and the intravascular pressure data to locations along a body lumen shown in the x-ray image. The processor circuit generates a longitudinal view of the body lumen based on the intravascular imaging data and outputs a screen display including the longitudinal view of the body lumen with an overlaid graphical representation corresponding to the intravascular pressure measurements.",KONINKLIJKE PHILIPS NV;;PHILIPS IMAGE GUIDED THERAPY CORP,COHEN ASHER;;CHAO PEI-YIN;;HELMSTRIJD RONALD CHRISTIAAN;;PREISLER EFRAT,,https://lens.org/080-678-433-802-983,Patent Application,yes,27,0,2,4,0,A61B8/12;;A61B8/5253;;A61B8/5261;;A61B8/463;;A61B6/12;;A61B8/04;;G06T7/30;;A61B5/0215;;A61B6/12;;A61B6/463;;A61B6/5247;;A61B8/12;;G06T7/0012;;G06T7/20;;G06T11/00;;G06T2207/10116;;G06T2207/30104;;G06T2210/41,A61B6/12;;A61B8/00;;A61B8/04;;A61B8/08;;A61B8/12,,0,0,,,,PENDING
576,EP,A2,EP 0423905 A2,166-795-630-988-976,1991-04-24,1991,EP 90202987 A,1988-02-01,US 1359687 A,1987-02-11,Hanger means for a Fuel cell power plant reformer.,"The reformer (2) is designed for use with a large fuel cell power plant capable of producing megawatts of power, as, for example, would be used by a public utility. The catalyst tubes (16) in the reformer (2) have their upper ends at staggered elevations so as to be capable of having their temperatures individually monitored by infrared temperature sensors. The catalyst tubes (16) are mounted on a floating support within the reformer housing (4) so as to be free to undergo expansion and contraction during periods of internal temperature variation as the reformer (2) is operated. The floating support is preferably formed from fuel manifolds suspended in the reformer housing (4). Baffles (64) are included in the reformer housing (4) for evenly distributing heat to the catalyst tube (16) arrays. The reformer has a long burner (56) tube which is approximately the same length as the catalyst tubes (16).  ",INT FUEL CELLS CORP,COHEN RONALD;;FAITANI JOSEPH J;;OLESEN OLE LUMHOLT;;SULJAK GEORGE THOMAS,,https://lens.org/166-795-630-988-976,Patent Application,yes,0,11,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,DISCONTINUED
577,CA,A,CA 953427 A,000-631-924-205-710,1974-08-20,1974,CA 139337 A,1972-04-10,US 15936571 A,1971-07-02,SINGLE DEVICE MEMORY SYSTEM HAVING SHIFT REGISTER OUTPUT CHARACTERISTICS,,GEN INSTRUMENT CORP,SEELY JOHN L;;COHEN LEO;;COLINO RONALD P;;PACE ROBERT E,,https://lens.org/000-631-924-205-710,Granted Patent,no,0,0,4,4,0,G11C8/04;;G11C11/404;;G11C11/4096;;G11C8/04;;G11C11/4096;;G11C11/404,G11C8/04;;G11C11/404;;G11C11/4096,354-237,0,0,,,,EXPIRED
578,AU,A,AU 2001/092963 A,140-845-518-756-285,2002-04-02,2002,AU 2001/092963 A,2001-09-20,US 23541000 P;;US 0129664 W,2000-09-21,Visual display methods for use in computer-animated speech production models,,UNIV CALIFORNIA,MASSARO DOMINIC W;;COHEN MICHAEL M;;BESKOW JONAS;;COLE RONALD A,,https://lens.org/140-845-518-756-285,Patent Application,no,0,0,5,5,0,G06T13/205;;G06T13/40;;G06T2210/56;;G10L2021/105;;G06T13/40;;G06T2210/56;;G06T13/205;;G10L2021/105,G06T13/20;;G06T13/40,,0,0,,,,PENDING
579,US,A1,US 2011/0114403 A1,171-425-910-236-202,2011-05-19,2011,US 90755710 A,2010-10-19,US 90755710 A;;US 25283409 P,2009-10-19,POWERTRAIN FOR HYBRID VEHICLE,"The invention encompasses a drivetrain or powertrain system including a unique, cost-effective, reliable means for creating a hybrid power system that utilizes a vehicle's stock manual transmission. The instant invention has the advantage of eliminating the cost and complexity of sophisticated transmissions, as well as replacing the vehicles starter and alternator. These basic components result in a cost effective, efficient and reliable drive system.",HAUGER SIMON A;;PREISS RONALD A;;DILOSSI GERALD C;;COHEN ANN,HAUGER SIMON A;;PREISS RONALD A;;DILOSSI GERALD C;;COHEN ANN,,https://lens.org/171-425-910-236-202,Patent Application,yes,1,20,1,1,0,B60K6/48;;B60K6/48;;B60K6/387;;B60K6/387;;B60L1/003;;B60L1/003;;B60L1/02;;B60L1/02;;B60L3/003;;B60L3/003;;B60L3/0061;;B60L3/0061;;B60L3/0069;;B60L3/0069;;B60L3/12;;B60L3/12;;B60L7/14;;B60L7/14;;B60L7/26;;B60L7/26;;B60L15/025;;B60L15/025;;B60L15/2009;;B60L15/2009;;B60L50/16;;B60L50/16;;B60L50/64;;B60L50/64;;B60L50/66;;B60L50/66;;B60L58/21;;B60L58/21;;B60L2210/40;;B60L2210/40;;B60L2240/12;;B60L2240/12;;B60L2240/30;;B60L2240/30;;B60L2240/34;;B60L2240/34;;B60L2240/36;;B60L2240/36;;B60L2240/421;;B60L2240/421;;B60L2240/423;;B60L2240/423;;B60L2240/441;;B60L2240/441;;B60L2240/443;;B60L2240/443;;B60L2240/547;;B60L2240/547;;B60L2240/80;;B60L2240/80;;B60L2250/16;;B60L2250/16;;B60L2250/26;;B60L2250/26;;F16H2057/02065;;F16H2057/02065;;Y02T10/62;;Y02T10/62;;Y02T10/64;;Y02T10/64;;Y02T10/70;;Y02T10/70;;Y02T10/7072;;Y02T10/7072;;Y02T10/72;;Y02T10/72;;Y02T90/12;;Y02T90/14,B60K6/48,180/65.25;;180/65.27;;903/903,0,0,,,,DISCONTINUED
580,EP,A3,EP 0423905 A3,153-904-186-130-639,1991-06-26,1991,EP 90202987 A,1988-02-01,US 1359687 A,1987-02-11,FUEL CELL POWER PLANT REFORMER,"The reformer (2) is designed for use with a large fuel cell power plant capable of producing megawatts of power, as, for example, would be used by a public utility. The catalyst tubes (16) in the reformer (2) have their upper ends at staggered elevations so as to be capable of having their temperatures individually monitored by infrared temperature sensors. The catalyst tubes (16) are mounted on a floating support within the reformer housing (4) so as to be free to undergo expansion and contraction during periods of internal temperature variation as the reformer (2) is operated. The floating support is preferably formed from fuel manifolds suspended in the reformer housing (4). Baffles (64) are included in the reformer housing (4) for evenly distributing heat to the catalyst tube (16) arrays. The reformer has a long burner (56) tube which is approximately the same length as the catalyst tubes (16).  ",INTERNATIONAL FUEL CELLS CORPORATION,"COHEN, RONALD;;FAITANI, JOSEPH J.;;OLESEN, OLE LUMHOLT;;SULJAK, GEORGE THOMAS",,https://lens.org/153-904-186-130-639,Search Report,yes,5,0,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,DISCONTINUED
581,US,A1,US 2012/0072899 A1,152-406-576-524-336,2012-03-22,2012,US 88599210 A,2010-09-20,US 88599210 A,2010-09-20,Conversion System And Method For Use In Upgrading A Monitoring System,"A conversion system for use with a first monitoring system includes an interface module for receiving a plurality of hardware configuration settings associated with the first monitoring system and a conversion module coupled to the interface module for converting the plurality of hardware configuration settings into a plurality of software configuration settings for use in a second monitoring system. The plurality of hardware configuration settings are established to enable the first monitoring system to monitor the operation of a first machine, and the plurality of software configuration settings are established to enable the second monitoring system to monitor the operation of at least one of the first machine and a second machine.",COHEN MITCHELL DEAN;;WILSON RONALD;;TRAN HAN;;OGLES CHARLES;;BOYER LANDON,COHEN MITCHELL DEAN;;WILSON RONALD;;TRAN HAN;;OGLES CHARLES;;BOYER LANDON,BAKER HUGHES A GE COMPANY LLC (2017-07-03);;GENERAL ELECTRIC COMPANY (2010-09-20),https://lens.org/152-406-576-524-336,Patent Application,yes,7,3,5,5,0,H04L41/0846;;H04L67/125;;H04L67/12;;H04L41/0823;;H04L67/565;;H04L41/0846;;H04L67/125;;H04L67/12;;H04L67/565;;H04L41/0823,G06F9/44,717/173,0,0,,,,ACTIVE
582,US,A1,US 2013/0210644 A1,184-736-080-910-13X,2013-08-15,2013,US 201313863992 A,2013-04-16,US 201313863992 A;;US 75194010 A;;US 76313307 A;;US 82077806 P;;US 80481606 P,2006-06-14,FETAL ANEUPLOIDY DETECTION BY SEQUENCING,"The present invention provides apparatus and methods for enriching components or cells from a sample and conducting genetic analysis, such as SNP genotyping to provide diagnostic results for fetal disorders or conditions.",STOUGHTON ROLAND;;KAPUR RAVI;;TONER MEHMET;;DAVIS RONALD;;COHEN BARB ARIEL,STOUGHTON ROLAND;;KAPUR RAVI;;TONER MEHMET;;DAVIS RONALD;;COHEN BARB ARIEL,ARTEMIS HEALTH INC (2006-06-20);;VERINATA HEALTH INC (2011-09-17);;GPB SCIENTIFIC LLC (2011-09-20);;THE GENERAL HOSPITAL CORPORATION (2006-08-15),https://lens.org/184-736-080-910-13X,Patent Application,yes,0,80,13,99,9,C12Q2600/156;;C12Q1/6883;;C12Q2600/156;;C12Q1/6883;;C12Q1/6874,C12Q1/68,506/2,0,0,,,,DISCONTINUED
583,EP,A1,EP 0278891 A1,035-019-304-278-061,1988-08-17,1988,EP 88630015 A,1988-02-01,US 1359687 A,1987-02-11,Fuel cell power plant reformer.,"The reformer (2) is designed for use with a large fuel cell power plant capable of producing megawatts of power, as, for example, would be used by a public utility. The catalyst tubes (16) in the reformer (2) have their upper ends at staggered elevations so as to be capable of having their temperatures individually monitored by infrared temperature sensors. The catalyst tubes (16) are mounted on a floating support within the reformer housing (4) so as to be free to undergo expansion and contraction during periods of internal temperature variation as the reformer (2) is operated. The floating support is preferably formed from fuel manifolds suspended in the reformer housing (4). Baffles (64) are included in the reformer housing (4) for evenly distributing heat to the catalyst tube (16) arrays. The reformer has a long burner (56) tube which is approximately the same length as the catalyst tubes (16).  ",INT FUEL CELLS CORP,COHEN RONALD;;FAITANI JOSEPH J;;OLESEN OLE LUMHOLT;;SULJAK GEORGE THOMAS,,https://lens.org/035-019-304-278-061,Patent Application,yes,4,1,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
584,EP,B1,EP 0278891 B1,018-879-211-679-88X,1992-09-23,1992,EP 88630015 A,1988-02-01,US 1359687 A,1987-02-11,FUEL CELL POWER PLANT REFORMER,,INTERNATIONAL FUEL CELLS CORPORATION,"COHEN, RONALD;;FAITANI, JOSEPH J.;;OLESEN, OLE LUMHOLT;;SULJAK, GEORGE THOMAS",,https://lens.org/018-879-211-679-88X,Granted Patent,yes,4,0,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
585,EP,A1,EP 2432159 A1,030-626-351-018-433,2012-03-21,2012,EP 11180142 A,2011-09-06,US 88599210 A,2010-09-20,Conversion system and method for use in upgrading a monitoring system,"A conversion system (300) for use with a first monitoring system (404) is provided. The conversion system includes an interface module (400) for receiving a plurality of hardware configuration settings associated with the first monitoring system, wherein the plurality of hardware configuration settings are established to enable the first monitoring system to monitor the operation of a first machine, and a conversion module (402) coupled to the interface module for converting the plurality of hardware configuration settings into a plurality of software configuration settings for use in a second monitoring system (406), wherein the plurality of software configuration settings are established to enable the second monitoring system to monitor the operation of at least one of the first machine and a second machine.
",GEN ELECTRIC,COHEN MITCHELL DEAN;;WILSON RONALD;;TRAN HAN;;OGLES CHARLES;;BOYER LANDON,,https://lens.org/030-626-351-018-433,Patent Application,yes,1,0,5,5,0,H04L41/0846;;H04L67/125;;H04L67/12;;H04L41/0823;;H04L67/565;;H04L41/0846;;H04L67/125;;H04L67/12;;H04L67/565;;H04L41/0823,H04L12/24;;G05B19/042;;G06F17/22;;G06F17/30,,2,1,080-675-512-041-568,10.1109/lescpe.2003.1204674,"KOSTIC T ET AL: ""TOWARDS THE FORMAL INTEGRATION OF TWO UPCOMING STANDARDS: IEC61970 AND IEC61850"", LESCOPE. LARGE ENGINEERING SYSTEMS CONFERENCE ON POWERENGINEERING CONFERENCE PROCEEDINGS. ENERGY FOR THE FUTURE, XX, XX, 7 May 2003 (2003-05-07), pages 24 - 29, XP008050807;;KEZUNOVI M ET AL: ""Automated Monitoring and Control Using New Data Integration Paradigm"", 20050103; 20050103 - 20050106, 3 January 2005 (2005-01-03), pages 66A - 66A, XP010762451",DISCONTINUED
586,US,B1,US 10620845 B1,033-718-725-023-171,2020-04-14,2020,US 201514674816 A,2015-03-31,US 201514674816 A,2015-03-31,Out of band I/O transfers,"Handling I/O operations between a plurality of virtual machines and a plurality of data storage volumes containing data for the virtual machines includes the virtual machines accessing a virtual data storage cluster engine that transfers I/O data between the virtual machines and the data storage volumes and caches at least some of the I/O data, where the virtual data storage cluster appears as a data storage volume to the virtual machines and includes drivers of at least some of the virtual machines routing at least some I/O operations directly to the volumes, where data for I/O operations that is directly routed does not pass through the virtual data storage cluster engine. Drivers for at least one of the virtual machines on a local site may communicate with drivers on a remote site in response to performing an I/O operation with at least one volume on the remote site.",EMC IP HOLDING CO LLC,NATANZON ASSAF;;COHEN SAAR;;UNRAU RONALD C;;LAKE BRIAN;;YE QINGHUA,EMC CORPORATION (2019-01-29);;EMC IP HOLDING COMPANY LLC (2016-09-06),https://lens.org/033-718-725-023-171,Granted Patent,yes,10,0,1,1,0,G06F3/0613;;G06F9/45558;;G06F3/0665;;G06F3/067;;G06F3/0689;;G06F9/45545;;G06F12/0868;;G06F12/0868;;G06F12/1036;;G06F2009/45579;;G06F2009/45583;;G06F2212/604;;G06F2212/604,G06F3/06;;G06F9/455;;G06F12/0868,,5,0,,,"“EMC RecoverPoint Continuous Remote Replication with EMC VPLEX”, EMC whitepaper, Jan. 2011.;;Dharma, R., & Jiang, L. “Networking for Storage Virtualization and EMC RecoverPoint” EMC Techbooks, 2011.;;Shulz, G. “EMC VPLEX: Virtual Storage Redefined or Respun” StoragelOblog, storageioblog.com /emc-vplex-virtual-storage-redefined-or-respun, May 10, 2010.;;Freund, D. “EMC Invista” Illuminata, Jun. 17, 2005.;;Lowe, S. “A Deeper Look at VPLEX”, Scott's Weblog, Jun. 7, 2010.",ACTIVE
587,DE,A1,DE 2604981 A1,055-797-493-113-990,1976-08-26,1976,DE 2604981 A,1976-02-09,US 54959775 A;;US 54959875 A;;US 54960075 A;;US 54960175 A,1975-02-12,UNTER DRUCK BETRIEBENE BRENNSTOFFZELLENSTROMVERSORGUNGSANLAGEN,,UNITED TECHNOLOGIES CORP,BLOOMFIELD DAVID PETER;;COHEN RONALD;;LANDAU MICHAEL BERNARD;;MENARD MAURICE CLEMENT,,https://lens.org/055-797-493-113-990,Patent Application,no,4,1,7,38,0,F02C6/00;;F02C6/10;;H01M8/0612;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;Y02E60/50;;Y02T50/60,F01K23/00;;F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
588,WO,B1,WO 2002/025595 B1,111-433-694-487-683,2002-07-04,2002,US 0129664 W,2001-09-20,US 23541000 P,2000-09-21,VISUAL DISPLAY METHODS FOR USE IN COMPUTER-ANIMATED SPEECH PRODUCTION MODELS,"A method of modeling speech distinctions within computer-animated talking heads (10) that utilize the manipulation of speech production articulators for selected speech segments. Graphical representations of voice characteristics and speech production characteristics are generated in response to said speech segment. by way of example, breath images are generated such as particle-cloud images (12, 14, 16, 18, 20), and particle-stream images (40, 42, 46, 48, 50, 52, 54) to represent the voiced characteristics such as the presence of stops and fricatives, respectively. The coloring on exterior portions of the talking head is displayed in response to selected voice characteristics such as nasality. The external physiology of the talking head is modulated, such as by changing the width and movement of the nose, the position of the eyebrows, and movement of the throat in response to the voiced speech characteristics such as pitch, nasality, and voicebox vibration, respectively. The invention also describes modeling a talking head on the facial image of a particular individual.",UNIV CALIFORNIA,MASSARO DOMINIC W;;COHEN MICHAEL M;;BESKOW JONAS;;COLE RONALD A,,https://lens.org/111-433-694-487-683,Patent Application,no,0,0,5,5,0,G06T13/205;;G06T13/40;;G06T2210/56;;G10L2021/105;;G06T13/40;;G06T2210/56;;G06T13/205;;G10L2021/105,G06T13/20;;G06T13/40,,0,0,,,,PENDING
589,ES,T3,ES 2034351 T3,134-965-734-658-339,1993-04-01,1993,ES 88630015 T,1988-02-01,US 1359687 A,1987-02-11,CONVERTIDORES PARA PLANTAS DE ENERGIA DE CELULAS DE COMBUSTIBLE.,"EL REFORMADOR (2) ESTA DISEÑADO PARA USAR CON UNA GRAN CENTRAL ELECTRICA DE CELULA DE COMBUSTIAN PARA PRODUCIR MEGAWATIOS DE POTENCIA COMO, POR EJEMPLO, SERIA PARA USAR EN SEVIVIO PUBLICO. LOS TUBOS DE CATALIZADOR (16) EN EL REFORMADOR (2) TIENEN SUS EXTREMOS SUPERIORES EN ELEVACIONES ESCALONADAS, DE MODO QUE SON CAPACES DE TENER SUS TEMPERATURAS CONTROLADAS INDIVIDUALMENTE POR SENSORES DE TEMPERATURA INFRARROJOS. LOS TUBOS DE CATALIZADOR (16) ESTAN INSTALADOS SOBRE UN SOPORTE FLOTANTE DENTRO DE LA CAJA (4) DEL REFORMADOR, DE MODO QUE PUEDEN SUFRIR EXPANSION Y CONTRACCION DURANTE PERIODOS DE VARIACION DE TEMPERATURA INTERNA, CUANDO EL REFORMADOR (2) ESTA TRABAJANDO. EL SOPORTE FLOTANTE ESTA FORMADO PREFERIBLEMENTE DE MULTIPLES DE COMBUSTIBLE SUSPENDIDOS EN LA CAJA (4) DEL REFORMADOR. SE INCLUYEN DEFLECTORES (64) EN LA CAJA (4) DEL REFORMADOR PARA DISTRIBUIR IGUALITARIAMENTE EL CALOR A LOS CONJUNTOS DE TUBOS DE CATALIZADOR (16). EL REFORMADOR TIENE UN LARGO TUBO DE MECHERO (56), QUE TIENE APROXIMADAMENTE LA MISMA LONGITUD QUE LOS TUBOS DE CATALIZADOR (16).",INTERNATIONAL FUEL CELLS CORPORATION,"COHEN, RONALD;;FAITANI, JOSEPH J.;;OLESEN, OLE LUMHOLT;;SULJAK, GEORGE THOMAS",,https://lens.org/134-965-734-658-339,Granted Patent,no,0,0,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
590,CA,C,CA 1292507 C,005-537-187-669-435,1991-11-26,1991,CA 558024 A,1988-02-03,US 1359687 A,1987-02-11,FUEL CELL POWER PLANT REFORMER,"Fuel Cell Power Plant Reformer The reformer is designed for use with a large fuel cell power plant capable of producing megawatts of power, as, for example, would be used by a public utility. The catalyst tubes in the reformer have their upper ends at staggered elevations so as to be capable of having their temperatures individually monitored by infrared temperature sensors. The catalyst tubes are mounted on a floating support within the reformer housing so as to be free to undergo expansion and contraction during periods of internal temperature variation as the reformer is operated. The floating support is preferably formed from fuel manifolds suspended in the reformer housing. Baffles are included in the reformer housing for evenly distributing heat to the catalyst tube arrays. The reformer has a long burner tube which is approximately the same length as the catalyst tubes.",INT FUEL CELLS CORP,COHEN RONALD;;OLESEN OLE L;;FAITANI JOSEPH J;;SULJAK GEORGE T,,https://lens.org/005-537-187-669-435,Granted Patent,no,0,0,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,D33190005    M,0,0,,,,EXPIRED
591,US,A,US 4820314 A,032-641-810-571-923,1989-04-11,1989,US 1359687 A,1987-02-11,US 1359687 A,1987-02-11,Fuel cell power plant reformer,"The reformer is designed for use with a large fuel cell power plant capable of producing megawatts of power, as, for example, would be used by a public utility. The catalyst tubes in the reformer have their upper ends at staggered elevations so as to be capable of having their temperatures individually monitored by infrared temperature sensors. The catalyst tubes are mounted on a floating support within the reformer housing so as to be free to undergo expansion and contraction during periods of internal temperature variation as the reformer is operated. The floating support is preferably formed from fuel manifolds suspended in the reformer housing. Baffles are included in the reformer housing for evenly distributing heat to the catalyst tube arrays. The reformer has a long burner tube which is approximately the same length as the catalyst tubes.",INT FUEL CELLS CORP,COHEN RONALD;;OLESEN OLE L;;FAINTANI JOSEPH J;;SULJAK GEORGE T,INTERNATIONAL FUEL CELLS CORPORTION SOUTH WINDSOR CT A CORP. OF MD (1987-02-04),https://lens.org/032-641-810-571-923,Granted Patent,yes,17,53,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,48/94;;X 48196A;;122/510;;422/110;;422/197;;422/204,0,0,,,,EXPIRED
592,DE,T2,DE 3874768 T2,109-582-850-678-009,1993-04-29,1993,DE 3874768 T,1988-02-01,US 1359687 A,1987-02-11,REFORMER FUER BRENNSTOFFZELLENKRAFTWERK.,,INT FUEL CELLS CORP,COHEN RONALD;;FAITANI JOSEPH J;;OLESEN OLE LUMHOLT;;SULJAK GEORGE THOMAS,,https://lens.org/109-582-850-678-009,Granted Patent,no,0,0,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
593,FR,A1,FR 2301106 A1,031-620-454-690-838,1976-09-10,1976,FR 7603697 A,1976-02-11,US 54959775 A;;US 54959875 A;;US 54960075 A;;US 54960175 A,1975-02-12,"INSTALLATION DE PRODUCTION D'ENERGIE A PILES A COMBUSTIBLE, SOUS PRESSION",,UNITED TECHNOLOGIES CORP,BLOOMFIELD DAVID PETER;;COHEN RONALD;;LANDAU MICHAEL BERNARD;;MENARD MAURICE CLEMENT,,https://lens.org/031-620-454-690-838,Patent Application,no,3,7,7,38,0,F02C6/00;;F02C6/10;;H01M8/0612;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;Y02E60/50;;Y02T50/60,F01K23/00;;F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
594,WO,A1,WO 2002/025595 A1,083-735-613-171-848,2002-03-28,2002,US 0129664 W,2001-09-20,US 23541000 P,2000-09-21,VISUAL DISPLAY METHODS FOR USE IN COMPUTER-ANIMATED SPEECH PRODUCTION MODELS,"A method of modeling speech distinctions within computer-animated talking heads (10) that utilize the manipulation of speech production articulators for selected speech segments. Graphical representations of voice characteristics and speech production characteristics are generated in response to said speech segment. by way of example, breath images are generated such as particle-cloud images (12, 14, 16, 18, 20), and particle-stream images (40, 42, 46, 48, 50, 52, 54) to represent the voiced characteristics such as the presence of stops and fricatives, respectively. The coloring on exterior portions of the talking head is displayed in response to selected voice characteristics such as nasality. The external physiology of the talking head is modulated, such as by changing the width and movement of the nose, the position of the eyebrows, and movement of the throat in response to the voiced speech characteristics such as pitch, nasality, and voicebox vibration, respectively. The invention also describes modeling a talking head on the facial image of a particular individual.",UNIV CALIFORNIA,MASSARO DOMINIC W;;COHEN MICHAEL M;;BESKOW JONAS;;COLE RONALD A,,https://lens.org/083-735-613-171-848,Patent Application,yes,3,0,5,5,0,G06T13/205;;G06T13/40;;G06T2210/56;;G10L2021/105;;G06T13/40;;G06T2210/56;;G06T13/205;;G10L2021/105,G06T13/20;;G06T13/40,,0,0,,,,PENDING
595,CN,A,CN 102411529 A,135-774-093-101-753,2012-04-11,2012,CN 201110293265 A,2011-09-20,US 88599210 A,2010-09-20,Conversion system and method for use in upgrading monitoring system,"The invention relates to a conversion system and method for use in upgrading a monitoring system. The conversion system (300) for use with a first monitoring system (404) is provided. The conversion system includes an interface module (400) for receiving a plurality of hardware configuration settings associated with the first monitoring system, wherein the plurality of hardware configuration settings are established to enable the first monitoring system to monitor the operation of a first machine, and a conversion module (402) coupled to the interface module for converting the plurality of hardware configuration settings into a plurality of software configuration settings for use in a second monitoring system (406), wherein the plurality of software configuration settings are established to enable the second monitoring system to monitor the operation of at least one of the first machine and a second machine.",GEN ELECTRIC,DEAN COHEN MITCHELL;;RONALD WILSON;;HAN TRAN;;CHARLES OGLES;;LANDON BOYER,,https://lens.org/135-774-093-101-753,Patent Application,no,5,0,5,5,0,H04L41/0846;;H04L67/125;;H04L67/12;;H04L41/0823;;H04L67/565;;H04L41/0846;;H04L67/125;;H04L67/12;;H04L67/565;;H04L41/0823,G06F11/30,,2,0,,,"KOSTIC T ET AL.: ""《2003 Large Engineering Systems Conference on Power Engineering（LESCOP）》"", 9 May 2003;;KEZUNOVI M ET AL.: ""《System Science,2005.HICSS’05.》"", 6 January 2005",DISCONTINUED
596,US,B2,US 8910143 B2,164-992-353-374-158,2014-12-09,2014,US 88599210 A,2010-09-20,US 88599210 A,2010-09-20,Conversion system and method for use in upgrading a monitoring system,"A conversion system for use with a first monitoring system includes an interface module for receiving a plurality of hardware configuration settings associated with the first monitoring system and a conversion module coupled to the interface module for converting the plurality of hardware configuration settings into a plurality of software configuration settings for use in a second monitoring system. The plurality of hardware configuration settings are established to enable the first monitoring system to monitor the operation of a first machine, and the plurality of software configuration settings are established to enable the second monitoring system to monitor the operation of at least one of the first machine and a second machine.",COHEN MITCHELL DEAN;;WILSON RONALD;;TRAN HAN;;OGLES CHARLES;;BOYER LANDON;;GEN ELECTRIC,COHEN MITCHELL DEAN;;WILSON RONALD;;TRAN HAN;;OGLES CHARLES;;BOYER LANDON,BAKER HUGHES A GE COMPANY LLC (2017-07-03);;GENERAL ELECTRIC COMPANY (2010-09-20),https://lens.org/164-992-353-374-158,Granted Patent,yes,19,97,5,5,0,H04L41/0846;;H04L67/125;;H04L67/12;;H04L41/0823;;H04L67/565;;H04L41/0846;;H04L67/125;;H04L67/12;;H04L67/565;;H04L41/0823,G06F3/00;;G06F9/445;;G06F9/00;;G06F9/45;;H04L12/24;;H04L29/08,717/174;;717/136;;713/1;;713/100;;719/327,3,0,,,"Search Report and Written Opinion from corresponding EP Application No. 11180142.9-1225 dated Dec. 19, 2011.;;Kostic, T. et al., ""Towards the Formal Integration of Two Upcoming Standards: IEC61970 and IEC61850"", Lescope. Large Engineering Systems Conference on Powerengineering Conference Proceedings. Energy for the Future, XX, XX, pp. 24-29, May 7, 2003.;;Kezunovi, M. et al., ""Automated Monitoring and Control Using New Data Integration Paradigm"", 20050103; 20050103-20050106, pp. 66A-66A, Jan. 3, 2005.",ACTIVE
597,DE,D1,DE 3874768 D1,109-671-732-452-396,1992-10-29,1992,DE 3874768 T,1988-02-01,US 1359687 A,1987-02-11,REFORMER FUER BRENNSTOFFZELLENKRAFTWERK.,,INT FUEL CELLS CORP,COHEN RONALD;;FAITANI JOSEPH J;;OLESEN OLE LUMHOLT;;SULJAK GEORGE THOMAS,,https://lens.org/109-671-732-452-396,Granted Patent,no,0,0,11,11,0,B01J8/008;;B01J8/062;;C01B3/26;;C01B3/384;;C01B2203/0227;;C01B2203/066;;C01B2203/0811;;C01B2203/0816;;C01B2203/0866;;C01B2203/1011;;C01B2203/1619;;H01M8/0631;;Y02E60/50;;H01M8/0631;;C01B2203/0816;;B01J8/008;;C01B2203/1011;;B01J8/062;;C01B2203/0866;;C01B2203/1619;;C01B2203/0811;;C01B2203/066;;C01B3/26;;C01B2203/0227;;C01B3/384,B01J8/00;;B01J8/06;;C01B3/26;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
598,EP,B1,EP 0256887 B1,016-064-797-125-146,1996-05-22,1996,EP 87307310 A,1987-08-18,US 89760386 A,1986-08-18,A method of characterizing the dynamic response of the Autonomic Nervous System.,,MASSACHUSETTS INST TECHNOLOGY,BERGER RONALD D;;CHEN MING HUI;;COHEN RICHARD J;;SAUL JEROME P,,https://lens.org/016-064-797-125-146,Granted Patent,yes,0,0,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,,2,2,002-292-907-360-283;;127-881-119-969-790,5937544;;10.1161/01.res.18.5.585;;10.1152/ajpheart.1985.248.1.h151;;3970172,"CIRCULATION RESEARCH vol. 18, 1966, pages 585-595; G.M Taylor et al.: ""Use of Random Excitation and Spectral Analysis in the Study of Frequency-Dependent Parameters of the Cardiovascular System"";;AMERICAN JOURNAL OF PHYSIOLOGY vol. 248, 1985, pages H151-H153; B. POMERANZ et al.: ""Assessment of autnomic function in humans by heart rate spectral analysis""",EXPIRED
599,EP,A3,EP 0256887 A3,149-632-394-667-704,1989-07-26,1989,EP 87307310 A,1987-08-18,US 89760386 A,1986-08-18,METHOD AND APPARATUS FOR THE ASSESSMENT OF AUTONOMIC RESPONSE BY BROAD-BAND EXCITATION,"This invention provides a rapid, noninvasive technique for quantifying the dynamic response of the autonomic nervous system (ANS) to perturbations it senses over a broad range of physiologically relevant frequencies. The technique involves two steps. First, a physiologic parameter sensed by the ANS is subjected to a broad-band perturbation as an input signal while a physiologic parameter modulated by the ANS is monitored as an output signal. Then, the transfer relation between input signal and output signal is determined. The computed transfer relation is then readily interpretable in terms of responsiveness of the various limbs of the ANS.  ",MASSACHUSETTS INSTITUTE OF TECHNOLOGY,"BERGER, RONALD D.;;CHEN, MING HUI;;COHEN, RICHARD J.;;SAUL, JEROME P.",,https://lens.org/149-632-394-667-704,Search Report,yes,1,0,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,,2,0,,,CIRCULATION RESEARCH;;AMERICAN JOURNAL OF PHYSIOLOGY,EXPIRED
600,WO,A1,WO 2009/089138 A1,199-428-631-236-875,2009-07-16,2009,US 2009/0030085 W,2009-01-05,US 1904308 P,2008-01-04,ORAL ADMINISTRATION OF IXABEPILONE,"Novel uses of administering ixabepilone are provided, namely, the oral administration of ixabepilone with surprising efficacy to safety profiles, comprising splitting the oral dose into to or more daily unit dosages administered on an intermittent dosing cycle.",BRISTOL MYERS SQUIBB CO;;LEE DAVID CHUAN;;LEE FRANCIS Y;;COHEN MARVIN BARRY;;PECK RONALD A,LEE DAVID CHUAN;;LEE FRANCIS Y;;COHEN MARVIN BARRY;;PECK RONALD A,,https://lens.org/199-428-631-236-875,Patent Application,yes,3,0,1,1,0,A61K31/427;;A61P35/00,A61K31/427;;A61P35/00,,0,0,,,,PENDING
601,EP,A2,EP 0256887 A2,026-107-525-704-398,1988-02-24,1988,EP 87307310 A,1987-08-18,US 89760386 A,1986-08-18,Method and apparatus for the assessment of autonomic response by broad-band excitation.,"This invention provides a rapid, noninvasive technique for quantifying the dynamic response of the autonomic nervous system (ANS) to perturbations it senses over a broad range of physiologically relevant frequencies. The technique involves two steps. First, a physiologic parameter sensed by the ANS is subjected to a broad-band perturbation as an input signal while a physiologic parameter modulated by the ANS is monitored as an output signal. Then, the transfer relation between input signal and output signal is determined. The computed transfer relation is then readily interpretable in terms of responsiveness of the various limbs of the ANS.  ",MASSACHUSETTS INST TECHNOLOGY,BERGER RONALD D;;CHEN MING HUI;;COHEN RICHARD J;;SAUL JEROME P,,https://lens.org/026-107-525-704-398,Patent Application,yes,0,2,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,,0,0,,,,EXPIRED
602,CA,C,CA 2162189 C,073-848-938-283-301,2003-08-12,2003,CA 2162189 A,1995-11-06,US 34509994 A,1994-11-28,INSULATOR FOR INTEGRATED CIRCUITS AND PROCESS,"An insulator for covering an interconnection wiring level in a surface there of on a semiconductor substrate containing semiconductor devices formed by curing a flowable oxide layer and annealing. The annealing is carried out in the presence of hydroge n and aluminum to obtain a dielectric constant of the oxide layer to a value below 3.2. Als o provided is electrical insulation between neighboring devices using the flowable oxide w hich is cured and annealed. In this case, the annealing can be carried out in hydrogen with or without the presence of aluminum.",IBM,COHEN STEPHAN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT;;BALLANCE DAVID S,,https://lens.org/073-848-938-283-301,Granted Patent,no,0,0,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,,0,0,,,,EXPIRED
603,CA,C,CA 1298656 C,170-336-963-518-990,1992-04-07,1992,CA 544674 A,1987-08-17,US 89760386 A,1986-08-18,METHOD AND APPARATUS FOR THE ASSESSMENT OF AUTONOMIC RESPONSE BY BROAD-BAND EXCITATION,"This invention provides a rapid, noninvasive technique for quantifying the dynamic response of the autonomic nervous system (ANS) to perturbations it senses over a broad range of physiologically relevant frequencies. The technique involves two steps. First, a physiologic parameter sensed by the ANS is subjected to a broad-band perturbation as an input signal while a physiologic parameter modulated by the ANS is monitored as an output signal. Then, the transfer relation between input signal and output signal is determined. The computed transfer relation is then readily interpretable in terms of responsiveness of the various limbs of the ANS.",MASSACHUSETTS INST TECHNOLOGY,BERGER RONALD D;;SAUL JEROME P;;CHEN MING H;;COHEN RICHARD J,,https://lens.org/170-336-963-518-990,Granted Patent,no,0,0,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,D23540022    M;;3260013    S;;32600136   S,0,0,,,,EXPIRED
604,US,A,US 5530293 A,013-724-562-393-869,1996-06-25,1996,US 34509994 A,1994-11-28,US 34509994 A,1994-11-28,Carbon-free hydrogen silsesquioxane with dielectric constant less than 3.2 annealed in hydrogen for integrated circuits,"An insulator for covering an interconnection wiring level in a surface thereof on a semiconductor substrate containing semiconductor devices formed by curing a flowable oxide layer and annealing is provided. The annealing is carried out in the presence of hydrogen and aluminum to obtain a dielectric constant of the oxide layer to a value below 3.2. Also provided is electrical insulation between neighboring devices using the flowable oxide which is cured and annealed. In this case, the annealing can be carried out in hydrogen with or without the presence of aluminum.",IBM,COHEN STEPHAN A;;MCGAHAY VINCENT J;;UTTECHT RONALD R;;BALLANCE DAVID S,IBM CORPORATION (1994-11-29),https://lens.org/013-724-562-393-869,Granted Patent,yes,8,74,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,257/752;;257/642,3,0,,,"Wolf et al., Silicon Processing for the VLSI Era, vol. 1, Process Technology, Lattice Press, Sunset Beach, CA, pp. 220 223.;;Pramanik et al., Reliability of Multilevel Circuits Using Hydrogen Silsesquioxane FO x for Interlevel Dielectric Planarization , Jun. 8 9, 1993 VMIC Conference, 1993 ISMIC 102/93/0329, pp. 329 331.;;Ballance et al., Low Temperature Reflow Planarization Using a Novel Spin on Interlevel Dielectric , Dow Corning Corporation, Fremont, CA, VMIC Conference, Jun. 9, 1992.",EXPIRED
605,US,B1,US 6559046 B1,060-005-984-907-843,2003-05-06,2003,US 88342797 A,1997-06-26,US 88342797 A;;US 61005996 A;;US 34509994 A,1994-11-28,Insulator for integrated circuits and process,"
    An insulator for covering an interconnection wiring level in a surface thereof on a semiconductor substrate containing semiconductor devices formed by curing a flowable oxide layer and annealing. The annealing is carried out in the presence of hydrogen and aluminum to obtain a dielectric constant of the oxide layer to a value below 3.2. 

    Also provided is electrical insulation between neighboring devices using the flowable oxide which is cured and annealed. In this case, the annealing can be carried out in hydrogen with or without the presence of aluminum. 
",IBM,COHEN STEPHAN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT;;BALLANCE DAVID S,DOW CORNING CORPORATION (1998-09-18),https://lens.org/060-005-984-907-843,Granted Patent,yes,22,3,10,10,0,H01L21/31;;H01L23/5329;;H01L23/5329;;H01L21/76224;;H01L21/76224;;H01L23/5222;;H01L23/5222;;H01L2924/0002;;H01L2924/0002,H01L21/768;;H01L21/316;;H01L21/762;;H01L23/522;;H01L23/532,438/624,4,0,,,"Wolf, Stanley, Silicon Processing for the VLSI Era, vol. 2, Lattice Press, 1990, pp. 188-191.*;;Wolf et al., Silicon Processing for the VLSI Era, vol. 1, Process Technology, Lattice Press, Sunset Beach, CA, pp. 220-223.;;Pramanik et al., ""Reliability of Multilevel Circuits Using Hydrogen Silsesquioxane FOx for Interlevel Dielectric Planarization,"" Jun. 8-9, 1993 VMIC Conference, 1993 ISMIC-102/93/0329, pp. 329-331.;;Ballance et al., ""Low Temperature Reflow Planarization Using a Novel Spin-on Interlevel Dielectric,"" Dow Corning Corporation, Fremont, CA, VMIC Conference, Jun. 9, 1992.",EXPIRED
606,DE,D1,DE 3751813 D1,016-873-197-875-293,1996-06-27,1996,DE 3751813 T,1987-08-18,US 89760386 A,1986-08-18,Ein Verfahren zum Kennzeichnen der dynamischer Reaktion des ANS.,,MASSACHUSETTS INST TECHNOLOGY,BERGER RONALD D;;CHEN MING HUI;;COHEN RICHARD J;;SAUL JEROME P,,https://lens.org/016-873-197-875-293,Granted Patent,no,0,0,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,,0,0,,,,EXPIRED
607,US,A,US 4777960 A,108-129-081-526-307,1988-10-18,1988,US 89760386 A,1986-08-18,US 89760386 A,1986-08-18,Method and apparatus for the assessment of autonomic response by broad-band excitation,"A rapid, noninvasive technique for quantifying the dynamic response of the autonomic nervous system (ANS) to perturbations it senses over a broad range of physiologically relevant frequencies. The technique involves two steps. First, a physiologic parameter sensed by the ANS is subjected to a broad-band perturbation as an input signal while a physiologic parameter modulated by the ANS is monitored as an output signal. Then, the transfer relation between input signal and output signal is determined. The computed transfer relation is then readily interpretable in terms of responsiveness of the various limbs of the ANS.",MASSACHUSETTS INST TECHNOLOGY,BERGER RONALD D;;SAUL JEROME P;;CHEN MING H;;COHEN RICHARD J,MASACHUSETTS INSTITUTE OF TECHNOLOGY A CORP. OF MA (1986-09-15);;UNITED STATES OF AMERICA THE AS REPRESENTED BY THE NATIONAL AERONAUTICS AND SPACE ADMINISTRATION (1991-09-10),https://lens.org/108-129-081-526-307,Granted Patent,yes,6,115,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,128/706;;128/670;;128/671;;128/741;;128/732;;364/413.03;;364/413.06,0,0,,,,EXPIRED
608,US,A,US 5523163 A,104-938-162-126-828,1996-06-04,1996,US 40242895 A,1995-03-10,US 40242895 A;;US 12452993 A,1993-09-22,Low dielectric constant coatings,Disclosed are Si--O containing ceramics having a dielectric constant less than or equal to about 3.2 which is stable over time. These properties render the ceramics valuable on electronic substrates.,DOW CORNING,BALLANCE DAVID S;;COHEN STEPHEN ALAN;;MCGAHAY VINCENT JAMES;;UTTECHT RONALD ROBERT,INTERNATIONAL BUSINESS MACHINES CORPORATION (1998-08-25),https://lens.org/104-938-162-126-828,Granted Patent,yes,12,36,13,13,0,H01L21/31058;;H01L21/02134;;H01L21/02282;;H01L21/02337;;Y10T428/31663;;H01L21/02134;;H01L21/02282;;H01L21/02337;;H01L21/31058;;H01L21/316;;Y10T428/31663;;H01L21/31058;;H01L21/02134;;H01L21/02337;;H01L21/02282,C01B33/00;;C01B33/113;;C04B35/04;;H01L21/3105;;H01L21/316,428/446;;428/447;;428/702;;428/450;;427/227;;427/377;;427/379;;427/397.7,0,0,,,,EXPIRED
609,DE,T2,DE 3751813 T2,023-962-969-689-799,1997-01-02,1997,DE 3751813 T,1987-08-18,US 89760386 A,1986-08-18,Ein Verfahren zum Kennzeichnen der dynamischer Reaktion des ANS.,,MASSACHUSETTS INST TECHNOLOGY,BERGER RONALD D;;CHEN MING HUI;;COHEN RICHARD J;;SAUL JEROME P,,https://lens.org/023-962-969-689-799,Granted Patent,no,0,0,9,9,0,A61B5/0809;;A61B5/0809;;A61B5/02405;;A61B5/02405;;A61B5/0245;;A61B5/0245;;A61B5/4035;;A61B5/4035;;A61B5/6826;;A61B5/6826;;A61B5/6838;;A61B5/6838;;Y10S128/925;;Y10S128/925,A61B5/145;;A61B5/02;;A61B5/08;;A61B5/1459;;A61B10/00;;G06F17/00,,0,0,,,,EXPIRED
610,AU,B2,AU 668488 B2,008-260-905-233-709,1996-05-02,1996,AU 1994/076310 A,1994-08-05,US 11007693 A;;US 9409025 W,1993-08-20,Hydrocarbon fueled solid polymer fuel cell electric power generation system,,BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,,https://lens.org/008-260-905-233-709,Granted Patent,no,2,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
611,WO,A1,WO 1995/006335 A1,065-831-487-675-400,1995-03-02,1995,US 9409025 W,1994-08-05,US 11007693 A,1993-08-20,HYDROCARBON FUELED SOLID POLYMER FUEL CELL ELECTRIC POWER GENERATION SYSTEM,"A power plant system (110) produces utility grade electrical AC power from gaseous or liquid hydrocarbon fuels using a fuel cell stack (186) employing ion exchange membranes. The fuel is desulfurized, mixed with water, heated and vaporized before being introduced into a reformer (168). The reformer (168) produces a hydrogen-rich gas (51) which is then directed through a series of heat exchangers (164), shift converters (172) and a selective oxidizer (142). The processed fuel stream is combined in the fuel cell stack (186) with a pressurized oxidant stream to generate DC power. Oxidant pressure is supplied by compressors (130, 134) driven by turbines using heated system exhaust gases. The DC power is converted into utility grade AC power (195) using an inverter (210) augmented by a battery peaking unit (212) for rapid load following. The water generated in the fuel cell stack (186) is recycled and used to cool the fuel cell stack and to humidify the fuel stream and oxidant stream prior to their introduction to the fuel cell stack (186).",BALLARD POWER SYSTEMS;;BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,,https://lens.org/065-831-487-675-400,Patent Application,yes,4,7,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,1,0,,,See also references of EP 0671059A4,PATENTED
612,AU,B2,AU 758530 B2,035-369-258-040-908,2003-03-27,2003,AU 1999/018138 A,1998-12-15,US 99803697 A;;US 9826211 W,1997-12-23,Delivery of multiple genes to cells using plural adeno-associated viral vectors,,CELL GENESYS INC,SNYDER RICHARD O;;RENDAHL KATHERINE;;LEFF STUART;;MANDEL RONALD;;COHEN LAWRENCE;;DANOS OLIVIER,,https://lens.org/035-369-258-040-908,Granted Patent,no,0,0,8,8,0,A61K48/00;;A61K48/00;;C12N15/86;;C12N2750/14143;;C12N2830/006;;C12N2830/42;;C12N2840/44,C12N15/09;;A61K31/711;;A61K35/76;;A61K38/22;;A61K38/46;;A61K48/00;;C12N5/10;;C12N7/00;;C12N15/864,,0,0,,,,EXPIRED
613,WO,A1,WO 2022/187010 A1,184-829-866-116-90X,2022-09-09,2022,US 2022/0017147 W,2022-02-21,US 202163155346 P,2021-03-02,PROCESS FOR THE RECOVERY AND/OR REGENERATION OF CATALYST COMPONENTS,"Disclosed herein is a method including decoupling one or more polymers containing the residue of a propiolactone, an epoxide, or both from a metal centered compound in a composition to form a Lewis acid containing one or more polar ligands, a Lewis acid containing one or more acid ion exchange resins, or a Lewis acid containing a halogen. Further included is removing one or more organic compounds, inorganic compounds, the one or more polymers, or any combination thereof from the composition. The method further includes forming a regenerated carbonylation catalyst by one or more of contacting a metal carbonyl and the Lewis acid containing the one or more polar ligands; or contacting a metal carbonyl additive and the Lewis acid containing the halogen with one or more polar ligands.",NOVOMER INC,TEDDER JONATHAN D;;RUHL JOHN B;;UHRIG JEFF;;COHEN STEVEN A;;BOYCE RONALD,,https://lens.org/184-829-866-116-90X,Patent Application,yes,9,0,1,1,0,B01J31/4015;;C07D305/12;;B01J2231/34;;B01J2531/025;;B01J2531/31;;B01J2531/845;;B01J31/20;;B01J31/183;;Y02P20/584,B01J31/40;;B01J31/18;;B01J31/20;;B01J38/02;;B01J38/52;;B01J38/60;;B01J38/74;;C07D305/12,,0,0,,,,PENDING
614,CA,A1,CA 2146326 A1,000-077-176-635-604,1995-03-02,1995,CA 2146326 A,1994-08-05,US 11007693 A,1993-08-20,HYDROCARBON FUELED SOLID POLYMER FUEL CELL ELECTRIC POWER GENERATION SYSTEM,,BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;COHEN RONALD;;CLAUSI JOSEPH V;;WATKINS DAVID S;;LOUIE CRAIG,,https://lens.org/000-077-176-635-604,Patent Application,no,0,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
615,US,A1,US 2016/0381089 A1,010-024-479-509-30X,2016-12-29,2016,US 201615262976 A,2016-09-12,US 201615262976 A;;US 78134207 A,2007-07-23,RELATIONSHIP-CENTRIC PORTALS FOR COMMUNICATION SESSIONS,"A method for providing relationship-centric resources includes establishing a communication session between a first device and a second device, determining, during the communication session between the first and second devices, an intersection of mutual topics of interest between users of the first and second devices by cross-referencing sets of interests for the users, retrieving content based on a determination that the content meets a content descriptor, and simultaneously displaying the retrieved content. The content descriptor describes a nature of the communication session. The retrieving is further based on a determination that the content is related to a mutual topic of interest from the intersection of mutual topics of interest between the users of the first and second devices. The determination of relatedness is based on a cross-reference between the content and the mutual topic of interest. The cross-reference is stored in a lookup table.",IBM,ABERNETHY JR MICHAEL N;;COHEN GABRIEL A;;CRAIG RONALD E;;GRIGSBY TRAVIS M,INTERNATIONAL BUSINESS MACHINES CORPORATION (2001-08-06),https://lens.org/010-024-479-509-30X,Patent Application,yes,38,0,4,4,0,G06Q10/10;;G06F16/2455;;G06F16/2455;;G06Q10/10;;H04L51/046;;H04L65/1069;;H04L65/1089,H04L29/06;;G06F17/30;;H04L12/58,,0,0,,,,ACTIVE
616,CA,C,CA 2146326 C,059-255-795-880-748,1998-04-21,1998,CA 2146326 A,1994-08-05,US 11007693 A,1993-08-20,HYDROCARBON FUELED SOLID POLYMER FUEL CELL ELECTRIC POWER GENERATION SYSTEM,"A power plant system (110) produces utility grade electrical AC power from gaseo us or liquid hydrocarbon fuels using a fuel cell stack (186) employing ion exchange membranes. The fuel is desulfurized, mixed w ith water, heated and vaporized before being introduced into a reformer (168). The reformer (168) produces a hydrogen-rich gas (51) whic h is then directed through a series of heat exchangers (164), shift converters (172) and a selective oxidizer (142). The processed fuel stream is combined in the fuel cell stack (186) with a pressurized oxidant stream to generate DC power. Oxidant pressure is supplied by compressors (130, 134) driven by turbines using heated system exhaust gases. The DC power is converted into utility grade AC power (195 ) using an inverter (210) augmented by a battery peaking unit (212) for rapid load following. The water generated in the fuel cell stack (186) is recycled and used to cool the fuel cell stack and to humidify the fuel stream and oxidant stream prior to their introduction to the f uel cell stack (186).",BALLARD POWER SYSTEMS,COHEN RONALD;;LOUIE CRAIG;;CLAUSI JOSEPH V;;BUSWELL RICHARD F;;WATKINS DAVID S,,https://lens.org/059-255-795-880-748,Granted Patent,no,0,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
617,WO,A1,WO 1999/032145 A1,188-170-674-031-20X,1999-07-01,1999,US 9826211 W,1998-12-15,US 99803697 A,1997-12-23,DELIVERY OF MULTIPLE GENES TO CELLS USING PLURAL ADENO-ASSOCIATED VIRAL VECTORS,"A method for transducing a polypoid, multinucleate or polysomic cell with plural rAAVs carrying different transgenes. A suitable cell is a striated muscle cell or hepatocyte.",CELL GENESYS INC,SNYDER RICHARD O;;RENDAHL KATHERINE;;LEFF STUART;;MANDEL RONALD;;COHEN LAWRENCE;;DANOS OLIVIER,,https://lens.org/188-170-674-031-20X,Patent Application,yes,0,2,8,8,0,A61K48/00;;A61K48/00;;C12N15/86;;C12N2750/14143;;C12N2830/006;;C12N2830/42;;C12N2840/44,C12N15/09;;A61K31/711;;A61K35/76;;A61K38/22;;A61K38/46;;A61K48/00;;C12N5/10;;C12N7/00;;C12N15/864,,11,9,009-416-320-508-847;;015-546-745-226-16X;;004-941-081-961-92X;;017-797-084-268-280;;037-060-010-690-680;;061-508-506-609-420;;057-375-448-660-20X;;043-619-194-006-282;;111-912-662-903-302,9305836;;10.1038/38410;;8886849;;10.1089/hum.1996.7.14-1781;;pmc6792786;;9592104;;10.1523/jneurosci.18-11-04271.1998;;10.1523/jneurosci.16-14-04449.1996;;8699255;;pmc6578851;;10.1142/9789814354189_0011;;8525429;;10.1007/bf02255778;;8796920;;10.1016/1357-4310(96)81800-4;;10.1073/pnas.93.24.14082;;8943064;;pmc19498;;10.1046/j.1471-4159.1997.68010233.x;;8978730,"ECK S L, WILSON J M: ""GENE-BASED THERAPY"", PHARMACOLOGICAL BASIS OF THERAPEUTICS, XX, XX, no. 09, 1 January 1995 (1995-01-01), XX, pages 77 - 101, XP002917020;;VERMA I M, SOMIA N: ""GENE THERAPY-PROMISES, PROBLEMS AND PROSPECTS"", NATURE, NATURE PUBLISHING GROUP, UNITED KINGDOM, vol. 389, 18 September 1997 (1997-09-18), United Kingdom, pages 239 - 242, XP002917021, ISSN: 0028-0836, DOI: 10.1038/38410;;ROSS G, ET AL.: ""GENE THERAPY IN THE UNITED STATES: A FIVE-YEAR STATUS REPORT"", HUMAN GENE THERAPY, MARY ANN LIEBERT, INC. PUBLISHERS, US, vol. 07, 10 September 1996 (1996-09-10), US, pages 1781 - 1790, XP002917022, ISSN: 1043-0342;;MANDEL R J, ET AL.: ""CHARACTERIZATION OF INTRASTRIATAL RECOMBINANT ADENO-ASSOCIATED VIRUS-MEDIATED GENE TRANSFER OF HUMAN TYROSINE HYDROXYLASE AND HUMAN GTP-CYCLOHYDROLASE I IN A RAT MODEL OF PARKINSON'S DISEASE"", JOURNAL OF NEUROSCIENCE, SOCIETY FOR NEUROSCIENCE, US, vol. 18, no. 11, 1 June 1998 (1998-06-01), US, pages 4271 - 4284, XP002917023, ISSN: 0270-6474;;BENCSICS C, ET AL.: ""DOUBLE TRANSUDCTION WITH GTP CYCLOHYDROLASE I AND TYROSINE HYDROXYLASE IS NECESSARY FOR SPONTANEOUS SYNTHESIS OF L-DOPA BY PRIMARY FIBROBLASTS"", JOURNAL OF NEUROSCIENCE, SOCIETY FOR NEUROSCIENCE, US, vol. 16, no. 14, 15 July 1996 (1996-07-15), US, pages 4449 - 4456, XP002917024, ISSN: 0270-6474;;SAMULSKI R J: ""ADENO-ASSOCIATED VIRUS-BASED VECTORS FOR HUMAN GENE THERAPY"", VIRUSES IN GENE THERAPY, XX, XX, 1 January 1994 (1994-01-01), XX, pages 232 - 271, XP002917025;;DHAWAN J, ET AL.: ""TETRACYCLINE-REGULATED GENE EXPRESSION FOLLOWING DIRECT GENE TRANSFER INTO MOUSE SKELETAL MUSCLE"", SOMATIC CELL AND MOLECULAR GENETICS, NEW YORK, NY, US, vol. 21, no. 04, 1 January 1995 (1995-01-01), US, pages 233 - 240, XP002917026;;NAFFAKH N, DANOS O: ""GENE TRANSFER FOR ERYTHROPOIESIS ENHANCEMENT"", MOLECULAR MEDICINE TODAY., ELSEVIER, CAMBRIDGE., GB, vol. 02, 1 August 1996 (1996-08-01), GB, pages 343 - 348, XP002917027, ISSN: 1357-4310, DOI: 10.1016/1357-4310(96)81800-4;;KESSLER P D, ET AL.: ""GENE DELIVERY TO SKELETAL MUSCLE RESULTS IN SUSTAINED EXPRESSION AND SYSTEMIC DELIVERY OF A THERAPEUTIC PROTEIN"", PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES, NATIONAL ACADEMY OF SCIENCES, US, vol. 93, 1 November 1996 (1996-11-01), US, pages 14082 - 14087, XP002917028, ISSN: 0027-8424, DOI: 10.1073/pnas.93.24.14082;;SOUZA SILVA DE M A, ET AL.: ""INTRANASAL ADMINISTRATION OF THE DOPAMINERGIC AGONISTS L-DOPA, AMPHETAMINE, AND COCAINE INCREASES DOPAMINE ACTIVITY IN THE NEOSTRIATUM: A MICRODIALYSIS STUDY IN THE RAT"", JOURNAL OF NEUROCHEMISTRY, WILEY INTERSCIENCE, NEW YORK, NY, US, vol. 68, 1 January 1997 (1997-01-01), NEW YORK, NY, US, pages 233 - 239, XP002917029, ISSN: 0022-3042;;See also references of EP 1042000A4",PATENTED
618,US,B1,US 6236317 B1,027-716-560-206-386,2001-05-22,2001,US 19707298 A,1998-11-20,US 19707298 A;;US 8343398 P,1998-04-29,Method and apparatus for monitoring actions taken by a user for enhancing hygiene,"An apparatus and a concomitant method for promoting hygienic practices is disclosed. The apparatus is a monitoring unit for monitoring the completion of a desired action, e.g., handwashing, by a user. Upon completion of the desired action, the monitoring unit transmits a satisfactory signal to the user.",FOOD SAFETY SOLUTION CORP,COHEN GLENN;;DISSER JAMES R;;HERSH MARK;;HEAGLE RONALD;;RICHARD DAN;;BRADY KEVIN,FOOD SAFETY SOLUTIONS CORP (2000-10-12);;GOJO INDUSTRIES INC (1999-03-15);;CYRO-CELL INTERNATIONAL INC (2000-09-29);;NET/TECH INTERNATIONAL INC (1998-10-13),https://lens.org/027-716-560-206-386,Granted Patent,yes,16,284,1,1,0,G08B21/245;;G08B21/245;;Y10T137/8208;;Y10T137/8208,G08B21/24,340/573.1;;340/286.09;;137/552.7;;4/623;;702/176;;222/39,0,0,,,,EXPIRED
619,EP,A4,EP 1042000 A4,080-147-030-001-10X,2005-03-02,2005,EP 98963026 A,1998-12-15,US 9826211 W;;US 99803697 A,1997-12-23,DELIVERY OF MULTIPLE GENES TO CELLS USING PLURAL ADENO-ASSOCIATED VIRAL VECTORS,,CELL GENESYS INC,SNYDER RICHARD O;;RENDAHL KATHERINE;;LEFF STUART;;MANDEL RONALD;;COHEN LAWRENCE;;DANOS OLIVIER,,https://lens.org/080-147-030-001-10X,Search Report,no,1,0,8,8,0,A61K48/00;;A61K48/00;;C12N15/86;;C12N2750/14143;;C12N2830/006;;C12N2830/42;;C12N2840/44,C12N15/09;;A61K31/711;;A61K35/76;;A61K38/22;;A61K38/46;;A61K48/00;;C12N5/10;;C12N7/00;;C12N15/864,,5,4,119-186-894-427-314;;078-919-719-885-502;;051-933-749-493-754;;115-513-568-986-663,9055857;;10.1038/nm0397-299;;9207793;;10.1038/ng0797-270;;9391156;;10.1073/pnas.94.25.14083;;pmc28436;;10.1038/nbt0898-757;;9702775,"BOHL DELPHINE ET AL: ""Long-term control of erythropoietin secretion by doxycycline in mice transplanted with engineered primary myoblasts"", NATURE MEDICINE, vol. 3, no. 3, March 1997 (1997-03-01), pages 299 - 305, XP008041084, ISSN: 1078-8956;;SNYDER ET AL: ""Persistent and therapeutic concentrations of human factor IX in mice after hepatic gene transfer of recombinant AAV vectors"", NATURE GENETICS, NEW YORK, NY, US, vol. 16, 16 July 1997 (1997-07-16), pages 270 - 276, XP002122888, ISSN: 1061-4036;;MANDEL R J ET AL: ""Midbrain injection of recombinant adeno-associated virus encoding rat glial cell line-derived neurotropic factor protects nigral neurons in a progressive 6-hydroxydopamine-induced degeneration model of Parkinson's disease in rats"", PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF USA, NATIONAL ACADEMY OF SCIENCE. WASHINGTON, US, vol. 94, December 1997 (1997-12-01), pages 14083 - 14088, XP002962773, ISSN: 0027-8424;;RENDAHL K G ET AL: ""REGULATION OF GENE EXPRESSION IN VIVO FOLLOWING TRANSDUCTION BY TWO SEPARATE RAAV VECTORS"", NATURE BIOTECHNOLOGY, NATURE PUBLISHING, US, vol. 16, August 1998 (1998-08-01), pages 757 - 761, XP001093146, ISSN: 1087-0156;;See also references of WO 9932145A1",DISCONTINUED
620,EP,A4,EP 0671059 A4,162-311-077-822-305,1999-05-26,1999,EP 94926490 A,1994-08-05,US 9409025 W;;US 11007693 A,1993-08-20,HYDROCARBON FUELED SOLID POLYMER FUEL CELL ELECTRIC POWER GENERATION SYSTEM.,,BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,BALLARD POWER SYSTEMS INC. (1997-09-10),https://lens.org/162-311-077-822-305,Search Report,no,6,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,8,1,066-475-887-128-64X,10.1016/0378-7753(93)01804-q,"PATENT ABSTRACTS OF JAPAN vol. 012, no. 193 (E - 617) 4 June 1988 (1988-06-04);;PATENT ABSTRACTS OF JAPAN vol. 017, no. 307 (E - 1379) 11 June 1993 (1993-06-11);;PATENT ABSTRACTS OF JAPAN vol. 016, no. 084 (E - 1172) 28 February 1992 (1992-02-28);;PATENT ABSTRACTS OF JAPAN vol. 015, no. 500 (C - 0895) 18 December 1991 (1991-12-18);;PATENT ABSTRACTS OF JAPAN vol. 016, no. 535 (E - 1288) 5 November 1992 (1992-11-05);;PATENT ABSTRACTS OF JAPAN vol. 017, no. 535 (E - 1439) 27 September 1993 (1993-09-27);;SHOESMITH J P ET AL: ""STATUS OF SOLID POLYMER FUEL CELL SYSTEM DEVELOPMENT"", JOURNAL OF POWER SOURCES, vol. 49, no. 1/03, 1 April 1994 (1994-04-01), pages 129 - 142, XP000540739;;See also references of WO 9506335A1",EXPIRED
621,US,B2,US 10542055 B2,036-466-363-359-196,2020-01-21,2020,US 201615262976 A,2016-09-12,US 201615262976 A;;US 78134207 A,2007-07-23,Relationship-centric portals for communication sessions,"A method for providing relationship-centric resources includes establishing a communication session between a first device and a second device, determining, during the communication session between the first and second devices, an intersection of mutual topics of interest between users of the first and second devices by cross-referencing sets of interests for the users, retrieving content based on a determination that the content meets a content descriptor, and simultaneously displaying the retrieved content. The content descriptor describes a nature of the communication session. The retrieving is further based on a determination that the content is related to a mutual topic of interest from the intersection of mutual topics of interest between the users of the first and second devices. The determination of relatedness is based on a cross-reference between the content and the mutual topic of interest. The cross-reference is stored in a lookup table.",IBM,ABERNETHY JR MICHAEL N;;COHEN GABRIEL A;;CRAIG RONALD E;;GRIGSBY TRAVIS M,INTERNATIONAL BUSINESS MACHINES CORPORATION (2001-08-06),https://lens.org/036-466-363-359-196,Granted Patent,yes,31,0,4,4,0,G06Q10/10;;G06F16/2455;;G06F16/2455;;G06Q10/10;;H04L51/046;;H04L65/1069;;H04L65/1089,H04L29/06;;G06F16/2455;;G06Q10/10;;H04L12/58,,0,0,,,,ACTIVE
622,US,B2,US 9477940 B2,119-852-677-593-932,2016-10-25,2016,US 78134207 A,2007-07-23,US 78134207 A,2007-07-23,Relationship-centric portals for communication sessions,"Relationship-centric resources are provided to users during a communication session. After establishing a communication session between a first communication device and a second communication device, content that meets a content descriptor is retrieved. This content descriptor describes a nature of a relationship between users of the first and second communication devices. The retrieved content, which meets the content descriptor, is then simultaneously displaying on both the first communication device and the second communication device.",ABERNETHY JR MICHAEL N;;COHEN GABRIEL A;;CRAIG RONALD E;;GRIGSBY TRAVIS M;;IBM,ABERNETHY JR MICHAEL N;;COHEN GABRIEL A;;CRAIG RONALD E;;GRIGSBY TRAVIS M,INTERNATIONAL BUSINESS MACHINES CORPORATION (2007-07-17),https://lens.org/119-852-677-593-932,Granted Patent,yes,17,7,4,4,0,G06Q10/10;;G06F16/2455;;G06F16/2455;;G06Q10/10;;H04L51/046;;H04L65/1069;;H04L65/1089,G06Q10/10,,0,0,,,,ACTIVE
623,EP,A1,EP 0671059 A1,168-542-316-728-516,1995-09-13,1995,EP 94926490 A,1994-08-05,US 9409025 W;;US 11007693 A,1993-08-20,HYDROCARBON FUELED SOLID POLYMER FUEL CELL ELECTRIC POWER GENERATION SYSTEM.,,BALLARD POWER SYSTEMS;;BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,BALLARD POWER SYSTEMS INC. (1997-09-10),https://lens.org/168-542-316-728-516,Patent Application,yes,0,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
624,AU,A,AU 1994/076310 A,184-659-783-188-941,1995-03-21,1995,AU 1994/076310 A,1994-08-05,US 11007693 A;;US 9409025 W,1993-08-20,Hydrocarbon fueled solid polymer fuel cell electric power generation system,,BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,,https://lens.org/184-659-783-188-941,Patent Application,no,0,0,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,0,0,,,,EXPIRED
625,EP,A1,EP 1042000 A1,068-139-768-627-980,2000-10-11,2000,EP 98963026 A,1998-12-15,US 9826211 W;;US 99803697 A,1997-12-23,DELIVERY OF MULTIPLE GENES TO CELLS USING PLURAL ADENO-ASSOCIATED VIRAL VECTORS,,CELL GENESYS INC,SNYDER RICHARD O;;RENDAHL KATHERINE;;LEFF STUART;;MANDEL RONALD;;COHEN LAWRENCE;;DANOS OLIVIER,,https://lens.org/068-139-768-627-980,Patent Application,yes,0,0,8,8,6,A61K48/00;;A61K48/00;;C12N15/86;;C12N2750/14143;;C12N2830/006;;C12N2830/42;;C12N2840/44,C12N15/09;;A61K31/711;;A61K35/76;;A61K38/22;;A61K38/46;;A61K48/00;;C12N5/10;;C12N7/00;;C12N15/864,,0,0,,,,DISCONTINUED
626,US,A1,US 2009/0031027 A1,094-732-956-399-209,2009-01-29,2009,US 78134207 A,2007-07-23,US 78134207 A,2007-07-23,Relationship-Centric Portals for Communication Sessions,"Relationship-centric resources are provided to users during a communication session. After establishing a communication session between a first communication device and a second communication device, content that meets a content descriptor is retrieved. This content descriptor describes a nature of a relationship between users of the first and second communication devices. The retrieved content, which meets the content descriptor, is then simultaneously displaying on both the first communication device and the second communication device.",ABERNETHY JR MICHAEL N;;COHEN GABRIEL A;;CRAIG RONALD E;;GRIGSBY TRAVIS M,ABERNETHY JR MICHAEL N;;COHEN GABRIEL A;;CRAIG RONALD E;;GRIGSBY TRAVIS M,INTERNATIONAL BUSINESS MACHINES CORPORATION (2007-07-17),https://lens.org/094-732-956-399-209,Patent Application,yes,17,29,4,4,0,G06Q10/10;;G06F16/2455;;G06F16/2455;;G06Q10/10;;H04L51/046;;H04L65/1069;;H04L65/1089,G06F15/16;;G06F3/147,709/227;;715/733,0,0,,,,ACTIVE
627,US,A,US 5360679 A,161-636-888-388-409,1994-11-01,1994,US 11007693 A,1993-08-20,US 11007693 A,1993-08-20,Hydrocarbon fueled solid polymer fuel cell electric power generation system,"A power plant system produces utility grade electrical AC power from gaseous or liquid hydrocarbon fuels using a fuel cell stack employing ion exchange membranes. The fuel is desulfurized, mixed with water, heated and vaporized before being introduced into a reformer. The reformer produces a hydrogen-rich gas which is then directed through a series of heat exchangers, shift converters and a selective oxidizer. The processed fuel stream is combined in the fuel cell stack with a pressurized oxidant stream to generate DC power. Oxidant pressure is supplied by compressors driven by turbines using heated system exhaust gases. The DC power is converted into utility grade AC power using an inverter augmented by a battery peaking unit for rapid load following. The water generated in the fuel cell stack is recycled and used to cool the fuel cell stack and to humidify the fuel stream and oxidant stream prior to their introduction to the fuel cell stack. System integration results in an electrical efficiency of at least about 40%, and with heat recovery the overall fuel efficiency is greater than approximately 80%.",BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,BALLARD POWER SYSTEMS INC (1993-11-17),https://lens.org/161-636-888-388-409,Granted Patent,yes,27,293,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,429/19;;429/30,0,0,,,,EXPIRED
628,EP,B1,EP 0671059 B1,123-203-577-228-721,2001-12-05,2001,EP 94926490 A,1994-08-05,US 9409025 W;;US 11007693 A,1993-08-20,HYDROCARBON FUELED SOLID POLYMER FUEL CELL ELECTRIC POWER GENERATION SYSTEM,,BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;CLAUSI JOSEPH V;;COHEN RONALD;;LOUIE CRAIG;;WATKINS DAVID S,BALLARD POWER SYSTEMS INC. (1997-09-10),https://lens.org/123-203-577-228-721,Granted Patent,yes,10,1,12,12,0,H01M8/0612;;H01M8/0612;;H01M8/04029;;H01M8/04029;;H01M8/04119;;H01M8/04119;;H01M8/04156;;H01M8/04156;;H01M8/04388;;H01M8/04388;;H01M8/04395;;H01M8/04395;;H01M8/04731;;H01M8/04731;;H01M8/04738;;H01M8/04738;;H01M8/04753;;H01M8/04753;;H01M8/04835;;H01M8/04835;;H01M2300/0082;;H01M2300/0082;;Y02E60/50,H01M8/00;;H01M8/04;;H01M8/06;;H01M8/10,,7,0,,,"PATENT ABSTRACTS OF JAPAN vol. 012, no. 193 (E-617), 4 June 1988 -& JP 62 296371 A (TOSHIBA CORP), 23 December 1987;;PATENT ABSTRACTS OF JAPAN vol. 017, no. 307 (E-1379), 11 June 1993 -& JP 05 022870 A (TOSHIBA CORP), 29 January 1993;;PATENT ABSTRACTS OF JAPAN vol. 016, no. 084 (E-1172), 28 February 1992 -& JP 03 269955 A (FUJI ELECTRIC CO LTD), 2 December 1991;;PATENT ABSTRACTS OF JAPAN vol. 015, no. 500 (C-0895), 18 December 1991 -& JP 03 218903 A (MITSUBISHI HEAVY IND LTD), 26 September 1991;;PATENT ABSTRACTS OF JAPAN vol. 016, no. 535 (E-1288), 5 November 1992 -& JP 04 206157 A (MITSUBISHI HEAVY IND LTD), 28 July 1992;;PATENT ABSTRACTS OF JAPAN vol. 017, no. 535 (E-1439), 27 September 1993 -& JP 05 151983 A (SANYO ELECTRIC CO LTD), 18 June 1993;;SHOESMITH J P ET AL: ""STATUS OF SOLID POLYMER FUEL CELL SYSTEM DEVELOPMENT"" JOURNAL OF POWER SOURCES, vol. 49, no. 1/03, 1 April 1994, pages 129-142, XP000540739",EXPIRED
629,CA,A1,CA 2316321 A1,037-522-626-761-284,1999-07-01,1999,CA 2316321 A,1998-12-15,US 99803697 A;;US 9826211 W,1997-12-23,DELIVERY OF MULTIPLE GENES TO CELLS USING PLURAL ADENO-ASSOCIATED VIRAL VECTORS,"A method for transducing a polypoid, multinucleate or polysomic cell with plural rAAVs carrying different transgenes. A suitable cell is a striated muscle cell or hepatocyte.",CELL GENESYS INC,RENDAHL KATHERINE;;SNYDER RICHARD O;;COHEN LAWRENCE;;MANDEL RONALD;;DANOS OLIVIER;;LEFF STUART,,https://lens.org/037-522-626-761-284,Patent Application,no,0,0,8,8,6,A61K48/00;;A61K48/00;;C12N15/86;;C12N2750/14143;;C12N2830/006;;C12N2830/42;;C12N2840/44,C12N15/09;;A61K31/711;;A61K35/76;;A61K38/22;;A61K38/46;;A61K48/00;;C12N5/10;;C12N7/00;;C12N15/864,,0,0,,,,DISCONTINUED
630,AU,A,AU 1999/018138 A,170-785-259-603-423,1999-07-12,1999,AU 1999/018138 A,1998-12-15,US 99803697 A;;US 9826211 W,1997-12-23,Delivery of multiple genes to cells using plural adeno-associated viral vectors,,CELL GENESYS INC,SNYDER RICHARD O;;RENDAHL KATHERINE;;LEFF STUART;;MANDEL RONALD;;COHEN LAWRENCE;;DANOS OLIVIER,,https://lens.org/170-785-259-603-423,Patent Application,no,0,0,8,8,0,A61K48/00;;A61K48/00;;C12N15/86;;C12N2750/14143;;C12N2830/006;;C12N2830/42;;C12N2840/44,C12N15/09;;A61K31/711;;A61K35/76;;A61K38/22;;A61K38/46;;A61K48/00;;C12N5/10;;C12N7/00;;C12N15/864,,0,0,,,,EXPIRED
631,US,B2,US 10591391 B2,007-157-246-969-058,2020-03-17,2020,US 201313830871 A,2013-03-14,US 201313830871 A;;US 201313738268 A;;US 201213433232 A;;US 72524010 A;;US 76342607 A;;US 82077806 P;;US 80481506 P,2006-06-14,Diagnosis of fetal abnormalities using polymorphisms including short tandem repeats,"The present invention provides systems, apparatuses, and methods to detect the presence of fetal cells when mixed with a population of maternal cells in a sample and to test fetal abnormalities, i.e. aneuploidy. In addition, the present invention provides methods to determine when there are insufficient fetal cells for a determination and report a non-informative case. The present invention involves quantifying regions of genomic DNA from a mixed sample. More particularly the invention involves quantifying DNA polymorphisms from the mixed sample.",VERINATA HEALTH INC;;MASSACHUSETTS GEN HOSPITAL;;GPB SCIENTIFIC LLC,STOUGHTON ROLAND;;KAPUR RAVI;;COHEN BARB ARIEL;;SHOEMAKER DANIEL;;DAVIS RONALD W;;TONER MEHMET,VERINATA HEALTH INC (2007-08-13);;GPB SCIENTIFIC LLC (2012-04-06);;THE GENERAL HOSPITAL CORPORATION (2012-04-06),https://lens.org/007-157-246-969-058,Granted Patent,yes,653,0,11,99,166,C12Q2600/156;;C12Q2600/158;;C12Q2600/16;;G16B20/00;;C12Q1/6883;;G16B20/20;;G16B20/10;;C12Q2600/16;;C12Q2600/156;;C12Q2600/158;;G16B20/00;;G16B20/10;;G16B20/20;;C12Q1/6883;;G01N1/30,G01N1/30;;C12Q1/6883;;G16B20/00;;G16B20/10;;G16B20/20,,590,334,145-980-837-366-069;;069-664-050-907-58X;;002-962-093-926-806;;093-923-594-402-41X;;061-972-410-678-308;;076-665-268-971-988;;023-470-740-030-442;;079-271-886-785-450;;074-073-313-612-529;;069-172-803-977-996;;024-788-387-676-408;;055-344-504-125-603;;037-683-830-699-745;;072-957-484-014-313;;025-444-311-000-572;;043-471-800-922-267;;084-740-087-142-344;;039-926-624-155-532;;100-517-437-329-034;;023-714-828-241-98X;;062-943-012-251-708;;032-773-210-009-878;;097-983-928-947-891;;030-388-628-647-910;;050-400-165-665-489;;021-395-452-375-411;;008-450-478-770-610;;130-453-527-139-398;;039-970-201-274-052;;023-066-996-949-458;;035-399-631-060-876;;066-738-100-492-387;;072-052-867-054-682;;091-918-335-559-560;;097-754-888-921-152;;088-168-216-983-870;;007-768-658-124-927;;004-912-500-478-498;;013-726-192-940-421;;006-922-788-878-66X;;057-832-111-015-791;;021-323-521-292-044;;011-369-235-031-266;;113-237-014-874-941;;015-591-934-599-873;;078-585-629-084-94X;;027-469-666-042-046;;011-226-665-143-454;;042-028-784-421-776;;090-450-965-717-845;;003-506-020-261-820;;036-084-868-306-571;;073-836-449-063-289;;061-680-405-606-671;;014-018-692-679-513;;049-917-149-198-776;;000-451-290-076-161;;018-518-176-671-482;;110-175-141-884-851;;119-432-872-620-86X;;022-110-498-789-075;;102-239-132-565-605;;055-709-830-577-882;;110-494-944-987-107;;056-649-011-137-95X;;030-275-384-700-023;;043-534-827-301-837;;014-011-716-300-159;;012-207-420-124-450;;091-582-343-202-549;;060-486-816-415-284;;008-949-275-765-611;;016-058-711-052-433;;007-845-582-358-28X;;013-354-479-811-526;;025-603-721-778-120;;112-812-964-916-481;;104-441-668-144-739;;015-163-802-994-897;;095-791-526-406-735;;197-259-304-278-042;;041-328-439-315-145;;096-288-971-803-913;;098-884-389-623-179;;018-565-258-437-405;;028-223-125-560-891;;023-780-324-643-913;;103-437-510-767-380;;110-488-475-875-151;;003-440-788-933-293;;002-252-470-409-219;;091-124-255-480-938;;071-853-342-448-623;;012-952-644-054-72X;;043-610-762-314-11X;;137-067-349-312-993;;025-476-029-218-056;;003-546-831-761-809;;033-641-401-169-948;;036-744-943-054-847;;145-664-732-655-556;;028-848-496-034-567;;009-898-247-038-15X;;111-225-290-242-210;;016-168-594-013-175;;119-551-692-604-266;;020-963-218-841-505;;056-731-028-664-484;;080-229-410-836-01X;;112-979-503-973-752;;018-197-916-469-980;;063-113-970-890-136;;027-949-866-536-676;;000-132-822-507-850;;023-453-484-239-380;;031-024-845-392-861;;012-419-229-225-661;;053-864-408-060-287;;048-307-566-990-778;;144-414-553-606-910;;002-794-018-140-037;;001-916-287-314-273;;009-546-007-869-748;;052-203-373-229-016;;012-994-011-348-491;;109-671-930-427-474;;115-031-091-131-489;;006-705-425-787-055;;062-432-639-909-863;;018-465-220-235-316;;042-046-581-693-797;;039-368-455-383-134;;043-612-721-618-925;;078-846-641-192-110;;025-014-850-112-135;;075-175-448-195-543;;081-635-437-544-738;;037-246-667-829-216;;035-702-243-213-446;;045-210-386-296-340;;143-498-220-029-646;;065-355-381-387-131;;001-334-092-953-139;;041-617-382-440-295;;001-425-405-313-161;;039-599-852-363-506;;083-321-798-349-752;;083-321-798-349-752;;038-299-786-769-127;;024-532-487-525-659;;003-975-284-397-766;;142-815-256-890-323;;090-480-935-984-35X;;020-989-451-816-934;;068-240-558-039-482;;152-905-408-401-018;;076-205-652-496-731;;001-299-465-443-457;;006-745-412-173-886;;075-257-623-567-05X;;010-752-407-460-856;;010-918-659-888-952;;119-387-317-093-650;;010-666-102-006-82X;;104-327-984-682-011;;045-121-767-490-468;;006-255-640-857-364;;012-120-064-706-240;;003-389-335-783-113;;019-111-640-909-135;;001-835-020-700-461;;003-505-875-300-448;;068-070-471-116-271;;062-130-188-392-821;;055-474-944-189-665;;063-841-635-946-126;;023-643-023-712-451;;043-403-907-375-369;;042-143-185-460-099;;004-738-352-893-591;;007-068-324-800-860;;078-046-137-489-382;;031-567-321-400-26X;;062-534-143-598-528;;005-493-100-787-606;;094-322-276-507-34X;;047-138-432-074-669;;044-257-231-686-194;;078-318-797-481-921;;025-732-878-703-11X;;049-077-218-155-157;;049-142-126-354-755;;035-874-511-846-241;;001-463-405-792-534;;006-469-975-468-356;;077-154-305-594-141;;133-198-598-868-84X;;006-213-323-479-202;;032-773-990-065-247;;112-816-534-945-862;;045-703-060-497-252;;022-362-408-310-392;;146-630-512-077-265;;089-155-244-656-088;;064-520-071-952-414;;034-993-359-958-083;;009-137-716-517-801;;066-498-966-986-863;;035-841-291-273-865;;016-414-961-017-057;;026-254-792-164-98X;;087-448-524-245-781;;001-176-959-270-170;;013-451-081-038-89X;;068-523-058-090-935;;135-344-914-322-845;;120-287-124-981-739;;025-236-904-358-231;;079-584-786-945-442;;036-418-376-263-058;;006-776-569-045-956;;069-201-326-498-369;;019-635-461-526-937;;010-939-414-333-337;;046-192-298-165-068;;007-266-645-707-429;;020-233-352-267-60X;;018-177-796-426-872;;049-605-074-974-335;;044-753-593-475-688;;127-480-285-495-829;;074-692-274-454-590;;004-759-683-199-951;;002-101-596-822-422;;070-645-405-751-636;;119-668-157-967-304;;004-044-841-731-378;;029-209-455-249-727;;091-644-988-844-822;;104-984-306-987-959;;042-687-188-007-05X;;124-608-264-234-68X;;112-043-942-907-759;;009-409-387-551-887;;042-188-217-377-10X;;071-526-300-014-730;;128-582-206-663-50X;;085-676-611-860-928;;052-422-871-439-42X;;065-009-089-183-148;;034-789-139-089-586;;077-387-005-438-531;;006-843-784-375-98X;;054-924-885-645-454;;035-157-982-709-903;;028-907-177-631-089;;004-008-616-000-423;;014-888-243-824-147;;023-472-553-173-121;;025-788-625-703-317;;123-470-727-563-530;;023-420-011-982-886;;089-613-034-005-477;;007-022-901-659-534;;022-082-160-606-117;;014-771-174-049-714;;027-742-933-656-371;;052-957-528-383-095;;097-567-234-089-615;;040-417-435-845-032;;030-232-325-211-49X;;010-467-626-105-19X;;023-470-740-030-442;;038-975-229-906-281;;005-801-311-027-908;;037-690-088-510-105;;053-785-246-530-083;;020-626-381-972-655;;039-390-905-548-030;;052-252-434-144-931;;053-902-328-766-487;;058-791-781-287-882;;059-915-929-396-902;;027-728-869-939-957;;004-739-115-831-447;;035-570-058-245-997;;011-574-579-733-993;;065-600-597-487-859;;138-818-651-954-867;;035-078-343-015-846;;009-731-372-323-457;;040-473-972-781-392;;131-023-342-376-721;;047-843-103-180-157;;037-357-780-822-464;;076-393-133-359-189;;054-165-398-485-292;;066-903-530-957-523;;031-862-180-586-540;;092-579-740-274-510;;039-358-754-467-996;;032-480-214-686-009;;116-628-846-164-835;;029-050-998-010-913;;058-449-019-265-362;;021-027-081-830-825;;007-886-305-977-737;;107-261-960-213-333;;069-739-770-688-833;;060-492-280-380-212;;022-262-263-271-354;;068-255-628-305-750;;010-791-672-524-98X;;011-516-573-186-006;;021-769-485-045-113;;017-112-591-676-778;;064-886-899-823-90X;;008-224-784-496-888;;003-996-208-073-770;;001-622-248-842-264;;126-493-929-146-912;;018-652-694-252-496;;097-695-465-307-188;;069-482-359-661-496;;000-058-261-678-04X;;025-224-986-816-700;;068-658-361-772-603;;019-822-409-513-235;;058-870-328-132-255;;033-459-397-346-84X;;100-453-901-699-515;;007-649-835-267-266;;022-365-450-364-769;;013-227-496-509-650,pmc5129580;;27616633;;10.1002/pd.4924;;26237488;;10.3390/jcm3030972;;pmc4449642;;10.1159/000073147;;14564124;;pmc4441954;;26000845;;10.1016/j.molcel.2015.05.005;;10.1034/j.1399-0004.2003.00087.x;;12786755;;10942488;;10.1067/mob.2000.106005;;11786398;;10.1016/s0002-9440(10)64348-9;;pmc1867119;;2047873;;10.1126/science.2047873;;10.1016/s0140-6736(89)90509-6;;9509547;;10.1002/(sici)1097-0223(199712)17:13<1299::aid-pd297>3.0.co;2-h;;10.1002/(sici)1097-0223(199712)17:13<1299::aid-pd297>3.3.co;2-8;;1800991;;10.1002/pd.1970111008;;10.1109/84.536621;;10.1158/1078-0432.ccr-04-0378;;15501967;;10.1002/pd.1970151006;;8587859;;11778067;;10.1046/j.1537-2995.2001.41121524.x;;12771927;;10.1038/sj.bjc.6600943;;pmc2377115;;16133462;;10.1007/s00404-005-0049-3;;17096850;;pmc1660550;;10.1186/1471-2164-7-289;;15591353;;10.1073/pnas.0407979101;;pmc535426;;6187862;;10.1016/s0022-1759(83)80016-7;;10.1016/s0378-4347(98)00308-9;;10068133;;10.1016/0167-9317(86)90004-3;;10.1088/0960-1317/8/1/004;;10.1038/35007047;;10766238;;10.1517/14622416.6.4.373;;16004555;;10.1097/00007890-198408000-00009;;6380041;;10.1016/0022-1759(86)90096-7;;3088123;;10.1002/1522-2683(200110)22:18<3883::aid-elps3883>3.0.co;2-4;;11700717;;2333281;;10.1073/pnas.87.9.3279;;pmc53883;;12124698;;10.1002/pd.347;;10.1002/pd.1970110807;;1766928;;pmc327104;;14762065;;10.1101/gr.2012304;;10.1371/journal.pone.0000197;;pmc1797623;;17299583;;10.1093/molehr/5.12.1166;;10587373;;10.1038/modpathol.3800560;;16514409;;9827904;;12651960;;10.1073/pnas.0230489100;;pmc153030;;10.1128/mcb.2.5.578-587.1982;;6896736;;pmc369828;;10.1128/mcb.2.5.578;;10.1016/s0006-3495(95)80443-1;;7647230;;pmc1282133;;10.1196/annals.1368.014;;17108199;;10.1056/nejmoa050995;;16251535;;10.1093/jnci/dji112;;15870435;;10.1002/pd.1199;;16032770;;pmc339001;;10.1093/nar/16.23.11141;;3205741;;pmc419792;;10.1101/gr.1635204;;15173119;;10.1373/clinchem.2003.024893;;14709639;;15616742;;10.1039/b400455h;;10.1097/01.gim.0000170992.63691.32;;16024975;;11514393;;10.1093/clinchem/47.9.1607;;10.1136/bmj.c7401;;21224326;;pmc3019239;;10.1016/j.tig.2009.05.004;;19540612;;10.1073/pnas.0810641105;;pmc2600580;;19073917;;10.1073/pnas.040562297;;10681460;;pmc15942;;10.1186/bcr898;;15318937;;pmc549166;;10.1093/molehr/gag027;;12651905;;pmc15083;;10.1073/pnas.96.1.11;;9874762;;10570146;;10.1073/pnas.96.24.13762;;pmc24138;;15692203;;10.1159/000082432;;pmc1011343;;8236972;;10.1515/jpme.1990.18.s1.39;;1815036;;10.1515/jpme.1991.19.6.411;;10.1093/molehr/7.10.1001;;11574670;;14168257;;11746096;;10.1002/1097-0320(20011201)45:4<267::aid-cyto10023>3.0.co;2-d;;pmc280436;;3260032;;10.1073/pnas.85.12.4397;;10.1038/nmeth.1251;;18794863;;pmc3171277;;10.1007/bf00280484;;3793097;;3192213;;10.1007/bf01790091;;20233831;;10.1001/jama.2010.292;;15317891;;10.1056/nejmoa040766;;10.1021/ac048196z;;pmc1542197;;15859584;;10521819;;10.1002/(sici)1097-0223(199910)19:10<934::aid-pd675>3.0.co;2-p;;10.1111/j.1399-0039.1980.tb00313.x;;6936871;;10778975;;10.1021/ja973071f;;10.1126/science.276.5313.779;;9115199;;10.1016/j.ajog.2008.09.476;;10.1016/s0140-6736(07)60115-9;;17292767;;10825377;;10.1093/molehr/6.6.571;;10.1097/cco.0b013e328011a8e7;;17133110;;2893918;;18660515;;pmc2532726;;10.1093/nar/gkn425;;10.1126/science.1068420;;11910102;;19636422;;10.1155/2009/804108;;pmc2712675;;10.1073/pnas.1133470100;;pmc166396;;12857956;;8503011;;10.1126/science.8503011;;7517036;;10.1073/pnas.91.13.5740;;pmc44073;;8043306;;10.1016/1050-3862(93)90009-8;;15627938;;10.1055/s-2004-830365;;17715994;;10.1021/ac0709394;;10.1101/sqb.2003.68.69;;15338605;;19375573;;10.1016/j.ajog.2009.03.002;;pmc4117196;;pmc2562413;;10.1073/pnas.0808319105;;18838674;;10.1631/jzus.2001.0318;;2722198;;10.1007/bf00284058;;10.1109/84.157362;;6312838;;10.1016/0003-2697(83)90418-9;;9599586;;10.1021/ac971063b;;10.1016/s0303-7207(01)00567-6;;11576725;;10.1126/science.7542800;;7542800;;10.1021/cen-v077n008.p027;;10.1021/ac0255330;;12069222;;10.1038/15095;;10545919;;10.1007/3-540-69544-3_4;;10.1101/gr.074906.107;;pmc3807531;;19339662;;10.1039/b409366f;;15570374;;10.1016/0002-9378(92)91603-8;;1595790;;8976177;;pmc2196361;;10.1084/jem.184.6.2217;;10.1038/184357a0;;10.1126/science.8502990;;8502990;;10.1111/j.1462-2920.2005.00779.x;;15946299;;10.1063/1.329003;;10.1016/0192-0561(81)90022-9;;6169674;;15068697;;10.1089/154732804773099290;;15838508;;10.1038/ng1547;;12370604;;10.1097/00003081-200209000-00008;;10949583;;10.1007/s000180050501;;10.1373/clinchem.2009.127480;;19797718;;10.1002/ajmg.1320410116;;1683159;;10.1126/science.288.5468.1026;;10807568;;pmc546528;;10.1101/gr.3185605;;15687290;;10.1038/nbt821;;12730666;;10.1126/science.1150427;;18388294;;10.1093/nar/gkl740;;pmc1635316;;17071717;;10.1073/pnas.76.3.1453;;286330;;pmc383270;;18519653;;10.1101/gr.073262.107;;1507189;;10.1038/nbt951;;15024389;;10.1088/0953-8984/18/18/s14;;pmc430878;;10.1101/gr.816903;;12695328;;pmc116571;;10.1186/1471-2393-2-4;;12057009;;12219075;;10.1038/nbt733;;15143275;;10.1126/science.1094567;;10.1021/ac001109s;;11321308;;10.1103/physrevlett.89.178301;;12398707;;10.1109/mmb.2002.1002375;;12446466;;10.1093/clinchem/48.12.2115;;10.1385/1-59745-074-x:45;;16916252;;15982637;;10.1016/j.bbrc.2005.06.040;;7050957;;10.1002/pd.1970010111;;10.1021/la000600b;;pmc1143700;;15942023;;10.1093/nar/gni089;;10.7150/ijbs.5.298;;19381348;;pmc2669597;;10596213;;10.1021/ac990504j;;4811823;;10.1182/blood.v43.3.411.411;;10.1093/nar/gkh613;;pmc419614;;15155856;;8553462;;8553462;;10.1126/science.285.5424.83;;0010390366;;10390366;;10.1038/376581a0;;15610773;;10.1016/j.mad.2004.09.014;;pmc16360;;10200290;;10.1073/pnas.96.8.4494;;10.1056/nejmoa044238;;15728811;;3657865;;10.1056/nejm198710153171603;;8197171;;10.1073/pnas.91.11.4997;;pmc43917;;10.1034/j.1399-0004.2001.600209.x;;11553049;;15249663;;pmc489966;;10.1073/pnas.0404036101;;6188677;;10.1007/bf00333523;;10794354;;10.1089/109065700316408;;11237011;;10.1038/35057062;;11251918;;10.1046/j.1469-0705.2001.00340.x;;10.1021/ac9606564;;9109354;;3419517;;10.1038/335414a0;;15073090;;10.1373/clinchem.2003.029835;;10.1101/gr.078212.108;;pmc2577856;;18714091;;3192212;;10.1007/bf01790090;;12941794;;pmc161798;;10.1186/1471-2164-4-19;;12740028;;10.1111/j.1365-2141.1994.tb08336.x;;7993816;;1972235;;10.1016/0140-6736(90)91491-r;;10.1073/pnas.0705765104;;pmc1934923;;17664418;;10818610;;10.1111/j.1749-6632.2000.tb06604.x;;17206148;;10.1038/nm1530;;9845707;;10.1056/nejm199812103392402;;17146468;;10.1038/nrg1982;;10.1016/s0140-6736(89)91969-7;;10.1016/s0140-6736(97)02174-0;;9274585;;9529358;;pmc1377040;;10.1086/301800;;10.1111/j.1471-0528.2008.02010.x;;19076946;;2947644;;10.1182/blood.v69.1.255.255;;10.1182/blood.v69.1.255.bloodjournal691255;;10.1373/clinchem.2008.111385;;18703764;;10.1172/jci6611;;pmc408407;;10393697;;10.1021/ac0513865;;16448074;;10.1038/nature03959;;16056220;;pmc1464427;;10.1002/pros.20715;;18409189;;1563980;;10.1016/0198-8859(92)90060-z;;2698825;;10.1139/g89-184;;10.1002/pd.1640;;17186566;;10.1007/bf00281061;;3030923;;12210249;;10.1002/1522-2683(200207)23:13<1984::aid-elps1984>3.0.co;2-u;;1134566;;10.1038/255706a0;;10.1021/jo060300k.s001;;16599623;;10.1021/jo060300k;;10.1038/nrg2626;;19997069;;10.1016/0167-7799(94)90008-6;;7764555;;17628577;;10.1016/j.chroma.2007.06.025;;10.1109/tnb.2004.837903;;15631136;;9825297;;10.1016/s0165-022x(98)00010-4;;10.1038/sj.ejhg.5201528;;16306880;;10.1016/0140-6736(90)91731-o;;1973769;;3951989;;pmc339507;;10.1093/nar/14.3.1325;;3472723;;10.1101/sqb.1986.051.01.032;;9766512;;10.1038/sj.leu.2401154;;10.1002/humu.20199;;15957185;;10.1126/science.4071043;;4071043;;18097410;;10.1038/nature06385;;pmc3090667;;16024607;;10.1158/0008-5472.can-05-0465;;10.1046/j.1423-0410.2001.00019.x;;11378966;;10.1002/(sici)1097-0258(19980430)17:8<857::aid-sim777>3.0.co;2-e;;9595616;;10.1373/49.5.727;;12709362;;10.1021/bp0256216;;12467482;;2781285;;10.1126/science.2781285;;10.1002/(sici)1097-0223(1998100)18:10<1082::aid-pd383>3.0.co;2-d;;9826902;;10.1002/(sici)1097-0223(1998100)18:10<1082::aid-pd383>3.3.co;2-4;;17138901;;10.1126/science.1131370;;656540;;10.1016/s0006-3495(78)85482-4;;pmc1473441;;10.1093/nar/gnh069;;pmc419624;;15150323;;10.1055/s-2001-16612;;11521211;;10.1002/ajmg.1350;;11424143;;17314005;;10.1016/j.canlet.2006.12.014;;10.2144/05384st01;;15884673;;12209705;;10.1002/cncr.10776;;pmc524418;;10.1101/gr.2890204;;15466292;;15753390;;10.1158/0008-5472.can-04-3196;;11530135;;10.1016/s0029-7844(01)01195-4;;10.1097/00006250-200109000-00023;;11972351;;10.1093/nar/30.9.e36;;pmc113859;;10.1073/pnas.83.9.2934;;3458254;;pmc323421;;10.1073/pnas.85.23.9138;;2973607;;pmc282679;;16733212;;10.1016/j.humpath.2006.01.026;;10.1586/14737159.4.1.41;;14711348;;10.1016/s0009-8981(01)00668-4;;11694254;;17057710;;10.1038/nm1491;;10.1016/0002-9378(91)90024-l;;1750468;;10.1515/cclm.2002.114;;12241011;;10.1093/nar/29.1.137;;pmc29787;;11125071;;10.1016/s1028-4559(09)60184-4;;17272202;;10.1038/sj.ejhg.5200833;;12111640;;16179219;;10.1016/j.ejmg.2005.03.003;;15801980;;pmc1087511;;10.1186/1477-7819-3-18;;16982673;;10.1074/mcp.m600246-mcp200;;11718302;;10.1007/s002490100171;;8474335;;10.1016/0076-6879(93)17069-h;;11514395;;10.1093/clinchem/47.9.1622;;10982031;;10.1007/s004390050006;;10.1007/s004390000327;;10.1016/0924-4247(90)87066-r;;4109537;;10.1182/blood.v39.2.153.153;;21519036;;10.1373/clinchem.2011.165910;;10.1021/ac049429p;;15516115;;15829238;;10.1016/j.mrfmmm.2004.07.022;;10.1126/science.1117389;;16081699;;18846087;;10.1038/nbt1486;;9659974;;10.1046/j.1469-1809.1998.6210009.x;;10.1017/s0003480098006630;;10.1016/j.yexcr.2004.08.039;;15561097;;10.1002/(sici)1097-0223(199708)17:8<743::aid-pd144>3.3.co;2-v;;9267898;;10.1002/(sici)1097-0223(199708)17:8<743::aid-pd144>3.0.co;2-3;;18644185;;10.1016/s1701-2163(16)32896-1;;12107088;;pmc1850686;;10.1016/s0002-9440(10)64155-7;;9059812;;10.1002/elps.1150180102;;10.1016/j.legalmed.2005.05.001;;15990351;;1389177;;10922068;;10.1073/pnas.97.16.9127;;pmc16833;;10.1038/387s098;;9169874;;9169868;;pmc6615710;;9169869;;pmc3057095;;9169867;;9169870;;9169871;;9169872;;9169875;;10.1016/0022-1759(89)90246-9;;2472455;;10.1002/cyto.a.20369;;17200956;;16004567;;10.1146/annurev.bioeng.7.011205.135108;;pmc3779643;;10.1126/science.2416058;;2416058;;10.1093/molehr/5.12.1162;;10587372;;10.1016/s1471-4914(03)00137-0;;12928035;;11292856;;10.1093/nar/29.8.e42;;pmc31326;;10.1126/science.1058040;;11181995;;10.1373/clinchem.2009.141267;;20040615;;10430926;;pmc17763;;10.1073/pnas.96.16.9236;;9496384;;10.1023/a:1008209720526;;1501715;;10.1038/358600a0;;9048933;;10.1007/s004390050351;;11786398;;10.1016/s0002-9440(10)64348-9;;pmc1867119;;10.1016/0168-1656(95)00007-d;;7654345;;10.1002/(sici)1097-0223(199909)19:9<846::aid-pd657>3.0.co;2-#;;10.1002/(sici)1097-0223(199909)19:9<846::aid-pd657>3.3.co;2-r;;10521843;;15108284;;10.1002/humu.20022;;10.1093/oxfordjournals.humrep.a137290;;1770146;;16314297;;10.1093/nar/gni177;;pmc1301601;;10.1056/nejmoa025273;;14534333;;pmc1693828;;17098862;;10.1073/pnas.0608512103;;10.1109/28.54263;;10.1126/science.283.5400.346;;10.1038/nature06884;;18421352;;10.1186/1471-2164-10-541;;pmc2667538;;10.1186/1471-2164-10-116;;19298667;;pmc484193;;10.1093/nar/gnh094;;15240836;;16354990;;10.1159/000089062;;pmc2823013;;10.3349/ymj.2005.46.2.193;;15861490;;10.1002/(sici)1097-0320(19970701)28:3<191::aid-cyto2>3.0.co;2-h;;10.1002/(sici)1097-0320(19970701)28:3<191::aid-cyto2>3.3.co;2-l;;9222103;;10.1016/j.gene.2005.06.030;;16125339;;15126342;;10.1158/0008-5472.can-03-3308;;10.1002/(sici)1097-0223(199811)18:11<1181::aid-pd410>3.0.co;2-k;;10.1002/(sici)1097-0223(199811)18:11<1181::aid-pd410>3.3.co;2-b;;9854729;;10329883;;10.1016/s0002-9378(99)70622-8;;12907803;;10.1126/science.1085792;;10.1038/nrg1901;;16847463;;10.1093/clinchem/47.10.1867;;11568107;;10.1093/humupd/8.6.493;;12498419;;20224049;;10.1373/clinchem.2009.137877;;10.1002/pd.1558;;16952193;;16203989;;pmc1253547;;10.1073/pnas.0503335102;;16916256;;10.1385/1-59745-074-x:101;;22538702;;10.1159/000337544;;16141041;;10.1126/science.309.5740.1476;;pmc4864235;;27167625;;10.1371/journal.pone.0155009;;15292918;;10.1038/sj.ejhg.5201224;;11751536;;10.1093/clinchem/48.1.35;;18001438;;10.1111/j.1447-0756.2007.00652.x;;17040955;;10.1373/clinchem.2006.076851;;10.1126/science.2565047;;2565047;;10.1373/clinchem.2005.052340;;16081506;;10.1073/pnas.1406103111;;24843150;;pmc4060699;;10.1038/83572;;11135558;;11812558;;10.1016/s0140-6736(02)07448-2;;10.1002/pd.2150;;19003785;;10.1093/jnci/94.22.1697;;12441325;;15830996;;10.1520/jfs2004216;;10.1073/pnas.0702165104;;17517648;;pmc1871563;;pmc1735643;;15591276;;10.1136/jmg.2004.023184;;10.1242/jeb.001370;;17449817;;10.1002/pd.1213;;16032774;;837366;;10.1080/00016340601159124;;17464580;;10.1093/clinchem/45.10.1747;;10508120;;10.1086/302205;;9915961;;pmc1377720;;10.1373/clinchem.2005.062893;;16423903;;10.1007/s004399900166;;10.1007/s004390051008;;10982181;;15096565;;pmc1867475;;10.1016/s1525-1578(10)60497-7;;10.1016/j.febslet.2007.01.051;;17289032;;10.1038/nm1437;;16799556;;18945714;;10.1093/humupd/dmn047;;pmc49394;;1631067;;10.1073/pnas.89.13.5847;;10.1126/science.1072047;;12169732;;10.1016/s1472-6483(10)62173-6;;12831600;;10.1038/nprot.2007.276;;17703209;;10.1073/pnas.202610899;;12461184;;pmc138581,"Illumina Technical Note: Reproductive Health, pp. 1-5 (2014).;;Iontorrent Application Note, pp. 1-6 (2016).;;Hua, R. et al., Prenatal Diagnosis, vol. 34, pp. 1-8 (2014).;;Breman, A.M. et al., Prenatal Diagnosis, vol. 36, pp. 1009-1019 (2016).;;Fiddler, M., J. Clin. Med., vol. 3, pp. 972-985 (2014).;;Hatt, L. et al., Prenatal Diagn., vol. 34, pp. 1-7 (2014).;;Christensen, B. et al., Fetal Diagn. Ther., vol. 18, pp. 479-484 (2003).;;Karow, J., “following Improvements in Noninvasive Fetal Cell Isolation, First Prenatal Tests Expected in 2016”, published on genomeweb (www.genomeweb.com/archive/following-improvements-noninvasive-fetal-cell-isolation-first-prenatal-tests-expected-2016; pp. 1-4; (Nov. 2015).;;Wang, Y. et al., Mol. Cell, vol. 58, pp. 598-609 (2015).;;Bischoff, F.Z. et al., Clin. Genet., vol. 63, pp. 483-489 (2003).;;Geifman-Holtzman, O. et al., Am. J. Obstet. Gynecol., vol. 183, pp. 462-468 (2000).;;Vona, G. et al., Am. J. Pathol., vol. 160, pp. 51-58 (2002).;;Office action dated Jul. 29, 2014 for U.S. Appl. No. 13/835,926.;;Office action dated Aug. 29, 2014 for U.S. Appl. No. 13/837,974.;;Office action dated Sep. 17, 2014 for U.S. Appl. No. 13/863,992.;;U.S. Appl. No. 60/764,420, filed Feb. 2, 2005, Quake.;;U.S. Appl. No. 60/949,227, filed Jul. 11, 2007, Kapur.;;U.S. Appl. No. 11/825,677, filed Jul. 5, 2007, Lopez et al.;;U.S. Appl. No. 11/909,959, filed Sep. 27, 2007, Duff.;;U.S. Appl. No. 13/794,503, filed Mar. 11, 2013, Stoughton et al.;;717.305 pending claims dated Jan. 10, 2013 for U.S. Appl. No. 13/738,268.;;Adams, et al. Complementary DNA Sequencing: Expressed Sequence Tags and Human Genome Project. Science Jun. 21, 1991: vol. 252 No. 5013 pp. 1651-1656 DOI: 10.1126/science.2047873.;;Adinolfi, et al. Gene Amplification to Detect Fetal Nucleated Cells in Pregnant Women. The Lancet. Aug. 5, 1989:328-329.;;Adinolfi, et al. Rapid detection of aneuploidies by microsatellite and the quantitative fluorescent polymerase chain reaction. Prenat. Diagn. 1997; 17(13):1299-311.;;Adinolfi, M. On a Non-Invasive Approach to Prenatel Diagnosis based on the detection of Fetal Nucleated Cells in Maternal Blood Samples. Prenatal Diagnosis. 1991;11:799-804.;;Advisory action dated Dec. 16, 2013 for U.S. Appl. No. 12/751,940.;;Ahn, et al. A fully integrated micromachined magnetic particle separator. Journal of Microelectromechanical Systems. 1996; 5(3):151-158.;;Allard, et al. Tumor cells circulate in the peripheral blood of all major carcinomas but not in healthy subjects or patients with nonmalignant diseases. Clin Cancer Res. Oct. 15, 2004;10(20):6897-904.;;Allowed claims dated Dec. 9, 2010 for U.S. Appl. No. 11/701,686.;;Amendments to the Claims Filed Mar. 29, 2013 with U.S. Patent Office for U.S. Appl. No. 12/751,940.;;Amendments to the Claims. Filed Aug. 14, 2013 with U.S. Patent Office for U.S. Appl. No. 13/737,730.;;Amendments to the Claims. Filed Jul. 11, 2013 with U.S. Patent Office for U.S. Appl. No. 13/831,342.;;Amendments to the Claims. Filed Jul. 22, 2013 with U.S. Patent Office for U.S. Appl. No. 13/794,503.;;Amendments to the Claims. Filed Jul. 25, 2013 with U.S. Patent Office for U.S. Appl. No. 13/829,971.;;Amendments to the Claims. Filed Mar. 15, 2013 with U.S. Patent Office for U.S. Appl. No. 13/835,926.;;Amendments to the Claims. Filed Mar. 15, 2013 with U.S. Patent Office for U.S. Appl. No. 13/837,974.;;Amendments to the Claims. Filed Nov. 7, 2013 with U.S. Patent Office for U.S. Appl. No. 13/863,992.;;Andrews, et al. Enrichment of fetal nucleated cells from maternal blood: model test system using cord blood. Prenatal Diagnosis. 1995; 15:913-919.;;Applicant's Amendment and Response dated Jun. 17, 2009 to Non-Final Office Action dated Jan. 28, 2009 re U.S. Appl. No. 11/701,686.;;Applicant's Amendment and Response dated Jun. 24, 2010 to Office Action dated Jan. 27, 2010 re U.S. Appl. No. 11/701,686.;;Applicant's Amendment and Response dated Nov. 13, 2009 to Office Action dated Sep. 11, 2009 re U.S. Appl. No. 11/701,686.;;Applicant's response dated Jun. 10, 2011 to Office action dated Apr. 25, 2011 for U.S. Appl. No. 12/393,803.;;Ariga, et al. Kinetics of fetal cellular and cell-free DNA in the maternal circulation during and after pregnancy: implications for noninvasive prenatal diagnosis. Transfusion. 2001; 41:1524-1530.;;Arnould, et al. Agreement between chromogenic in situ hybridisation (CISH) and FISH in the determination of HER2 status in breast cancer. Br J Cancer. 2003; 88(10):1587-91. (Abstract only).;;Babochkina, et al. Direct detection of fetal cells in maternal blood: a reappraisal using a combination of two different Y chromosome-specific FISH probes and a single X chromosome-specific probe. Arch Gynecol Obstet. Dec. 2005;273(3):166-9. (Abstract only).;;Babochkina, T. I. Ph. D. Dissertation—Fetal cells in maternal circulation: Fetal cell separation and FISH analysis. University of Basel, Switzerland. Dec. 8, 2005. (123 pages).;;Balko, et al. Gene expression patterns that predict sensitivity to epidermal growth factor receptor tyrosine kinase inhibitors in lung cancer cell lines and human lung tumors. BMC Genomics. Nov. 10, 2006;7:289 (14 pages).;;Barrett, et al. Comparative genomic hybridization using oligonucleotide microarrays and total genomic DNA. Proc Natl Acad Sci U S A. 2004; 101(51):17765-70.;;Basch, et al. Cell separation using positive immunoselective techniques. Journal of Immunological Methods. 1983;56:269-280.;;Bauer, J. Advances in cell separation: recent developments in counterflow centrifugal elutriation and continuous flow cell separation. Journal of Chromatography. 1999;722:55-69.;;Becker, et al. Fabrication of Microstructures With High Aspect Ratios and Great Structural Heights by Synchrotron Radiation Lithography, Galvanoforming, and Plastic Moulding (LIGA Process). Microelectronic Engineering. 1986;4:35-56.;;Becker, et al. Planar quartz chips with submicron channels for two-dimensional capillary electrophoresis applications. J. Micromech Microeng.1998;9:24-28.;;Beebe et al. Functional Hydrogel Structures for Autonomous Flow Control Inside Microfluidic Channels. Nature. 2000; 404:588-590.;;Bennett, et al. Toward the 1,000 dollars human genome. Pharmacogenomics. 2005; 6(4):373-82.;;Berenson, et al. Cellular Immunoabsorption Using Monoclonal Antibodies. Transplantation.1984 ;38:136-143.;;Berenson, et al. Positive selection of viable cell populations using avidin-biotin immunoadsorption. Journal of Immunological Methods. 1986;91:11-19.;;Berg, H. C. Random Walks in Biology, Ch. 4. Princeton University Press. Princeton, NJ. 1993. pp. 48-64.;;Berger, et al. Design of a microfabricated magnetic cell separator. Electrophoresis. Oct. 2001;22(18):3883-92.;;Bianchi, et al. Isolation of fetal DNA from nucleated erythrocytes in maternal blood. Medical Sciences. 1990;87:3279-3283.;;Bianchi, et al. Demonstration of fetal gene sequences in nucleated erythrocytes isolated from maternal blood. American Journal of Human Genetics. 1989;45:A252.;;Bianchi, et al. Fetal gender and aneuploidy detection using fetal cells in maternal blood: analysis of NIFTY I data. Prenatal Diagnosis. 2002; 22:609-615.;;Bianchi, et al. Fetal nucleated erythrocytes (FNRBC) in maternal blood: erythroid-specific antibodies improve detection. The American Journal of Human Genetics. Oct. 1992. Supplemental to vol. 51, No. 4: 996.;;Bianchi, et al. Isolation of Male Fetal DNA from Nucleated Erythrocytes (NRBC) in Maternal Blood. The American Pediatric Society and Society for Pediatric Research, (1989) Mar. 1989; 818:139A.;;Bianchi, et al. Possible Effects of Gestational Age on the Detection of Fetal Nucleated Erythrocytes in Maternal Blood. Prenatal Diagnosis. 1991;11:523-528.;;Bignell, et al. High-resolution analysis of DNA copy number using oligonucleotide microarrays. Genome Research. 2004; 14(2):287-295.;;Binladen, et al. The Use of Coded PCR Primers Enables High-Throughput Sequencing of Multiple Homolog Amplification Products by 454 Parallel Sequencing. Feb. 2007, PLoS One. 2(2):e197, doi:10.1371/journal.pone.0000197.;;Blake, et al. Assessment of multiplex fluorescent PCR for screening single cells for trisomy 21 and single gene defects. Mol. Hum. Reprod. 1999; 5(12):1166-75.;;Bode, et al. Mutations in the tyrosine kinase domain of the EGFR gene are rare in synovial sarcoma. Mod Pathol. Apr. 2006;19(4):541-7.;;Boehm, et al. Analysis of Defective Dystrophin Genes with cDNA Probes: Rearrangement Polymorphism, Detection of Deletions in Carrier Females, and Lower Than Expected Frequency of Carrier Mothers in Isolated Cases of Delections. Pediatric Research. Apr. 1989: 139A-820.;;Bohmer, et al. Differential Development of Fetal and Adult Haemoglobin Profiles in Colony Culture: Isolation of Fetal Nucleated Red Cells by Two-Colour Fluorescence Labelling. Br. J. Haematol. 1998; 103:351-60.;;Bookout, et al. High-throughput real-time quantifative reverse transcription PCR. Curr. Prot. Mol. Biol. 2005; 15.8.1-15.8.21.;;Braslavsky, et al. “Sequence information can be obtained from single DNA molecules,” PNAS, Apr. 2003, vol. 100, No. 7, 3960-3964.;;Brison, et al. General Method for Cloning Amplified DNA by Differential Screening with Genomic Probes. Molecular and Cellular Biology. 1982;2:578-587.;;Brody, et al. Deformation and Flow of Red Blood Cells in a Synthetic Lattice: Evidence for an Active Cytoskeleton. Biophys. J. 68:2224-2232 (1995).;;Brown, et al. Applicant-Initiated Interview Summary, with Office Action Summary, and Information Disclosure Statement by Applicant. dated Sep. 16, 2009.;;ANA BUSTAMANTE-ARAGONES, MARIA GARCIA-HOYOS, MARTA RODRIGUEZ DE ALBA, CRISTINA GONZALEZ-GONZALEZ, ISABEL LORDA-SANCHEZ, DAN DIEGO-: ""Detection of a paternally inherited fetal mutation in maternal plasma by the use of automated sequencing"", ANNALS OF THE NEW YORK ACADEMY OF SCIENCES, NEW YORK ACADEMY OF SCIENCES., US, vol. 1075, no. IV, 4 September 2005 (2005-09-04), US, pages 108 - 117, XP002652985, ISSN: 0077-8923, DOI: 10.1196/ANNALS.1368.014;;Caggana, M. Microfabricated devices for sparse cell isolation. CNF Project #905-00. Cornell NanoScale Facility. 2003; pp. 38-39.;;Caggana, M. Microfabricated devices for sparse cell isolation. CNF Project #905-00. Cornell NanoScale Facility. 2004-2005; pp. 32-33.;;Calin, et al. A microRNA signature Associated with prognosis and progression in chronic lymphocytic leukemia. New England Journal of Medicine. 2005; 353:1793-1801.;;Cappuzzo, et al. Epidermal growth factor receptor gene and protein and gefitinib sensitivity in non-small-cell lung cancer. J Natl Cancer Inst. May 4, 2005;97(9):643-55.;;Cha, The utility of an erythroblast scoring system and gender-independent short tandem repeat (STR) analysis for the detection of aneuploid fetal cells in maternal blood. Prenat. Diagn. 2005; 25(7):586-91.;;Chamberlain, et al. Deletion screening of the Duchenne muscular dystrophy locus via multiplex DNA amplification. Nucleic Acids Research. 1988;16:11141-11156.;;Chan, et al. “DNA Mapping Using Microfluidic Stretching and Single-Molecule Detection of Fluorescent Site-Specific Tags,” Genome Research, 2004, vol. 14, 1137-1146.;;Chan, et al. Size distributions of maternal and fetal DNA in maternal plasma. Clin Chem. Jan. 2004;50(1):88-92.;;Chang, et al. Biomimetic technique for adhesion-based collection and separation of cells in a microfluidic channel. Lab Chip. 2005; 5:64-73.;;Cheung, et al. Development and validation of a CGH microarray for clinical cytogenetic diagnosis. Genet Med. 2005; 7(6):422-32.;;Chiu, et al. “Effects of Blood-Processing Protocols on Fetal and Total DNA Quantification in Maternal Plasma,” Clinical Chemistry, 2001, vol. 47, No. 9, 1607-1613.;;Chiu, et al. Non-invasive prenatal assessment of trisomy 21 by multiplexed maternal plasma DNA sequencing: large scale validity study. BMJ. Jan. 11, 2011;342:c7401. doi: 10.1136/bmj.c7401.;;Chiu, et al. Non-invasive prenatal diagnosis by single molecule counting technologies. Trends in Genetics, vol. 25, Issue 7, Jul. 2009, pp. 324-331.;;Chiu, et al. Noninvasive prenatal diagnosis of fetal chromosomal aneuploidy by massively parallel genomic sequencing of DNA in maternal plasma. Proc Natl Acad Sci U S A. Dec. 23, 2008;105(51):20458-63.;;Chiu, et al. Patterned Deposition of Cells and Proteins Onto Surfaces by Using Three-Dimensional Microfluidic Systems. Proceedings of the National Academy of Sciences of the United States of America. 2000; pp. 2408-2413.;;Choesmel, et al. Enrichment methods to detect bone marrow micrometastases in breast carcinoma patients: clinical relevance. Breast Cancer Res. 2004;6(5):R556-569.;;Choolani, et al. Characterization of First Trimester Fetal Erythroblasts for Non-Invasive Prenatal Diagnosis. Mol. Hum. Reprod. 2003; 9:227-35.;;Chou, et al. A Microfabricated Device for Sizing and Sorting DNA Molecules. Proceedings of the National Academy of Sciences of the United States of America. 1999; pp. 11-13.;;Chou, et al. Sorting by diffusion: An asymmetric obstacle course for continuous molecular separation. PNAS. 1999; 96(24):13762-13765.;;Christel, et al. High aspect ratio silicon microstructures for nucleic acid extraction. Solid-state sensor and actuator workshop. Hilton Head, SC. Jun. 8-11, 1998; 363-366.;;Christensen, et al. Fetal Cells in Maternal Blood: A Comparison of Methods for Cell Isolation and Identification. Fetal Diagn. Ther. 2005; 20:106-12.;;Chueh, et al. Prenatal Diagnosis Using Fetal Cells from the Maternal Circulation. West J. Med. 159:308-311 (1993).;;Chueh, et al. Prenatal Diagnosis Using Fetal Cells in the Maternal Circulation. Seminars in Perinatology. 1990;14:471-482.;;Chueh, et al. The search for fetal cells in the maternal circulation. J Perinat Med. 1991;19:411-420.;;Cirigliano, et al. “Clinical application of multiplex quantitative fluorescent polymerase chain reaction (QF-PCR) for the rapid prenatal detection of common chromosome aneuploidies,” Molecular Human Reproduction, 2001, vol. 7, No. 10, 1001-1006.;;Claims mailed with RCE Response to Final Rejection dated Dec. 31, 2009 for U.S. Appl. No. 11/763,421, filed Jun. 14, 2007 (6 pages).;;Claims. Filed Nov. 29, 2011 with U.S. Patent Office for U.S. Appl. No. 13/306,520.;;Claims. Filed Nov. 29, 2011 with U.S. Patent Office for U.S. Appl. No. 13/306,640.;;Claims. Filed Nov. 29, 2011 with U.S. Patent Office for U.S. Appl. No. 13/306,698.;;Clayton, et al. Fetal Erythrocytes in the Maternal Circulation of Pregnant Women. Obstetrics and Gynecology. 1964;23:915-919.;;Collarini, et al. Comparison of methods for erythroblast selection: application to selecting fetal erythroblasts from maternal blood. Cytometry. 2001; 45:267-276.;;Cotton, et al. Reactivity of cytosine and thymine in single-base-pair mismatches with hydroxylamine and osmium tetroxide and its application to the study of mutations. Proc Natl Acad Sci U S A. Jun. 1988;85(12):4397-401.;;Craig, et al. Identification of genetic variants using bar-coded multiplexed sequencing. Nat Methods. Oct. 2008 ; 5(10): 887-893. DOI:10.1038/nmeth.1251.;;Cremer, et al. Detection of chromosome aberrations in human interphase nucleus by visualization of specific target DNAs with radioactive and non-radioactive in situ hybridization techniques: diagnosis of trisomy 18 with probe L1.84. Human Genetics.1986;74:346-352.;;Cremer, et al. Detection of chromosome aberaations in metaphase and interphase tumor cells by in situ hybridization using chromosome-specific library probes. Human Genetics.1988;80:235-246.;;Cristofanilli, et al. Circulating tumor cells revisited. JAMA. 2010; 303(11):1092-1093.;;Cristofanilli, et al. Circulating tumor cells, disease progression, and survival in metastatic breast cancer. N Engl J Med. Aug. 19, 2004;351(8):781-91.;;Das, et al. Dielectrophoretic segregation of different human cell types on microscope slides. Anal. Chem. 2005; 77:2708-2719.;;De Alba, et al. Prenatal diagnosis on fetal cells obtained from maternal peripheral blood: report of 66 cases. Prenat Diagn. Oct. 1999;19(10):934-40.;;De Kretser, et al. The Separation of Cell Populations using Monoclonal Antibodies attached to Sepharose. Tissue Antigens. 1980;16:317-325.;;De Luca, et al. Detection of circulating tumor cells in carcinoma patients by a novel epidermal growth factor receptor reverse transcription—PCR assay. Clin Cancer Res. Apr. 2000;6(4):1439-44.;;Decision re: Institution of Inter Partes Review 37 C.F.R. § 42.108. Entered Oct. 25, 2013. For Case IPR2013-00277. U.S. Pat. No. 8,318,430.;;Decision: Institution of Inter Partes Review 37 C.F.R. § 42.108. Dated . Entered Oct. 25, 2013. For Case IPR2013-00276. U.S. Pat. No. 8,318,430 B2.;;Declaration of Cynthia Casson Morton. Dated May 29, 2013. U.S. Pat. No. 8,296,076.;;Declaration of Cynthia Casson Morton. Dated May 10, 2013. In re: Chuu, et al., U.S. Pat. No. 8,318,430.;;Declaration of Cynthia Casson Morton. Dated May 10, 2013. In re: Chuu, et al., U.S. Pat. No. 8,318,430, claims 1-18.;;Declaration of Robert Nussbaum. Dated May 22, 2013. U.S. Pat. No. 8,296,076.;;Declaration of Robert Nussbaum. Dated May 8, 2013. In re Patent of: Chuu, et al. U.S. Pat. No. 8,318,430.;;Declaration of Robert Nussbaum. Dated Apr. 16, 2013. In re Patent of: Fan, et al. U.S. Pat. No. 8,318,430, claims 1-18.;;Delamarche, et al. Microfluidic Networks for Chemical Patterning of Substrates: Design and Application to Bioassays. Journal of the American Chemical Society. 1998; 120:500-508.;;Delamarche, et al. Patterned Delivery of Immunoglobulins to Surfaces Using Microfluidic Networks. Science. 1997; 276:779-781.;;Deng, et al. Enumeration and microfluidic chip separation of circulating fetal cells early in pregnancy from maternal blood. American Journal of Obstetrics & Gynecology. Dec. 2008 (vol. 199, Issue 6, p. S134).;;Deshmukh, et al. Continuous Micromixer With Pulsatile Micropumps. Solid-State Sensor and Actuator Workshop. Hilton Head Island, South Carolina; Jun. 4-8, 2000:73-76.;;Devotek. “Separation of RNA 8 DNA by Gel Filtration Chromatography,” Edvotek, 1987. 1-9.;;Dhallan, et al. A non-invasive test for prenatal diagnosis based on fetal DNA present in maternal blood: a preliminary study. The Lancet, vol. 369, Issue 9560, Feb. 10, 2007, pp. 440-442.;;Di Naro, et al. Prenatal diagnosis of beta-thalassaemia using fetal erythroblasts enriched from maternal blood by a novel gradient. Mol Hum Reprod. 2000; 6(6):571-4.;;Diehl, et al. Digital quantification of mutant DNA in cancer patients. Curr Opin Oncol. Jan. 2007;19(1):36-42.;;Dilella, et al. Screening for Phenylketonuria Mutations by DNA Amplification with the Polymerase Chain Reaction. The Lancet. Mar. 5, 1988:497-499.;;Dohm, et al. Substantial biases in ultra-short read data sets from high-throughput DNA sequencing. Nucleic Acids Research. 2008. 36: e105 doi: 10.1093\nark\gkn425.;;Doyle, et al. Self-Assembled Magnetic Matrices for DNA Separation Chips. Science 295:2237 (2002).;;Dragovich, et al. Anti-EGFR-targeted therapy for exophageal and gastric cancers: an evolving concept. Jornal of Oncology. 2009; vol. 2009, Article ID 804108.;;Dressman, et al. “Transforming single DNA molecules into fluorescent magnetic particles for detection and enumeration of genetic variations.” PNAS, Jul. 2003, vol. 100. No. 15, 8817-8822.;;Drmanac, et al. DNA Sequence Determination by Hybridization: A Strategy for Efficient Large-Scale Sequencing. Science Jun. 11, 1993: vol. 260 No. 5114 pp. 1649-1652 DOI: 10.1126/science.8503011. Jun. 11, 1993.;;Eigen, et al. Sorting Single Molecules: Application to Diagnostics and Evolutionary Biotechnology. Proceedings of the National Academy of Sciences of the United States of America. 1994; 91:5740-5747.;;Emanuel, et al. Amplification of Specific Gene Products from Human Serum. GATA, 1993, vol. 10, No. 6, 144-146.;;European office action dated Jun. 26, 2012 for EP Application No. 11159371.1.;;European office action dated Jul. 17, 2013 for EP Application No. 11159371.1, 8 pages.;;European office action dated Oct. 8, 2012 for EP Application No. 11175845.;;European office action dated Dec. 13, 2013 for EP Application No. 11159371.1.;;European office action dated Dec. 16, 2013 for EP Application No. 12175907.;;European office action dated Dec. 18, 2012 for EP Application No. 11159371.1.;;European Search Opinion dated Jul. 31, 2009 for EP07763674.4.;;European Search Report Office action dated Dec. 21, 2010 for EP07763674.4.;;European search report and search opinion dated Jan. 2, 2013 for EP Application No. 12175907.0.;;European search report and search opinion dated Mar. 16, 2012 for EP Application No. 11182181.;;European search report and search opinion dated Apr. 9, 2013 for EP Application No. 12180149.2.;;European search report and search opinion dated Nov. 17, 2011 for EP Application No. 11175845.;;European Search Report dated Jul. 31, 2009 for EP07763674.4.;;European search report dated Nov. 9, 2009 for Application No. 7784442.1.;;European search report dated Dec. 21, 2009 for Application No. 07798579.4.;;European search report dated Dec. 22, 2009 for Application No. 07798580.2.;;European search report dated Dec. 22, 2009 for Application No. 07784444.7.;;Applicant's Response with Allowed Claims dated Dec. 2, 2010 issued in U.S. Appl. No. 11/701,686.;;Pending Claims filed with the USPTO on Jun. 24, 2010 for U.S. Appl. No. 11/701,686.;;Extended European Search Report for Application No. 11159371 dated Aug. 10, 2011, 10 pages.;;Falcidia, et al. Fetal Cells in maternal blood: a six-fold increase in women who have undergone mniocentesis and carry a fetus with Down syndrome: a multicenter study. Neuropediatrics. 2004; 35(6):321-324. (Abstract only).;;Fan, et al. Detection of aneuploidy with digital polymerase chain reaction. Anal Chem. Oct. 1, 2007; 79(19):7576-9.;;Fan, et al. Highly parallel SNP genotyping. Cold Spring Harb. Symp. Quant. Biol. 2003; 68:69-78.;;Fan, et al. Microfluidic digital PCR enables rapid prenatal diagnosis of fetal aneuploidy. Am J Obstet Gynecol. May 2009;200(5):543.e1-7.;;Fan, et al. Noninvasive diagnosis of fetal aneuploidy by shotgun sequencing DNA from maternal blood. Proc Natl Acad Sci U S A. Oct. 21, 2008;105(42):16266-71.;;Fan, et al. Single cell degenerate oligonucleotide primer-PCR and comparative genomic hybridization with modified control reference. Journal of Ahejian University—Science A. 2001; 2(3):318-321.;;Farber, et al. Demonstration of spontaneous XX/XY chimerism by DNA fingerprinting. Human Genetics. 1989;82:197-198.;;Farooqui, et al. Microfabrication of Submicron Nozzles in Silicon Nitride. Journal of Microelectromechanical Systems. 1992; 1(2):86-88.;;Feinberg, et al. A technique for radiolabeling DNA restriction endonuclease fragments to high specific activity. Anal Biochem. Jul. 1, 1983;132(1):6-13.;;Fiedler, et al. Dielectrophoretic Sorting of Particles and Cells in a Microsystem. Analytical Chemistry. 1998; pp. 1909-1915.;;Findlay, et al. Using MF-PCR to diagnose multiple defects from single cells: implications for PGD. Mol Cell Endocrinol. 2001; 183 Suppl 1:S5-12.;;Fleischmann, et al. Whole-Genome Random Sequencing and Assembly of Haemophilus influenzae Rd. Science Jul. 28, 1995: vol. 269 No. 5223 pp. 496-512 DOI: 10.1126/science.7542800.;;Freemantle, M. Downsizing Chemistry. Chemical analysis and synthesis on microchips promise a variety of potential benefits. Chemical & Engineering News. 1999; pp. 27-36.;;Fu, et al. An integrated miscrofabricated cell sorter. Anal Chem. 2002;74:2451-2457.;;Fu, et al. A Microfabricated Fluorescence-Activated Cell Sorter. Nature Biotechnology.1999; 17:1109-1111.;;Fuhr, et al. Biological Application of Microstructures. Topics in Current Chemistry. 1997; 194:83-116.;;Fullwood, et al. Next Generation DNA sequencin of paired-end tags (PET) for transcriptome and genome analyses. Genome Research. 2009. 19:521-532.;;Furdui, et al. Immunomagnetic T cell capture from blood for PCR analysis using microfluidic systems. Lab Chip. Dec. 2004;4(6):614-8.;;Ganshirt-Ahlert, et al. Magnetic cell sorting and the transferrin receptor as potential means of prenatal diagnosis from maternal blood. Am J Obstet Gynecol. 1992;166:1350-1355.;;Ganshirt-Ahlert, et al. Noninvasive prenatal diagnosis: Triple density gradient, magnetic activated cell sorting and FISH prove to be an efficient and reproducible method for detection of fetal aneuploidies from maternal blood. The American Journal of Human Genetics. Oct. 1992. Supplemental to vol. 51, No. 4: 182.;;Gardella, et al. Second Petition for Inter Partes Review Under 35 U.S.C. §§ 311-319 and 37 C.F.R. § 42.100 ET SEQ.(Claims 19-30). Dated May 10, 2013, for U.S. Pat. No. 8,318,430.;;Gardella, G. First Petition for Inter Partes Review Under 35 U.S.C. §§ 311-319 and 37 C.F.R. § 42.100 ET SEQ. (Claims 1-18). Dated May 10, 2013. U.S. Pat. No. 8,318,430.;;Gardella, G. Petition for Inter Partes Review Under 35 U.S.C. §§ 311-319 and 37 C.F.R. § 42.100 ET SEQ. Dated May 24, 2013. U.S. Pat. No. 8,296,076.;;GenomeWeb. Immunicon inks biomarker assay, lab services deal with merck serona. Available at C:\Documents and Settings\fc3\Local Settings\Temporary Internet Files\OLK35E\141896-1.htm. Accessed on Sep. 11, 2007.;;Ghia, et al. Ordering of human bone marrow B lymphocyte precursors by single-cell polymerase chain reaction analyses of the rearrangement status of the immunoglobulin H and L chain gene loci. J Exp Med. Dec. 1, 1996;184(6):2217-29.;;Giddings, J. C. Chemistry ‘Eddy’ Diffusion in Chromatography. Nature. 1959;184:357-358.;;Giddings, J. C. Field-Flow Fractionation: Analysis of Macromolecular, Colloidal, and Particulate Materials. Science. 1993;260:1456-1465.;;Gonzalez, et al. Multiple displacement amplification as a pre-polymerase chain reaction (pre-PCR) to process difficult to amplify samples and low copy number sequences from natural environments. Environ Microbiol. 2005; 7(7):1024-8.;;Graham. Efficiency comparison of two preparative mechanisms for magnetic separation of erthrocytes from whole blood. J. Appl. Phys. 1981; 52:2578-2580.;;Greaves, et al. Expression of the OKT Monoclonal Antibody Defined Antigenic Determinants in Malignancy. Int. J. Immunopharmac. 1981;3:283-299.;;Guetta, et al. Analysis of fetal blood cells in the maternal circulation: challenges, ongoing efforts, and potential solutions. Stem Cells Dev. 2004;13(1):93-9.;;Gunderson, et al. A genome-wide scalable SNP genotyping assay using microarray technology. Nat Genet. 2005; 37(5):549-54.;;Hahn, et al. “Prenatal Diagnosis Using Fetal Cells and Cell-Free Fetal DNA in Maternal Blood: What is Currently Feasible?” Clinical Obstetrics and Gynecology, Sep. 2002, vol. 45, No. 3, 649-656.;;Hahn, et al. Current applications of single-cell PCR. Cell. Mol. Life Sci. 2000; 57(1):96-105. Review.;;Hahn, et al. Micro system for isolation of fetal DNA from maternal plasma by preparative size separation. Clin Chem. Dec. 2009;55(12):2144-52. doi: 10.1373/clinchem.2009.127480. Epub Oct. 1, 2009.;;Hamabe, et al. Molecular study of the Prader-Willi syndrome: deletion, RFLP, and phenotype analyses of 50 patients. Am J Med Genet. Oct. 1, 1991;41(1):54-63.;;Han, et al. Separation of Long DNA Molecules in a Microfabricated Entropic Trap Array. Science. 2000;288:1026-1029.;;Hardenbol, et al. Highly multiplexed molecular inversion probe genotyping: over 10,000 targeted SNPs genotyped in a single tube assay. Genome Res. 2005;15(2):269-75.;;Hardenbol, et al. Multiplexed genotyping with sequence-tagged molecular inversion probes. Nat. Biotechnol. 2003; 21(6):673-8.;;Harris, et al. Single-molecule DNA sequencing of a viral genome. Science. Apr. 4, 2008;320(5872):106-9.;;Hartmann, et al. Gene expression profiling of single cells on large-scale oligonucleotide arrays. Nucleic Acids Research. 2006; 34(21): e143. (11 pages).;;Herzenberg, et al. Fetal cells in the blood of pregnant women: Detection and enrichment by flourescence-activated cell sorting. Proc. Natl. Acad. Sci. 1979;76:1453-1455.;;Holt, et al. The new paradigm of flow cell sequencing. DOI: 10.1101/gr.073262.107 Genome Res. 2008. 18: 839-846.;;Holzgreve, et al. Fetal Cells in the Maternal Circulation. Journal of Reproductive Medicine. 1992;37:410-418.;;Hong, et al. A nanoliter-scale nucleic acid processor with parallel architecture. Nat. Biotechnol. 2004; 22(4):435-9.;;Hong, et al. Molecular biology on a microfluidic chip. Journal of Physics: Condensed Matter, 2006, vol. 18, S691-S701.;;Hosono, et al. Unbiased whole-genome amplification directly from clinical samples. Genome Res. May 2003;13(5):954-64.;;Hromadnikova, et al. “Quantitative analysis of DNA levels in maternal plasma in normal and Down syndrome pregnancies.” Bio Med Central, May 2002, 1-5.;;Huang, et al. A DNA prism for high-speed continuous fractionation of large DNA molecules. Nature Biotechnology. 2002;20:1048-1051.;;Huang, et al. Continuous Particle Separation Through Deterministic Lateral Displacement. Science 304:987-90 (2004).;;Huang, et al. Electric Manipulation of Bioparticles and Macromoledules on Microfabricated Electrodes. Analytical Chemistry. 2001; pp. 1549-1559.;;Huang, et al. Role of Molecular Size in Ratchet Fractionation. 2002; 89(17):178301-1-178301-4.;;Huh, et al. Gravity-driven microhydrodynamics-based cell sorter (microHYCS) for rapid, inexpensive, and efficient cell separation and size-profiling. 2nd Annual International IEEE-EMBS Special Topic Conference on Microtechnology in Medicine and Biology. Madison, Wisconsin USA; May 2-4, 2002:466-469.;;Hviid T. In-Cell PCT method for specific genotyping of genomic DNA from one individual in a micture of cells from two individuals: a model study with specific relevance to prenatal diagnosis based on fetal cells in maternal blood. Molecular Diagnostics and Genetics. 2002; 48:2115-2123.;;Hviid, T. In-cell polymerase chain reaction: strategy and diagnostic applications. Methods Mol Biol. 2006;336:45-58.;;International preliminary report on patentability dated Oct. 29, 2008 for PCT/US2007/003209.;;International search report and written opinion dated Mar. 16, 2010 for PCT Application No. US2009/57136.;;International Search Report and Written Opinion dated Sep. 18, 2008 for PCT/US2007/003209.;;International search report dated Jan. 16, 2008 for PCT Application No. US2007/71247.;;International search report dated Jan. 25, 2008 for PCT Application No. US2007/71250.;;International search report dated Nov. 15, 2007 for PCT Application No. US2007/71149.;;International search report dated Nov. 26, 2007 for PCT Application No. US2007/71256.;;International search report dated Feb. 25, 2008 for PCT Application No. US07/71148.;;International search report dated Feb. 25, 2008 for PCT Application No. US2007/71248.;;Ishikawa, et al. Allelic dosage analysis with genotyping microarrays. Biochem Biophys Res Commun. Aug. 12, 2005;333(4):1309-14.;;Iverson, et al. Detection and Isolation of Fetal Cells From Maternal Blood Using the Flourescence-Activated Cell Sorter (FACS). Prenatal Diagnosis 1981;1:61-73.;;Jan, et al. Fetal Erythrocytes Detected and Separated from Maternal Blood by Electronic Fluorescent Cell Sorter. Texas Rep Biol Med.1973;31:575.;;Jeon, et al. Generation of Solution and surface Gradients Using Microfluidic Systems. Langmuir. 2000, pp. 8311-8316.;;Jiang, et al. Genome amplification of single sperm using multiple displacement amplification. Nucleic Acids Res. 2005; 33(10):e91. (9 pages).;;Jiang, et al. Old can be new again: HAPPY whole genome sequencing, mapping and assembly. Int J Biol Sci. 2009;5(4):298-303. Epub Apr. 15, 2009.;;Joint Claim Construction and Prehearing Statement. Case: 12-cv-05501-SI; Dated May 3, 2013.;;Kamholz, et al. Quantitative Analysis of Molecular Interaction in a Microfluidic Channel: the T-Sensor. Analytical Chemistry. 1999; pp. 5340-5347.;;Kan, et al. Concentration of Fetal Red Blood Cells From a Mixture of Maternal and Fetal Blood by Anti-i Serum—An Aid to Prenatal Diagnosis of Hemoglobinopathies. Blood. 1974; 43:411-415.;;KARTALOV EMIL P, QUAKE S R: ""Microfluidic device reads up to four consecutive base pairs in DNA sequencing-by-synthesis."", JOURNAL OF ORGANIC CHEMISTRY, AMERICAN CHEMICAL SOCIETY, US, vol. 32, no. 9, 1 January 2004 (2004-01-01), US, pages 2873 - 2879, XP002652987, ISSN: 0022-3263, DOI: 10.1093/NAR/GKH613;;Kasakov, et al. Extracellular DNA in the blood of pregnant women. Tsitologiia. 1995;37(3):232-6. (English translation only).;;Kazakov, et al. Extracellular DNA in the blood of pregnant women Tsitologiia. 1995; 37(3): 232-6.;;Kenis, et al. Microfabrication Inside Capillaries Using Multiphase Laminar Flow Patterning. Science. 1999; 285:83-85. et al.",ACTIVE
632,CA,A,CA 1086087 A,008-793-424-605-702,1980-09-23,1980,CA 285920 A,1977-09-01,US 72160476 A,1976-09-07,PHOTOFLASH LAMP AND METHOD OF MAKING SAME,"A high voltage type photoflash lamp filled with a filamentary combustible material and oxygen and having a beadless ignition structure comprising a pair of spaced apart lead-in wires with spherically shaped terminations, a glass frit coating over the lead-in wires with scraped-off portions exposing the bare metal of the wire adjacent each termination, and a coating of primer material over the frit-coated terminations and bared portions of the wires. The primer may bridge the wire terminations or comprise separate spaced apart coatings on the respective terminations, with the filamentary combustible being in contact with both terminations to provide a conducting path therebetween. The frit coating is thick enough to prevent preignition short circuits. Also disclosed is a method of making the lamp including the steps of applying a flame to melt down the ends of the lead-in wires to provide smooth and rounded terminations, dipping the wires in a liquid suspension of glass frit, air drying, passing a blade between the wires to scrape away portions of the frit coating and expose bare wire adjacent the terminations, sealing the lead-in wires into one end of a length of glass tubing, dipping the coated leadin wires into a primer cup to provide a coat of primer over the terminations and scraped portions, and then finishing the lamp.",GTE SYLVANIA INC,ARMSTRONG DONALD E;;SINDLINGER RONALD E;;COHEN BERNARD;;TOZIER JOHN E;;AUDESSE EMERY G,,https://lens.org/008-793-424-605-702,Granted Patent,no,0,0,12,12,0,F21K5/02;;F21K5/02,F21K5/06;;F21K5/08,67-10,0,0,,,,EXPIRED
633,EP,A4,EP 1346296 A4,138-726-612-348-233,2008-07-02,2008,EP 01992199 A,2001-12-19,US 0149260 W;;US 25899100 P,2000-12-29,LOSSY INDEX COMPRESSION,,IBM,CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,,https://lens.org/138-726-612-348-233,Search Report,no,2,0,11,11,0,G06F16/328;;G06F16/319,G06F17/30,,3,1,064-271-398-574-625,10.1109/pdis.1993.253078,"""INVERTED INDEX"", INTERNET, 15 September 1999 (1999-09-15), pages 1 - 31, XP002480543, Retrieved from the Internet <URL:http://ir.iit.edu/~dagr/IRCourse/Notes/02%20Inverted%20Index.ppt> [retrieved on 20080514];;TOMASIC A ET AL: ""Performance of inverted indices in shared-nothing distributed text document information retrieval systems"", PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, 1993., PROCEEDINGS OF TH E SECOND INTERNATIONAL CONFERENCE ON SAN DIEGO, CA, USA 20-22 JAN. 1993, LOS ALAMITOS, CA, USA,IEEE COMPUT. SOC, US, 20 January 1993 (1993-01-20), pages 8 - 17, XP010031709, ISBN: 978-0-8186-3330-0;;See also references of WO 02054289A1",EXPIRED
634,CA,C,CA 2149793 C,168-190-750-649-275,2001-04-10,2001,CA 2149793 A,1995-05-19,US 25037194 A,1994-05-27,CATALYTIC HYDROCARBON REFORMER WITH ENHANCED INTERNAL HEAT TRANSFER MECHANISM,"A catalytic hydrocarbon reformer operates at lower temperature and pressure relative to conventional reformers. Convective heat transfer between the hot combustion gas stream and the reactor tube is enhanced through use of a narrow gap heat transfer area, which induces turbulent flow of the combustion gas stream across the reactor tube. The reactor tube includes a catalyst fines collection tube to accumulate and retain catalyst particles or fines entrained in the reformate gas stream.",,BUSWELL RICHARD F;;COHEN RONALD;;CLAUSI JOSEPH V;;LEAVITT STANLEY L;;WATKINS DAVID S,,https://lens.org/168-190-750-649-275,Granted Patent,no,0,0,3,3,0,B01J8/062;;B01J8/062;;C01B3/384;;C01B3/384;;C01B2203/0233;;C01B2203/0233;;C01B2203/04;;C01B2203/04;;C01B2203/066;;C01B2203/066;;C01B2203/0811;;C01B2203/0811;;C01B2203/0816;;C01B2203/0816;;C01B2203/0827;;C01B2203/0827;;C01B2203/0866;;C01B2203/0866;;C01B2203/1011;;C01B2203/1011;;C01B2203/1235;;C01B2203/1235;;C01B2203/1241;;C01B2203/1241;;C01B2203/148;;C01B2203/148;;H01M8/0631;;H01M8/0631;;Y02E60/50,B01J8/06;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
635,US,B2,US 7356527 B2,100-931-473-870-366,2008-04-08,2008,US 45105604 A,2004-01-09,US 45105604 A;;US 0149260 W,2001-12-19,Lossy index compression,"An apparatus and method is provided for pruning an index of a corpus of text documents by creating an inverted index of terms appearing in the documents, wherein the index includes postings of the terms in the documents, ranking the postings in the index, and pruning from the index the postings below a given level in the ranking.",IBM,CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,INTERNATIONAL BUSINESS MACHINES CORPORATION (2004-03-12),https://lens.org/100-931-473-870-366,Granted Patent,yes,8,40,2,2,0,G06F16/328;;G06F16/328;;Y10S707/99935;;Y10S707/99942,G06F7/00;;G06F17/00,707/5;;707/101,0,0,,,,EXPIRED
636,CA,A1,CA 2432357 A1,119-339-680-928-804,2002-07-11,2002,CA 2432357 A,2001-12-19,US 25899100 P;;US 0149260 W,2000-12-29,LOSSY INDEX COMPRESSION,"An apparatus is provided for performing a method (Fig. 2) for pruning an ind ex of a corpus of text documents, wherein the method includes steps for ranking (50) the postings in the index and pruning (48) from the index the postings below a given level in the ranking. The pruning methods of the invention are lossy, since some document postings are removed from the full index; however , the user cannot differentiate the lossy index from the full index.",IBM,MAAREK YOELLE;;HERSCOVICI MICHAEL;;FAGIN RONALD;;SOFFER AYA;;COHEN DORON;;CARMEL DAVID;;FARCHI EITAN,,https://lens.org/119-339-680-928-804,Patent Application,no,0,1,11,11,0,G06F16/328;;G06F16/319,G06F17/30,,0,0,,,,DISCONTINUED
637,NO,D0,NO 962549 D0,114-071-547-469-876,1996-06-14,1996,NO 962549 A,1996-06-14,US 9312245 W,1993-12-15,Reptidinhibitorer av CXC interkrine molekyler,,UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/114-071-547-469-876,Patent Application,no,0,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,0,0,,,,DISCONTINUED
638,EP,B1,EP 1346296 B1,013-856-853-054-052,2012-09-19,2012,EP 01992199 A,2001-12-19,US 0149260 W;;US 25899100 P,2000-12-29,LOSSY INDEX COMPRESSION,,IBM,CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,,https://lens.org/013-856-853-054-052,Granted Patent,yes,0,0,11,11,0,G06F16/328;;G06F16/319,G06F17/30,,1,1,065-938-278-068-903,10.1145/305110.305119,"DAVID HAWKING: ""Efficiency/Effectiveness Trade-offs in Query Processing"", FROM THEORY INTO PRACTICE WORKSHOP, 1998 SIGIR CONF., 31 October 1998 (1998-10-31), pages 16 - 22, XP055019333, Retrieved from the Internet <URL:http://delivery.acm.org/10.1145/310000/305119/p16-hawking.pdf?ip=145.64.134.242&acc=ACTIVE%20SERVICE&CFID=66241776&CFTOKEN=38284250&__acm__=1329222596_065fade8997fc87471b86915ac3149b9> [retrieved on 20120214]",EXPIRED
639,US,A1,US 2017/0216409 A1,146-861-008-873-973,2017-08-03,2017,US 201515500845 A,2015-08-05,US 201515500845 A;;US 201462033526 P;;US 2015/0043821 W,2014-08-05,"MODULATION OF LAMININ ALPHA-4 IN THE PREVENTION, TREATMENT, AND MANAGEMENT OF METABOLIC SYNDROMES","The disclosure provides methods of preventing or treating metabolic syndrome in a subject by administering an effective amount of an inhibitor of laminin α4 expression, laminin α4 activity, or both.",UNIV CHICAGO;;ILLINOIS INST OF TECH,VAICIK MARCELLA K;;COHEN RONALD N;;BREY ERIC M;;TRYGGVASON KARL;;KORTESMAA JILL THYBOLL,THE UNIVERSITY OF CHICAGO (2015-06-04);;ILLINOIS INSTITUTE OF TECHNOLOGY (2015-08-03),https://lens.org/146-861-008-873-973,Patent Application,yes,0,0,2,2,4,C07K16/18;;A61K2039/505;;A61K38/39;;C07K16/18;;A61K2039/505;;A61K38/39;;C07K2317/76,A61K38/39;;C07K16/18,,0,0,,,,DISCONTINUED
640,CA,A1,CA 2149793 A1,160-289-784-312-733,1995-11-28,1995,CA 2149793 A,1995-05-19,US 25037194 A,1994-05-27,CATALYTIC HYDROCARBON REFORMER WITH ENHANCED INTERNAL HEAT TRANSFER MECHANISM,"A catalytic hydrocarbon reformer operates at lower temperature and pressure relative to conventional reformers. Convective heat transfer between the hot combustion gas stream and the reactor tube is enhanced through use of a narrow gap heat transfer area, which induces turbulent flow of the combustion gas stream across the reactor tube. The reactor tube includes a catalyst fines collection tube to accumulate and retain catalyst particles or fines entrained in the reformate gas stream.",BALLARD POWER SYSTEMS,BUSWELL RICHARD F;;COHEN RONALD;;CLAUSI JOSEPH V;;LEAVITT STANLEY L;;WATKINS DAVID S,,https://lens.org/160-289-784-312-733,Patent Application,no,0,0,3,3,0,B01J8/062;;B01J8/062;;C01B3/384;;C01B3/384;;C01B2203/0233;;C01B2203/0233;;C01B2203/04;;C01B2203/04;;C01B2203/066;;C01B2203/066;;C01B2203/0811;;C01B2203/0811;;C01B2203/0816;;C01B2203/0816;;C01B2203/0827;;C01B2203/0827;;C01B2203/0866;;C01B2203/0866;;C01B2203/1011;;C01B2203/1011;;C01B2203/1235;;C01B2203/1235;;C01B2203/1241;;C01B2203/1241;;C01B2203/148;;C01B2203/148;;H01M8/0631;;H01M8/0631;;Y02E60/50,B01J8/06;;C01B3/38;;H01M8/06,,0,0,,,,EXPIRED
641,US,A,US 5965536 A,143-273-705-002-815,1999-10-12,1999,US 66656496 A,1996-06-14,US 66656496 A;;US 9312245 W,1993-12-15,Methods of inhibiting CXC intercrine molecules,"Disclosed are methods for inhibiting and modulating the actions of CXC intercrine molecules. The antileukinate peptides described inhibit IL-8, GRO and MIP2.beta. binding to neutrophils and neutrophil activation. The peptides are particularly advantageous as they inhibit IL-8-induced enzyme release at a 25 fold lower concentration than is required to inhibit chemotaxis, which makes them ideal for treating various inflammatory diseases and disorders including, amongst others, Adult Respiratory Distress Syndrome (ARDS), cystic fibrosis and chronic bronchitis.",UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,BOARD OF REGENTS THE UNIVERSITY OF TEXAS SYSTEM (1996-05-30),https://lens.org/143-273-705-002-815,Granted Patent,yes,3,23,1,1,58,A61K38/00;;A61K38/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/54;;C07K14/5421;;C07K14/5421,A61K38/00;;C07K7/06;;C07K14/54,514/17;;514/16;;514/15;;514/14;;514/13,38,29,022-386-867-324-263;;136-135-608-418-684;;060-372-030-951-215;;105-510-018-248-707;;009-328-947-109-030;;034-529-760-793-925;;047-104-355-267-583;;091-744-002-626-238;;041-977-709-194-794;;021-295-680-224-895;;001-912-572-374-015;;041-200-624-633-310;;004-137-640-378-769;;004-137-640-378-769;;076-457-866-487-532;;079-573-639-111-487;;077-658-220-398-482;;010-324-726-760-767;;033-013-086-814-638;;066-189-092-346-291;;168-124-318-861-781;;001-927-580-163-340;;107-062-274-292-949;;052-800-993-635-942;;004-703-061-449-124;;079-186-364-835-274;;053-028-568-338-985;;073-975-681-422-151;;023-492-103-726-284,8381283;;10.1006/bbrc.1993.1099;;8473010;;pmc1421822;;10.1016/0161-5890(93)90065-j;;8384312;;1744111;;10.1016/s0021-9258(18)54472-0;;pmc553883;;3327687;;10.1002/j.1460-2075.1987.tb02746.x;;8463264;;10.1016/s0021-9258(18)53174-4;;7814885;;7590784;;10.1089/hyb.1995.14.225;;8805676;;9029135;;8797614;;10.1097/00003246-199609000-00004;;10.1006/prep.1995.1047;;7663173;;8872512;;10.1007/bf02252934;;8872512;;10.1007/bf02252934;;10.1007/bf02252933;;8872511;;10.1164/ajrccm/146.2.427;;1489135;;8253060;;10.3109/01902149309031730;;10.1007/bf01984062;;8023744;;8371232;;8463247;;10.1016/s0021-9258(18)53154-9;;8390538;;1891716;;10.1126/science.1891716;;pmc443018;;1569186;;10.1172/jci115738;;8476069;;10.1152/ajplung.1993.264.4.l413;;2206128;;10.1016/0006-291x(90)91178-u;;10.1165/ajrcmb/6.1.75;;1728298;;10.1126/science.8316840;;8316840;;1744577;;pmc2119025;;10.1084/jem.174.6.1355;;10.1016/0165-2478(92)90203-z;;1500087,"International Search Report Mailed Aug. 31, 1994.;;Cassatellas et al., Studies on the Regulatory Mechanisms of Interleukin 8 Gene Expression in Resting and IFN y Treated Neutrophils: Evidence on the Capability of Staurosporine of Inducing the Production of Interleukin 8 by Human Neutrophils, Biochem. and Biophys. Research Comm., 190(2):660 667, 1993.;;Cassatella et al., Interferon gamma Inhibits Interleukin 8 Production by Human Polymorphonuclear Leucocytes, Immun., 78:177 184, 1993.;;Cerretti et al., Molecular Characterization of Receptors fro Human Interleukin 8, Gro/Melanoma Growth Stimulatory Activity and Neutrophil Activating Peptide 2, Mol. Immun., 30:359 367, 1993.;;Clark Lewis et al., Structure Activity Relationships of Interleukin 8 Determined Using Chemically Synthesized Analogs, J Biol. Chem., 266(34):23128 23134, 1991.;;Corbi et al., cDNA Cloning and Complete Primary Structure of the Subunit of a Leukocyte Adhesion Glycoprotein, p150,95, EMBO J. , 6(13):4023 4028, 1987.;;Gayle III et al., Importance of the Amino Terminus of the Interleukin 8 Receptor in Ligand Interactions, J. Biol. Chem., 268(10):7283 7289, 1993.;;Goodman et al., A Pentapeptide Domain Within the N Terminus of Interleukin 8 Inhibits Neutrophil Chemotaxis, FASEB J., 5(4):A892, Abstract 3032.;;Hayashi et al., Synthetic Hexa and Heptapeptides that Inhibit IL 8 from Binding to and Activating Human Blood Neutrophils, J. Immun., 154:814 824, 1995.;;Kurdowska et al., An Anti Interleukin 8 Monoclonal Antibody that Interferes with the Binding of Interleukin 8 to Cellular Receptors and the Activation of Human Blood Neutrophils, Hybridoma 14(3):225 233, 1995.;;Kurdowska et al., Anti Interleukin 8 Autoantibodies in Alveolar Fluid from Patients with the Acute Respiratory Distress Syndrome (ARDS), Am. J. Resp. And Critical Care Medicine, 153(4,2):Abstract, 1996.;;Kurdowska et al., The Fate of Interleukin 8 (IL 8) in the Lung. Only IL 8 2 Macroglobulin Complexes are Taken up by Human Alveolar Macrophages, Presented at the AAI meeting, 1997.;;Kurdowska et al., Preliminary Studies on the Interaction of Interleukin 8 (IL 8) with 2 Macroglobulin ( 2 M), Experimental Biology 95 , Atlanta, Georgia, Apr. 9 13, 1995, Abstract 3110.;;Kurdowska et al., Anti IL 8 Autoantibodies in Alveolar Fluid from Patients with the Adult Respiratory Distress Syndrome, J. Immun., 157:2699 2706, 1996.;;Kurdowska et al., Studies on the Interactin of IL 8 with Human Plasma 2 Macroglobulin, J. Immun., 158:1930 1940, 1997.;;Lam et al., Differential Effects of Protein Kinase C Inhibitors on Interleukin 8 Induced Exocytosis in Human Neutrophils, In: Chemotactic Cytokines. Biology of the Inflammatory Peptide Supergene Family, (Westwick et al., eds.), 175 176, Plenum Press Inc., New York, 1990.;;Miller et al., Elevated Interleukin 8 Levels in the Pulmonary Edema Fluid of Patients with ARDS from Sepsis, Critical Care Medicine, 24(9):1448 1454, 1996.;;Miller et al., High Yields of Interleukin 8 Produced by a Synthetic Gene Expressed in Escherichia coli and Purified with a Single Antibody Affinity Column, Protein Expression and Purification, 6:357 362, 1995.;;Miller et al., Interleukin 8 (IL 8) Induced Neutrophil Chemotaxis is Inhibited by Synthetic Peptides, Endocytosis/Phacogytosis, FASEB J., 4(5):A2117, Abstract 2452, 1990.;;Miller et al., Peptide Inhibitor of Interleukin 8 (IL 8) Reduces Staphylococcal Enterotoxin A (SEA) Induced Neutrophil Trafficking to the Lung, Am. J. Resp. Critical Care Med, 153(4):A285, Abstract, Apr. 1996.;;Miller et al., Peptide Inhibitor of Interleukin 8 (IL 8) Reduces Staphylococcal Enterotoxin A (SEA) Induced Neutrophhil Trafficking to the Lung, Inflamm. Res., 45:393 397, 1996.;;Miller et al., Interleukin 8 (IL 8) is a Major Neutrophil Chemotaxin from Human Alveolar Macrophages Stimulated with Staphylococcal Enterotoxin A (SEA), Inflamm. Res., 45:386 392, 1996.;;Miller et al., Elevated Levels of NAP 1/Interleukin 8 are Present in the Airspaces of Patients with the Adult Respiratory Distress Syndrome and are Associated with Increased Mortality, Am. Rev. Respir. Dis., 146:427 432, 1992.;;Miller and Idell, Interleukin 8: An Important Neutrophil Chemotaxin in Some Cases of Exudative Pleural Effusions, Experimental Lung Research, 19:589 601, 1993.;;Miller et al., A Synthetic Peptide Which Specifically Inhibits Heat Treated Interleukin 8 Binding and Chemotaxis for Neutrophils, Agents Actions, 40:200 208, 1993.;;Miller and Brelsford, Interleukin 8: The Major Neutrophil Chemotaxin in a Case of Pseudogout, J. Rheumatology, 20(7):1250 1252, 1993.;;Moser et al., Interleukin 8 Antagonists Generated by N Terminal Modification, J. Biol. Chem., 268(10):7125 7128, 1993.;;Mulligan et al., Inhibition of Lung Inflammatory Reactions in Rats by an Anti Human IL 8 Antibody, J. Immun., 150(12):5585 5595, 1993.;;Murphy and Tiffany, Cloning of Complementary DNA Encoding a Functional Human Interleukin 8 Receptor, Science, 253:1280 1283, 1991.;;Nakamura et al., Neutrophil Elastase in Respiratory Epithelial Lining Fluid of Individuals with Cystic Fibrosis Induces Interleukin 8 Gene Expression in a Human Bronchial Epithelial Cell Line, J. Clin. Invest., 89:1478 1484, 1992.;;Peterson et al., Salmeterol Prevents Influx of Neutrophils at Proximal Sites in Rabbit Airways, Am. J. Resp. And Critical Care Med., 153(4):A444, Abstract, 1996.;;Peterson et al., Salmeterol Prevents Influx of Neutrophils into the Lungs, but not by Adrenergic Stimulation, FASEB J., 10(3):A639, Abstract 3691, 1996.;;Richman Eisenstat et al., Interleukin 8: An Important Chemoattractant in Sputum of Patients with Chronic Inflammatory Airway Diseases, Am. J. Physiol. ( Lung Cell Mol. Physiol. ), 264:L413 L418, 1993.;;Standiford et al., Disparate Regulation of Interleukin 8 Gene Expression from Blood Monocytes, Endothelial Cells, and Fibroblasts by Interleukin 4, 171(2):531 536, 1990.;;Standiford et al., Regulation of Human Alveolar Macrophage and Blood Monocyte Derived Interleukin 8 by Prostaglandin E 2 and Dexamethasone, Am. J. Respir. Cell Mol. Biol., 6:75 81, 1992.;;Wu et al., G Protein Coupled Signal Transduction Pathways for Interleukin 8, Science, 261:101 103, 1993.;;Walz et al., J. Exp. Med., vol. 174, No. 6, Dec. 1991, pp. 1355 1362.;;Dewald et al., Immunology Letters, vol. 32, No. 1, Mar. 1992, pp. 81 84.",EXPIRED
642,US,A,US 5484577 A,161-817-854-682-864,1996-01-16,1996,US 25037194 A,1994-05-27,US 25037194 A,1994-05-27,Catalytic hydrocarbon reformer with enhanced internal heat transfer mechanism,"A catalytic hydrocarbon reformer operates at lower temperature and pressure relative to conventional reformers. Convective heat transfer between the hot combustion gas stream and the reactor tube is enhanced through use of a narrow gap heat transfer area, which induces turbulent flow of the combustion gas stream across the reactor tube. The reactor tube includes a catalyst fines collection tube to accumulate and retain catalyst particles or fines entrained in the reformate gas stream.",BALLARD POWER SYSTEM INC,BUSWELL RICHARD F;;COHEN RONALD;;CLAUSI JOSEPH V;;LEAVITT STANLEY L;;WATKINS DAVID S,BALLARD POWER SYSTEMS INC (1994-06-01);;BALLARD POWER SYSTEMS INC. (CANADIAN CORP. NO. 7076991) (2009-05-27),https://lens.org/161-817-854-682-864,Granted Patent,yes,16,95,3,3,0,B01J8/062;;B01J8/062;;C01B3/384;;C01B3/384;;C01B2203/0233;;C01B2203/0233;;C01B2203/04;;C01B2203/04;;C01B2203/066;;C01B2203/066;;C01B2203/0811;;C01B2203/0811;;C01B2203/0816;;C01B2203/0816;;C01B2203/0827;;C01B2203/0827;;C01B2203/0866;;C01B2203/0866;;C01B2203/1011;;C01B2203/1011;;C01B2203/1235;;C01B2203/1235;;C01B2203/1241;;C01B2203/1241;;C01B2203/148;;C01B2203/148;;H01M8/0631;;H01M8/0631;;Y02E60/50,B01J8/06;;C01B3/38;;H01M8/06,422/211;;208/134;;422/148;;422/197,1,0,,,"Fuels And Reformer Technologies , Application And Marketing Assessment Of Fuel Cells In Canadian Electric Systems Workshop, Vancouver, B.C. Udengaard Apr. 1993.",EXPIRED
643,DE,A1,DE 102011089306 A1,066-798-319-607-470,2012-06-21,2012,DE 102011089306 A,2011-12-20,US 97421510 A,2010-12-21,Intraorale Bildgebungsvorrichtungen und -Verfahren,"Offenbart wird ein intraorales Bildgebungsverfahren, das das Bereitstellen einer intraoralen Bildgebungsvorrichtung, die mindestens eine Aufbissplatte mit einem Zahnabdruckmaterial und einer Spur, mindestens eine Schlittenanordnung, die entlang mindestens eines Abschnitts der Spur läuft, und eine Bildgebungseinrichtung, die an der mindestens einen Schlittenanordnung befestigt ist, aufweist; das Positionieren der mindestens einen Aufbissplatte zwischen oberen und unteren Zähnen der Person, so dass das Zahnabdruckmaterial mit mindestens einem der oberen und unteren Zähne zusammenwirkt, um eine reproduzierbare Erfassung innerhalb einer Mundhöhle der Person bereitzustellen; und das Gewinnen von Bilddaten mithilfe der Bildgebungseinrichtung umfasst.",PROCTER & GAMBLE,DUFF RONALD R;;CHRISTMAN THOMAS A;;ZSISKA MARIANNE;;COHEN RICHARD H;;VALLON MARK DAVID,,https://lens.org/066-798-319-607-470,Patent Application,no,0,0,2,2,0,A61B1/0016;;A61B1/00172;;A61B1/24;;A61B1/00089;;A61B1/00172;;A61B1/0016;;A61B1/24,A61C19/04,,1,0,,,"Standard Package, P/N 137307",DISCONTINUED
644,NO,L,NO 962549 L,184-979-689-036-725,1996-08-14,1996,NO 962549 A,1996-06-14,US 9312245 W,1993-12-15,Reptidinhibitorer av CXC interkrine molekyler,,UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/184-979-689-036-725,Abstract,no,0,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,0,0,,,,DISCONTINUED
645,AU,A,AU 1994/060147 A,046-012-768-260-588,1995-07-03,1995,AU 1994/060147 A,1993-12-15,US 9312245 W,1993-12-15,Peptide inhibitors of cxc intercrine molecules,,UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/046-012-768-260-588,Patent Application,no,0,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,0,0,,,,EXPIRED
646,US,A1,US 2023/0168160 A1,067-817-721-264-418,2023-06-01,2023,US 202217850599 A,2022-06-27,US 202217850599 A;;US 202016819992 A;;US 201313830871 A;;US 201313738268 A;;US 201213433232 A;;US 72524010 A;;US 76342607 A;;US 82077806 P;;US 80481506 P,2006-06-14,DIAGNOSIS OF FETAL ABNORMALITIES USING POLYMORPHISMS INCLUDING SHORT TANDEM REPEATS,"The present invention provides systems, apparatuses, and methods to detect the presence of fetal cells when mixed with a population of maternal cells in a sample and to test fetal abnormalities, i.e. aneuploidy. In addition, the present invention provides methods to determine when there are insufficient fetal cells for a determination and report a non-informative case. The present invention involves quantifying regions of genomic DNA from a mixed sample. More particularly the invention involves quantifying DNA polymorphisms from the mixed sample.",MASSACHUSETTS GEN HOSPITAL;;VERINATA HEALTH INC;;GPB SCIENTIFIC LLC,STOUGHTON ROLAND;;KAPUR RAVI;;COHEN BARB ARIEL;;SHOEMAKER DANIEL;;DAVIS RONALD W;;TONER MEHMET,VERINATA HEALTH INC (2007-08-13);;GPB SCIENTIFIC LLC (2012-04-06);;THE GENERAL HOSPITAL CORPORATION (2012-04-06),https://lens.org/067-817-721-264-418,Patent Application,yes,0,0,11,99,0,C12Q2600/156;;C12Q2600/158;;C12Q2600/16;;G16B20/00;;C12Q1/6883;;G16B20/20;;G16B20/10;;C12Q2600/16;;C12Q2600/156;;C12Q2600/158;;G16B20/00;;G16B20/10;;G16B20/20;;C12Q1/6883;;G01N1/30,G01N1/30;;C12Q1/6883;;G16B20/10;;G16B20/20,,0,0,,,,PENDING
647,US,B2,US 11378498 B2,066-381-986-035-476,2022-07-05,2022,US 202016819992 A,2020-03-16,US 202016819992 A;;US 201313830871 A;;US 201313738268 A;;US 201213433232 A;;US 72524010 A;;US 76342607 A;;US 82077806 P;;US 80481506 P,2006-06-14,Diagnosis of fetal abnormalities using polymorphisms including short tandem repeats,"The present invention provides systems, apparatuses, and methods to detect the presence of fetal cells when mixed with a population of maternal cells in a sample and to test fetal abnormalities, i.e. aneuploidy. In addition, the present invention provides methods to determine when there are insufficient fetal cells for a determination and report a non-informative case. The present invention involves quantifying regions of genomic DNA from a mixed sample. More particularly the invention involves quantifying DNA polymorphisms from the mixed sample.",VERINATA HEALTH INC;;MASSACHUSETTS GEN HOSPITAL;;GPB SCIENTIFIC LLC;;GPR SCIENT LLC,STOUGHTON ROLAND;;KAPUR RAVI;;COHEN BARB ARIEL;;SHOEMAKER DANIEL;;DAVIS RONALD W;;TONER MEHMET,VERINATA HEALTH INC (2007-08-13);;GPB SCIENTIFIC LLC (2012-04-06);;THE GENERAL HOSPITAL CORPORATION (2012-04-06),https://lens.org/066-381-986-035-476,Granted Patent,yes,162,0,11,99,0,C12Q2600/156;;C12Q2600/158;;C12Q2600/16;;G16B20/00;;C12Q1/6883;;G16B20/20;;G16B20/10;;C12Q2600/16;;C12Q2600/156;;C12Q2600/158;;G16B20/00;;G16B20/10;;G16B20/20;;C12Q1/6883;;G01N1/30,G01N1/30;;C12Q1/6883;;G16B20/00;;G16B20/10;;G16B20/20,,150,69,053-666-745-409-710;;100-453-901-699-515;;037-357-780-822-464;;076-393-133-359-189;;061-972-410-678-308;;145-980-837-366-069;;054-165-398-485-292;;066-903-530-957-523;;011-516-573-186-006;;031-862-180-586-540;;092-579-740-274-510;;002-962-093-926-806;;021-769-485-045-113;;017-112-591-676-778;;064-886-899-823-90X;;039-358-754-467-996;;047-843-103-180-157;;069-664-050-907-58X;;076-665-268-971-988;;008-224-784-496-888;;016-555-437-449-434;;037-401-345-017-773;;007-649-835-267-266;;032-480-214-686-009;;116-628-846-164-835;;003-996-208-073-770;;022-365-450-364-769;;001-622-248-842-264;;126-493-929-146-912;;018-652-694-252-496;;097-695-465-307-188;;029-050-998-010-913;;069-482-359-661-496;;000-058-261-678-04X;;058-449-019-265-362;;021-027-081-830-825;;025-224-986-816-700;;068-658-361-772-603;;019-822-409-513-235;;007-886-305-977-737;;107-261-960-213-333;;023-470-740-030-442;;013-227-496-509-650;;093-923-594-402-41X;;069-739-770-688-833;;058-870-328-132-255;;060-492-280-380-212;;033-459-397-346-84X;;022-262-263-271-354;;068-255-628-305-750;;010-791-672-524-98X;;071-692-113-791-239;;046-273-961-995-426;;031-956-542-450-673;;012-320-937-350-412;;155-067-965-751-44X;;092-579-740-274-510;;104-441-668-144-739;;140-652-446-466-244;;040-398-240-595-239;;076-326-089-795-353;;062-975-141-835-212;;039-045-972-562-994;;117-749-798-077-91X;;020-031-842-104-314;;056-085-729-754-497;;035-570-058-245-997;;075-210-786-004-51X;;033-459-397-346-84X,12196708;;10.1111/j.1741-4520.2002.tb00860.x;;10.1126/science.1072047;;12169732;;10.1093/clinchem/47.10.1867;;11568107;;10.1093/humupd/8.6.493;;12498419;;10.1034/j.1399-0004.2003.00087.x;;12786755;;pmc5129580;;27616633;;10.1002/pd.4924;;20224049;;10.1373/clinchem.2009.137877;;10.1002/pd.1558;;16952193;;10.1093/jnci/94.22.1697;;12441325;;16203989;;pmc1253547;;10.1073/pnas.0503335102;;16916256;;10.1385/1-59745-074-x:101;;10.1159/000073147;;14564124;;15830996;;10.1520/jfs2004216;;10.1073/pnas.0702165104;;17517648;;pmc1871563;;pmc1735643;;15591276;;10.1136/jmg.2004.023184;;22538702;;10.1159/000337544;;10.1038/nrg1901;;16847463;;26237488;;10.3390/jcm3030972;;pmc4449642;;10942488;;10.1067/mob.2000.106005;;10.1242/jeb.001370;;17449817;;24912661;;10.1002/pd.4429;;25178640;;10.1002/pd.4491;;10.1016/s1472-6483(10)62173-6;;12831600;;16141041;;10.1126/science.309.5740.1476;;pmc4864235;;27167625;;10.1371/journal.pone.0155009;;10.1002/pd.1213;;16032774;;10.1038/nprot.2007.276;;17703209;;837366;;10.1080/00016340601159124;;17464580;;10.1093/clinchem/45.10.1747;;10508120;;10.1086/302205;;9915961;;pmc1377720;;15292918;;10.1038/sj.ejhg.5201224;;10.1373/clinchem.2005.062893;;16423903;;10.1007/s004399900166;;10.1007/s004390051008;;10982181;;11751536;;10.1093/clinchem/48.1.35;;18001438;;10.1111/j.1447-0756.2007.00652.x;;15096565;;pmc1867475;;10.1016/s1525-1578(10)60497-7;;10.1016/j.febslet.2007.01.051;;17289032;;10.1038/nm1437;;16799556;;17040955;;10.1373/clinchem.2006.076851;;10.1126/science.2565047;;2565047;;11786398;;10.1016/s0002-9440(10)64348-9;;pmc1867119;;10.1073/pnas.202610899;;12461184;;pmc138581;;pmc4441954;;26000845;;10.1016/j.molcel.2015.05.005;;10.1373/clinchem.2005.052340;;16081506;;18945714;;10.1093/humupd/dmn047;;10.1073/pnas.1406103111;;24843150;;pmc4060699;;pmc49394;;1631067;;10.1073/pnas.89.13.5847;;10.1038/83572;;11135558;;11812558;;10.1016/s0140-6736(02)07448-2;;10.1002/pd.2150;;19003785;;15907998;;10.1016/j.biomaterials.2005.03.040;;11028946;;10.1023/a:1007535506705;;10.1006/bbrc.1999.0445;;10208845;;16097771;;10.1021/ac058013o;;11410505;;16916256;;10.1385/1-59745-074-x:101;;10.1016/s0140-6736(07)60115-9;;17292767;;11329017;;10.1038/88135;;10.1093/clinchem/45.9.1628;;10471678;;pmc2939611;;10.1186/1471-2105-11-432;;20718989;;10.1073/pnas.0402993101;;pmc438987;;15194824;;10.1136/gut.52.suppl_4.iv1;;12746261;;pmc1867764;;11159423;;10.1016/s0006-3495(01)76035-3;;pmc1301254;;10623654;;pmc1868645;;10.1016/s0002-9440(10)64706-2;;10445322;;10.1002/(sici)1522-2683(19990701)20:9<1829::aid-elps1829>3.0.co;2-b;;16354990;;10.1159/000089062;;12668472;;10.1016/s0006-3495(03)75069-3;;pmc1302830;;pmc49394;;1631067;;10.1073/pnas.89.13.5847,"Zhao, X.X. et al., Enrichment of fetal cells from maternal blood by magnetic activated cell sorting (MACS) with fetal cell specific antibodies: One-step versus two-step MACS, Congen. Anomal., vol. 42, pp. 120-124 (Year: 2002).;;U.S. Appl. No. 14/705,239 filed May 6, Kapur et al.;;U.S. Appl. No. 60/951,438, filed Jul. 23, 2007, Lo et al.;;Advisory action dated Mar. 4, 2015 for U.S. Appl. No. 12/689,548.;;Amendment to the Claims dated Jun. 16, 2014 for U.S. Appl. No. 13/863,992.;;Amendment to the Claims dated Dec. 5, 2013 for U.S. Appl. No. 12/751,940.;;Amendments to the Claims. Filed Oct. 14, 2014 with U.S. Patent Office for U.S. Appl. No. 13/831,342.;;Bailey et al., “Recent Segmental Duplications in the Human Genome,” Science, Aug. 2002, 297: 1003-1007.;;Bianchi, et al. Large amounts of cell-free fetal DNA are present in amniotic fluid. Clinical chemistry 47.10 (2001): 1867-1869.;;Bischoff, et al. Cell-free fetal DNA and intact fetal cells in maternal blood circulation: implications for first and second trimester non-invasive prenatal diagnosis. Human reproduction update 8.6 (2002): 493-500.;;Bischoff et al., “Intact fetal cell isolation from maternal blood: improved isolation using a simple whole blood progenitor cell enrichment approach (RosetteSep™),” Clin. Genet., vol. 63, pp. 483-489 (2003).;;Breman et al., “Evidence for feasibility of fetal trophoblastic cell-based noninvasive prenatal testing,” Prenatal Diagnosis, vol. 36, pp. 1009-1019 (2016).;;Brown et al., “Aneuploidy detection in mixed DNA samples by methylation-sensitive amplification and microarray analysis,” Clinical chemistiy 56.5 (2010): 805-813.;;Brown et al., “Validation of QF-PCR for prenatal aneuploidy screening in the United States,” Prenatal diagnosis 26 .11 (2006): 1068-1074.;;Chang et al., “Assessment of Plasma DNA Levels, Allelic Imbalance, and CA 125 as Diagnostic Tests for Cancer,” Nov. 20, 2002, J, Nat'l Cancer Inst. 94(22): 1697-1703.;;Chim et al., “Detection of the placental epigenetic signature of the maspin gene in maternal plasma,” Proceedings of the National Academy of Sciences of the United States of America 102.41(2005): 14753-14758.;;Chiu et al. Noninvasive prenatal diagnosis by analysis of fetal DNA in maternal plasma. Clinical Applications of PCR (2006): 101-109.;;Christensen et al., “Sensitivity and specificity of the identification of fetal cells in maternal blood by combined staining with antibodies against beta-, gamma-and epsilon-globin chains,” Fetal Diagn. Ther., vol. 18, pp. 479-484 (2003).;;Coble et al. “Characterization of New MiniSTR Loci to Aid Analysis of Degraded DNA,” Jan. 2005. J. Forensic Sci. 50(1):43-53.;;Dahl et al., “Multigene Amplification and Massively Parallel Sequencing for Cancer Mutation Discoveiy,” May 29, 2007, PNAS USA 104(22):9387-9392.;;Declaration of Atul J. Butte, M.D. Ph.D. in Support of Patent Owner's Response to Inter Partes Review of U.S. Pat. No. 8,316,430. US Patent Office. dated Jan. 16, 2014.;;Deposition of Dr. Cynthia Casson Morton. US Patent Office. dated Dec. 10, 2013.;;Deposition of Dr. Robert Nussbaum. US Patent Office. dated Dec. 11, 2013.;;Deutsch et al., “Detection of aneuploidies by paralogous sequence quantification,” J Med Genet. Dec. 2004;41(12):908-15.;;EP Office Action in European Appln. No. 18170287, dated Apr. 6, 2020, 8 pages.;;European office action dated May 22, 2015 for EP Application No. 07798579.4.;;European office action dated Aug. 22, 2013 for EP Application No. 07798579.4.;;Evans et al., “Digital PCR for noninvasive detection of aneuploidy: power analysis equations for feasibility,” Fetal diagnosis and therapy 31.4 (2012): 244-247.;;Extended European Search Report in Application No. 18170287.9, dated Sep. 19, 2018, 10 pages.;;Fan et al., “Highly Parallel Genomic Assays,” Aug. 2006. Nat. Rev. Genet. 7(8):632-44.;;Fiddler, “Fetal cell based prenatal diagnosis: perspectives on the present and future,” J. Clin Med., vol. 3, pp. 972-985 (2014).;;Geifman-Holtzman et al., “The clinical utility of fetal cell sorting to determine prenatally fetal E/e or e/e Rh genotype from peripheral maternal blood,” Am. J. Obstet. Gynecol., vol. 183, pp. 462-468 (2000).;;Grundevik et al., “Molecular Diagnostics of Aneuploidies. Chalmers University of Technology,” May 17, 2005.;;Hall, “Advanced Sequencing Technologies and their Wider Impact in Microbiology,” 2007. J. Exp. Biol. 209:1518-1525.;;Hatt et al., “A New Marker Set That Identifies Fetal Cells in Maternal Circulation With High Specificity,” Prenatal Diagn., vol. 34, pp. 1-7 (2014).;;Hua et al., “Detection of aneuploidy from single fetal nucleated red blood cells using whole genome sequencing,” Prenatal Diagnosis, vol. 34, pp. 1-8 (2014).;;International Preliminary Report on Patentability dated Dec. 16, 2008 for PCT Application No. US2007/071248.;;Jama et al., “Quantification of cell-free DNA levels in maternal plasma by STR analysis,” Mar. 24-28, 2010. ACMG Annual Clinical Genetics Meeting Poster 398. Available at http://acmg.omnibooksonline.com/2010/data/papers/398.pdf. Accessed Apr. 5, 2013.;;Jauniaux et al., “Very early prenatal diagnosis on coelomic cells using quantitative fluorescent polymerase chain reaction,” Reproductive BioMedicine Online, Jan. 2003, 6: 494-498.;;Kaiser, “An earlier look at baby's genes,” Science, 309.5740 (2005): 1476.;;Karow, “Following Improvements in Noninvasive Fetal Cell Isolation, First Prenatal Tests Expected in 2016”, published on Genomeweb (www.genomeweb.com/archive/following-improvements-noninvasive-fetal-cell-isolation-first-prenatal-testsexpected-2016; pp. 1-4; (Nov. 2015).;;Khattabi et al., “Could Digital PCR Be an Alternative as a Non-Invasive Prenatal Test for Trisomy,” 21: A Proof of Concept Study. PloS one 11.5 (2016): e0155009.;;Koide et al., “Fragmentation of Cell-Free Fetal DNA in Plasma and Urine of Pregnant Women,” Jul. 2005, Prenat. Diagn, 25(7):604-7.;;Leary et al., “Digital karyotyping,” Nature Protocols, 2007, 2: 1973-1986.;;Leon et al., “Free DNA in the serum of cancer patients and the effect of therapy,” Cancer Res. Mar. 1977;37(3):646-50.;;Liu et al., “Feasibility Study of Using Fetal DNA in Maternal Plasma for Non-invasive Prenatal Diagnosis,” Acta Obstet. Gynecol. Scand. May 2007; 86(5):535-41.;;Illumina Technical Note: Reproductive Health, pp. 1-5 (2014).;;Lo et al., “Increased Fetal DNA Concentrations in the Plasma of Pregnant Women Carrying Fetuses with Trisomy,” Oct. 21, 1999, Clin. Chem. 45(10): 1747-51.;;Lo et al., “Rapid Clearance of Fetal DNA from Maternal Plasma,” Jan. 1999. Am. J. Hum. Genet. 64(1):218-24.;;Iontorrent Application Note, pp. 1-6 (2016).;;Mann et al., “Strategies for the rapid prenatal diagnosis of chromosome aneuploidy,” European Journal of Human Genetics 12.11 (2004): 907-915.;;Notice of allowance dated Jan. 22, 2016 for U.S. Appl. No. 13/837,974.;;Notice of allowance dated Jan. 26, 2015 for U.S. Appl. No. 13/835,926.;;Notice of allowance dated Jul. 27, 2016 for U.S. Appl. No. 12/816,043.;;Notice of allowance dated Oct. 27, 2015 for U.S. Appl. No. 13/829,971.;;Office action dated Jan. 26, 2015 for CA Application No. 2655272.;;Office action dated Jan. 28, 2014 for U.S. Appl. No. 13/835,926.;;Office action dated Jan. 30, 2014 for U.S. Appl. No. 13/837,974.;;Office action dated Feb. 5, 2014 for U.S. Appl. No. 12/689,517.;;Office action dated Feb. 23, 2015 for U.S. Appl. No. 12/689,517.;;Office action dated Mar. 11, 2015 for U.S. Appl. No. 13/737,730.;;Office action dated Mar. 14, 2016 for U.S. Appl. No. 12/816,043.;;Office action dated Mar. 15, 2016 for U.S. Appl. No. 12/751,940.;;Office action dated Mar. 20, 2014 for U.S. Appl. No. 12/816,043.;;Office action dated Mar. 21, 2014 for U.S. Appl. No. 12/815,674.;;Office action dated Mar. 31, 2016for U.S. Appl. No. 13/863,992.;;Office action dated Apr. 7, 2015 for U.S. Appl. No. 13/829,971.;;Office action dated Apr. 28, 2014 for U.S. Appl. No. 12/689,548.;;Office action dated Apr. 29, 2015 for U.S. Appl. No. 13/794,503.;;Office action dated May 8, 2015 for U.S. Appl. No. 12/816,043.;;Office action dated May 11, 2015 for U.S. Appl. No. 13/863,992.;;Office action dated Jul. 16, 2015 for U.S. Appl. No. 13/837,974.;;Office action dated Jul. 21, 2015 for U.S. Appl. No. 12/689,548.;;Office action dated Jul. 29, 2014 for U.S. Appl. No. 13/835,926.;;Office action dated Aug. 1, 2014 for U.S. Appl. No. 12/816,043.;;Office action dated Aug. 16, 2016 for U.S. Appl. No. 13/863,992.;;Office action dated Aug. 19, 2015 for U.S. Appl. No. 12/689,517.;;Office action dated Aug. 29, 2014 for U.S. Appl. No. 13/837,974.;;Office action dated Sep. 16, 2016 for U.S. Appl. No. 12/689,517.;;Office action dated Sep. 17, 2014 for U.S. Appl. No. 13/863,992.;;Office action dated Sep. 18, 2015 for U.S. Appl. No. 12/816,043.;;Office action dated Nov. 7, 2014 for U.S. Appl. No. 13/831,342.;;Office action dated Nov. 24, 2014 for U.S. Appl. No. 12/689,548.;;Office action dated Dec. 1, 2016 for U.S. Appl. No. 13/794,503.;;Office action dated Dec. 10, 2014 for U.S. Appl. No. 12/751,940.;;Office action dated Dec. 12, 2014 for U.S. Appl. No. 13/738,268.;;Office action dated Dec. 22, 2015 for U.S. Appl. No. 13/794,503.;;Office action dated Dec. 27, 2016 for U.S. Appl. No. 13/863,992.;;Opposition dated Apr. 10, 2014 by Olswang against EP Application No. EP07763674.4.;;Opposition dated Jun. 12, 2015 by Premaitha Health PLC against EP Application No. EP07763674.4.;;Pathak et al., “Circulating Cell-Free DNA in Plasma/Serum of Lung Cancer Patients as a Potential Screening and Prognostic Tool,” Oct. 2006, Clin. Chem. 52(10): 1833-42.;;Pertl et al., “Detection of Male and Female DNA in Maternal Plasma by Multiplex Fluorescent Polymerase Chain Reaction Amplification of Short Tandem Repeats,” Jan. 2000. Hum. Genet. 106(1):45-9.;;Poon et al., “Differential DNA methylation between fetus and mother as a strategy for detecting fetal DNA in maternal plasma,” Clinical chemistry 48.1 (2002): 35-41.;;REPLI-g® Mini and Midi Kits pamphlet from Qiagen (Oct. 2005).;;Sekiza et al., “Recent advances in non-invasive prenatal DNA diagnosis through analysis of maternal blood,” Journal of Obstetrics and Gynaecology Research, 33.6 (2007): 747-764.;;Su et al., “Human Urine Contains Small, 150 to 250 Nucleotide-Sized, Soluble DNA Derived from the Circulation and may be Useful in the Detection of Colo rectal Cancer,” May 2005, J. Mol. Diagn. 6(2):101-7.;;Swarup et al., “Circulating (cell free) nucleic acids—A promising, non-invasive tool for early detection of several human diseases,” 2007 FEBS Letters 581 :795-799.;;Thomas et al., “Sensitive Mutation Detection in Heterogeneous Cancer Specimens by Massively Parallel Picoliter Reactor Sequencing,” Jul. 2006. Nature Medicine. 12(7):852-855.;;Tong et al., “Noninvasive prenatal detection of fetal trisomy 18 by epigenetic allelic ratio analysis in maternal plasma: theoretical and empirical considerations,” Clinical Chemistry 52.12 (2006): 2194-2202.;;Vogelstein et al., “Allelotype of colorectal carcinomas,” Science 244 (4): 207-211. 1989.;;Vona et al., “Enrichment, immunomorphological, and genetic characterization of fetal cells circulating in maternal blood,” Am. J. Pathol., vol. 160, pp. 51-58 (2002).;;Wang et al., “Digital karyotyping,” PNAS, Dec. 2002, 99: 16156-16161.;;Wang et al., “Advances and applications of single-cell sequencing technologies,” Mol. Cell, vol. 58, pp. 598-609 (2015).;;Wong et al., “Circulating placental RNA in maternal plasma is associated with a preponderance of 5′ mRNA fragments: implications for noninvasive prenatal diagnosis and monitoring,” Clinical chemistry 51.10 (2005): 1786-1795.;;Wright et al., “The use of cell-free fetal nucleic acids in maternal blood for noninvasive prenatal diagnosis,” Hum. Reprod. Update. Jan.-Feb. 2009;15(1):139-51.;;Yu et al., “Size-based molecular diagnostics using plasma DNA for noninvasive prenatal testing,” Proceedings of the National Academy of Sciences 111.23 (2014): 8583-8588.;;Zhang et al., “Whole genome amplification from a single cell: implications for genetic analysis,” Proc Natl Acad Sci US A Jul. 1, 1992;89(13):5847-51.;;Zhou et al., “Counting alleles reveals a connection between chromosome 18q loss and vascular invasion,” Nature biotechnology 19 .1 (2001 ): 78-81.;;Zhou et al., “Counting alleles to predict recurrence of early-stage colorectal cancers,” The Lancet 359.9302 (2002): 219-225.;;Zimmerman, et al., “Digital PCR: a powerful new tool for noninvasive prenatal diagnosis?,” 2008 Prenat Diagn 28, 1087-1093.;;[No. Author Listed] “REPLI-g® Mini and Midi Kits: For highly uniform whole genome amplification from small or precious samples,” Qiagen, Oct. 2005, 4 pages.;;Aggarwal et al., “A combinatorial approach to the selective capture of circulating malignant epithelial cells by peptide ligands,” Biomaterials, 2005, 26(30):6077-86.;;Andre et al., “Lectin-Mediated Drug Targeting: Selection of Valency, Sugar Type (Gal/Lac), and Spacer Length for Cluster Glycosides as Parameters to Distinguish Ligand Binding to C-Type Asialoglycoprotein Receptors and Galectins,” Pharmaceutical Research, 2000, 17(8):985-990.;;Archer et al., “Cell Reactions to Dielectrophoretic Manipulation,” Biochemical and Biophysical Research Communications, 1999, 257:687-698.;;AU Notice of Acceptance in Australian Application No. 2013204127, dated Jul. 7, 2015, 3 pages.;;Benincasa et al., “Cell Sorting by One Gravity SPLITT Fractionation,” Analytical Chemistry, 2005, 77(16):5294-5301.;;Birner et al., “Evaluation of the United States Food and Drug Administration-approved scoring and test system of HER-2 protein expression in breast cancer,” Clin Cancer Res., 2001 7(6): 1669-1675.;;Chiu et al., “Noninvasive prenatal diagnosis by analysis of fetal DNA in maternal plasma,” Methods Mol Biol., 2006, 336:101-109.;;CN Office Action in Chinese Appln. No. 201711191019.9, dated Oct. 22, 2020, 13 pages (with English translation).;;Dhallan et al., “A non-invasive test for prenatal diagnosis based on fetal DNA present in maternal blood: apreliminaiy study,” Lancet, 2007, 369(9560):474-481.;;EP Extended European Search Report in Application No. 18171950.1, dated Oct. 15, 2018, 8 pages.;;EP Extended European Search Report in European Appln. No. 12175907.0, dated Jan. 2, 2013, 11 pages.;;EP Office Action in European Appln No. 07784444.7, dated Aug. 2, 2010, 6 pages.;;EP Office Action in European Appln. No. 07763674.4, dated Mar. 3, 2009, 3 pages.;;EP Office Action in European Appln. No. 07784444.7, dated Apr. 4, 2012, 7 pages.;;EP Office Action in European U.S. Appl. No. 18170287, dated Feb. 22, 2021, 7 pages.;;EP Office Action in European Appln. No. 18171950.1, dated Apr. 7, 2020, 6 pages.;;Pending Claims filed with the USPTO in U.S. Appl. No. 11/701,686, filed Jun. 24, 2010, 6 pages.;;Notice of Allowance in U.S. Appl. No. 12/393,803, dated Jul. 12, 2011, with allowed claims, 11 pages.;;Office Action in U.S. Appl. No. 11/067,102, dated Aug. 1, 2008, 24 pages.;;Office Action in U.S. Appl. No. 11/067,102, dated Apr. 13, 2009, 22 pages.;;Office Action in U.S. Appl. No. 11/067,102, dated Feb. 4, 2010, 21 pages.;;Office Action in U.S. Appl. No. 11/067,102, dated Jun. 15, 2007, 18 pages.;;Office Action in U.S. Appl. No. 11/067,102, dated Sep. 17, 2010, 31 pages.;;Office Action in U.S. Appl. No. 11/763,426, dated Jun. 14, 2010, 14 pages.;;FDA.gov [online], “Premarket Approval Decisions for Sep. 1998,” available on or before Oct. 16, 1998, via Internet Archive: Wayback Machine URL <http://web.archive.org/web/19990507012424/http://www.fda.gov/cdrh/pma/pmasep98.html>, retrieved on May 28, 2021, URL http://www.fda.gov/cdrh/pma/pmasep98.html>, 12 pages.;;Hatch et al., “A rapid diffusion immunoassay in a T-sensor,” Nature Biotechnology, 2001, 19:461-465.;;Jayasena, “Aptamers: an emerging class of molecules that rival antibodies in diagnostics,” Clin Chem., 1999, 45(9): 1628-1650.;;Kim et al., “rSW-seq: algorithm for detection of copy number alterations in deep sequencing data,” BMC Bioinformatics, 2010, 11:432, 13 pages.;;Meng et al., “HER-2 gene amplification can be acquired as breast cancer progresses,” PNAS, 2004, 101:9393-9398.;;Scoazec, “Tissue and cell imaging in situ: potential for applications in pathology and endoscopy,” Gut, 2003, 52(Suppl 4):iv1-iv6.;;Solexa, “Protocol for whole genome digital expression profiling using Solexa Technology,” Biotechniques, Protocol Guide, 2007, 1 page.;;Voldman et al., “Holding Forces of Single-Particle Dielectrophoretic Traps,” Biophysical Journal, 2001,80:531-541.;;Vona et al., “Isolation by size of epithelial tumor cells,” American Journal of Pathology, 2000, 156:57-63.;;Xu et al., “Dielectrophoresis of human red cells in microchips,” Electrophoresis, 1999, 20:1829-1831.;;Yang et al., “Prenatal diagnosis of trisomy 21 with fetal cells i maternal blood using comparative genomic hybridization,” Fetal Diagn Ther., 2006, 21:125-133.;;Zborowski et al., “Red Blood Cell Magnetophoresis,” Biophys. J., 2003, 84:2638-2645.;;Zhang et al., “Whole genome amplification from a single cell: Implications for genetic analysis,” PNAS, 1992, 89:5847-5851.;;EP Intention to Grant in European Appln. No. 18171950.1, dated Dec. 23, 2021, 5 pages.;;EP Summons to attend oral proceedings pursuant to Rule 115(1) EPC in European Appln. No. 18171950.1, dated Mar. 3, 2021, 9 pages.",ACTIVE
648,CA,A1,CA 2178927 A1,153-546-573-038-27X,1995-06-22,1995,CA 2178927 A,1993-12-15,CA 2178927 A,1993-12-15,PEPTIDE INHIBITORS OF CXC INTERCRINE MOLECULES,"Disclosed are peptide-based compositions and methods for inhibiting and modulating the actions of CXC intercrine molecules. The antileukinate peptides described inhibit IL-8, GRO and MIP2.beta. binding to neutrophils and neutrophil activation. The peptides are particularly advantageous as they inhibit IL-8-induced enzyme release at a 25 fold lower concentration than is required to inhibit chemotaxis, which makes them ideal for treating various inflammatory diseases and disorders including, amongst others, Adult Respiratory Distress Syndrome (ARDS), cystic fibrosis and chronic bronchitis.",UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/153-546-573-038-27X,Patent Application,no,0,0,1,1,0,A61K38/08;;A61K38/10;;C07K7/06;;C07K7/08;;A61K38/08,A61K38/08;;A61K38/10;;C07K7/06;;C07K7/08,,0,0,,,,DISCONTINUED
649,US,A,US 4059389 A,169-710-560-260-237,1977-11-22,1977,US 72160476 A,1976-09-07,US 72160476 A,1976-09-07,Photoflash lamp and method of making same,"A high-voltage type photoflash lamp filled with a filamentary combustible material and oxygen and having a beadless ignition structure comprising a pair of spaced apart lead-in wires with spherically shaped terminations, a glass frit coating over the lead-in wires with scraped-off portions exposing the bare metal of the wire adjacent each termination, and a coating of primer material over the frit-coated terminations and bared portions of the wires. The primer may bridge the wire terminations or comprise separate spaced apart coatings on the respective terminations, with the filamentary combustible being in contact with both terminations to provide a conducting path therebetween. The frit coating is thick enough to prevent preignition short circuits. Also disclosed is a method of making the lamp including the steps of applying a flame to melt down the ends of the lead-in wires to provide smooth and rounded terminations, dipping the wires in a liquid suspension of glass frit, air drying, passing a blade between the wires to scrape away portions of the frit coating and expose bare wire adjacent the terminations, sealing the lead-in wires into one end of a length of glass tubing, dipping the coated lead-in wires into a primer cup to provide a coat of primer over the terminations and scraped portions, and then finishing the lamp.",GTE SYLVANIA INC,ARMSTRONG DONALD E;;SINDLINGER RONALD E;;COHEN BERNARD;;TOZIER JOHN E;;AUDESSE EMERY G,FLOWIL INTERNATIONAL (HOLDING) B.V (1993-01-29);;GTE PRODUCTS CORPORATION (1980-01-09),https://lens.org/169-710-560-260-237,Granted Patent,yes,3,11,12,12,0,F21K5/02;;F21K5/02,F21K5/08;;F21K5/06,431 95R,0,0,,,,EXPIRED
650,FI,A,FI 962413 A,049-060-634-507-958,1996-07-24,1996,FI 962413 A,1996-06-11,US 9312245 W,1993-12-15,CXC-interkriinimolekyylien peptidi-inhibiittoreita,,UNIV TEXAS,MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R;;COHEN ALLEN BARRY,,https://lens.org/049-060-634-507-958,Patent Application,no,0,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,0,0,,,,DISCONTINUED
651,JP,A,JP 2008117407 A,172-724-304-304-291,2008-05-22,2008,JP 2007303708 A,2007-11-22,US 25899100 P,2000-12-29,LOSSY INDEX COMPRESSION APPARATUS,"<P>PROBLEM TO BE SOLVED: To provide a device for performing a method for pruning an index of a corpus of text documents. <P>SOLUTION: The method includes steps for ranking the postings in the index (50) and pruning from the index the postings below a given level in the ranking (48). The given level is set based on a parameter received from a user and the rank thereof so that the top of results returned using a reverse index before pruning is similar to the top of results returned using the reverse index after pruning. <P>COPYRIGHT: (C)2008,JPO&INPIT",IBM,CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,,https://lens.org/172-724-304-304-291,Patent Application,no,4,0,11,11,0,G06F16/328;;G06F16/319,G06F17/30,,0,0,,,,INACTIVE
652,US,A1,US 2012/0183963 A1,190-004-830-054-840,2012-07-19,2012,US 201213433232 A,2012-03-28,US 201213433232 A;;US 72524010 A;;US 76342607 A;;US 80481506 P;;US 82077806 P,2006-06-14,DETERMINATION OF FETAL ANEUPLOIDY BY QUANTIFICATION OF GENOMIC DNA FROM MIXED SAMPLES,"The present invention provides systems, apparatuses, and methods to detect the presence of fetal cells when mixed with a population of maternal cells in a sample and to test fetal abnormalities, i.e. aneuploidy. In addition, the present invention provides methods to determine when there are insufficient fetal cells for a determination and report a non-informative case. The present invention involves quantifying regions of genomic DNA from a mixed sample. More particularly the invention involves quantifying DNA polymorphisms from the mixed sample.",STOUGHTON ROLAND;;KAPUR RAVI;;TONER MEHMET;;SHOEMAKER DANIEL;;DAVIS RONALD W;;COHEN BARB ARIEL,STOUGHTON ROLAND;;KAPUR RAVI;;TONER MEHMET;;SHOEMAKER DANIEL;;DAVIS RONALD W;;COHEN BARB ARIEL,VERINATA HEALTH INC (2007-08-13);;GPB SCIENTIFIC LLC (2012-04-06);;THE GENERAL HOSPITAL CORPORATION (2012-04-06),https://lens.org/190-004-830-054-840,Patent Application,yes,0,16,11,99,166,C12Q2600/156;;C12Q2600/158;;C12Q2600/16;;G16B20/00;;C12Q1/6883;;G16B20/20;;G16B20/10;;C12Q2600/16;;C12Q2600/156;;C12Q2600/158;;G16B20/00;;G16B20/10;;G16B20/20;;C12Q1/6883;;G01N1/30,C12Q1/68;;G16B20/10;;G16B20/20,435/6.11,0,0,,,,DISCONTINUED
653,WO,A1,WO 2002/054289 A1,139-408-618-484-298,2002-07-11,2002,US 0149260 W,2001-12-19,US 25899100 P,2000-12-29,LOSSY INDEX COMPRESSION,"An apparatus is provided for performing a method (Fig. 2) for pruning an index of a corpus of text documents, wherein the method includes steps for ranking (50) the postings in the index and pruning (48) from the index the postings below a given level in the ranking. The pruning methods of the invention are lossy, since some document postings are removed from the full index; however, the user cannot differentiate the lossy index from the full index.",IBM;;CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,,https://lens.org/139-408-618-484-298,Patent Application,yes,4,0,11,11,0,G06F16/328;;G06F16/319,G06F17/30,,4,1,067-023-993-111-795,10.1007/978-1-4471-2099-5_35,"See also references of EP 1346296A4;;WITTEN ET AL.: ""Managing Gigabytes"", 1999, MORGAN KAUFINAN PUBLISHERS;;DEERWEESTER ET AL.: ""Indexing by Latent Semantic Analysis"", JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE, vol. 41, no. 1, 1990, pages 391 - 407;;PERSIN: ""Proceedings of the 1 7th Annual International A CM-SIGIR Conference on Research and Development in Information Retrieval"", July 1994, DUBLIN, article ""Document Filtering for Fast Ranking"", pages: 339 - 348",PENDING
654,DE,A1,DE 2739388 A1,142-335-254-981-659,1978-03-09,1978,DE 2739388 A,1977-09-01,US 72160476 A,1976-09-07,PIEZOELEKTRISCH ZUENDBARE PHOTOBLITZLAMPE UND METHODE ZU IHRER HERSTELLUNG,,GTE SYLVANIA INC,ARMSTRONG DONALD E;;SINDLINGER RONALD E;;COHEN BERNARD;;TOZIER JOHN E;;AUDESSE EMERY G,,https://lens.org/142-335-254-981-659,Patent Application,no,2,0,12,12,0,F21K5/02;;F21K5/02,F21K5/06;;F21K5/08,,0,0,,,,EXPIRED
655,KR,A,KR 20050103133 A,163-672-892-709-819,2005-10-27,2005,KR 20040084781 A,2004-10-22,US 83069304 A,2004-04-23,TOOTHBRUSH,,GILLETTE CO,BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF RONALD RJR;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,,https://lens.org/163-672-892-709-819,Patent Application,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
656,WO,A1,WO 1995/016702 A1,182-041-387-211-436,1995-06-22,1995,US 9312245 W,1993-12-15,US 9312245 W,1993-12-15,PEPTIDE INHIBITORS OF CXC INTERCRINE MOLECULES,"Disclosed are peptide-based compositions and methods for inhibiting and modulating the actions of CXC intercrine molecules. The antileukinate peptides described inhibit IL-8, GRO and MIP2β binding to neutrophils and neutrophil activation. The peptides are particularly advantageous as they inhibit IL-8-induced enzyme release at a 25 fold lower concentration than is required to inhibit chemotaxis, which makes them ideal for treating various inflammatory diseases and disorders including, amongst others, Adult Respiratory Distress Syndrome (ARDS), cystic fibrosis and chronic bronchitis.",UNIV TEXAS;;COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/182-041-387-211-436,Patent Application,yes,3,2,11,11,58,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,3,2,009-328-947-109-030;;105-510-018-248-707,pmc553883;;3327687;;10.1002/j.1460-2075.1987.tb02746.x;;1744111;;10.1016/s0021-9258(18)54472-0,"A.L. CORBI ET AL.: ""cDNA cloning and complete primary structure of the alpha subunit of a leukocyte adhesion glycoprotein, p150,95"", EMBO JOURNAL, vol. 6, no. 13, 20 December 1987 (1987-12-20), EYNSHAM, OXFORD GB, pages 4023 - 4028;;I. CLARK-LEWIS ET AL.: ""Structure-Activity Relationships of Interleukin-8 Determined Using Chemically Synthesized Analogs"", JOURNAL OF BIOLOGICAL CHEMISTRY, vol. 266, no. 34, 5 December 1991 (1991-12-05), BALTIMORE, MD US, pages 23128 - 23134;;See also references of EP 0734394A1",PENDING
657,US,A1,US 2004/0158580 A1,018-777-523-004-227,2004-08-12,2004,US 45105604 A,2004-01-09,US 45105604 A;;US 0149260 W,2001-12-19,Lossy index compression,"
    An apparatus is provided for performing a method (FIG. 2 ) for pruning an index of a corpus of text documents, wherein the method includes steps for ranking ( 50 ) the postings in the index and pruning ( 48 ) from the index the postings below a given level in the ranking. The pruning methods of the invention are lossy, since some document postings are removed from the full index; however, the user cannot differentiate the lossy index from the full index. 
",CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,CARMEL DAVID;;COHEN DORON;;FAGIN RONALD;;FARCHI EITAN;;HERSCOVICI MICHAEL;;MAAREK YOELLE;;SOFFER AYA,INTERNATIONAL BUSINESS MACHINES CORPORATION (2004-03-12),https://lens.org/018-777-523-004-227,Patent Application,yes,8,36,2,2,0,G06F16/328;;G06F16/328;;Y10S707/99935;;Y10S707/99942,G06F17/00,707/104.1,0,0,,,,EXPIRED
658,US,A1,US 2021/0010913 A1,031-180-206-830-743,2021-01-14,2021,US 202016819992 A,2020-03-16,US 202016819992 A;;US 201313830871 A;;US 201313738268 A;;US 201213433232 A;;US 72524010 A;;US 76342607 A;;US 82077806 P;;US 80481506 P,2006-06-14,DIAGNOSIS OF FETAL ABNORMALITIES USING POLYMORPHISMS INCLUDING SHORT TANDEM REPEATS,"The present invention provides systems, apparatuses, and methods to detect the presence of fetal cells when mixed with a population of maternal cells in a sample and to test fetal abnormalities, i.e. aneuploidy. In addition, the present invention provides methods to determine when there are insufficient fetal cells for a determination and report a non-informative case. The present invention involves quantifying regions of genomic DNA from a mixed sample. More particularly the invention involves quantifying DNA polymorphisms from the mixed sample.",VERINATA HEALTH INC;;MASSACHUSETTS GEN HOSPITAL;;GPB SCIENTIFIC LLC,STOUGHTON ROLAND;;KAPUR RAVI;;COHEN BARB ARIEL;;SHOEMAKER DANIEL;;DAVIS RONALD W;;TONER MEHMET,VERINATA HEALTH INC (2007-08-13);;GPB SCIENTIFIC LLC (2012-04-06);;THE GENERAL HOSPITAL CORPORATION (2012-04-06),https://lens.org/031-180-206-830-743,Patent Application,yes,0,0,11,99,0,C12Q2600/156;;C12Q2600/158;;C12Q2600/16;;G16B20/00;;C12Q1/6883;;G16B20/20;;G16B20/10;;C12Q2600/16;;C12Q2600/156;;C12Q2600/158;;G16B20/00;;G16B20/10;;G16B20/20;;C12Q1/6883;;G01N1/30,G01N1/30;;C12Q1/6883;;G16B20/10;;G16B20/20,,0,0,,,,ACTIVE
659,AU,B2,AU 685079 B2,087-229-268-121-316,1998-01-15,1998,AU 1994/060147 A,1993-12-15,US 9312245 W,1993-12-15,Peptide inhibitors of CXC intercrine molecules,,UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/087-229-268-121-316,Granted Patent,no,1,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,0,0,,,,EXPIRED
660,EP,A1,EP 1346296 A1,130-567-003-185-719,2003-09-24,2003,EP 01992199 A,2001-12-19,US 0149260 W;;US 25899100 P,2000-12-29,LOSSY INDEX COMPRESSION,,IBM,"CARMEL, DAVID;;COHEN, DORON;;FAGIN, RONALD;;FARCHI, EITAN;;HERSCOVICI, MICHAEL;;MAAREK, YOELLE;;SOFFER, AYA",,https://lens.org/130-567-003-185-719,Patent Application,yes,0,0,11,11,0,G06F16/328;;G06F16/319,G06F17/30,,0,0,,,,EXPIRED
661,EP,B1,EP 2029778 B1,101-319-409-161-990,2018-05-02,2018,EP 07798579 A,2007-06-14,US 2007/0071247 W;;US 80481506 P,2006-06-14,DIAGNOSIS OF FETAL ABNORMALITIES,,VERINATA HEALTH INC,STOUGHTON ROLAND;;KAPUR RAVI;;COHEN BARB ARIEL;;SHOEMAKER DANIEL;;DAVIS RONALD W;;TONER MEHMET,"ARTEMIS HEALTH, INC. (2011-09-07);;VERINATA HEALTH, INC (2012-01-18)",https://lens.org/101-319-409-161-990,Granted Patent,yes,0,0,7,99,0,C12Q1/6883;;C12Q2600/156;;C12Q2600/16,C12Q1/68;;G01N33/48,,1,1,006-705-425-787-055,10.1038/nbt951;;15024389,"HONG JONG WOOK ET AL: ""A nanoliter-scale nucleic acid processor with parallel architecture."", NATURE BIOTECHNOLOGY APR 2004, vol. 22, no. 4, April 2004 (2004-04-01), pages 435 - 439, ISSN: 1087-0156",ACTIVE
662,EP,A1,EP 0734394 A1,168-331-856-554-609,1996-10-02,1996,EP 94906442 A,1993-12-15,US 9312245 W,1993-12-15,PEPTIDE INHIBITORS OF CXC INTERCRINE MOLECULES,,UNIV TEXAS,COHEN ALLEN BARRY;;MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R,,https://lens.org/168-331-856-554-609,Patent Application,yes,3,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,3,2,009-328-947-109-030;;105-510-018-248-707,pmc553883;;3327687;;10.1002/j.1460-2075.1987.tb02746.x;;1744111;;10.1016/s0021-9258(18)54472-0,"A.L. CORBI ET AL.: ""cDNA cloning and complete primary structure of the alpha subunit of a leukocyte adhesion glycoprotein, p150,95"" EMBO JOURNAL, vol. 6, no. 13, 20 December 1987, pages 4023-4028, XP000576163 EYNSHAM, OXFORD GB;;I. CLARK-LEWIS ET AL.: ""Structure-Activity Relationships of Interleukin-8 Determined Using Chemically Synthesized Analogs"" JOURNAL OF BIOLOGICAL CHEMISTRY, vol. 266, no. 34, 5 December 1991, pages 23128-23134, XP000576162 BALTIMORE, MD US;;See also references of WO 9516702A1",DISCONTINUED
663,FI,A0,FI 962413 A0,036-248-472-624-491,1996-06-11,1996,FI 962413 A,1996-06-11,US 9312245 W,1993-12-15,CXC-interkriinimolekyylien peptidi-inhibiittoreita,,UNIV TEXAS,MILLER EDMUND J;;HAYASHI SHINICHIRO;;KURDOWSKA ANNA K;;TUTTLE RONALD R;;COHEN ALLEN BARRY,,https://lens.org/036-248-472-624-491,Patent Application,no,0,0,11,11,0,A61K38/00;;A61K38/08;;A61K38/10;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K7/06;;C07K14/54;;C07K14/5421,A61K9/12;;A61K9/72;;A61K38/00;;A61P1/04;;A61P11/00;;A61P17/00;;A61P29/00;;A61P43/00;;C07K7/06;;C07K14/54,,0,0,,,,DISCONTINUED
664,DK,T3,DK 2029778 T3,057-751-959-967-752,2018-08-20,2018,DK 07798579 T,2007-06-14,US 80481506 P;;US 2007/0071247 W,2006-06-14,DIAGNOSE AF FØTALE ABNORMITETER,,VERINATA HEALTH INC,STOUGHTON ROLAND;;KAPUR RAVI;;COHEN BARB ARIEL;;SHOEMAKER DANIEL;;DAVIS RONALD W;;TONER MEHMET,,https://lens.org/057-751-959-967-752,Granted Patent,no,0,0,7,99,0,C12Q1/6883;;C12Q2600/156;;C12Q2600/16,G01N33/48,,0,0,,,,ACTIVE
665,CN,A,CN 1182591 A,059-767-330-420-521,1998-05-27,1998,CN 97122530 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvement for prevention of mammary gland cancer or the prevention of mammary gland canner,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/059-767-330-420-521,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
666,JP,A,JP H10147530 A,075-268-075-224-112,1998-06-02,1998,JP 29868297 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,IMPROVEMENT IN PROPHYLAXIS OF BREAST CANCER,"PROBLEM TO BE SOLVED: To obtain a medicine composition capable of suppressing occurrence of breast cancer in female after menopause by a specific dose, comprising raloxifene as an active ingredient. SOLUTION: Raloxifene of the formula is obtained by using benzo[b]thiophene containing a 6-hydroxyl group and 2-(4-hydroxyphenyl) group as a starting substance, protecting the hydroxyl group, acylating the 3-position and deprotecting the reaction product. A medicine composition comprising raloxifene (salt) as an active ingredient is obtained. The composition is pharmaceutically manufactured with a general excipient, diluent and carrier into tablet, capsule, suspension, powder, etc., to give the medicine composition. Raloxifene (salt) is administered in an amount of 30-150mg, preferably 50-70mg per day for >=6 months, preferably >=2 years. Oral administration is preferable as the method for administration.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/075-268-075-224-112,Patent Application,no,0,1,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
667,DK,T3,DK 0839532 T3,152-040-691-277-461,2003-08-25,2003,DK 97308588 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Forbedringer af eller i forbindelse med forebyggelse af brystkræft ved indgift af raloxifen,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/152-040-691-277-461,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
668,ZA,B,ZA 979720 B,006-089-562-178-209,1999-04-29,1999,ZA 979720 A,1997-10-29,US 2985096 P,1996-10-30,Prophylaxis of breast cancer,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/006-089-562-178-209,Granted Patent,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,EXPIRED
669,DE,T2,DE 69721692 T2,006-614-411-575-162,2004-03-25,2004,DE 69721692 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Verbesserung in oder in Bezug auf der Vorbeugung von Brustkrebs durch Verabreichung von Raloxifen,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/006-614-411-575-162,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
670,AU,A1,AU 2010/202925 A1,046-940-511-676-440,2010-07-29,2010,AU 2010/202925 A,2010-07-09,AU 2007/205787 A;;AU 2010/202925 A,2007-08-14,Toothbrush,,GILLETTE CO,BRAUN PHILLIP M;;COHEN RICHARD H;;DUFF RONALD R JR;;MATERMAN THOMAS CRAIG;;SYNODIS JOSEPH,,https://lens.org/046-940-511-676-440,Patent Application,no,0,0,2,53,0,A46B9/04;;A46B5/0025;;A46B7/06;;A46B9/06;;A46B9/12;;A46B2200/1066;;A46D1/00;;A61C17/3481,A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
671,SI,T1,SI 0839532 T1,084-377-711-644-097,2003-10-31,2003,SI 9730529 T,1997-10-29,EP 97308588 A;;GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer by the administration of raloxifene,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/084-377-711-644-097,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
672,AU,B2,AU 2007/205787 B2,170-614-551-431-204,2011-02-17,2011,AU 2007/205787 A,2007-08-14,AU 2004/222737 A;;AU 2007/205787 A,2004-10-19,AU 2007/205787 B2,,GILLETTE CO LLC,COHEN RICHARD H;;MATERMAN THOMAS CRAIG;;DUFF RONALD R JR;;SYNODIS JOSEPH;;BRAUN PHILLIP M,,https://lens.org/170-614-551-431-204,Granted Patent,no,0,0,2,53,0,,,,0,0,,,,ACTIVE
673,GB,D0,GB 9722796 D0,176-990-846-626-970,1997-12-24,1997,GB 9722796 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/176-990-846-626-970,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
674,DE,D1,DE 69725878 D1,100-091-619-733-542,2003-12-11,2003,DE 69725878 T,1997-08-13,US 2386796 P;;US 9714465 W,1996-08-13,ZUSAMMENSETZUNGEN ZUR POLYNUKLEOTIDABGABE,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS A;;MURPHY E;;COHEN FRED;;UNO TETSUO,"NOVARTIS VACCINES AND DIAGNOSTICS,INC.(N.D.GES, US (2009-05-07)",https://lens.org/100-091-619-733-542,Granted Patent,no,0,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,EXPIRED
675,IT,A1,IT MI972433 A1,118-311-996-126-540,1999-04-29,1999,IT MI972433 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,COMPOSTI IMPIEGATI NELLA PREVENZIONE DEL CANCRO DELLA MAMMELLA E MANUFATTO COMPRENDENTE GLI STESSI,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/118-311-996-126-540,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
676,PT,E,PT 839532 E,148-095-541-295-975,2003-09-30,2003,PT 97308588 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,MELHORAMENTOS NA PROFILAXIA DO CANCRO DA MAMA OU RELACIONADOS COM A PROFILAXIA POR ADMINISTRACAO DE RALOXIFENO,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/148-095-541-295-975,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
677,AU,A1,AU 2007/205787 A1,161-710-176-128-820,2007-08-30,2007,AU 2007/205787 A,2007-08-14,AU 2004/222737 A;;AU 2007/205787 A,2004-10-19,Toothbrush,,GILLETTE CO,COHEN RICHARD H;;MATERMAN THOMAS CRAIG;;DUFF RONALD R JR;;SYNODIS JOSEPH;;BRAUN PHILLIP M,,https://lens.org/161-710-176-128-820,Patent Application,no,0,0,2,53,0,,A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
678,TW,A,TW 200534831 A,073-407-478-431-460,2005-11-01,2005,TW 93131405 A,2004-10-15,US 83069304 A,2004-04-23,Toothbrush,A toothbrush includes a head and a tooth cleaning element extending from a top surface of the head. The head is divided into at least two portions which can be moved independent of each other. The tooth cleaning element is rotatable relative to that portion of the head from which it extends. A vibrator vibrates the head and tooth cleaning element.,GILLETTE CO,BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF RONALD R JR;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,,https://lens.org/073-407-478-431-460,Patent of Addition,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,PENDING
679,HU,A2,HU P9701777 A2,114-465-165-921-857,1999-06-28,1999,HU P9701777 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,USE OF RALOXIFENE FOR PRODUCING PHARMACEUTICAL COMPOSITIONS FOR PREVENTING BREAST CANCER,"A találmány tárgya az (I) képletű vegyület vagy gyógyszerészetilegelfőgadható sója vagy szőlvátja alkalmazása őlyan gyógyszerkészítményelőállítására, amely alkalmas hűmán betegekben a mellrákkialakűlásának megelőzésére. A találmány szerinti gyógyszerkészítményta fenti hűmán betegnek megfelelő időtartamőn át és megfelelő hatásősdózisban kell adagőlni. A találmány szerinti készítménygyógyszerészetben használható. ŕ",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/114-465-165-921-857,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
680,AU,B2,AU 2004/222737 B2,094-750-130-400-938,2007-09-20,2007,AU 2004/222737 A,2004-10-19,US 83069304 A;;AU 2004/222373 A;;AU 2004/222737 A,2004-03-09,Toothbrush,,GILLETTE CO LLC,BRAUN PHILLIP M;;COHEN RICHARD H;;MATERMAN THOMAS CRAIG;;SYNODIS JOSEPH;;DUFF RONALD R JR,,https://lens.org/094-750-130-400-938,Granted Patent,no,2,1,2,53,0,A61C17/34,A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
681,US,A1,US 2005/0235439 A1,092-727-352-430-501,2005-10-27,2005,US 83069304 A,2004-04-23,US 83069304 A;;US 38944803 A,2003-03-14,Toothbrush,A toothbrush includes a head and a tooth cleaning element extending from a top surface of the head. The head is divided into at least two portions which can be moved independent of each other. The tooth cleaning element is rotatable relative to that portion of the head from which it extends. A vibrator vibrates the head and tooth cleaning element.,GILLETTE CO,BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF RONALD R JR;;COHEN RICHARD H;;MASTERMAN THOMAS C,,https://lens.org/092-727-352-430-501,Patent Application,yes,69,36,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,15/22.1;;15/201,0,0,,,,DISCONTINUED
682,EP,A2,EP 1588673 A2,124-346-857-493-321,2005-10-26,2005,EP 04023980 A,2004-10-07,US 83069304 A,2004-04-23,Vibrating toothbrush,A toothbrush includes a head and a tooth cleaning element extending from a top surface of the head. The head is divided into at least two portions which can be moved independent of each other. The tooth cleaning element is rotatable relative to that portion of the head from which it extends. A vibrator vibrates the head and tooth cleaning element.,GILLETTE CO,BRAUN PHILLIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY LLC (2016-12-07);;THE GILLETTE COMPANY (2012-06-06),https://lens.org/124-346-857-493-321,Patent Application,yes,8,6,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
683,US,A1,US 2019/0128653 A1,125-220-223-002-44X,2019-05-02,2019,US 201816175020 A,2018-10-30,US 201816175020 A;;US 201762579020 P,2017-10-30,EXPLOSIVE SEPARATING JOINT,"An explosive separation joint system having an expandable tube containing a mild detonating fuse (MDF) in separable portions of the joint. The MDF extends into a detonation manifold at a first port, an end of the MDF having booster bonded thereto. An external initiating ordnance transfer line enters the manifold at an initiating ordnance (IO) port, has an IO end tip and provides a detonation impulse train where each detonating component is axially aligned within a passageway with the next detonating component. In embodiments, particular detonating components of the detonation train are fixed in place where other detonating components are movable. Each detonating component that is not in direct contact with a preceding detonating component in the detonation train is in direct linear access.",NORTHROP GRUMMAN INNOVATION SYSTEMS INC,COHEN DAVID BRUCE;;DOYLE JOHN THOMAS;;HAYNIE RICHARD MARK;;HARRINGTON PAUL JESSE;;BURNSIDE GARY RONALD,NORTHROP GRUMMAN INNOVATION SYSTEMS INC (2018-11-19);;NORTHROP GRUMMAN SYSTEMS CORPORATION (2021-01-11),https://lens.org/125-220-223-002-44X,Patent Application,yes,0,3,3,3,0,B64G1/641;;B64G1/645;;F42B15/38;;F42B15/38;;F42B3/093;;F42B3/093,F42B15/38;;B64G1/64;;F42B3/093,,0,0,,,,ACTIVE
684,WO,A1,WO 1998/018325 A1,157-962-143-922-549,1998-05-07,1998,US 9719726 W,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,PROPHYLAXIS OF BREAST CANCER,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI;;COHEN FREDRIC J;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/157-962-143-922-549,Patent Application,yes,2,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
685,FR,A1,FR 2755014 A1,011-040-745-353-165,1998-04-30,1998,FR 9713579 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,AMELIORATIONS CONCERNANT LA PROPHYLAXIE DU CANCER DU SEIN,"<P>Prophylaxie du cancer du sein chez une femme post-ménopausique par administration, à cette femme, de raloxifène, ou d'un sel pharmaceutiquement acceptable de celui-ci, en une quantité d'environ 30 mg à environ 150 mg par jour.</P>",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/011-040-745-353-165,Patent Application,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
686,IL,A0,IL 122025 A0,016-892-605-725-600,1998-03-10,1998,IL 12202597 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/016-892-605-725-600,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
687,BE,A5,BE 1011381 A5,036-368-666-217-110,1999-08-03,1999,BE 9700864 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,AMELIORATIONS CONCERNANT LA PROPHYLAXIE DU CANCER DU SEIN.,"Prophylaxie du cancer du sein chez une femme post-ménopausique par administration, à cette femme, de raloxifène, ou d'un sel pharmaceutiquement acceptable de celui-ci, en une quantité d'environ 60 mg à environ 120 mg par jour.",LILLY CO ELI,FREDERIC JAY COHEN;;JOAN ELLEN GLUSMAN;;RONALD KEITH KNICKERBOCKER;;NIKOLAUS THOMAS NICKELSEN;;TERI JANINE SCOTT,,https://lens.org/036-368-666-217-110,Granted Patent,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
688,AU,A,AU 1997/050056 A,042-156-676-105-086,1998-05-22,1998,AU 1997/050056 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/042-156-676-105-086,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
689,GB,A,GB 2318733 A,140-416-428-836-550,1998-05-06,1998,GB 9722796 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Prophylaxis of breast cancer,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/140-416-428-836-550,Patent Application,no,3,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,A5B BHA           BHA3;;A5B B170          BHA3;;A5B B180          BHA3;;A5B B48Y          BHA3;;A5B B482          BHA3;;A5B B483          BHA3;;A5B B50Y          BHA3;;A5B B503          BHA3;;A5B B54Y          BHA3;;A5B B541          BHA3;;A5B B55Y          BHA3;;A5B B553          BHA3;;A5B B56Y          BHA3;;A5B B566          BHA3;;A5B B57Y          BHA3;;A5B B575          BHA3;;A5B B58Y          BHA3;;A5B B586          BHA3;;A5B B61Y          BHA3;;A5B B616          BHA3;;A5B B65Y          BHA3;;A5B B650          BHA3;;A5B B654          BHA3;;A5B B66Y          BHA3;;A5B B664          BHA3;;A5B B828          BHA3;;A5B B829          BHA3;;U1S S1313,5,5,116-238-224-441-339;;090-621-258-864-815;;039-179-689-155-908;;006-388-692-923-22X;;129-192-318-027-682,10.1093/jnci/88.2.123;;8537973;;8573710;;10.1007/bf00713399;;6431104;;10.1021/jm00374a021;;10.1016/0024-3205(83)90323-5;;6406781;;10.1002/jcb.240590808,CAPLUS Abs. acc. no. 1996:122169 & J. Natl. Cancer Inst. (1996) 88(2) (Anzano) pages 123-5;;BIOSIS Abs. acc. no. 95:496471 & Breast Cancer Research and Treatment (1995) 36(3) (Jordan) 267-285;;CAPLUS Abs. acc. no. 1984:448784 & J. Med. Chem. (1984) 27(8) (Jones) pages 1057-66;;CAPLUS Abs. acc. no. 1983:432846 & Life Science (1983) 32(25) (Clemens) pages 2869-75;;J. Cellular Biochemistry 58/suppl. 22 1995 (JORDAN) pages 51-57.,DISCONTINUED
690,SG,A1,SG 72765 A1,130-752-440-947-130,2000-05-23,2000,SG 1997003899 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/130-752-440-947-130,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
691,NL,C2,NL 1007386 C2,137-871-944-145-832,1998-05-14,1998,NL 1007386 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Werkwijzen ter voorkoming van borstkanker.,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/137-871-944-145-832,Granted Patent,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
692,GB,D0,GB 9722801 D0,168-867-550-028-409,1997-12-24,1997,GB 9722801 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/168-867-550-028-409,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
693,BR,A,BR PI0404553 A,034-659-389-997-303,2006-01-24,2006,BR PI0404553 A,2004-10-22,US 83069304 A,2004-04-23,Escova de dente,"""ESCOVA DE DENTE"". Uma escova de dente inclui uma cabeça e um elemento de limpeza do dente que se estende a partir de uma superfície superior da cabeça. A cabeça é dividida em pelo menos duas partes que podem mover-se independente uma da outra. O elemento de limpeza do dente é girável em relação a essa parte da cabeça a partir da qual ele se estende. Um vibrador vibra a cabeça e o elemento de limpeza do dente.",GILLETTE CO,BRAUN PHILLIP M;;SYNNODIS JOSEPH;;DUFF RONALD R JR;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY LLC (US) (2017-07-18),https://lens.org/034-659-389-997-303,Patent Application,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/06;;A46B9/04;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
694,CZ,A3,CZ 341297 A3,072-553-239-215-073,1998-05-13,1998,CZ 341297 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHOD OF ENHANCING TREATMENT OF PROPHYLAXIS OF MASTOCARCINOMA,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/072-553-239-215-073,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
695,CN,A,CN 1689480 A,112-033-785-965-963,2005-11-02,2005,CN 200410085984 A,2004-10-25,US 83069304 A,2004-04-23,Toothbrush,,GILLETTE CO,BRAUN PHILLIP M;;DUFF RONALD R JR;;JOSEPH SYNODIS;;COHEN RICHARD H;;CRAIG MASTERMAN THOMAS,,https://lens.org/112-033-785-965-963,Patent Application,no,0,3,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
696,EP,A1,EP 0839533 A1,141-108-506-199-799,1998-05-06,1998,EP 97308626 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer by the administration of Raloxifene,"A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula
      and pharmaceutically acceptable salts and solvates thereof.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/141-108-506-199-799,Patent Application,yes,6,6,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",DISCONTINUED
697,CA,A1,CA 2219070 A1,165-096-299-553-833,1998-04-30,1998,CA 2219070 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula <IMG> (I) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/165-096-299-553-833,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
698,HU,D0,HU 9701778 D0,166-509-515-279-197,1997-12-29,1997,HU P9701778 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,IMPROVED PROCESS FOR PROFILACTING BREAST CANCER,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/166-509-515-279-197,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
699,US,B2,US 7974943 B2,170-910-556-604-30X,2011-07-05,2011,US 26105508 A,2008-10-30,US 26105508 A,2008-10-30,Building a synchronized target database,One embodiment is a method that builds a target database with transaction logs from an online source database. The transaction logs include both existing data in the source database and updates that occur to the source database while the target database is being built.,HEWLETT PACKARD DEVELOPMENT CO,GILBERT GARY M;;BROEDER SEAN L;;COHEN RONALD P;;FISHLER LEONARD R;;SMITH GARY S,HEWLETT PACKARD ENTERPRISE DEVELOPMENT LP (2015-10-27);;HEWLETT-PACKARD DEVELOPMENT COMPANY L.P (2008-10-29),https://lens.org/170-910-556-604-30X,Granted Patent,yes,14,29,2,2,0,G06F16/27;;G06F16/27,G06F17/30,707/610;;707/648;;707/615;;707/616;;707/626;;707/635;;707/636;;707/633;;707/634;;707/637;;707/638;;707/639,0,0,,,,ACTIVE
700,BR,B1,BR PI0404553 B1,033-579-972-422-842,2018-02-14,2018,BR PI0404553 A,2004-10-22,US 83069304 A,2004-04-23,escova de dente,"""escova de dente"". uma escova de dente inclui uma cabeça e um elemento de limpeza do dente que se estende a partir de uma superfície superior da cabeça. a cabeça é dividida em pelo menos duas partes que podem mover-se independente uma da outra. o elemento de limpeza do dente é girável em relação a essa parte da cabeça a partir da qual ele se estende. um vibrador vibra a cabeça e o elemento de limpeza do dente.",GILLETTE CO;;GILLETTE CO LLC,JOSEPH SYNODIS;;PHILLIP M BRAUN;;RICHARD H COHEN;;RONALD R DUFF JR;;THOMAS CRAIG MASTERMAN,THE GILLETTE COMPANY LLC (US) (2017-07-18),https://lens.org/033-579-972-422-842,Granted Patent,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A46B13/02;;A46B9/06;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
701,HU,A2,HU P9701778 A2,077-807-320-760-270,1999-01-28,1999,HU P9701778 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,USE OF RALOXIFENE FOR PRODUCING PHARMACEUTICAL COMPOSITIONS FOR PROFILACTING BREAST CANCER,"A találmány tárgya eljárás az (I) képletű ralőxifene vagygyógyszerészetileg elfőgadható sója alkalmazására gyógyszerkészítményelőállítása céljára, a találmány szerint őlyan készítményt állítanakelő, amely körülbelül 30- körülbelül 150 mg/nap közötti ralőxifenevagy gyógyszerészetileg elfőgadható sója dózisát biztősítja, és eztmenőpaűsa űtáni nőknek adagőlják abból a célból, hőgy ezekben a nőkbena mellrák kifejlődését inhibiálják. Az eljárás gyógyszerészetben alkalmazható. ŕ",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/077-807-320-760-270,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
702,PL,A1,PL 322926 A1,072-678-193-415-182,1998-05-11,1998,PL 32292697 A,1997-10-30,US 2985096 P,1996-10-30,"APPLICATION OF THIOPHENE DERIVATIVES IN PRODUCTION OF A PHARMACEUTIC AGENT, METHOD OF OBTAINING A PHARMACEUTIC AGENT AND PHARMACEUTIC AGENT AS SUCH",,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/072-678-193-415-182,Patent Application,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,EXPIRED
703,GB,D0,GB 9911557 D0,082-533-121-147-815,1999-07-21,1999,GB 9911557 A,1999-05-18,GB 9911557 A;;GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/082-533-121-147-815,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
704,US,A1,US 2012/0156634 A1,097-824-397-431-045,2012-06-21,2012,US 97421510 A,2010-12-21,US 97421510 A,2010-12-21,Intraoral Imaging Devices And Methods,"Disclosed is an intraoral imaging method that includes providing an intraoral imaging device having at least one biteplate including a dental impression material and a track, at least one carriage assembly that travels along at least a portion of the track, and imaging equipment which is secured to the at least one carriage assembly; locating the at least one biteplate between upper and lower teeth of the subject such that the dental impression material cooperates with at least one of the upper and lower teeth to provide repeatable registration within an oral cavity of the subject; and obtaining image data using the imaging equipment.",DUFF JR RONALD RICHARD;;CHRISTMAN THOMAS AURELE;;ZSISKA MARIANNE;;COHEN RICHARD H;;VALLON MARK DAVID;;PROCTER & GAMBLE,DUFF JR RONALD RICHARD;;CHRISTMAN THOMAS AURELE;;ZSISKA MARIANNE;;COHEN RICHARD H;;VALLON MARK DAVID,THE PROCTER & GAMBLE COMPANY (2011-02-01),https://lens.org/097-824-397-431-045,Patent Application,yes,0,6,2,2,0,A61B1/0016;;A61B1/00172;;A61B1/24;;A61B1/00089;;A61B1/00172;;A61B1/0016;;A61B1/24,A61B1/24,433/29;;433/215,0,0,,,,DISCONTINUED
705,ES,T3,ES 2197312 T3,114-120-285-218-636,2004-01-01,2004,ES 97308588 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,MEJORAS EN O EN RELACION CON LA PROFILAXIS DEL CANCER DE MAMA POR ADMINISTRACION DE RALOXIFENO.,"PROFILAXIS DEL CANCER DE MAMA EN MUJERES POSMENOPAUSICAS MEDIANTE LA ADMINISTRACION DE RALOXIFENO O UNA SAL ACEPTABLE FARMACOLOGICAMENTE, EN UNA CANTIDAD DE 30 A 150 MG/DIA.",LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/114-120-285-218-636,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
706,MX,A,MX 9708340 A,137-946-592-663-321,1998-08-30,1998,MX 9708340 A,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER.,A method of preventing breast cancer comprising administering to a patient in need thereof an effective amount of a compound having the formula (see formula) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/137-946-592-663-321,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
707,LU,B1,LU 90157 B1,172-054-045-799-954,1998-06-02,1998,LU 90157 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Méthodes de prévention du cancer du sein,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/172-054-045-799-954,Unknown,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
708,AU,A,AU 1997/043647 A,189-189-880-646-930,1998-05-07,1998,AU 1997/043647 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/189-189-880-646-930,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
709,WO,A1,WO 1998/018449 A1,005-917-324-344-704,1998-05-07,1998,US 9719779 W,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having formula (I) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI;;COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/005-917-324-344-704,Patent Application,yes,1,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,1,0,,,"CRISP DATA BASE NATIONAL INSTITUTES OF HEALTH, CRISP-96-PO57 86-01, ANZANO, ""National Chemopreventive Agents in Experimental Mammary Carcinogenesis"", 1995.",PATENTED
710,IT,A1,IT MI972434 A1,018-963-283-384-345,1999-04-29,1999,IT MI972434 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,MIGLIORAMENTI NELLA O RELATIVI ALLA PROFILASSI DEL CANCRO DELLA MAMMELLA IN UNA DONNA IN POST-MENOPAUSA,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/018-963-283-384-345,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
711,US,B2,US 8332982 B2,127-486-606-561-960,2012-12-18,2012,US 54606609 A,2009-08-24,US 54606609 A;;US 83069304 A,2004-04-23,Vibrating toothbrush,"A toothbrush has a head extending from a neck which extends from a handle, and the head has a plurality of tooth cleaning elements extending therefrom. A first group of tooth cleaning elements is located towards a free end of the head, and a second group of tooth cleaning elements is located towards the outside of the head. A third group of tooth cleaning elements, which alternate with the second group of tufts, are oriented at an acute angle to a top surface of the head in a direction that is across the width of the head. A fourth group of tooth cleaning elements is located toward the inside of the head, and each is made of a thermoplastic elastomer and each is in the shape of a curved wall. A fifth group of tooth cleaning elements is located towards the inside of the head.",BRAUN PHILLIP M;;SYNDOSIS JOSEPH;;DUFF JR RONALD R;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG;;GILLETTE CO,BRAUN PHILLIP M;;SYNDOSIS JOSEPH;;DUFF JR RONALD R;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY LLC (2016-09-01),https://lens.org/127-486-606-561-960,Granted Patent,yes,103,34,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,15/22.1;;15/167.1;;15/110,51,0,,,"Computer generated English translation of DE 3628722 A1, Weihrauch, Feb. 1988.;;Board Opinion from the Chinese Patent Office with regard to Application No. 01806615.1 dated Jul. 17, 2007 with translation.;;""Santroprene Rubber Physical Properties Guide, Tensile Properties, Dynamic Mechanical Properties, Tension and Compression Set, Fatigue Resistance"", Advanced Elastomer Systems, pp. 2-19, Undated.;;""Distinctive Plastics-Multi-Component Molding"" http://www.distinctiveplastics.com/html/?id=2 copyright 2006.;;Office Action for U.S. Appl. No. 10/389,448 dated Feb. 25, 2009; Braun et al.; filed Mar. 14, 2003.;;Office Action for U.S. Appl. No. 10/389,448 dated Jun. 2, 2006; Braun et al.; filed Mar. 14, 2003.;;Office Action for U.S. Appl. No. 10/389,448 dated Oct. 26, 2007; Braun et al.; filed Mar. 14, 2003.;;Office Action for U.S. Appl. No. 10/389,448 dated Jul. 2, 2008; Braun et al.; filed Mar. 14, 2003.;;Office Action for U.S. Appl. No. 10/389,448 dated Apr. 4, 2008; Braun et al.; filed Mar. 14, 2003.;;Office Action for U.S. Appl. No. 10/389,448 dated Feb. 22, 2007; Braun et al.; filed Mar. 14, 2003.;;Office Action for U.S. Appl. No. 11/825,387 dated Feb. 19, 2010; Braun et al.; filed Jul. 6, 2007.;;Office Action for U.S. Appl. No. 11/825,387 dated Feb. 11, 2009; Braun et al.; filed Jul. 6, 2007.;;Office Action for U.S. Appl. No. 11/825,387 dated Aug. 29, 2008; Braun et al.; filed Jul. 6, 2007.;;Office Action for U.S. Appl. No. 11/825,387 dated Dec. 6, 2007; Braun et al.; filed Jul. 6, 2007.;;Office Action for U.S. Appl. No. 12/186,639 dated Jun. 22, 2010; Braun et al.; filed Aug. 6, 2008.;;Office Action for U.S. Appl. No. 12/186,639 dated Dec. 23, 2009; Braun et al.; filed Aug. 6, 2008;;Office Action for U.S. Appl. No. 10/830,693 dated Feb. 26, 2009; Masterman et al.; filed Apr. 23, 2004.;;Office Action for U.S. Appl. No. 10/830,693 dated Jul. 2, 2008; Masterman et al.; filed Apr. 23, 2004.;;Office Action for U.S. Appl. No. 10/830,693 dated Mar. 3, 2008; Masterman et al.; filed Apr. 23, 2004.;;Office Action for U.S. Appl. No. 10/830,693 dated Oct. 24, 2007; Masterman et al.; filed Apr. 23, 2004.;;Office Action for U.S. Appl. No. 10/830,693 dated May 15, 2007; Masterman et al.; filed Apr. 23, 2004.;;Office Action for U.S. Appl. No. 10/830,693 dated Aug. 17, 2006; Masterman et al.; filed Apr. 23, 2004.;;Office Action for U.S. Appl. No. 11/799,793 dated Jun. 19, 2009; Braun et al.; filed May 2, 2007.;;Office Action for U.S. Appl. No. 11/799,793 dated Apr. 25, 2008; Braun et al.; filed May 2, 2007.;;Office Action for U.S. Appl. No. 10/820,562 dated Jun. 22, 2010; Braun et al.; Mar. 16, 2000.;;Office Action for U.S. Appl. No. 10/820,562 dated Dec. 2, 2008; Braun et al.; filed Mar. 16, 2000.;;Office Action for U.S. Appl. No. 10/820,562 dated Jul. 27, 2009; Braun et al.; filed Mar. 16, 2000.;;Office Action for U.S. Appl. No. 10/820,562 dated Jul. 5, 2007; Braun et al.; filed Mar. 16, 2000.;;Office Action for U.S. Appl. No. 10/820,562 dated May 8, 2006; Braun et al.; filed Mar. 16, 2000.;;Office Action for U.S. Appl. No. 10/820,562 dated Aug. 15, 2005; Braun et al.; filed Mar. 16, 2000.;;U.S. Appl. No. 10/820,562, filed Mar. 16, 2000, Braun et al.;;U.S. Appl. No. 11/825,387, filed Jul. 6, 2007, Braun et al.;;U.S. Appl. No. 12/186,639, filed Aug. 6, 2008, Braun et al.;;""Plastics-Determination of flexural properties"", British Standard, BS EN ISO 178:2003, Apr. 9, 2003.;;Plastics Extrusion Technology Handbook Chapter Seven, Coextrusion and Dual-Extrusion Technology, pp. 168-189.;;Modern Plastic Encyclopedia, 67:168-175, 1990.;;Pebax 3533 SA 00, ""Base Polymer for Structural Hot Melt Adhesives"".;;Product Literature, Kraton Polymers, pp. 13-21.;;""Standard Test Methods for Flexural Properties of Unreinforced and Reinforced Plastics and Electrical Insulating Materials [Metric]"", American Society for Testing Materials, Designation: D790M-93 Metric, pp. 1-9, Undated.;;""Standard Terminology Relating to Plastics"", American Society for Testing Materials, Designation: D883-00, pp. 1-15, Undated.;;Hendricks et al., ""Rubber-Related Polymers I. Thermoplastic Elastomers"", Rubber Technology, pp. 515-533, Undated.;;European Search Report dated Dec. 1, 2005.;;U.S. Appl. No. 12/828,653, filed Jul. 1, 2010, Braun et al.;;U.S. Appl. No. 12/828,667, filed Jul. 1, 2010, Braun et al.;;All Office Actions, U.S. Appl. No. 09/526,679.;;All Office Actions, U.S. Appl. No. 10/820,562.;;All Office Actions, U.S. Appl. No. 11/825,387.;;All Office Actions, U.S. Appl. No. 12/186,639.;;All Office Actions, U.S. Appl. No. 12/828,653.;;All Office Actions, U.S. Appl. No. 12/828,667.;;All Office Actions, U.S. Appl. No. 13/154,644.",ACTIVE
712,EP,B1,EP 0839532 B1,172-472-970-670-674,2003-05-07,2003,EP 97308588 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer by the administration of raloxifene,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,ELI LILLY AND COMPANY (2007-10-15),https://lens.org/172-472-970-670-674,Granted Patent,yes,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,0,,,"""FIRST PHASE III RESULTS WITH RALOXIFENE"" DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997, page 17 XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"" JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51-57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"" DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996, XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"" JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996, pages 123-125, XP002054376",EXPIRED
713,CA,A1,CA 2737847 A1,009-346-857-330-283,2005-10-23,2005,CA 2737847 A,2004-10-04,US 83069304 A;;CA 2483825 A,2004-04-23,TOOTHBRUSH,,GILLETTE CO,BRAUN PHILIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,,https://lens.org/009-346-857-330-283,Patent Application,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
714,US,A1,US 2015/0001402 A1,029-150-957-460-326,2015-01-01,2015,US 201414485916 A,2014-09-15,US 201414485916 A;;US 201113198804 A,2011-08-05,PET Scanner with Emission and Transmission Structures in a Checkerboard Configuration,"Apparatuses, computer-readable mediums, and methods are provided. In one embodiment, a positron emission tomography (“PET”) detector array is provided which includes a plurality of crystal elements arranged in a two-dimensional checkerboard configuration. In addition, there are empty spaces in the checkerboard configuration. In various embodiments, the empty spaces are filled with passive shielding, transmission source assemblies, biopsy instruments, surgical instruments, and/or electromagnetic sensors. In various embodiments, the crystal elements and the transmission source assemblies simultaneously perform emission/transmission acquisitions.",SIEMENS MEDICAL SOLUTIONS,MICHEL CHRISTIAN J;;CONTI MAURIZIO;;GRAZIOSO RONALD;;COHEN PETER CARL;;CAREY A ANDREW;;BYARS LARRY,SIEMENS MEDICAL SOLUTIONS USA INC (2014-09-04),https://lens.org/029-150-957-460-326,Patent Application,yes,13,2,4,4,0,G01T1/202;;G01T1/1615;;G01T1/202;;G01T1/1615;;A61B6/037;;G01T1/2985,A61B6/03;;G01T1/29,250/362,0,0,,,,ACTIVE
715,FR,B1,FR 2755014 B1,089-767-486-070-992,1999-02-05,1999,FR 9713579 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,AMELIORATIONS CONCERNANT LA PROPHYLAXIE DU CANCER DU SEIN,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/089-767-486-070-992,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
716,AT,T1,AT E239475 T1,142-133-928-814-975,2003-05-15,2003,AT 97308588 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,VERBESSERUNG IN ODER IN BEZUG AUF DER VORBEUGUNG VON BRUSTKREBS DURCH VERABREICHUNG VON RALOXIFEN,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/142-133-928-814-975,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
717,IL,A0,IL 122026 A0,042-879-949-360-007,1998-03-10,1998,IL 12202697 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/042-879-949-360-007,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
718,NL,C2,NL 1007387 C2,045-336-422-986-714,1998-05-14,1998,NL 1007387 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Verbeteringen in of met betrekking tot de profylaxe van borstkanker.,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/045-336-422-986-714,Granted Patent,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
719,US,B2,US 10739120 B2,053-628-585-242-394,2020-08-11,2020,US 201816175020 A,2018-10-30,US 201816175020 A;;US 201762579020 P,2017-10-30,Explosive separating joint,"An explosive separation joint system having an expandable tube containing a mild detonating fuse (MDF) in separable portions of the joint. The MDF extends into a detonation manifold at a first port, an end of the MDF having booster bonded thereto. An external initiating ordnance transfer line enters the manifold at an initiating ordnance (IO) port, has an IO end tip and provides a detonation impulse train where each detonating component is axially aligned within a passageway with the next detonating component. In embodiments, particular detonating components of the detonation train are fixed in place where other detonating components are movable. Each detonating component that is not in direct contact with a preceding detonating component in the detonation train is in direct linear access.",NORTHROP GRUMMAN INNOVATION SYSTEMS INC,COHEN DAVID BRUCE;;DOYLE JOHN THOMAS;;HAYNIE RICHARD MARK;;HARRINGTON PAUL JESSE;;BURNSIDE GARY RONALD,NORTHROP GRUMMAN INNOVATION SYSTEMS INC (2018-11-19);;NORTHROP GRUMMAN SYSTEMS CORPORATION (2021-01-11),https://lens.org/053-628-585-242-394,Granted Patent,yes,21,3,3,3,0,B64G1/641;;B64G1/645;;F42B15/38;;F42B15/38;;F42B3/093;;F42B3/093,F42B15/38;;B64G1/64;;F42B3/093,,0,0,,,,ACTIVE
720,AR,A1,AR 046691 A1,124-405-883-062-733,2005-12-21,2005,AR P040103871 A,2004-10-25,US 83069304 A,2004-04-23,CEPILLO DE DIENTES,Se describe un cepillo de dientes que incluye una cabeza y un elemento limpiador de dientes que se extiende desde una superficie superior de la cabeza. La cabeza es dividida en por lo menos dos porciones que pueden ser movidas independientemente entre sí. El elemento limpiador de dientes es giratorio en relación con aquella porción de la cabeza desde la cual se extiende. Un vibrador hace vibrar la cabeza y el elemento limpiador de dientes.,GILLETTE CO,MASTERMAN THOMAS CRAIG;;COHEN RICHARD H;;DUFF RONALD R JR;;SYNODIS JOSEPH;;BRAUN PHILLIP M,,https://lens.org/124-405-883-062-733,Patent Application,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,DISCONTINUED
721,NO,L,NO 974972 L,134-028-392-687-466,1998-05-04,1998,NO 974972 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,FremgangsmÕte for Õ hindre brystcancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/134-028-392-687-466,Abstract,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
722,EP,A3,EP 1588673 A3,167-150-974-314-607,2006-04-19,2006,EP 04023980 A,2004-10-07,US 83069304 A,2004-04-23,Vibrating toothbrush,"A toothbrush includes a head and a tooth cleaning element extending from a top surface of the head. The head is divided into at least two portions which can be moved independent of each other. The tooth cleaning element is rotatable relative to that portion of the head from which it extends. A vibrator vibrates the head and tooth cleaning element.
",GILLETTE CO,BRAUN PHILLIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY LLC (2016-12-07);;THE GILLETTE COMPANY (2012-06-06),https://lens.org/167-150-974-314-607,Search Report,yes,3,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A61C17/34;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22,,0,0,,,,ACTIVE
723,JP,A,JP H10147529 A,184-327-444-244-266,1998-06-02,1998,JP 29865497 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,PROPHYLAXIS OF BREAST CANCER,"PROBLEM TO BE SOLVED: To obtain a medicine preparation capable of preventing human breast cancer, containing a specific compound as an active ingredient. SOLUTION: A compound (salt or solvate) of the formula as an active ingredient is pharmaceutically manufactured by using an ordinary excipient, diluent or carrier into tablet, elixir or solution corresponding to administration form such as oral administration, intramuscular administration or intravenous administration to give a medicine preparation. Breast cancer of people hardly having danger as well as people having high danger, including male, can be prevented by administering this medicinal preparation in a dose of 0.1-1,000mg/day, preferably 60-120mg/day calculated as the compound of the formula for >=6 months, preferably >=2 years.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/184-327-444-244-266,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
724,GB,D0,GB 9624800 D0,183-375-171-069-924,1997-01-15,1997,GB 9624800 A,1996-11-29,GB 9624800 A,1996-11-29,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/183-375-171-069-924,Patent Application,no,0,0,2,132,0,A61K31/4535;;A61K31/4535,A61K31/4535,,0,0,,,,PENDING
725,GR,A,GR 970100409 A,192-662-840-250-703,1998-06-30,1998,GR 970100409 A,1997-10-29,GB 9624800 A;;US 4026097 P;;US 2985096 P,1996-10-30,IMPROVEMENTS IN OR RELATING TO THE PROPHYLAXIS OF BREAST CANCER,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/192-662-840-250-703,Patent Application,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",DISCONTINUED
726,NO,D0,NO 974972 D0,014-105-161-033-559,1997-10-28,1997,NO 974972 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Fremgangsmåte for å hindre brystcancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/014-105-161-033-559,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
727,AU,A,AU 1997/043648 A,026-110-779-974-491,1998-05-07,1998,AU 1997/043648 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/026-110-779-974-491,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
728,CZ,A3,CZ 341197 A3,033-139-033-649-265,1998-05-13,1998,CZ 341197 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,PREVENTION METHODS OF MASTOCARCINOMA,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/033-139-033-649-265,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
729,CA,C,CA 2483825 C,073-893-404-550-279,2011-05-31,2011,CA 2483825 A,2004-10-04,US 83069304 A,2004-04-23,TOOTHBRUSH,A toothbrush includes a head and a tooth cleaning element extending from a top surface of the head. The head is divided into at least two portions which can be moved independent of each other. The tooth cleaning element is rotatable relative to that portion of the head from which it extends. A vibrator vibrates the head and tooth cleaning element.,GILLETTE CO,BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF RONALD R JR;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,,https://lens.org/073-893-404-550-279,Granted Patent,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A61C17/34;;A46B7/06;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/16;;A61C17/22,,0,0,,,,ACTIVE
730,JP,A,JP 2005305116 A,104-114-398-472-186,2005-11-04,2005,JP 2004309592 A,2004-10-25,US 83069304 A,2004-04-23,TOOTH BRUSH,"<P>PROBLEM TO BE SOLVED: To provide a vibrating tooth brush which is associated with an oral care field in the tooth brush. <P>SOLUTION: The tooth brush is equipped with a head 16 and a tooth cleaning element extended from the upper surface of the head. The head 16 is divided into at least two parts 20 and 22 which are independently movable. The tooth cleaning element is freely rotatable to the head part which the tooth cleaning element is extended from. A vibrator vibrates the head 16 and the tooth cleaning element. <P>COPYRIGHT: (C)2006,JPO&NCIPI",GILLETTE CO,BRAUN PHILLIP M;;JOSEPH SYNODIS;;DUFF RONALD R JR;;COHEN RICHARD H;;THOMAS CRAIG MASTERMAN,,https://lens.org/104-114-398-472-186,Patent Application,no,0,1,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/06;;A46B13/02;;A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,DISCONTINUED
731,DE,D1,DE 69721692 D1,115-275-544-774-809,2003-06-12,2003,DE 69721692 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Verbesserung in oder in Bezug auf der Vorbeugung von Brustkrebs durch Verabreichung von Raloxifen,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/115-275-544-774-809,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
732,PL,A1,PL 322925 A1,164-517-724-443-608,1998-05-11,1998,PL 32292597 A,1997-10-30,US 2985096 P,1996-10-30,"APPLICATION OF THIOPHENE DERIVATIVES IN PRODUCTION OF A PHARMACEUTIC AGENT, METHOD OF OBTAINING A PHARMACEUTIC AGENT AND PHARMACEUTIC AGENT AS SUCH",,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/164-517-724-443-608,Patent Application,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,PENDING
733,US,A1,US 2008/0225000 A1,010-860-705-335-197,2008-09-18,2008,US 68740507 A,2007-03-16,US 68740507 A,2007-03-16,Cancellation of Environmental Motion In Handheld Devices,"A method, system and computer program product for compensating the environmental motion in handheld devices. A sensor unit is affixed to an object in the environment to detect and measure environmental motion. Upon measuring any detected environmental motion, the sensor unit transmits a value corresponding to the measured environmental motion to one or more handheld devices. Alternatively, the sensor unit may transmit the value corresponding to the measured environmental motion to a unit configured to retransmit the value to one or more handheld devices. Upon receiving the value corresponding to the measured environmental motion, the handheld device cancels this environmental motion from the motion it measured thereby taking into consideration only the motion inputted by the user of the handheld device.",BELLWOOD THOMAS ALEXANDER;;COHEN GABRIEL A;;CRAIG RONALD EUGENE;;GRIGSBY TRAVIS M;;MITCHELL GERALD LAVERTE,BELLWOOD THOMAS ALEXANDER;;COHEN GABRIEL A;;CRAIG RONALD EUGENE;;GRIGSBY TRAVIS M;;MITCHELL GERALD LAVERTE,INTERNATIONAL BUSINESS MACHINES CORPORATION (2007-02-12),https://lens.org/010-860-705-335-197,Patent Application,yes,7,35,1,1,0,A63F13/10;;A63F2300/1031;;A63F2300/105;;A63F2300/204;;G06F3/0346;;H04M2250/12;;A63F13/45;;A63F13/92;;A63F13/211;;A63F13/235;;A63F2300/1031;;A63F2300/105;;G06F3/0346;;H04M2250/12;;A63F2300/204,G06F3/033,345/158,0,0,,,,DISCONTINUED
734,BR,B1,BR PI0419322 B1,076-013-262-634-75X,2018-05-29,2018,BR PI0419322 A,2004-10-22,US 83069304 A;;BR PI0404553 A,2004-04-23,escova de dente,uma escova de dente inclui uma cabeça e um elemento de limpeza do dente que se estende a partir de uma superficie superior da cabeça. a cabeça é dividida em pelo menos duas partes que podem mover-se independente uma da outra. o elemento de limpeza do dente é girável em relação a essa parte da cabeça a partir da qual ele se estende. um vibrador vibra a cabeça e o elemento de limpeza do dente.,GILLETTE CO,JOSEPH SYNODIS;;PHILLIP M BRAUN;;RICHARD H COHEN;;RONALD R DUFF JR;;THOMAS CRAIG MASTERMAN,,https://lens.org/076-013-262-634-75X,Granted Patent,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A46B13/02;;A46B9/06;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
735,FR,A1,FR 2756490 A1,068-987-596-217-396,1998-06-05,1998,FR 9713580 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODES DE PREVENTION DU CANCER DU SEIN,"<P>Méthode de prévention du cancer du sein, comprenant l'admission, pendant un terme suffisant, à un sujet humain nécessitant un tel traitement d'une dose efficace d'un composé répondant à la formule:<BR/>(CF DESSIN DANS BOPI)<BR/>ou des sels ou solvates pharmaceutiquement acceptables de celui-ci.</P>",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/068-987-596-217-396,Patent Application,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
736,CN,A,CN 1182590 A,096-845-824-417-878,1998-05-27,1998,CN 97122526 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Method for prevention of mammary gland cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/096-845-824-417-878,Patent Application,no,0,2,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
737,GB,A,GB 2318734 A,100-104-801-009-104,1998-05-06,1998,GB 9722801 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Prevention of breast cancer,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/100-104-801-009-104,Patent Application,no,3,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,A5B BHA           BHA3;;A5B B170          BHA3;;A5B B180          BHA3;;A5B B48Y          BHA3;;A5B B482          BHA3;;A5B B483          BHA3;;A5B B50Y          BHA3;;A5B B503          BHA3;;A5B B54Y          BHA3;;A5B B541          BHA3;;A5B B55Y          BHA3;;A5B B553          BHA3;;A5B B56Y          BHA3;;A5B B566          BHA3;;A5B B57Y          BHA3;;A5B B575          BHA3;;A5B B58Y          BHA3;;A5B B586          BHA3;;A5B B61Y          BHA3;;A5B B616          BHA3;;A5B B65Y          BHA3;;A5B B650          BHA3;;A5B B654          BHA3;;A5B B66Y          BHA3;;A5B B664          BHA3;;A5B B822          BHA3;;A5B B828          BHA3;;A5B B829          BHA3;;U1S S1313,5,5,116-238-224-441-339;;090-621-258-864-815;;039-179-689-155-908;;006-388-692-923-22X;;129-192-318-027-682,10.1093/jnci/88.2.123;;8537973;;8573710;;10.1007/bf00713399;;6431104;;10.1021/jm00374a021;;10.1016/0024-3205(83)90323-5;;6406781;;10.1002/jcb.240590808,CAPLUS Abs. ac. no. 1996:122169 & J. Natl. Cancer Inst. (1996) 88(2) (Anzano) pages 123-5;;BIOSIS Abs. ac. no. 95:496471 & Breast Cancer Research and Treatment (1995) (Jordan) 36(3) 267-285;;CAPLUS Abs. ac. no. 1984:448784 & J. Med. Chem. (1984) 27(8)(Jones) pages 1057-66;;CAPLUS Abs. ac. no. 1983:432846 & Life Science (1983) 32(25)(Clemens) pages 2869-75;;J. Cellular Biochemistry 58/suppl. 22 1995 (Jordan) pages 51-57,EXPIRED
738,IE,A1,IE 970773 A1,136-863-408-945-469,2000-02-09,2000,IE 970773 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,SCOTT TERI JANINE;;NICKELSEN NIKOLAUS THOMAS;;COHEN FREDRIC JAY;;KNICKERBOCKER RONALD KEITH;;GLUSMAN JOAN ELLEN,,https://lens.org/136-863-408-945-469,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
739,TW,B,TW 586942 B,010-677-344-138-028,2004-05-11,2004,TW 86116215 A,1997-10-30,US 4026097 P;;US 2985096 P,1996-10-30,A pharmaceutical composition for use in preventing breast cancer,A pharmaceutical composition for use in preventing breast cancer comprising an effective amount of a compound having the formula and pharmaceutically acceptable salt sand solvates thereof to a human in need for a sufficient term.,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/010-677-344-138-028,Granted Patent,no,0,0,3,132,0,A61K31/4453,A61K9/00;;A61K31/445,,0,0,,,,EXPIRED
740,GR,A,GR 970100408 A,062-390-226-476-809,1998-06-30,1998,GR 970100408 A,1997-10-29,GB 9624800 A;;US 4026097 P;;US 2985096 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/062-390-226-476-809,Patent Application,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
741,EP,A1,EP 0839532 A1,092-551-723-573-266,1998-05-06,1998,EP 97308588 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer by the administration of raloxifene,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,ELI LILLY AND COMPANY (2007-10-15),https://lens.org/092-551-723-573-266,Patent Application,yes,6,1,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
742,HK,A1,HK 1010495 A1,197-699-985-000-802,1999-06-25,1999,HK 98111812 A,1998-11-06,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,IMPROVEMENTS IN OR RELATING TO THE PROPHYLAXIS OF BREAST CANCER BY THE ADMINISTRATION OF RALOXIFENE,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/197-699-985-000-802,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
743,AU,A1,AU 2004/222737 A1,025-734-170-550-436,2005-11-10,2005,AU 2004/222737 A,2004-10-19,US 83069304 A;;AU 2004/222373 A;;AU 2004/222737 A,2004-03-09,Toothbrush,,GILLETTE CO,BRAUN PHILLIP M;;COHEN RICHARD H;;MATERMAN THOMAS CRAIG;;SYNODIS JOSEPH;;DUFF RONALD R JR,,https://lens.org/025-734-170-550-436,Patent Application,no,0,0,2,53,0,A61C17/34,A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
744,ZA,B,ZA 200408173 B,094-661-093-473-059,2005-07-06,2005,ZA 200408173 A,2004-10-08,US 83069304 A,2004-04-23,Toothbrush.,,GILLETTE CO,BRAUN PHILLIP M;;DUFF JR RONALD R;;MASTERMAN THOMAS CRAIG;;SYNODIS JOSEPH;;COHEN RICHARD H,,https://lens.org/094-661-093-473-059,Granted Patent,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
745,US,A1,US 2010/0114831 A1,114-386-811-590-234,2010-05-06,2010,US 26105508 A,2008-10-30,US 26105508 A,2008-10-30,Building a Synchronized Target Database,One embodiment is a method that builds a target database with transaction logs from an online source database. The transaction logs include both existing data in the source database and updates that occur to the source database while the target database is being built.,GILBERT GARY M;;BROEDER SEAN L;;COHEN RONALD P;;FISHLER LEONARD R;;SMITH GAY S,GILBERT GARY M;;BROEDER SEAN L;;COHEN RONALD P;;FISHLER LEONARD R;;SMITH GAY S,HEWLETT PACKARD ENTERPRISE DEVELOPMENT LP (2015-10-27);;HEWLETT-PACKARD DEVELOPMENT COMPANY L.P (2008-10-29),https://lens.org/114-386-811-590-234,Patent Application,yes,14,126,2,2,0,G06F16/27;;G06F16/27,G06F17/30,707/648;;X707E17005;;X707E17044,0,0,,,,ACTIVE
746,CA,A1,CA 2219377 A1,183-252-581-559-846,1998-04-30,1998,CA 2219377 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,IMPROVEMENTS IN OR RELATING TO THE PROPHYLAXIS OF BREAST CANCER,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/183-252-581-559-846,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
747,AU,B2,AU 2010/202925 B2,023-727-906-863-42X,2012-11-29,2012,AU 2010/202925 A,2010-07-09,AU 2007/205787 A;;AU 2010/202925 A,2007-08-14,Toothbrush,"A toothbrush comprising a head (16) and a first (28), second (30), third (34), fourth (36) and fifth (38) group of cleaning elements. The head (16) extends from a neck (14) which extends from a handle. The head (16) has a plurality of tooth cleaning elements extending therefrom. The first (28) group of tooth cleaning elements are located 5 towards a free end of the head (16). The second (30) group of tooth cleaning elements are located towards the outside of the head (16). The third (34) group of tooth cleaning elements alternate with the second (30) group of tufts. The third (34) group of tooth cleaning elements are oriented at an acute angle to a top surface of the head (16) in a direction that is across the width of the head (16). The fourth (36) group of tooth cleaning 10 elements are fixed toward the inside of the head (16), wherein each of the fourth (36) group of tooth cleaning elements is made of a thermoplastic elastomer. Each of the fourth (36) group of tooth cleaning elements is in the shape of a curved wall. Each of the fourth (36) group of tooth cleaning elements having an anchor (50) disposed in the head (16). The anchor (50) has a first portion (58) and a second portion (60). The first portion (58) is being smaller in an X and Y dimension than the second portion (60). The fifth (38) group of tooth cleaning elements are located towards the inside of the head (16).",GILLETTE CO LLC,BRAUN PHILLIP M;;COHEN RICHARD H;;DUFF JR RONALD R;;MATERMAN THOMAS CRAIG;;SYNODIS JOSEPH,,https://lens.org/023-727-906-863-42X,Granted Patent,no,2,0,2,53,0,A46B5/0025;;A46B7/06;;A46B9/04;;A46B9/06;;A46B9/12;;A46B2200/1066;;A46D1/00;;A61C17/3481,A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
748,AU,A,AU 1997/050051 A,055-356-845-988-43X,1998-05-22,1998,AU 1997/050051 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719726 W,1996-10-30,Prophylaxis of breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/055-356-845-988-43X,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
749,LU,B1,LU 90158 B1,091-467-431-205-682,1998-06-02,1998,LU 90158 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Améliorations concernant la prophylaxie du cancer du sein,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/091-467-431-205-682,Unknown,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
750,TW,B,TW 419373 B,099-401-122-715-661,2001-01-21,2001,TW 86116198 A,1997-10-30,US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/099-401-122-715-661,Granted Patent,no,0,0,3,132,0,A61K31/4453,A61K9/00;;A61K31/445,,0,0,,,,EXPIRED
751,EP,A2,EP 2213260 A2,102-035-809-108-824,2010-08-04,2010,EP 10005202 A,2004-10-07,EP 04023980 A;;US 83069304 A,2004-04-23,Vibrating toothbrush,"A toothbrush, comprising: 
a head extending from a neck which extends from a handle, the head having a plurality of tooth cleaning elements extending therefrom; 
a first group of tooth cleaning elements located towards a free end of the head; 
a second group of tooth cleaning elements located towards the outside of the head; 
a third group of tooth cleaning elements which alternate with the second group of tufts, wherein the third group of tooth cleaning elements are oriented at an acute angle to a top surface of the head in a direction that is across the width of the head; 
 
characterized in that the toothbrush further comprises a fourth group of tooth cleaning elements fixed toward the inside of the head, wherein each of the fourth group of tooth cleaning elements is made of a thermoplastic elastomer, wherein each of the fourth group of tooth cleaning elements is in the shape of a curved wall, each of the fourth group of tooth cleaning elements having an anchor disposed in the head, wherein the anchor has a first portion and a second portion, the first portion being smaller in an X and Y dimension than the second portion; and 
a fifth group of tooth cleaning elements located towards the inside of the head.
",GILLETTE CO,BRAUN PHILLIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY (2012-06-06),https://lens.org/102-035-809-108-824,Patent Application,yes,9,3,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/04;;A46B9/06;;A61C17/34;;A46B13/02;;A46D1/00;;A61C17/22,,0,0,,,,ACTIVE
752,EP,A3,EP 2213260 A3,012-768-429-456-021,2012-05-30,2012,EP 10005202 A,2004-10-07,EP 04023980 A;;US 83069304 A,2004-04-23,Vibrating toothbrush,"A toothbrush, comprising: 
a head extending from a neck which extends from a handle, the head having a plurality of tooth cleaning elements extending therefrom; 
a first group of tooth cleaning elements located towards a free end of the head; 
a second group of tooth cleaning elements located towards the outside of the head; 
a third group of tooth cleaning elements which alternate with the second group of tufts, wherein the third group of tooth cleaning elements are oriented at an acute angle to a top surface of the head in a direction that is across the width of the head; 
 
characterized in that the toothbrush further comprises a fourth group of tooth cleaning elements fixed toward the inside of the head, wherein each of the fourth group of tooth cleaning elements is made of a thermoplastic elastomer, wherein each of the fourth group of tooth cleaning elements is in the shape of a curved wall, each of the fourth group of tooth cleaning elements having an anchor disposed in the head, wherein the anchor has a first portion and a second portion, the first portion being smaller in an X and Y dimension than the second portion; and 
a fifth group of tooth cleaning elements located towards the inside of the head.
",GILLETTE CO,BRAUN PHILLIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY (2012-06-06),https://lens.org/012-768-429-456-021,Search Report,yes,9,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A61C17/34;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22,,0,0,,,,ACTIVE
753,HU,D0,HU 9701777 D0,023-099-584-547-947,1997-12-29,1997,HU P9701777 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/023-099-584-547-947,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
754,NO,D0,NO 974973 D0,043-856-168-223-290,1997-10-28,1997,NO 974973 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Forbedringer vedrörende profylakse av brystcancer,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/043-856-168-223-290,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
755,CN,B,CN 101112332 B,049-748-315-260-383,2013-04-10,2013,CN 200710146833 A,2004-10-25,US 83069304 A,2004-04-23,Toothbrush,,GILLETTE CO,BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF RONALD R JR;;COHEN RICHARD H;;MATERMAN THOMAS CRAIG,,https://lens.org/049-748-315-260-383,Granted Patent,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A61C17/34;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22,,0,0,,,,ACTIVE
756,US,B2,US 10222490 B2,070-896-035-583-562,2019-03-05,2019,US 201414485916 A,2014-09-15,US 201414485916 A;;US 201113198804 A,2011-08-05,PET scanner with emission and transmission structures in a checkerboard configuration,"Apparatuses, computer-readable mediums, and methods are provided. In one embodiment, a positron emission tomography (“PET”) detector array is provided which includes a plurality of crystal elements arranged in a two-dimensional checkerboard configuration. In addition, there are empty spaces in the checkerboard configuration. In various embodiments, the empty spaces are filled with passive shielding, transmission source assemblies, biopsy instruments, surgical instruments, and/or electromagnetic sensors. In various embodiments, the crystal elements and the transmission source assemblies simultaneously perform emission/transmission acquisitions.",SIEMENS MEDICAL SOLUTIONS USA INC,MICHEL CHRISTIAN J;;CONTI MAURIZIO;;GRAZIOSO RONALD;;COHEN PETER CARL;;CAREY A ANDREW;;BYARS LARRY,SIEMENS MEDICAL SOLUTIONS USA INC (2014-09-04),https://lens.org/070-896-035-583-562,Granted Patent,yes,25,0,4,4,0,G01T1/202;;G01T1/1615;;G01T1/202;;G01T1/1615;;A61B6/037;;G01T1/2985,A61B6/03;;G01T1/161;;G01T1/202;;G01T1/29,,5,3,032-946-469-768-016;;085-424-389-861-75X;;028-485-522-908-134,10.1109/nssmic.1991.259196;;8326401;;10.1109/23.856566;;10416801;;10.1109/42.774167,"David W. Townsend, et al., A Rotating Pet Scanner Using BGO Block Detectors: Design, Performance and Applications, 34 J Nucl Med 1367-1376 (1993).;;C J Thompson, et al., Feasibility of Using Beta-Gamma Coincidence for 3D PET Attenuation Correction, 47 IEEE Transactions on Nuclear Science, 1176-1181 (2002).;;Marie-Laure Camborde, et al., Use of Beta-Gamma Coincidence Detection to Improve the Quality of Transmission Scans for PET, Medical Physics Unit, McGill University, Montreal (Sep. 2001).;;Johan Nuyts et al., Simultaneous Maximum A—Posteriori Reconstruction of Attenuation and Activity Distributions from Emission Sinograms, 18 IEEE Trans Med Imaging, 393-403 (1999).;;C.C. Watson, et al., Design and Performance of a Single Photon Transmission Measurement for the ECAT ART, 48 IEEE Trans. NucL Sci., 673-679 (1998).",ACTIVE
757,DE,T2,DE 69725878 T2,091-998-649-391-951,2004-07-29,2004,DE 69725878 T,1997-08-13,US 2386796 P;;US 9714465 W,1996-08-13,ZUSAMMENSETZUNGEN ZUR POLYNUKLEOTIDABGABE,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS A;;MURPHY E;;COHEN FRED;;UNO TETSUO,"NOVARTIS VACCINES AND DIAGNOSTICS,INC.(N.D.GES, US (2009-05-07)",https://lens.org/091-998-649-391-951,Granted Patent,no,0,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,EXPIRED
758,EP,B1,EP 1588673 B1,114-045-753-906-513,2018-09-05,2018,EP 04023980 A,2004-10-07,US 83069304 A,2004-04-23,Vibrating toothbrush,,GILLETTE CO LLC,BRAUN PHILLIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY LLC (2016-12-07);;THE GILLETTE COMPANY (2012-06-06),https://lens.org/114-045-753-906-513,Granted Patent,yes,3,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A61C17/34;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22,,0,0,,,,ACTIVE
759,CA,A1,CA 2483825 A1,124-267-047-722-000,2005-10-23,2005,CA 2483825 A,2004-10-04,US 83069304 A,2004-04-23,TOOTHBRUSH,,GILLETTE CO,MASTERMAN THOMAS CRAIG;;BRAUN PHILLIP M;;DUFF RONALD R JR;;COHEN RICHARD H;;SYNODIS JOSEPH,,https://lens.org/124-267-047-722-000,Patent Application,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B7/06;;A46B9/06;;A46B13/02;;A46B9/04;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
760,ES,A1,ES 2135343 A1,126-530-501-043-621,1999-10-16,1999,ES 9702225 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer by the administration of raloxifene,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/126-530-501-043-621,Patent Application,no,2,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,2,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"JORDAN et al. Alternate antiestrogens and approaches to the prevention of breast cancer, Journal of Biochemistry, Vol. 58, no 522, 51-57 (1995), resumen; paginas 54,55; figura 3.;;M.A. ANZANO et al. Chemoprevention of Mammary carcinogenesis in the rat: combined use of raloxifene and 9-cis-retinoic acid, Journal of the National Cancer Institute, Vol. 88, no 2, Enero 1996, paginas 123-125.",DISCONTINUED
761,US,A1,US 2010/0162499 A1,154-228-054-943-297,2010-07-01,2010,US 54606609 A,2009-08-24,US 54606609 A;;US 83069304 A,2004-04-23,Vibrating Toothbrush,"A toothbrush has a head extending from a neck which extends from a handle, and the head has a plurality of tooth cleaning elements extending therefrom. A first group of tooth cleaning elements is located towards a free end of the head, and a second group of tooth cleaning elements is located towards the outside of the head. A third group of tooth cleaning elements, which alternate with the second group of tufts, are oriented at an acute angle to a top surface of the head in a direction that is across the width of the head. A fourth group of tooth cleaning elements is located toward the inside of the head, and each is made of a thermoplastic elastomer and each is in the shape of a curved wall. A fifth group of tooth cleaning elements is located towards the inside of the head.",BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF JR RONALD R;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,BRAUN PHILLIP M;;SYNODIS JOSEPH;;DUFF JR RONALD R;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY LLC (2016-09-01),https://lens.org/154-228-054-943-297,Patent Application,yes,99,9,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A46B13/00;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,15/22.1;;15/167.1,0,0,,,,ACTIVE
762,EP,B1,EP 2213260 B1,177-243-909-734-803,2019-05-15,2019,EP 10005202 A,2004-10-07,EP 04023980 A;;US 83069304 A,2004-04-23,Vibrating toothbrush,,GILLETTE CO,BRAUN PHILLIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG,THE GILLETTE COMPANY (2012-06-06),https://lens.org/177-243-909-734-803,Granted Patent,yes,9,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A61C17/34;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22,,0,0,,,,ACTIVE
763,ES,T3,ES 2292758 T3,168-473-767-015-332,2008-03-16,2008,ES 02731094 T,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARILETIL) BENCILAMINAS COMO ANTAGONISTAS DEL RECEPTOR 5-HT6.,"Un compuesto de fórmula Formula 1 en la cual X se selecciona entre el grupo que consiste en -O-, -NH-, -S-, -SO2-, -CH2-, -CH(F)-, -CH(OH) y -C(O)-; R1 se selecciona entre el grupo que consiste en fenilo opcionalmente sustituido, naftilo opcionalmente sustituido un heterociclo aromático monocíclico de 5 a 6 miembros opcionalmente sustituido que tiene un heteroátomo seleccionado entre el grupo que consiste en nitrógeno, oxígeno y azufre, de forma que el heterociclo aromático monocíclico de 5 a 6 miembros está opcionalmente benzocondensado. R2 se selecciona entre el grupo que consiste en hidrógeno y alquilo C1-C3; R3 se selecciona entre el grupo que consiste en hidrógeno, flúor y metilo; R4 se selecciona entre el grupo que consiste en hidrógeno, alilo, alquilo C2-C4, alquilo C2-C4 fluorado, fenilo opcionalmente sustituido, fenilsulfonilo opcionalmente sustituido, bencilo opcionalmente sustituido y un heterociclo aromático monocíclico de 5 a 6 miembros opcionalmente sustituido que tiene uno o dos heteroátomos seleccionados entre el grupo que consiste en nitrógeno, oxígeno y azufre, con la condición de que R4 no es fenilsulfonilo opcionalmente sustituido cuando X es -SO2-, -CH2-, -CH(F)-, -CH(OH)- o -C(O)-; y sus sales farmacéuticamente aceptables, distintas de 3-etoxibencil-[2-(4-etoxifenil)etil]amina, 3-etoxibencil-[2-(3-etoxifenil)etil]amina, 3-etoxibencil-[2-(2-etoxifenil)etil]amina y N-[2-(3, 4-dimetoxifenil)etil]-3-fenoxibencilamina.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY,,https://lens.org/168-473-767-015-332,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
764,EP,B1,EP 0941122 B1,108-732-663-613-300,2003-10-29,2003,EP 97938367 A,1997-08-13,US 9714465 W;;US 2386796 P,1996-08-13,COMPOSITIONS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;UNO TETSUO,"NOVARTIS VACCINES & DIAGNOSTICS, INC. (2008-02-29)",https://lens.org/108-732-663-613-300,Granted Patent,yes,1,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,EXPIRED
765,EP,A2,EP 4089426 A2,166-324-984-519-586,2022-11-16,2022,EP 22171468 A,2022-05-03,US 202117321020 A,2021-05-14,SYSTEMS AND METHODS FOR PHASE-VOLTAGE BASED MOTOR PERIOD MEASUREMENT AND CONTROLLED SIGNAL PATH FAULT DETECTION,"A method for phase-voltage based motor period measurement includes generating a commanded phase voltage and applying the commanded phase voltage to a first phase voltage input of an electric motor, a second phase voltage input of the electric motor, and a third phase voltage input of the electric motor. The method also includes measuring a first period of a phase voltage associated with the first phase voltage input and the second phase voltage input and comparing the first period of the phase voltage associated with the first phase voltage input and the second phase voltage input to a frequency of the commanded phase voltage. The method also includes, in response to a determination that the first period of the phase voltage associated with the first phase voltage input and the second phase voltage input is outside of a range of the frequency associated with the commanded phase voltage, identifying a fault associated with the first integrated circuit or signal path.
 
",DELPHI TECH IP LTD,BUKSH RAQUIB;;GERTISER KEVIN M;;NAHLUS IHAB;;NACHNANI TUSHAR;;SHEARER RONALD M;;COHEN MITCHELL;;BARRE SPANDANA V,,https://lens.org/166-324-984-519-586,Patent Application,yes,0,0,6,6,0,G01R31/343;;G01R31/343;;G01R31/42;;G01R23/02;;G01R23/005;;G01R31/343;;G01R19/252;;G01R23/005;;G01R25/005;;G01R31/52;;B60R16/023;;B60L3/0061;;H02P21/32;;H02P6/185;;H02P6/186;;H02P2203/03,G01R31/34,,0,0,,,,PENDING
766,WO,A3,WO 1998/006437 A3,047-712-280-464-679,1998-02-19,1998,US US9714465,1997-08-13,"US 60/0/023,867",1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates to compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORPORATION,"ZUKERMANN, Ronald;;DUBOIS-STRINGFELLOW, Nathalie;;DWARKI, Varavani;;INNIS, Michael, A.;;MURPHY, John, E.;;COHEN, Fred;;TETSUO, Uno",,https://lens.org/047-712-280-464-679,Search Report,yes,0,0,1,1,0,,A61K47/48;;A61K48/00;;C12N15/87,,0,0,,,,UNKNOWN
767,CA,C,CA 2264012 C,053-706-518-195-525,2011-04-26,2011,CA 2264012 A,1997-08-13,US 2386796 P;;US 9714465 W,1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates to compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUCKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;UNO TETSUO,,https://lens.org/053-706-518-195-525,Granted Patent,no,0,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,C12N15/87;;A61K31/70;;A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/16;;A61K47/30;;A61K47/34;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00,,0,0,,,,EXPIRED
768,EP,A3,EP 4089426 A3,109-496-447-428-690,2022-11-23,2022,EP 22171468 A,2022-05-03,US 202117321020 A,2021-05-14,SYSTEMS AND METHODS FOR PHASE-VOLTAGE BASED MOTOR PERIOD MEASUREMENT AND CONTROLLED SIGNAL PATH FAULT DETECTION,"A method for phase-voltage based motor period measurement includes generating a commanded phase voltage and applying the commanded phase voltage to a first phase voltage input of an electric motor, a second phase voltage input of the electric motor, and a third phase voltage input of the electric motor. The method also includes measuring a first period of a phase voltage associated with the first phase voltage input and the second phase voltage input and comparing the first period of the phase voltage associated with the first phase voltage input and the second phase voltage input to a frequency of the commanded phase voltage. The method also includes, in response to a determination that the first period of the phase voltage associated with the first phase voltage input and the second phase voltage input is outside of a range of the frequency associated with the commanded phase voltage, identifying a fault associated with the first integrated circuit or signal path.
 
",DELPHI TECH IP LTD,BUKSH RAQUIB;;GERTISER KEVIN M;;NAHLUS IHAB;;NACHNANI TUSHAR;;SHEARER RONALD M;;COHEN MITCHELL;;BARRE SPANDANA V,,https://lens.org/109-496-447-428-690,Search Report,yes,2,0,6,6,0,G01R31/343;;G01R31/343;;G01R31/42;;G01R23/02;;G01R23/005;;G01R31/343;;G01R19/252;;G01R23/005;;G01R25/005;;G01R31/52;;B60R16/023;;B60L3/0061;;H02P21/32;;H02P6/185;;H02P6/186;;H02P2203/03,G01R31/34;;G01R23/00;;G01R23/02;;G01R31/42,,1,1,032-985-854-930-19X,10.1109/icassda.2018.8477626,"RASYADAN AMIR ET AL: ""Modeling of Time Domain Analysis for Single and Double Open-Circuit Inverter Switch Faults in Three-Phase Induction Motor Drives"", 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL APPROACH IN SMART SYSTEMS DESIGN AND APPLICATIONS (ICASSDA), IEEE, 15 August 2018 (2018-08-15), pages 1 - 7, XP033410804, DOI: 10.1109/ICASSDA.2018.8477626",PENDING
769,AT,T1,AT E252914 T1,198-333-661-522-989,2003-11-15,2003,AT 97938367 T,1997-08-13,US 2386796 P;;US 9714465 W,1996-08-13,ZUSAMMENSETZUNGEN ZUR POLYNUKLEOTIDABGABE,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;UNO TETSUO,,https://lens.org/198-333-661-522-989,Granted Patent,no,0,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,DISCONTINUED
770,EP,A2,EP 0941122 A2,030-533-627-550-576,1999-09-15,1999,EP 97938367 A,1997-08-13,US 9714465 W;;US 2386796 P,1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;TETSUO UNO,"NOVARTIS VACCINES & DIAGNOSTICS, INC. (2008-02-29)",https://lens.org/030-533-627-550-576,Patent Application,yes,0,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,EXPIRED
771,KR,A,KR 20220155228 A,152-236-428-489-912,2022-11-22,2022,KR 20220058912 A,2022-05-13,US 202117321020 A,2021-05-14,- SYSTEMS AND METHODS FOR PHASE-VOLTAGE BASED MOTOR PERIOD MEASUREMENT AND CONTROLLED SIGNAL PATH FAULT DETECTION,"A method for measuring a phase-voltage based motor period comprises: a step of generating commanded phase voltage; and a step of applying the commanded phase voltage to a first phase voltage input of an electric motor, a second phase voltage input of the electric motor, and a third phase voltage input of the electric motor. In addition, the method comprises: a step of measuring a first period of phase voltage related to the first phase voltage input and the second phase voltage input; and a step of comparing the first period of the phase voltage related to the first phase voltage input and the second phase voltage input with a frequency related to the commend phase voltage. In addition, the method comprises a step of identifying a fault related to a first integrated circuit or a signal path in response to decision of allowing the first period of the phase voltage related to the first phase voltage input and the second phase voltage input to be outside a range of the frequency related to the commended phase voltage.",DELPHI TECH IP LTD,BUKSH RAQUIB;;GERTISER KEVIN M;;NAHLUS IHAB;;NACHNANI TUSHAR;;SHEARER RONALD M;;COHEN MITCHELL;;BARRE SPANDANA V,,https://lens.org/152-236-428-489-912,Patent Application,no,0,0,6,6,0,G01R31/343;;G01R31/343;;G01R31/42;;G01R23/02;;G01R23/005;;G01R31/343;;G01R19/252;;G01R23/005;;G01R25/005;;G01R31/52;;B60R16/023;;B60L3/0061;;H02P21/32;;H02P6/185;;H02P6/186;;H02P2203/03,G01R31/34;;B60L3/00;;B60R16/023;;G01R19/252;;G01R23/00;;G01R25/00;;G01R31/52,,0,0,,,,PENDING
772,US,A1,US 2009/0027334 A1,102-646-736-525-24X,2009-01-29,2009,US 13137508 A,2008-06-02,US 13137508 A;;US 94148507 P,2007-06-01,METHOD FOR CONTROLLING A GRAPHICAL USER INTERFACE FOR TOUCHSCREEN-ENABLED COMPUTER SYSTEMS,"A method for controlling a graphical user interface (GUI) for a touchscreen-enabled computer systems provides a variety of software methods (tools) provide for high-fidelity control of the user interface. The TrackScreen tool provides finger-friendly mouse functions such as scrolling, dragging and clicking. The Magnifier application continuously captures the current screen image, and displays a magnified subset of it. Selecting within this magnified area with a pointing device (mouse, touchscreen, digitizer, etc) causes the application to simulate the action on the portion of the screen corresponding to the point in the magnified image that was selected. A KeyBoard application, a keyboard is rendered on screen, with sufficient size that the individual keys are easily selectable with an unaided finger. The Common Tasks Tool or CTT) allows common keyboard shortcuts, mouse events, and other user interface events to be specified in a configuration file and represented on screen as a large, easy-to-click button. The Touchscreen Task Switcher is invoked using any interface (software or hardware) element, and visually takes up the entire screen. The Touchscreen Snapshot utility ties in with an external camera with a physical button on it. The Window Template Manager (WTM), is used to specify, and then instantiate, the position and sizes of multiple windows for use with a touchscreen display. The Touch Portal is a full-screen application with a set of customizable buttons representing applications and other tools.",CYBERNET SYSTEMS CORP,FOULK EUGENE;;HAY RONALD;;SCOTT KATHERINE;;SQUIERS MERRILL D;;TESAR JOSEPH;;COHEN CHARLES J;;JACOBUS CHARLES J,CYBERNET SYSTEMS CORPORATION (2008-08-22);;NORTHERN LIGHTS SERIES 74 OF ALLIED SECURITY TRUST I (2017-05-05);;JOLLY SEVEN SERIES 70 OF ALLIED SECURITY TRUST I (2019-06-06),https://lens.org/102-646-736-525-24X,Patent Application,yes,21,110,1,1,0,G06F3/04886;;G06F3/04886;;G06F3/0488;;G06F3/0488,G06F3/033;;G06F3/041,345/157;;345/173,0,0,,,,DISCONTINUED
773,JP,A,JP 2006257088 A,052-015-315-881-518,2006-09-28,2006,JP 2006086765 A,2006-03-27,US 2386796 P,1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"<P>PROBLEM TO BE SOLVED: To provide compositions and methods for increasing the uptake of polynucleotides into cells. <P>SOLUTION: A compound represented by the formula and exhibiting a clear positive charge at physiological pH, wherein Ta and Tc are each a terminal group. The compound is capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides. <P>COPYRIGHT: (C)2006,JPO&NCIPI",CHIRON CORP,ZUCKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;UNO TETSUO,,https://lens.org/052-015-315-881-518,Patent Application,no,0,1,17,17,4,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K47/48;;A61K9/127;;A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/09;;C12N15/87,,0,0,,,,DISCONTINUED
774,WO,A3,WO 1998/006437 A3,094-149-449-402-970,1998-08-27,1998,US 9714465 W,1997-08-13,US 2386796 P,1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates to compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;TETSUO UNO,,https://lens.org/094-149-449-402-970,Search Report,yes,5,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,5,4,016-265-122-983-119;;175-833-149-417-043;;118-843-647-887-744;;035-886-556-173-632,7873664;;10.1021/bc00030a017;;10.1016/0168-3659(96)01537-4;;10.1016/0960-894x(95)00187-x;;9001404;;10.1016/s0014-5793(96)01397-x,"MERWIN J R ET AL: ""TARGETED DELIVERY OF DNA USING YEE(GALNACAH)3, A SYNTHETIC GLYCOPEPTIDE LIGAND FOR THE ASIALOGLYCOPROTEIN RECEPTOR"", BIOCONJUGATE CHEMISTRY, vol. 5, no. 6, 1 November 1994 (1994-11-01), pages 612 - 620, XP000484176;;TOMLINSON E ET AL: ""Controllable gene therapy Pharmaceutics of non-viral gene delivery systems"", JOURNAL OF CONTROLLED RELEASE, vol. 39, no. 2, May 1996 (1996-05-01), pages 357-372, XP004037341;;RICHTER L S ET AL: ""SYNTHESIS OF PEPTIDE NUCLEIC ACIDS (PNA) BY SUBMONOMER SOLID-PHASE SYNTHESIS"", BIOORGANIC & MEDICINAL CHEMISTRY LETTERS, vol. 5, no. 11, 1 January 1995 (1995-01-01), pages 1159 - 1162, XP000566512;;BEHR J. P.: ""The proton sponge: a trick to enter cells the viruses did not exploit"", CHIMIA, vol. 51, no. 1/2, 1997, pages 34 - 36, XP002067584;;HONG K. ET AL: ""Stabilization of cationic liposome-plasmid DNA complexes by polyamines and poly (ethylene glycol)-phospholipid conjugates for efficient in vivo gen delivery"", FEBS LETTERS, vol. 400, 1997, pages 233 - 237, XP002067585",PATENTED
775,US,A1,US 2022/0368253 A1,117-118-871-649-072,2022-11-17,2022,US 202117321020 A,2021-05-14,US 202117321020 A,2021-05-14,SYSTEMS AND METHODS FOR PHASE-VOLTAGE BASED MOTOR PERIOD MEASUREMENT AND CONTROLLED SIGNAL PATH FAULT DETECTION,"A method for phase-voltage based motor period measurement includes generating a commanded phase voltage and applying the commanded phase voltage to a first phase voltage input of an electric motor, a second phase voltage input of the electric motor, and a third phase voltage input of the electric motor, measuring a first period of a phase voltage associated with the first phase voltage input and the second phase voltage input and comparing the measured first period to a frequency of the commanded phase voltage, and, in response to a determination that the measured first period of the phase voltage associated with the first phase voltage input and the second phase voltage input is outside of a range of the frequency associated with the commanded phase voltage, identifying a fault associated with the first integrated circuit or signal path.",DELPHI TECH IP LTD,BUKSH RAQUIB;;GERTISER KEVIN M;;NAHLUS IHAB;;NACHNANI TUSHAR;;SHEARER RONALD M;;COHEN MITCHELL;;BARRE SPANDANA V,,https://lens.org/117-118-871-649-072,Patent Application,yes,1,0,6,6,0,G01R31/343;;G01R31/343;;G01R31/42;;G01R23/02;;G01R23/005;;G01R31/343;;G01R19/252;;G01R23/005;;G01R25/005;;G01R31/52;;B60R16/023;;B60L3/0061;;H02P21/32;;H02P6/185;;H02P6/186;;H02P2203/03,H02P6/18;;H02P6/185;;H02P21/32,,0,0,,,,ACTIVE
776,US,B2,US 11557992 B2,054-422-932-082-763,2023-01-17,2023,US 202117321020 A,2021-05-14,US 202117321020 A,2021-05-14,Systems and methods for phase-voltage based motor period measurement and controlled signal path fault detection,"A method for phase-voltage based motor period measurement includes generating a commanded phase voltage and applying the commanded phase voltage to a first phase voltage input of an electric motor, a second phase voltage input of the electric motor, and a third phase voltage input of the electric motor, measuring a first period of a phase voltage associated with the first phase voltage input and the second phase voltage input and comparing the measured first period to a frequency of the commanded phase voltage, and, in response to a determination that the measured first period of the phase voltage associated with the first phase voltage input and the second phase voltage input is outside of a range of the frequency associated with the commanded phase voltage, identifying a fault associated with the first integrated circuit or signal path.",DELPHI TECH IP LTD,BUKSH RAQUIB;;GERTISER KEVIN M;;NAHLUS IHAB;;NACHNANI TUSHAR;;SHEARER RONALD M;;COHEN MITCHELL;;BARRE SPANDANA V,DELPHI TECHNOLOGIES IP LIMITED (2021-05-14),https://lens.org/054-422-932-082-763,Granted Patent,yes,4,0,6,6,0,G01R31/343;;G01R31/343;;G01R31/42;;G01R23/02;;G01R23/005;;G01R31/343;;G01R19/252;;G01R23/005;;G01R25/005;;G01R31/52;;B60R16/023;;B60L3/0061;;H02P21/32;;H02P6/185;;H02P6/186;;H02P2203/03,H02P6/18;;H02P6/185;;H02P21/32,,3,1,032-985-854-930-19X,10.1109/icassda.2018.8477626,"Freescale Semiconductor, 3-Phase BLDC Motor Control with Sensorless Back EMF Zero Crossing Detection Using 56F80x, Nov. 2005, Chandler, Arizona, USA.;;Rasyadan Amir et al: “Modeling of Time Domain Analysis for Single and Double Open-Circuit Inverter Switch Faults in Three-Phase Induction Motor Drives”, 2018 International Conference on Computational Approach in Smart Systems Design and Applications (ICASSDA), Aug. 15, 2018, pp. 1-7.;;Extended European Search Report in EP Application No. 22171468.6 dated Oct. 25, 2022 (5 pages).",ACTIVE
777,WO,A2,WO 1998/006437 A2,038-696-790-212-769,1998-02-19,1998,US 9714465 W,1997-08-13,US 2386796 P,1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates to compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUKERMANN RONALD;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED;;TETSUO UNO,,https://lens.org/038-696-790-212-769,Patent Application,no,0,50,17,17,4,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,PATENTED
778,CA,A1,CA 2264012 A1,005-312-587-325-714,1998-02-19,1998,CA 2264012 A,1997-08-13,US 2386796 P;;US 9714465 W,1996-08-13,COMPOSITIONS AND METHODS FOR POLYNUCLEOTIDE DELIVERY,"This invention relates to compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUCKERMANN RONALD;;MURPHY JOHN E;;COHEN FRED;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;UNO TETSUO,,https://lens.org/005-312-587-325-714,Patent Application,no,0,0,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,,0,0,,,,EXPIRED
779,SG,A1,SG 83672 A1,038-332-781-935-60X,2001-10-16,2001,SG 1997003900 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,,LILLY CO ELI,FREDRIC JAY COHEN;;JOAN ELLEN GLUSMAN;;RONALD KEITH KNICKERBOCKER;;NIKOLAUS THOMAS NICKELSEN;;TERI JANINE SCOTT;;ROBERT STEPHEN ECKERT,,https://lens.org/038-332-781-935-60X,Patent Application,no,4,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
780,MX,A,MX 9708341 A,080-388-285-849-281,1998-08-30,1998,MX 9708341 A,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER.,A method of preventing breast cancer comprising administering to a patient in need thereof an effective amount of a compound having the formula (see formula) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/080-388-285-849-281,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
781,EE,B1,EE 03663 B1,083-290-237-753-211,2002-04-15,2002,EE 9900162 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,"Rinnavähi vältimise meetod, farmatseutiline preparaat ja toode ning toimeaine kasutamine",,LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/083-290-237-753-211,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
782,LV,A,LV 12353 A,012-079-042-999-984,1999-10-20,1999,LV 990066 A,1999-04-26,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,Kruts veza profilakses metodes,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having formula (I) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/012-079-042-999-984,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
783,UA,C2,UA 76451 C2,029-594-317-087-161,2006-08-15,2006,UA 2003098796 A,2002-03-15,US 27992801 P;;US 0205115 W,2001-03-29,"N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF 5-HT6 RECEPTOR, PHARMACEUTICAL COMPOSITION","The present invention provides compounds of formula (I), which are antagonists of the 5-HT6, receptor. , (I)",LILLY CO ELI,COHEN MICHAEL PHILIP;;FICHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/029-594-317-087-161,Limited Patent,no,0,0,2,58,0,,A61K31/404;;A61K/;;A61K31/506;;A61P/;;A61P25/18;;A61P25/28;;C07C/;;C07C217/54;;C07C317/14;;C07C323/01;;C07D/;;C07D209/14;;C07D209/16;;C07D213/64;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/12,,0,0,,,,EXPIRED
784,EA,B1,EA 006083 B1,065-413-903-528-281,2005-08-25,2005,EA 200100716 A,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having formula (I) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDERIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/065-413-903-528-281,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
785,BE,A5,BE 1011382 A5,193-524-988-543-036,1999-08-03,1999,BE 9700865 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODES DE PREVENTION DU CANCER DU SEIN.,"Méthode de prévention du cancer du sein, comprenant l'administration, pendant un terme suffisant, à un sujet humain nécessitant un tel traitement d'une dose efficace d'un composé répondant à la formule ou des sels ou solvates pharmaceutiquement acceptables de celui-ci.",LILLY CO ELI,FREDERIC JAY COHEN;;JOAN ELLEN GLUSMAN;;RONALD KEITH KNICKERBOCKER;;NIKOLAUS THOMAS NICKELSEN;;TERI JANINE SCOTT;;ROBERT STEPHEN ECKERT,,https://lens.org/193-524-988-543-036,Granted Patent,no,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
786,AU,B2,AU 731388 B2,134-759-344-739-435,2001-03-29,2001,AU 1997/043647 A,1997-10-30,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/134-759-344-739-435,Granted Patent,no,3,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
787,GR,B,GR 1003189 B,022-111-455-518-392,1999-09-01,1999,GR 970100408 A,1997-10-29,GB 9624800 A;;US 4026097 P;;US 2985096 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula,LILLY CO ELI,ECKERT STEPHEN ROBERT;;COHEN JAY FREDERIC;;NICKELSEN THOMAS NIKOLAUS;;KNICKERBOCKER RONALD KEITH;;GLUSMAN ELLEN JOAN;;SCOTT JANINE TERI,,https://lens.org/022-111-455-518-392,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
788,EE,A,EE 9900162 A,056-768-279-700-055,1999-12-15,1999,EE 9900162 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,"Rinnavähi vältimise meetod, farmatseutiline preparaat ja toode ning toimeaine kasutamine",,LILLY CO ELI,FREDRIC J COHEN;;ROBERT S ECKERT;;JOAN E GLUSMAN;;RONALD K KNICKERBOCKER;;NIKOLAUS T NICKELSEN;;TERI J SCOTT,,https://lens.org/056-768-279-700-055,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
789,FR,B1,FR 2756490 B1,076-182-326-277-788,2003-06-20,2003,FR 9713580 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODES DE PREVENTION DU CANCER DU SEIN,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/076-182-326-277-788,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
790,CA,C,CA 2219070 C,069-564-729-100-362,2007-12-18,2007,CA 2219070 A,1997-10-27,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula <IMG> and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRIC JAY;;ECKERT ROBERT STEPHEN;;SCOTT TERI JANINE;;GLUSMAN JOAN ELLEN;;NICKELSEN NIKOLAUS THOMAS;;KNICKERBOCKER RONALD KEITH,,https://lens.org/069-564-729-100-362,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/445;;C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
791,PL,B1,PL 190551 B1,118-255-092-246-159,2005-12-30,2005,PL 32292697 A,1997-10-30,US 2985096 P,1996-10-30,"APPLICATION OF THIOPHENE DERIVATIVES IN PRODUCTION OF A PHARMACEUTIC AGENT, METHOD OF OBTAINING A PHARMACEUTIC AGENT AND PHARMACEUTIC AGENT AS SUCH",,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/118-255-092-246-159,Granted Patent,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,EXPIRED
792,TR,T2,TR 199900951 T2,088-084-456-246-601,1999-07-21,1999,TR 9900951 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Gögüs kanserinin engellenmesi için yöntemler.,"Gögüs kanserinin engellenmesi için bir yöntem olup, bu yöntem, ihtiyaç duyan bir insana, yeterli bir süre için, (I)formülüne sahip olan bir bilesigin ya da farmasötik açidan kabul edilebilir tuzlari ve solvatlarinin etkili bir miktarinin tatbik edilmesini içermektedir.",LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/088-084-456-246-601,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
793,BG,A,BG 103369 A,120-768-809-056-594,2000-05-31,2000,BG 10336999 A,1999-04-28,GB 9624800 A;;US 9719779 W;;US 2985096 P;;US 4026097 P,1996-10-30,METHOD FOR THE PREVENTION OF THE CANCER OF THE BREAST,The method is effected when achieved quantity of compound with the following formula is adminsitered to patients for a sufficiently long period of time and the compound's pharmaceutical acceptable salts and solvates. 126 claims,LILLY CO ELI,COHEN FREDRIC J;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J;;ECKERT ROBERT S,,https://lens.org/120-768-809-056-594,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
794,GE,B,GE P20032910 B,159-464-314-400-202,2003-03-25,2003,GE AP1997004831 A,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,Method for Prophylaxis of Breast Cancer,1. Technical Result Providing prophylaxis of breast cancer and reduce of complications. 2. Essence Prophylaxis of breast cancer is effected by administering to an organism raloxifene. 3. Field of Application Medicine.,LILLY CO ELI,KNICKERBOCKER RONALD KEITH;;SCOTT TERI JANINE;;NICKELSEN NIKOLAUS THOMAS;;GLUSMAN JOAN ELLEN;;ECKERT ROBERT STEPHEN;;COHEN FREDERIC JAY,,https://lens.org/159-464-314-400-202,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
795,AU,A1,AU 2004/231254 A1,001-237-299-256-862,2004-12-23,2004,AU 2004/231254 A,2004-11-23,AU 2004/231254 A;;AU 2001/054106 A,2001-06-28,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;ECKERT ROBERT STEPHEN;;SCOTT TERI JAMES;;NICKELSON NIKOLAUS THOMAS;;KNICKERBOCKER RONALD KEITH;;GLUSMAN JOAN ELLEN,,https://lens.org/001-237-299-256-862,Patent Application,no,0,0,5,5,0,,A61K31/4535;;A61P35/00,,0,0,,,,EXPIRED
796,DE,T2,DE 69736644 T2,012-865-222-197-59X,2007-10-25,2007,DE 69736644 T,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,Verfahren zur Vorbeugung von Brustkrebs durch Verabreichung von Raloxifen,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/012-865-222-197-59X,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
797,US,A1,US 2002/0019418 A1,113-284-820-374-185,2002-02-14,2002,US 93115901 A,2001-08-16,US 93115901 A;;GB 9624800 A;;US 36868899 A;;US 25437599 A;;US 9719779 W;;US 4026097 P;;US 2985096 P,1996-10-30,Methods of preventing breast cancer,"
    A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula 

   and pharmaceutically acceptable salts and solvates thereof. 
",COHEN FREDRIC J.;;ECKERT ROBERT S.;;GLUSMAN JOAN E.;;KNICKERBOCKER RONALD K.;;NICKELSEN NIKOLAUS T.;;SCOTT TERI J.,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/113-284-820-374-185,Patent Application,yes,0,1,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,514/324,0,0,,,,DISCONTINUED
798,LT,A,LT 99040 A,128-147-149-332-424,1999-10-25,1999,LT 99040 A,1999-04-26,US 2985096 P,1996-10-30,ARTICLES OF MANUFACTURE FOR PREVENTING BREAST CANCER,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/128-147-149-332-424,Patent Application,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,EXPIRED
799,ZA,B,ZA 992858 B,166-377-819-800-816,1999-07-29,1999,ZA 992858 A,1997-10-29,US 2985096 P,1996-10-30,Methods of preventing breast cancer.,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/166-377-819-800-816,Granted Patent,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,EXPIRED
800,SK,A3,SK 55999 A3,186-259-477-317-303,2000-06-12,2000,SK 55999 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,METHODS OF PREVENTING BREAST CANCER,,LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/186-259-477-317-303,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
801,YU,A,YU 42397 A,195-142-815-561-85X,2000-10-30,2000,YU 42397 A,1997-10-27,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,USING RALOXIPHENE FOR MEDICINE PREPARATION,Opisano je korišćenje raloksifena formule ili njegove farmaceutski prihvatljive soli ili solvata za pripremu leka koji se u efikasnoj količini daje pacijentu.,LILLY CO ELI,JAY COHEN FREDRIC;;ELLEN GLUSMAN JOAN;;KEITH KNICKERBOCKER RONALD;;THOMAS NICKELSEN NIKOLAUS;;JANINE SCOTT TERI;;STEPHEN ECKERT ROBERT,,https://lens.org/195-142-815-561-85X,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
802,DK,T3,DK 1369115 T3,032-683-981-128-657,2007-01-02,2007,DK 03102726 T,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,Fremgangsmåder til forebyggelse af brystcancer ved administration af raloxifen,,LILLY CO ELI,COHEN FREDRIC JAY;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;GLUSMAN JOAN ELLEN;;ECKERT ROBERT STEPHEN,,https://lens.org/032-683-981-128-657,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
803,DE,B2,DE 2739388 B2,083-224-927-385-107,1980-09-18,1980,DE 2739388 A,1977-09-01,US 72160476 A,1976-09-07,DE 2739388 B2,,"GTE SYLVANIA INC., WILMINGTON, DEL. (V.ST.A.)","ARMSTRONG, DONALD E., WILLIAMSPORT;;SINDLINGER, RONALD E., MUNCY;;COHEN, BERNARD;;TOZIER, JOHN E.;;AUDESSE, EMERY G., BEVERLY, MASS.",,https://lens.org/083-224-927-385-107,Patent Application,no,0,0,12,12,0,F21K5/02;;F21K5/02,F21K5/06;;F21K5/08,,0,0,,,,EXPIRED
804,AU,A,AU 2001/054106 A,078-548-057-421-011,2001-09-06,2001,AU 2001/054106 A,2001-06-28,AU 2001/054106 A,2001-06-28,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDERIC JAY;;ECKERT ROBERT STEPHEN;;SCOTT TERI JANINE;;NICKELSEN NIKOLAUS THOMAS;;KNICKERBOCKER RONALD KEITH;;GLUSMAN JOAN ELLEN,,https://lens.org/078-548-057-421-011,Patent Application,no,0,0,5,5,0,,A61K31/4535;;A61P35/00,,0,0,,,,PENDING
805,SI,A,SI 20107 A,158-554-339-043-38X,2000-06-30,2000,SI 9720070 A,1997-10-29,GB 9624800 A;;US 9719779 W;;US 2985096 P;;US 4026097 P,1996-10-30,METHOD OF PREVENTION OF BREAST CANCER,"The invention is directed towards the method of prevention of breast cancer of people and comprises administering effective doses of a compound with the formula (I) or its pharmaceutically acceptable solvate or salt respectively over an enough long period. Besides, the invention refers to products comprising both the packing and the pharmaceutically active substance which is contained in the packing, the active substance being a compound with the formula I or its pharmaceutically acceptable solvate or salt respectively, where a label on the packing is designating that the pharmaceutically active substance is to be prescribed for the breast cancer prevention.",LILLY CO ELI,COHEN J FREDRIC;;ECKERT S ROBERT;;GLUSMAN E JOAN;;KNICKERBOCKER K RONALD;;NICKELSEN T NIKOLAUS;;SCOTT J TERI,,https://lens.org/158-554-339-043-38X,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
806,EP,B1,EP 1369115 B1,181-582-282-034-969,2006-09-06,2006,EP 03102726 A,1997-10-29,EP 97308626 A;;GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer by the administration of Raloxifene,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,ELI LILLY & COMPANY (2007-10-15),https://lens.org/181-582-282-034-969,Granted Patent,yes,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,4,0,,,"""FIRST PHASE III RESULTS WITH RALOXIFENE"" DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), page 17 XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"" JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51-57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"" DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"" JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01), pages 123-125, XP002054376",EXPIRED
807,ID,A,ID P000008233 A,013-693-338-792-575,2001-08-16,2001,ID W00199900250 A,1997-10-29,GB 9624800 A;;US 2985096 P,1996-10-30,METODE PENCEGAHAN KANKER PAYUDARA,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/013-693-338-792-575,Patent Application,no,0,9,1,132,0,,A61K9/00;;A61K9/14;;A61K9/20,,0,0,,,,PENDING
808,US,B1,US 6303634 B1,143-992-751-917-507,2001-10-16,2001,US 36868899 A,1999-08-05,US 36868899 A;;GB 9624800 A;;US 25437599 A;;US 9719779 W;;US 4026097 P;;US 2985096 P,1996-10-30,Methods of preventing breast cancer,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula ##STR1## and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/143-992-751-917-507,Granted Patent,yes,11,6,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,514/324;;514/333,10,7,063-610-624-614-160;;129-192-318-027-682;;116-238-224-441-339;;116-238-224-441-339;;090-621-258-864-815;;039-179-689-155-908;;006-388-692-923-22X,2194650;;10.1002/jcb.240590808;;10.1093/jnci/88.2.123;;8537973;;10.1093/jnci/88.2.123;;8537973;;8573710;;10.1007/bf00713399;;6431104;;10.1021/jm00374a021;;10.1016/0024-3205(83)90323-5;;6406781,"Lerner L. J., et al., ""Development of Antiestrogens and Their Use in Breast Cancer: Eighth Cain Memorial Award Lecture"", Cancer Research, 50, pp. 4177-4189 (1990).;;Jordan, V. Craig, Journal of Cellular Biochemistry, 58:S.22.,51-57 (1995), ""Alternate Antiestrogens and Approaches to the Prevention of Breast Cancer"".;;Anzano, M.A., et al., Journal of the National Cancer Institute, 88:2, pp. 123-125 (1996) ""Chemoprevention of Mammary Carcinogenesis in the Rat: Combined Use of Raloxifene and 9-Cis-Retinoic Acid"".;;""First Phase III Results with Raloxifene"" Database File 129, Dialog Information Services; 540210, Jun. 13, 1997.;;""Market Analysis from Decision Resources: Breast Cancer"", Database File 187, Dialog Information Services, 1249, Apr. 1, 1996.;;""National Chemopreventive Agents in Experimental Mammary Carcinogenesis"", Anzano, Crisp Data Base National Institutes of Health, CRISP-96-PO57 (1995).;;Caplus Abstract Accession No. 1996:122169 and J. Natl. Cancer Inst. (1996) 88 (2) pp. 123-125 (Anzano).;;Biosis Abstract Accession No. 95:496471 and Breast Cancer Research and Treatment (1995) 36 (3) pp. 267-285 (Jordan).;;Caplus Abstract Accession No. 1984:448784 and J. Med. Chem. (1984) 27 (8) pp. 1057-1066 (Jones).;;Caplus Abstract Accession No. 1983-432846 and Life Science (1983) 32 (25) pp. 2869-2875 (Clemens).",EXPIRED
809,MY,A,MY 121623 A,000-256-730-307-100,2006-02-28,2006,MY PI9705106 A,1997-10-28,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER.,A METHOD OF PREVENTING BREAST CANCER COMPRISING ADMINISTERING FOR A SUFFICIENT TERM TO A HUMAN IN NEED THEREOF AN EFFECTIVE AMOUNT OF A COMPOUND HAVING THE FORMULA FORMULA I AND PHARMACEUTICALLY ACCEPTABLE SALTS AND SOLVATES THEREOF.,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEVEN,,https://lens.org/000-256-730-307-100,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/445;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
810,NZ,A,NZ 329042 A,013-161-486-095-897,1999-08-30,1999,NZ 32904297 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,USE OF RALOXIFENE FOR PREVENTING BREAST CANCER,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEVEN,"ELI LILLY AND COMPANY, US (2012-07-27)",https://lens.org/013-161-486-095-897,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;C07D333/56;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
811,EA,B1,EA 002054 B1,127-006-234-387-205,2001-12-24,2001,EA 199900431 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,METHOD FOR PREVENTING BREAST CANCER,"1. A method for preventing breast cancer in a human which comprises administering to said human for a sufficient term an effective dose of a compound of the formula or a pharmaceutical ly acceptable salt or solvate thereof, said term being at least one year. 2. The method of Claim 1 wherein said effective dose is between about 30mg to about 200mg/day. 3. The method of Claim 1 wherein said effective dose is between about 50mg to about 150mg/day. 4. The method of Claim 1 wherein said effective dose is between about 60mg to about 120mg/day. 5. The method of Claim 1 wherein said effective dosage is about 60mg/day. 6. The method of Claim 1 wherein said term is at least two years. 7. The method of Claim 1 wherein said term is chronic. 8. The method of Claim 1 wherein said compound is the hydrochloride salt thereof. 9. The method of Claim 1 wherein said human is a post-menopausal female, at no particular risk of developing breast cancer. 10. The method of Claim 1 where said breast cancer is de novo. 11. The method of claim 1 wherein said human is a post-menopausal female. 12. A method for preventing breast cancer in a post-menopausal human female which comprises administering to said post-menopausal human female for a sufficient term an effective dose of a compound of the formula or a pharmaceutically acceptable salt or solvate thereof, said term being at least one year. 13. The method of Claim 12 wherein said effective dose is between about 30mg to about 200mg/day. 14. The method of Claim 12 wherein said effective dose is between about 50mg to about 150mg/day. 15. The method of Claim 12 wherein said effective dose is between about 60mg to about 120mg/day. 16. The method of Claim 12 wherein said effective dosage is about 60mg/day. 17. The method of Claim 12 wherein said term is at least two years. 18. The method of Claim 12 wherein said term is chronic. 19. The method of Claim 12 wherein said compound is the hydrochloride salt thereof. 20. The method of Claim 12 wherein said human is a post-menopausal female, at no particular risk of developing breast cancer. 21. The method of Claim 12 where said breast cancer is de novo. 22. A method for preventing breast cancer comprising administrating to a human for a sufficient term an effective dose of a compound of formula 1 or a pharmaceutically acceptable salt or solvate thereof, said human being at no particular risk of developing breast cancer, said term being at least one year. 23. The method of Claim 22 wherein said effective dose is between about 30mg to about 200mg/day. 24. The method of Claim 22 wherein said effective dose is between about 50mg to about 150mg/day. 25. The method of Claim 22 wherein said effective dose is between about 60mg to about 120mg/day. 26. The method of Claim 22 wherein said effective dosage is about 60mg/day. 27. The method of Claim 22 wherein said term is at least two years. 28. The method of Claim 22 wherein said term is chronic. 29. The method of Claim 22 wherein said compound is the hydrochloride salt thereof. 30. The method of claim 1 or 3 wherein said human is a post-menopausal female. 31. An article of manufacture comprising packaging material and a pharmaceutical agent contained within said packaging material, wherein said packaging material comprises a label which indicates said pharmaceutical agent may be administered, for a sufficient term at an effective dose, for preventing breast cancer in a human and wherein said pharmaceutical agent is a compound of formula I or a pharmaceutically acceptable salt or solvate thereof, said term is at least one year. 32. An article of manufacture of Claim 31 wherein said label indicates an effective dose of the compound of formula I is between about 30 mg to about 200 mg/day. 33. An article of manufacture of Claim 31 wherein said label indicates an effective dose of the compound of formula I is between about 50 mg to about 150 mg/day. 34. An article of manufacture of Claim 31 wherein said label indicates an effective dose of the compound of formula I is between about 60 mg to about 120 mg/day. 35. An article of manufacture of Claim 31 wherein said label indicates an effective dosage of the compound of formula I is about 60 mg/day. 36. An article of manufacture of Claim 31 wherein said label indicates the term of administration is at least two years. 37. An article of manufacture of Claim 31 wherein said label indicates the term of administration is chronic. 38. An article of manufacture of Claim 31 wherein said compound is the hydrochloride salt thereof. 39. An article of manufacture of Claim 31 wherein said human is a post-menopausal female, at no particular risk of developing breast cancer. 40. An article of manufacture of Claim 31 where said breast cancer is de novo. 41. An article of manufacture of Claim 31 wherein said human is a post-menopausal female. 42. An article of manufacture comprising packaging material and a pharmaceutical agent contained within said packaging material, wherein said packaging material comprises a label which indicates said pharmaceutical agent may be administered, for a sufficient term and at an effective dose, for preventing breast cancer in a post-menopausal human female wherein said pharmaceutical agent is a compound of formula I or a pharmaceutically acceptable salt or solvate thereof, said term is at least one year. 43. An article of manufacture of Claim 42 wherein said label indicates an effective dose of the compound of formula I is between about 30 mg to about 200 mg/day. 44. An article of manufacture of Claim 42 wherein said label indicates an effective dose of the compound of formula I is between about 50 mg to about 150 mg/day. 45. An article of manufacture of Claim 42 wherein said label indicates an effective dose of the compound of formula I is between about 60 mg to about 120 mg/day. 46. An article of manufacture of Claim 42 wherein said label indicates an effective dosage of the compound of formula I is about 60 mg/day. 47. An article of manufacture of Claim 42 wherein said label indicates the term of administration is at least six months. 48. An article of manufacture of Claim 42 wherein said label indicates the term of administration is chronic. 49. An article of manufacture of Claim 42 wherein said compound is the hydrochloride salt thereof. 50. An article of manufacture of Claim 42 wherein said post-menopausal female is at no particular risk of developing breast cancer. 51. An article of manufacture of Claim 42 where, said breast cancer is de novo. 52. An article of manufacture comprising packaging material and a pharmaceutical agent contained within said packaging material, wherein said packaging material comprises a label which indicates said pharmaceutical agent may be administered, for a sufficient term at an effective dose, for preventing breast cancer in a human at no particular risk of developing breast cancer wherein said pharmaceutical agent is a compound of formula I or a pharmaceutically acceptable salt or solvate thereof , said term is at least one year. 53. An article of manufacture of Claim 52 wherein said label indicates the effective dose of a compound of Formula I is between about 30 mg to about 200 ing/day. 54. An article of manufacture of Claim 52 wherein said label indicates the effective dose of a compound of Formula I is between about 50 mg to about 150 mg/day. 55. An article of manufacture of Claim 52 wherein said label indicates the effective dose of a compound of Formula I is between about 60 mg to about 120 mg/day. 56. An article of manufacture of Claim 52 wherein said label indicates the effective dosage of a compound of Formula I is about 60 mg/day. 57. An article of manufacture of Claim 52 wherein said label indicates the term is at least two years. 58. An article of manufacture of Claim 52 wherein said label indicates the term is chronic. 59. An article of manufacture of Claim 52 wherein said compound is the hydrochloride salt thereof. 60. An article of manufacture of Claim 52 wherein said human is a post-menopausal female. 61. The use of a compound of the formula or a pharmaceutically acceptable salt or solvate thereof, in the preparation of a medicament for preventing breast cancer in a human, said medicament to be administered to said human for a sufficient term and at an effective dose, said term being at least one year. 62. The use of Claim 61 wherein said effective dose is between about 30 mg to about 200 mg/day. 63. The use of Claim 61 wherein said effective dose is between about 50 mg to about 150 mg/day. 64. The use of Claim 61 wherein said effective .dose is between about 60 mg to about 120 mg/day. 65. The use of Claim 61 wherein said effective dosage is about 60 mg/day. 66. The use of Claim 61 wherein said term is at least two years. 67. The use of Claim 61 wherein said term is chronic. 68. The use of Claim 61 wherein said compound is the hydrochloride salt thereof. 69. The use of Claim 61 wherein said human is a post-menopausal female, at no particular risk of developing breast cancer. 70. The use of Claim 61 where said breast cancer is de novo. 71. The use of Claim 61 wherein said human is a post-menopausal female. 72. The use of a compound of the formula or a pharmaceutically acceptable salt or solvate thereof, in the preparation of a medicament for preventing breast cancer in a post-menopausal human female, said medicament to be administered to said post-menopausal human female for a sufficient term and at an effective dose, said term being at least one year. 73. The use of Claim 72 wherein said effective dose is between about 30 mg to about 200 mg/day. 74. The use of Claim 72 wherein said effective dose is between about 50 mg to about 150 mg/day. 75. The use of Claim 72 wherein said effective dose is between about 60 mg to about 120 mg/day. 76. The use of Claim 72 wherein said effective dosage is about 60 mg/day. 77. The use of Claim 72 wherein said term is at least two years. 78. The",LILLY CO ELI,COHEN FREDERIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/127-006-234-387-205,Granted Patent,no,0,4,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
812,IS,A,IS 5035 A,112-226-242-056-65X,1999-04-27,1999,IS 5035 A,1999-04-27,GB 9624800 A;;US 9719779 W;;US 2985096 P;;US 4026097 P,1996-10-30,Aðferðir til varnar gegn brjóstakrabbameini,,LILLY CO ELI,COHEN FREDERIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/112-226-242-056-65X,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,PENDING
813,LT,B,LT 4634 B,124-565-802-823-418,2000-03-27,2000,LT 99040 A,1999-04-26,US 2985096 P,1996-10-30,ARTICLES OF MANUFACTURE FOR PREVENTING BREAST CANCER,,LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/124-565-802-823-418,Granted Patent,no,7,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,8,6,010-636-275-079-472;;072-664-751-171-040;;088-862-416-650-974;;039-165-786-737-566;;074-008-516-204-700;;029-876-786-714-514,9045313;;1443971;;10.7326/0003-4819-117-12-1016;;10.1016/s1278-3218(97)80011-x;;10.1210/jc.81.6.2027;;10.1210/jcem.81.6.8964823;;8964823;;7894318;;10.1038/nm0496-381;;8597938,"J. F. FORBES: ""The incidence of breast cancer: The global burden, public health considerations"", SEMINARS IN ONCOLOGY, 1997, pages 1 - 20;;GRADY D ET AL.: ""Hormone therapy to prevent disease and prolong life in postmenopausal women."", ANN INTERN MED., 1992, pages 1016 - 1037;;BERNARD FISHER ET AL.: ""Five Versus More Than Five Years of Tamoxifen Therapy for Breast Cancer Patients With Negative Lymph Nodes and Estrogen Receptor-Positive Tumors"", J. NATL. CANC. INST., 1996, pages 1529 - 1542;;GOLDHIRSH ET AL.: ""Endocrine Therapies of Breast cancer"", SEM. IN ONC., 1996, pages 494 - 505;;R J SANTEN: ""Long-term tamoxifen therapy: can an antagonist become an agonist?"", JOURNAL OF CLINICAL ENDOCRINOLOGY AND METABOLISM, 1996, pages 2027 - 2029;;KELLOFF GJ ET AL.: ""APPROACHES TO THE DEVELOPMENT AND MARKETING APPROVAL OF DRUGS THAT PREVENT CANCER"", CANCER EPIDEMIOLOGY, BIOMARKERS & PREVENTION, 1995, pages 1 - 10;;GRAINGER ET AL.: ""Tamoxifen: Teaching an Old drug new Tricks"", NAT. MED., 1996, pages 381 - 385, XP000604987, DOI: doi:10.1038/nm0496-381;;HARRIS ET AL.: ""Diseases of the Breast"", pages: 159 - 168",EXPIRED
814,EP,A1,EP 1369115 A1,185-097-335-733-63X,2003-12-10,2003,EP 03102726 A,1997-10-29,EP 97308626 A;;GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer by the administration of Raloxifene,"A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula
      and pharmaceutically acceptable salts and solvates thereof.",LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,ELI LILLY & COMPANY (2007-10-15),https://lens.org/185-097-335-733-63X,Patent Application,yes,6,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;C07D333/56;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,4,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"""FIRST PHASE III RESULTS WITH RALOXIFENE"", DATABASE FILE 129, PHIND; DIALOG INFORMATION SERVICES; AN=540210, 13 June 1997 (1997-06-13), pages 17, XP002054373;;V.C. JORDAN ET AL.: ""ALTERNATE ANTIESTROGENS AND APPROACHES TO THE PREVENTION OF BREAST CANCER"", JOURNAL OF CELLULAR BIOCHEMISTRY, vol. 58, no. S.22, 1995, pages 51 - 57, XP002054374;;""MARKET ANALYSIS FROM DECISION RESOURCES: BREAST CANCER"", DATABASE FILE 187, FDC REPORTS; DIALOG INFORMATION SERVICES, AN=1249, vol. 1, no. 4, 1 April 1996 (1996-04-01), XP002054375;;M.A. ANZANO ET AL.: ""CHEMOPREVENTION OF MAMMARY CARCINOGENESIS IN THE RAT: COMBINED USE OF RALOXIFENE AND 9-CIS-RETINOIC ACID"", JOURNAL OF THE NATIONAL CANCER INSTITUTE, vol. 88, no. 2, January 1996 (1996-01-01), pages 123 - 125, XP002054376",EXPIRED
815,AP,A,AP 971 A,006-553-096-827-369,2001-05-30,2001,AP 9901494 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,Use of raloxifene in preventing breast cancer.,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having formula (I) and phamaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRICK JAY;;ECKERT ROBERT STEPHEN;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE,,https://lens.org/006-553-096-827-369,Granted Patent,no,1,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
816,ES,T3,ES 2271476 T3,023-736-111-248-495,2007-04-16,2007,ES 03102726 T,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,PROCEDIMIENTOS DE PREVENCION DE CANCER DE MAMA POR ADMINISTRACION DE RALOXIFENO.,"El uso de una sal de clorhidrato de un compuesto de fórmula (I) en la preparación de un medicamento para administración oral para prevenir el cáncer de mama en una hembra humana post-menopáusica durante un plazo suficiente y a una dosis efectiva, en la que dicha dosis está comprendida entre 55 y 65 mg/día.",LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/023-736-111-248-495,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
817,ES,B1,ES 2135342 B1,175-104-036-041-561,2000-05-16,2000,ES 9702224 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,USO DEL RALOXIFENO O UNA SAL O SALVATO DEL MISMO EN LA PREPARACION DE UN MEDICAMENTO PARA PREVENIR EL CANCER DE MAMA.,"Uso del raloxifeno o una sal o solvato del mismo en la preparación de un medicamento para prevenir el cáncer de mama. Un procedimiento para prevenir el cáncer de mama, que comprende administrar durante un período suficiente a un ser humano que lo necesite una cantidad eficaz de un compuesto que tiene la fórmula I, y las sales y solvatos farmacéuticamente aceptables del mismo.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/175-104-036-041-561,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
818,BG,B1,BG 63841 B1,179-676-511-253-811,2003-03-31,2003,BG 10336999 A,1999-04-28,GB 9624800 A;;US 9719779 W;;US 2985096 P;;US 4026097 P,1996-10-30,METHOD FOR THE PREVENTION OF THE CANCER OF THE BREAST,"The method is effected when achieved quantity of compound with the following formula is adminsitered to patients for a sufficiently long period of time and the compound's pharmaceutical acceptable salts and solvates. 28 claims, 1 figure",LILLY CO ELI,COHEN FREDRIC J;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J;;ECKERT ROBERT S,,https://lens.org/179-676-511-253-811,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
819,LV,B,LV 12353 B,105-429-031-409-714,2000-02-20,2000,LV 990066 A,1999-04-26,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,METHODS OF PREVENTING BREAST CANCER,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having formula (I) and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/105-429-031-409-714,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K31/38;;A61K31/381;;C07D333/56;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
820,DE,D1,DE 69736644 D1,045-834-200-580-024,2006-10-19,2006,DE 69736644 T,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,Verfahren zur Vorbeugung von Brustkrebs durch Verabreichung von Raloxifen,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/045-834-200-580-024,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
821,IE,A1,IE 970772 A1,058-126-371-179-969,2000-02-09,2000,IE 970772 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having the formula [FORMULA] and pharmaceutically acceptable salts and solvates thereof.,LILLY CO ELI,NICKELSEN NIKOLAUS THOMAS;;COHEN FREDRIC JAY;;KNICKERBOCKER RONALD KEITH;;GLUSMAN JOAN ELLEN;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/058-126-371-179-969,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
822,US,A1,US 2004/0167170 A1,150-379-676-026-445,2004-08-26,2004,US 78532604 A,2004-02-24,US 78532604 A;;GB 9624800 A;;US 93115901 A,1996-11-29,Methods of preventing breast cancer,"
   A method of preventing breast cancer comprising administering for a sufficient term to a human in need thereof an effective amount of a compound having formula (I) and pharmaceutically acceptable salts and solvates thereof. 
",COHEN FREDRIC J.;;ECKERT ROBERT S.;;GLUSMAN JOAN E.;;KNICKERBOCKER RONALD K.;;NICKELSEN NIKOLAUS T.;;SCOTT TERI J.,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/150-379-676-026-445,Patent Application,yes,22,2,2,132,0,A61K31/4535;;A61K31/4535,A61K31/4535,51432,0,0,,,,DISCONTINUED
823,RO,B1,RO 120813 B1,163-886-974-892-999,2006-08-30,2006,RO 9900482 A,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P;;US 9719779 W,1996-10-30,UTILIZATION OF RALOXIFENE AND THE SALTS THEREOF FOR PREVENTING BREAST CANCER,"The invention relates to the utilization of the general formula (I) and the pharmaceutically acceptable salts thereof, for preparing an oral medicine, administered in a dose ranging from 55 to 65 mg/ per day for preventing and reducing the probability of exposure or development of estrogen-dependent breast carcinoma in postmenopausal women.",LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/163-886-974-892-999,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;A61K9/00;;C07D333/56;;A61K9/14;;A61K9/20;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
824,ES,A1,ES 2135342 A1,179-380-341-989-638,1999-10-16,1999,ES 9702224 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Improvements in or relating to the prophylaxis of breast cancer by the administration of raloxifene,"Prophylaxis of breast cancer in a post-menopausal woman, by administering to such a woman raloxifene, or a pharmaceutically-acceptable salt thereof, in an amount from about 30 mg to about 150 mg per day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/179-380-341-989-638,Patent Application,no,5,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,2,1,116-238-224-441-339,10.1093/jnci/88.2.123;;8537973,"JORDAN et al. Alternate Antiestrogens and approaches to the prevention of breast cancer, Journal of Cellular Biochemistry, Vol. 58, no 5.22, 1995, paginas 51-57, resumen; paginas 54,55; figura 3.;;ANZANO et al. Chemoprevention of mammary carcinogenesis in the rat: combined use of raloxifene and 9-cis-retinoic acid, Journal of the National Cancer Institute, Vol. 88, no 2, Enero 1996, paginas 123-125.",EXPIRED
825,GB,B,GB 2318734 B,186-846-407-386-529,1999-12-01,1999,GB 9722801 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Methods of preventing breast cancer,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/186-846-407-386-529,Granted Patent,no,3,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,A5B BHA           BHA3;;A5B B170          BHA3;;A5B B180          BHA3;;A5B B48Y          BHA3;;A5B B482          BHA3;;A5B B483          BHA3;;A5B B50Y          BHA3;;A5B B503          BHA3;;A5B B54Y          BHA3;;A5B B541          BHA3;;A5B B55Y          BHA3;;A5B B553          BHA3;;A5B B56Y          BHA3;;A5B B566          BHA3;;A5B B57Y          BHA3;;A5B B575          BHA3;;A5B B58Y          BHA3;;A5B B586          BHA3;;A5B B61Y          BHA3;;A5B B616          BHA3;;A5B B65Y          BHA3;;A5B B650          BHA3;;A5B B654          BHA3;;A5B B66Y          BHA3;;A5B B664          BHA3;;A5B B822          BHA3;;A5B B828          BHA3;;A5B B829          BHA3;;U1S S1313,5,5,116-238-224-441-339;;090-621-258-864-815;;039-179-689-155-908;;006-388-692-923-22X;;129-192-318-027-682,10.1093/jnci/88.2.123;;8537973;;8573710;;10.1007/bf00713399;;6431104;;10.1021/jm00374a021;;10.1016/0024-3205(83)90323-5;;6406781;;10.1002/jcb.240590808,CAPLUS Abs. ac. no. 1996:122169 & J. Natl. Cancer Inst. (1996) 88(2) (Anzano) pages 123-5;;BIOSIS Abs. ac. no. 95:496471 & Breast Cancer Research and Treatment (1995) (Jordan) 36(3) 267-285;;CAPLUS Abs. ac. no. 1984:448784 & J. Med. Chem. (1984) 27(8)(Jones) pages 1057-66;;CAPLUS Abs. ac. no. 1983:432846 & Life Science (1983) 32(25)(Clemens) pages 2869-75;;J. Cellular Biochemistry 58/suppl. 22 1995 (Jordan) pages 51-57,EXPIRED
826,NZ,A,NZ 336321 A,038-653-058-303-176,2000-11-24,2000,NZ 33632199 A,1999-06-16,GB 9624800 A;;NZ 32904299 A;;US 2985096 P;;US 4026097 P,1996-10-30,Use of benzothiophene (raloxifene) for treating breast cancer,"Use of a compound of Formula (I) as a medicament for preventing invasive breast cancer. The medicament may be administered at a concentration of 30-200mg/day, preferably 60mg/day.",LILLY CO ELI,COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;SCOTT TERI JANINE;;NICKELSEN NIKOLAUS THOMAS;;ECKERT ROBERT STEPHEN,"ELI LILLY AND COMPANY, US (2012-07-27)",https://lens.org/038-653-058-303-176,Patent Application,no,0,0,1,132,0,,A61K31/38;;A61K31/40;;A61K31/445,,0,0,,,,DISCONTINUED
827,PT,E,PT 1369115 E,020-173-782-818-246,2006-12-29,2006,PT 03102726 T,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,METHODS OF PREVENTING BREAST CANCER BY THE ADMINISTRATION OF RALOXIFENE,,LILLY CO ELI,KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;ECKERT ROBERT STEPHEN,,https://lens.org/020-173-782-818-246,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
828,NO,B1,NO 322468 B1,076-333-648-261-661,2006-10-09,2006,NO 974972 A,1997-10-28,GB 9624800 A;;US 2985096 P;;US 4026097 P,1996-10-30,Anvendelse av raloksifen for primaer forhindring av ostrogenavhengig brystcancer hos post-menopausale kvinner,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEVEN,,https://lens.org/076-333-648-261-661,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/4535;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
829,ZA,B,ZA 979723 B,077-889-527-361-13X,1999-07-29,1999,ZA 979723 A,1997-10-29,US 2985096 P,1996-10-30,Methods of preventing breast cancer.,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/077-889-527-361-13X,Granted Patent,no,0,0,10,132,0,,A61K31/4535;;A61K/;;A61K9/00;;A61K9/14;;A61K9/20;;A61K31/38;;A61P35/00;;B65D/,,0,0,,,,EXPIRED
830,AT,T1,AT E338551 T1,136-841-194-254-63X,2006-09-15,2006,AT 03102726 T,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P,1996-10-30,VERFAHREN ZUR VORBEUGUNG VON BRUSTKREBS DURCH VERABREICHUNG VON RALOXIFEN,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/136-841-194-254-63X,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
831,BR,A,BR 9712703 A,163-354-953-213-013,1999-10-26,1999,BR 9712703 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,Métodos para previnir cncer de mama,Patente de Invenção: <B>''MéTODOS PARA PREVENIR CNCER DE MAMA''<D>. Um método para prevenir câncer de mama compreendendo administrar durante um prazo suficiente a um ser humano necessitando da mesma uma quantidade eficaz de um composto tendo fórmula (I) e sais e solvatos dos mesmos farmaceuticamente aceitáveis.,LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/163-354-953-213-013,Patent Application,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K9/00;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P43/00,,0,0,,,,DISCONTINUED
832,SI,T1,SI 1369115 T1,159-293-434-280-870,2006-12-31,2006,SI 9730752 T,1997-10-29,US 2985096 P;;GB 9624800 A;;US 4026097 P;;EP 97308626 A,1996-10-30,Methods of preventing breast cancer by the administration of Raloxifene,,LILLY CO ELI,COHEN FREDRIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JANINE;;ECKERT ROBERT STEPHEN,,https://lens.org/159-293-434-280-870,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,A61K31/00;;A61K9/00;;C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
833,SK,B6,SK 287047 B6,194-011-313-976-012,2009-10-07,2009,SK 55999 A,1997-10-29,GB 9624800 A;;US 2985096 P;;US 4026097 P;;US 9719779 W,1996-10-30,Use of raloxifene hydrochloride for the manufacture of a medicament for prophylaxis of breast cancer,"Use of hydrochloride salt of the compound of general formula (I) for the manufacture of orally administered medicament for prophylaxis of breast cancer in postmenopausal women during sufficient period of time and in effective dose, whereby the dose being from 55 to 65 mg per day, preferably 60 mg per day.",LILLY CO ELI,COHEN FREDRIC J;;ECKERT ROBERT S;;GLUSMAN JOAN E;;KNICKERBOCKER RONALD K;;NICKELSEN NIKOLAUS T;;SCOTT TERI J,,https://lens.org/194-011-313-976-012,Granted Patent,no,0,0,111,132,0,A61K31/4535;;A61P35/00;;A61P35/04;;A61P43/00;;A61P5/00;;A61P5/24;;A61P5/32;;A61K31/4535,C07D333/56;;A61K31/38;;A61K31/381;;A61K31/445;;A61K31/4535;;A61P5/32;;A61P35/00;;A61P35/00;;A61P43/00,,0,0,,,,EXPIRED
834,US,B2,US 7462592 B2,159-521-471-821-80X,2008-12-09,2008,US 27875102 A,2002-10-22,US 27875102 A;;US 9714465 W;;US 62092500 A;;US 91064797 A;;US 2386796 P,1996-08-13,Compositions and methods for polynucleotide delivery,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",NOVARTIS VACCINES & DIAGNOSTIC,ZUCKERMANN RONALD N;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED E;;UNO TETSUO,,https://lens.org/159-521-471-821-80X,Granted Patent,yes,20,8,17,17,4,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K9/14;;A01N37/18;;A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,514/2;;424/486;;530/300,30,24,019-810-335-711-889;;038-490-918-925-431;;114-517-649-646-486;;059-172-353-640-68X;;038-206-696-631-102;;096-317-125-842-948;;050-885-886-277-521;;035-886-556-173-632;;072-395-547-617-233;;004-456-464-309-219;;022-200-580-308-452;;012-595-233-448-094;;001-596-965-870-798;;155-997-957-806-763;;016-265-122-983-119;;166-492-343-373-663;;078-403-096-840-094;;088-686-971-255-340;;118-843-647-887-744;;175-833-149-417-043;;009-416-320-508-847;;157-947-201-686-965;;011-307-053-684-81X;;071-211-641-209-775,9579858;;7584089;;10.1021/bc00029a002;;7849066;;9669880;;10.1016/s1359-0278(98)00030-3;;8750010;;8547238;;10.1021/bi952436a;;10.1007/bf02789334;;7552693;;9001404;;10.1016/s0014-5793(96)01397-x;;10.1021/bc00031a002;;7711106;;10.1016/0169-409x(96)00002-6;;10.1089/hum.1995.6.9-1129;;8527471;;9026036;;10.1021/bc960076d;;10.1074/jbc.270.42.24864;;7559609;;8607031;;8629036;;7873664;;10.1021/bc00030a017;;7584085;;7619428;;10.1016/1045-1056(95)90004-7;;7878052;;pmc42596;;10.1073/pnas.92.5.1744;;10.1016/0960-894x(95)00187-x;;10.1016/0168-3659(96)01537-4;;9305836;;10.1038/38410;;10.1021/bc00010a006;;1772904;;1518816;;pmc49829;;10.1073/pnas.89.17.7934;;10.1016/0005-2736(95)00256-1;;8634302,"Canadian patent application No. 2,264,012, Examination Report mailed Jan. 11, 2007.;;Japan patent application No. 10-508319, Office Action mailed Mar. 18, 2008.;;Anderson et al., Human gene therapy, Apr. 30, 1998, Nature, vol. 392, pp. 25-30.;;Batra et al., ""Receptor-Mediated Gene Delivery Emplyong Lectin-Binding Specificity"" Gene Therapy 1:255-260, 1994.;;Behr et al., ""Gene Transfer with Synthetic Cationic Amphiphiles: Prospects for Gene Therapy"" Bioconjugate Chem. 5:382-389, 1994.;;Behr et al., ""The Proton Sponge: a Trick to Enter Cells the Viruses did not Exploit"" Chimia 51:34-36 (1997).;;Chiu et al., Optimizing energy potentials for success in protein tertiary sturcture prediction, May 7, 1998, Folding & Design, vol. 3, pp. 223-228.;;Gao and Huang, ""Cationic Liposome-Mediated Gene Transfer"" Gene Therapy 2:710-722, 1995.;;Gao and Huang, ""Potentiation of Cationic Liposome-Mediated Gene Transfer Delivery by Polycations"" Biochemistry 35:1027-1036, 1996.;;Guy et al., ""Delivery of DNA into Mammalian Cells by Receptor-Mediated Endocytosis and Gene Therapy"" Molecular Biology 3:237-248, 1995.;;Hong et al., ""Stabilization of Cationic Liposome-Plasmid DNA Complexes by Polyamines and . . . "" FEBS Letters 400:233-237, 1997.;;Kabanov and Kabanov, ""DNA Complexes with Polycations for the Delivery of Genetic Material into Cells"" Bioconjugate Chem. 6:7-20, 1995.;;Lasic and Tenpleton, ""Liposomes in Gene Therapy"" Advanced Drug Delivery Reviews 20:221-226, 1996.;;Ledley, ""Nonviral Gene Therapy: The Promise of Genes as Pharmaceutical Products"" Human Gene Ther. 6:1129-1144, Sep. 1995.;;Legendre et al., ""Dioleoylmelittin as a Novel Serum-Insensitive Reagent for Efficient Transfection of Mammalian Cells"" Bioconjugate Chem. 8:57-63, 1997.;;Liu et al., ""Cationic Liposome-Mediated Intravenous Gene Delivery"" J. Biological Chemistry 270(42):24864-24870, 1995.;;Mastrangelo et al., ""Gene Therapy for Human Cancer: an Essay for Clinicians"" Seminars in Oncology 23:4-21, 1996.;;Merwin et al., ""Targeted Delivery of DNA Using Yee(GalNacAH).sub.3, a Synthetic Glycopeptide Ligand . . . "" Bioconjugate Chemistry 5(6):612-620, 1994.;;Michael and Curiel, ""Strategies to Achieve Targeted Gene Delivery via the Receptor-Mediated Endocytosis Pathway"" Gene Therapy 1:223-232, 1994.;;Ngo et al., Computational Complexity Protein Structure Prediction, and the Levinthal Parasdox, 1994, vol. 14, pp. 492-495.;;Ngo et al., in: The Protein Folding Problem and Tertiary Structure Prediction, 1994, Merz et ., (ed)., Birkhauser, Boston, MA, pp. 433 and 492-495.;;Phillips, ""Receptor-Mediated DNA Delivery Approaches to Human Gene Therapy"" Biologicals 23:13-16, 1995.;;Raz et al., Cationic Lipids Inhibit Intradermal Genetic Vaccination, 1994, pp. 71-75.;;Remy et al., ""Targeted Gene Transfer into Hepatoma Cells With Lipopolyamine-Condensed DNA Particles . . . "" PNAS USA 92:1744-1748, 1995.;;Richter and Zuckerman, ""Synthesis of Peptide Nucleic Acids (PNA) by Submonomer Solid-Phase Synthesis"" 5(11) : 1159-1162 (1995).;;Tomlinson and Rolland, ""Controllable Gene Therapy Pharmaceutics of Non-Viral Gene Delivery Systems"" J. Controlled Release 39:357-372, 1996.;;Verma et al., Gene therapy-promises, problems and prospects, Sep. 18, 1997, Nature, vol. 389, pp. 239-242.;;Wagner et al., ""DNA-Binding Transferrin Conjugates as Functional Gene-Delivery Agents: . . . "" Bioconjugate Chem. 2:226-231, 1991.;;Wagner et al., ""Influenza Virus Hemagglutinin HA-2 N-terminal Fusogenic Peptides Augment Gene Transfer by . . . "" PNAS USA 89:7934-7938, 1992.;;Wheeler et al., ""Converting an Alcohol to an Amine in a Cationic Lipid Dramatically Alters the Co-Lipid Requirement, . . . "" Biochim. et Biophsica Acta. 1280:1-11, 1996.",EXPIRED
835,US,A9,US 2008/0089938 A9,177-424-644-764-312,2008-04-17,2008,US 27875102 A,2002-10-22,US 27875102 A;;US 9714465 W;;US 62092500 A;;US 91064797 A;;US 2386796 P,1996-08-13,Compositions and methods for polynucleotide delivery,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",ZUCKERMANN RONALD N;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED E;;UNO TETSUO,ZUCKERMANN RONALD N;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED E;;UNO TETSUO,,https://lens.org/177-424-644-764-312,Amended Application,yes,7,5,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K48/00;;A61K9/14;;A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,424/484;;514/8;;530/324;;530/325;;530/327;;530/326;;514/44,0,0,,,,EXPIRED
836,US,B1,US 6468986 B1,004-997-933-238-225,2002-10-22,2002,US 62092500 A,2000-07-21,US 62092500 A;;US 91064797 A;;US 2386796 P,1996-08-13,Compositions and methods for polynucleotide delivery,"
    This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides. 
",CHIRON CORP,ZUCKERMANN RONALD N;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED E;;UNO TETSUO,,https://lens.org/004-997-933-238-225,Granted Patent,yes,19,37,17,17,4,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,514/44;;424/486;;424/450;;435/320.1;;435/325;;435/91.4;;435/455,28,24,019-810-335-711-889;;009-416-320-508-847;;059-172-353-640-68X;;157-947-201-686-965;;011-307-053-684-81X;;038-490-918-925-431;;114-517-649-646-486;;166-492-343-373-663;;096-317-125-842-948;;038-206-696-631-102;;050-885-886-277-521;;072-395-547-617-233;;035-886-556-173-632;;016-265-122-983-119;;118-843-647-887-744;;022-200-580-308-452;;071-211-641-209-775;;155-997-957-806-763;;001-596-965-870-798;;078-403-096-840-094;;028-650-332-166-498;;004-456-464-309-219;;175-833-149-417-043;;012-595-233-448-094,9579858;;9305836;;10.1038/38410;;9669880;;10.1016/s1359-0278(98)00030-3;;10.1021/bc00010a006;;1772904;;1518816;;pmc49829;;10.1073/pnas.89.17.7934;;7584089;;10.1021/bc00029a002;;7849066;;7584085;;8547238;;10.1021/bi952436a;;8750010;;10.1007/bf02789334;;7552693;;10.1021/bc00031a002;;7711106;;9001404;;10.1016/s0014-5793(96)01397-x;;7873664;;10.1021/bc00030a017;;10.1016/0960-894x(95)00187-x;;10.1089/hum.1995.6.9-1129;;8527471;;10.1016/0005-2736(95)00256-1;;8634302;;8607031;;8629036;;10.1074/jbc.270.42.24864;;7559609;;7619428;;10.1016/1045-1056(95)90004-7;;10.1016/0168-9525(95)90478-6;;10.1016/0169-409x(96)00002-6;;10.1016/0168-3659(96)01537-4;;9026036;;10.1021/bc960076d,"Raz et al., Cationic Lipids Inhibit Intradermal Genetic Vaccination, 1994, pp. 71-75.*;;Anderson et al., Human gene therapy, Apr. 30, 1998, Nature, vol. 392, pp. 25-30.*;;Verma et al., Gene therapy-promises, problems and prospects, Sep. 18, 1997, Nature, vol. 389, pp. 239-242.*;;Ngo et al., Computational Complexity Protein Structure Prediction, and the Levinthal Parasdox, 1994, vol. 14, pp. 492-495.*;;Chiu et al., Optimizing energy potentials for success in protein tertiary sturcture prediction, May 7, 1998, Folding & Design, vol. 3, pp. 223-228.*;;Wagner et al., ""DNA-Binding Transferrin Conjugates as Functional Gene-Delivery Agents: Synthesis by Linkage of Polylysine or Ethidium Homodimer to the Transferrin Carbohydrate Moiety"" Bioconjugate Chem. 2(4) :226-231, 1991.;;Wagner et al., ""Influenza Virus Hemagglutinin HA-2 N-terminal Fusogenic Peptides Augment Gene Transfer by Transferrin-Polylysine-DNA Complexes: Toward a Synthetic Virus-Like Gene-Transfer Vehicle"" Proc. Natl. Acad. Sci. USA 89:7934-7938, Sep., 1992.;;Batra et al., ""Receptor-Mediated Gene Delivery Emplyong Lectin-Binding Specificity"" Gene Therapy 1:255-260, 1994.;;Behr et al., ""Gene Transfer with Synthetic Cationic Amphiphiles: Prospects for Gene Therapy"" Bioconjugate Chem. 5:382-389, 1994.;;Michael and Curiel, ""Strategies to Achieve Targeted Gene Delivery via the Receptor-Mediated Endocytosis Pathway"" Gene Therapy 1:223-232, 1994.;;Gao and Huang, ""Potentiation of Cationic Liposome-Mediated Gene Transfer Delivery by Polycations"" Biochemistry 35:1027-1036, 1996.;;Gao and Huang, ""Cationic Liposome-Mediated Gene Transfer"" Gene Therapy 2:710-722, 1995.;;Guy et al., ""Delivery of DNA into Mammalian Cells by Receptor-Mediated Endocytosis and Gene Therapy"" Molecular Biology 3:237-248, 1995.;;Kabanov and Kabanov, ""DNA Complexes with Polycations for the Delivery of Genetic Material into Cells"" Bioconjugate Chem. 6:7-20, 1995.;;Behr et al., ""The Proton Sponge: a Trick to Enter Cells the Viruses did not Exploit"" Chimia 51:34-36 (1997).;;Hong et al., ""Stabilization of Cationic Liposome-Plasmid DNA Complexes by Polyamines and Poly(ethylene glycol) -phospholipid Conjugates for Efficient in vivo Gene Delivery"" FEBS Letters 400:233-237 (1997).;;Merwin et al., ""Targeted Delivery of DNA Using Yee(GalNacAH)3 , a Synthetic Glycopeptide Ligand for the Asialoglycoprotein Receptor"" Bioconjugate Chemistry 5(6):612-620 (1994).;;Richter and Zuckerman, ""Synthesis of Peptide Nucleic Acids (PNA) by Submonomer Solid-Phase Synthesis"" 5(11) : 1159-1162 (1995).;;Ledley, ""Nonviral Gene Therapy: The Promise of Genes as Pharmaceutical Products"" Human Gene Ther. 6:1129-1144, Sep. 1995.;;Wheeler et al., ""Converting an Alcohol to an Amine in a Cationic Lipid Dramatically Alters the Co-Lipid Requirement, Cellular Transfection Activity and The Ultrastructure of DNA-Cytofectin Complexes"" Biochim. et Biophsica Acta. 1280:1-11, 1996.;;Mastrangelo et al., ""Gene Therapy for Human Cancer: an Essay for Clinicians"" Seminars in Oncology 23:4-21, 1996.;;Ngo et al., in: The Protein Folding Problem and Tertiary Structure Prediction, 1994, Merz et ., (ed)., Birkhauser, Boston, MA, pp. 433 and 492-495.;;Liu et al., ""Cationic Liposome-Mediated Intravenous Gene Delivery"" J. Biological Chemistry 270(42):24864-24870, 1995.;;Phillips, ""Receptor-Mediated DNA Delivery Approaches to Human Gene Therapy"" Biologicals 23:13-16, 1995.;;Remy et al., ""Targeted Gene Transfer into Hepatoma Cells With Lipopolyamine-Condensed DNA Particles Presenting Galactose Ligands: a Stage Toward Artificial Viruses"" Proc. Natl. Acad. Sci. USA 92:1744-1748, Feb., 1995.;;Lasic and Tenpleton, ""Liposomes in Gene Therapy"" Advanced Drug Delivery Reviews 20:221-226, 1996.;;Tomlinson and Rolland, ""Controllable Gene Therapy Pharmaceutics of Non-Viral Gene Delivery Systems"" J. Controlled Release 39:357-372, 1996.;;Legendre et al., ""Dioleoylmelittin as a Novel Serum-Insensitive Reagent for Efficient Transfection of Mammalian Cells"" Bioconjugate Chem. 8:57-63, 1997.",EXPIRED
837,US,B1,US 6251433 B1,117-066-478-824-290,2001-06-26,2001,US 91064797 A,1997-08-13,US 91064797 A;;US 2386796 P,1996-08-13,Polycationic polymers,"This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides.",CHIRON CORP,ZUCKERMANN RONALD N;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED E;;UNO TETSUO,CHIRON CORPORATION (1997-09-22),https://lens.org/117-066-478-824-290,Granted Patent,yes,17,45,17,17,4,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,424/486;;424/450;;530/300;;530/333;;435/320.1;;525/54.1;;525/420,23,21,157-947-201-686-965;;011-307-053-684-81X;;038-490-918-925-431;;114-517-649-646-486;;166-492-343-373-663;;096-317-125-842-948;;038-206-696-631-102;;050-885-886-277-521;;072-395-547-617-233;;001-596-965-870-798;;078-403-096-840-094;;028-650-332-166-498;;004-456-464-309-219;;175-833-149-417-043;;012-595-233-448-094;;035-886-556-173-632;;016-265-122-983-119;;118-843-647-887-744;;022-200-580-308-452;;071-211-641-209-775;;155-997-957-806-763,10.1021/bc00010a006;;1772904;;1518816;;pmc49829;;10.1073/pnas.89.17.7934;;7584089;;10.1021/bc00029a002;;7849066;;7584085;;8547238;;10.1021/bi952436a;;8750010;;10.1007/bf02789334;;7552693;;10.1021/bc00031a002;;7711106;;10.1074/jbc.270.42.24864;;7559609;;7619428;;10.1016/1045-1056(95)90004-7;;10.1016/0168-9525(95)90478-6;;10.1016/0169-409x(96)00002-6;;10.1016/0168-3659(96)01537-4;;9026036;;10.1021/bc960076d;;9001404;;10.1016/s0014-5793(96)01397-x;;7873664;;10.1021/bc00030a017;;10.1016/0960-894x(95)00187-x;;10.1089/hum.1995.6.9-1129;;8527471;;10.1016/0005-2736(95)00256-1;;8634302;;8607031;;8629036,"Ngo et al., in: The Protein Folding Problem and Tertiary Structure Prediction, 1994, Merz et al., (ed.), Birkhauser, Boston, MA, pp. 433 and 492-495.;;Wagner et al., ""DNA-Binding Transferrin Conjugates as Functional Gene-Delivery Agents: Synthesis by Linkage of Polylysine or Ethidium Homodimer to the Transferrin Carbohydrate Moiety"" Bioconjugate Chem. 2(4):226-231, 1991.;;Wagner et al., ""Influenza Virus Hemagglutinin HA-2 N-terminal Fusogenic Peptides Augment Gene Transfer by Transferrin-Polylysine-DNA Complexes: Toward a Synthetic Virus-Like Gene-Transfer Vehicle"" Proc. Natl. Acad. Sci. USA89 :7934-7938, Sep., 1992.;;Batra et al., ""Receptor-Mediated Gene Delivery Emplyong Lectin-Binding Specificity"" Gene Therapy1 :255-260, 1994.;;Behr et al., ""Gene Transfer With Synthetic Cationic Amphiphiles: Prospects for Gene Therapy"" Bioconjugate Chem. 5:382-389, 1994.;;Michael and Curiel, ""Strategies to Achieve Targeted Gene Delivery via the Receptor-Mediated Endocytosis Pathway"" Gene Therapy 1:223-232, 1994.;;Gao and Huang, ""Potentiation of Cationic Liposome-Mediated Gene Transfer Delivery by Polycations"" Biochemistry 35 :1027-1036, 1996.;;Gao and Huang, ""Cationic Liposome-Mediated Gene Tranfer"" Gene Therapy 2 :710-722, 1995.;;Guy et al., ""Delivery of DNA into Mammalian Cells by Receptor-Mediated Endocytosis and Gene Therapy"" Molecular Biology 3:237-248, 1995.;;Kabanov and Kabanov, ""DNA Complexes with Polycations for the Delivery of Genetic Material into Cells"" Bioconjugate Chem. 6 :7-20, 1995.;;Liu et al., ""Cationic Liposome-Mediated Intravenous Gene Delivery"" J. Biological Chemistry 270 (42):24864-24870, 1995.;;Phillips, ""Receptor-Mediated DNA Delivery Approaches to Human Gene Therapy"" Biologicals 23 :13-16, 1995.;;Remy et al., ""Targeted Gene Transfer into Hepatoma Cells With Lipopolyamine-Condensed DNA Particles Presenting Galactose Ligands: a Stage Toward Artificial Viruses"" Proc. Natl. Acad. Sci. USA 92 :1744-1748, Feb., 1995.;;Lasic and Tenpleton, ""Liposomes in Gene Therapy"" Advanced Drug Delivery Reviews 20:221-226, 1996.;;Tomlinson and Rolland, ""Controllable Gene Therapy Pharmaceutics of Non-Viral Gene Delivery Systems"" J. Controlled Release 39 :357-372, 1996.;;Legendre et al., ""Dioleoylmelittin as a Novel Serum-Insensitive Reagent for Efficient Transfection of Mammalian Cells"" Bioconjugate Chem. 8 :57-63, 1997.;;Behr et al., ""The Proton Sponge: a Trick to Enter Cells the Viruses did not Exploit"" Chimia 51 :34-36 (1997).;;Hong et al., ""Stabilization of Cationic Liposome-Plasmid DNA Complexes by Polyamines and Poly(ethylene glycol)-phospholipid Conjugates for Efficient in vivo Gene Delivery"" FEBS Letters400 :233-237 (1997).;;Merwin et al., ""Targeted Delivery of DNA Using YEE(GalNAcAH)3, a Synthetic Glyopeptide Ligand for the Asialoglycoprotein Receptor"" Bioconjugate Chemistry 5 (6):612-620 (1994).;;Richter and Zuckermann, ""Synthesis of Peptide Nucleic Acids (PNA) by Submonomer Solid-Phase Synthesis"" 5(11):1159-1162 (1995).;;Ledley (Human Gene Ther. (1995) 6:1129-1144).*;;Wheeler et al. (Biochim. et Biophsica Acta 1280, 1996, 1-11).*;;Mastrangelo et al. (Seminars in Oncology, vol. 23, 1:4-21, 1996).*",EXPIRED
838,US,A1,US 2003/0185890 A1,020-436-902-374-662,2003-10-02,2003,US 27875102 A,2002-10-22,US 27875102 A;;US 9714465 W;;US 62092500 A;;US 91064797 A;;US 2386796 P,1996-08-13,Compositions and methods for polynucleotide delivery,"
   This invention relates compositions and methods for increasing the uptake of polynucleotides into cells. Specifically, the invention relates to vectors, targeting ligands, and polycationic agents. The polycationic agents are capable of (1) increasing the frequency of uptake of polynucleotides into a cell, (2) condensing polynucleotides; and (3) inhibiting serum and/or nuclease degradation of polynucleotides. 
",ZUCKERMANN RONALD N.;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A.;;MURPHY JOHN E.;;COHEN FRED E.;;UNO TETSUO,ZUCKERMANN RONALD N;;DUBOIS-STRINGFELLOW NATHALIE;;DWARKI VARAVANI;;INNIS MICHAEL A;;MURPHY JOHN E;;COHEN FRED E;;UNO TETSUO,,https://lens.org/020-436-902-374-662,Patent Application,yes,7,15,17,17,0,A61K38/1816;;A61K38/2264;;A61K48/00;;A61K48/0008;;A61K48/0041;;C07K7/08;;C07K14/001;;C12N15/87;;C12N2810/858;;A61K47/645;;A61P11/00;;A61P17/06;;A61P19/02;;A61P25/00;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;A61P3/06;;A61P7/00;;A61P7/04;;A61P7/06;;A61P9/10;;A61P3/10;;A61K38/2264;;A61K48/00;;A61K48/0041;;A61K48/0008;;C07K7/08;;C07K14/001;;A61K38/1816;;C12N2810/858;;C12N15/87;;A61K47/645,A61K31/711;;A61K38/00;;A61K38/18;;A61K38/22;;A61K47/30;;A61K47/48;;A61K48/00;;A61P3/06;;A61P3/10;;A61P7/00;;A61P7/06;;A61P9/10;;A61P29/00;;A61P31/00;;A61P31/12;;A61P35/00;;C07K7/08;;C07K14/00;;C12N15/87,424/484;;514/8;;530/324;;530/325;;530/327;;530/326;;514/44,0,0,,,,EXPIRED
839,US,A1,US 2007/0073823 A1,028-319-998-619-772,2007-03-29,2007,US 23952205 A,2005-09-29,US 23952205 A,2005-09-29,Method and apparatus to secure and retrieve instant messages,"A computer implemented method, apparatus, and computer usable code for managing instant messages. An instant message is received at a client. A set of parameters in the instant message is identified. The instant message on a display in the client is presented, and the instant message is removed from the display after a period of time defined by the set of parameters.",IBM,COHEN GABRIEL A;;COX PATRICK H JR;;CRAIG RONALD E;;HAYNES THOMAS R;;MITCHELL GERALD L JR;;SALAHSHOOR MOHAMAD R,INTERNATIONAL BUSINESS MACHINES CORPROATION (2005-09-16),https://lens.org/028-319-998-619-772,Patent Application,yes,14,504,4,4,0,G06Q10/107;;G06Q10/107;;H04L63/0428;;H04L63/0428;;H04L63/083;;H04L63/083,G06F15/16,709/207,0,0,,,,DISCONTINUED
840,CN,B,CN 1941698 B,002-373-098-686-199,2010-08-25,2010,CN 200610082759 A,2006-05-25,US 23952205 A,2005-09-29,Method for managing instant messages and data processing system,"A computer implemented method, apparatus, and computer usable code for managing instant messages. An instant message is received at a client. A set of parameters in the instant message is identified. The instant message on a display in the client is presented, and the instant message is removed from the display after a period of time defined by the set of parameters.",IBM,CRAIG RONALD E;;COX PATRICK H JR;;COHEN GABRIEL A;;MITCHELL GERALD L JR;;HAYNES THOMAS R;;SALAHSHOOR MOHAMAD R,,https://lens.org/002-373-098-686-199,Granted Patent,no,0,3,4,4,0,G06Q10/107;;G06Q10/107;;H04L63/0428;;H04L63/0428;;H04L63/083;;H04L63/083,H04L9/18,,0,0,,,,INACTIVE
841,WO,A1,WO 2022/186821 A1,115-321-268-175-897,2022-09-09,2022,US 2021/0020417 W,2021-03-02,US 2021/0020417 W,2021-03-02,METHODS AND COMPOSITIONS FOR PROVIDING A PREECLAMPSIA ASSESSMENT USING LEPTIN AND CERAMIDE,"Preeclampsia markers, preeclampsia marker panels, and methods for obtaining a preeclampsia marker level representation for a sample are provided. These composition and methods find use in a number of applications, including, for example, diagnosing preeclampsia, prognosing preeclampsia, monitoring a subject with preeclampsia, and determining a treatment for preeclampsia. In addition, systems, devices, and kits thereof that find use in practicing the subject methods are provided.",MPROBE INC;;THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR;;LING BRUCE XUEFENG;;CHEN LIMIN;;COHEN HARVEY J;;HAO SHIYING;;MCELHINNEY DOFF B;;SYLVESTER KARL G;;TIAN LU;;WONG RONALD J;;SHAW GARY M;;STEVENSON DAVID K,LING BRUCE;;CHEN LIMIN;;COHEN HARVEY;;HAO SHIYING;;MCELHINNEY DOFF;;SYLVESTER KARL;;TIAN LU;;WONG RONALD;;SHAW GARY;;STEVENSON DAVID,,https://lens.org/115-321-268-175-897,Patent Application,yes,2,0,1,1,0,G01N2800/368;;G01N33/92;;G01N33/689;;G01N33/74,G01N33/68;;C12Q1/68;;G01N33/53,,2,2,154-949-984-069-233;;136-517-352-737-721,10.22541/au.161111178.89108280/v1;;10.1101/2020.02.24.963462;;33017796;;10.1016/j.jpba.2020.113639,"HUANG QIANYANG, SHIYING HAO, JIN YOU, XIAOMING YAO, ZHEN LI, JAMES SCHILLING, ZHEN LI, SHEENO THYPARAMBIL: ""Case finding of early pregnancies at risk of preeclampsia using maternal blood leptin/ceramide ratio: multi-omics discovery and validation from a longitudinal study"", MEDRXIV, 7 January 2021 (2021-01-07), pages 1 - 33, XP055967859, Retrieved from the Internet <URL:http://dx.doi.org/10.1101/ 2020.12.17.20248418> [retrieved on 20221004], DOI: 10.1101/ 2020.12.17.20248418;;HUANG QIANYANG, HAO SHIYING, YAO XIAOMING, YOU JIN, LI XIAO, LAI DONGHAI, HAN CHUNLE, SCHILLING JAMES, HWA KUO YUAN, THYPARAMBIL S: ""Quantitative LCMS for ceramides/dihydroceramides: pregnancy baseline biomarkers and potential metabolic messengers"", BIORXIV, 25 February 2020 (2020-02-25), pages 1 - 52, XP055967866, [retrieved on 20221004], DOI: 10.1101/2020.02.24.963462",PENDING
842,JP,A,JP 2007095074 A,115-965-121-430-797,2007-04-12,2007,JP 2006265602 A,2006-09-28,US 23952205 A,2005-09-29,"COMPUTER IMPLEMENTED METHOD FOR MANAGING INSTANT MESSAGE, PROGRAM PRODUCT, AND DATA PROCESSING SYSTEM (METHOD AND APPARATUS TO SECURE AND RETRIEVE INSTANT MESSAGE)","<P>PROBLEM TO BE SOLVED: To provide a computer implemented method for managing instant messages, an apparatus, and a computer-usable code. <P>SOLUTION: An instant message is received at a client. A set of parameters in the instant message is identified. The instant message on a display in the client is presented, and the instant message is removed from the display after a period of time defined by the set of parameters. <P>COPYRIGHT: (C)2007,JPO&INPIT",IBM,PATRICK HERBERT COX JR;;GERALD LAVERTE MITCHELL JR;;THOMAS RICHARD HAYNES;;GABRIEL AARON COHEN;;RONALD EUGENE CRAIG;;MOHAMAD R SALAHSHOOR,,https://lens.org/115-965-121-430-797,Patent Application,no,5,7,4,4,0,G06Q10/107;;G06Q10/107;;H04L63/0428;;H04L63/0428;;H04L63/083;;H04L63/083,G06F13/00,,0,0,,,,PENDING
843,AU,B2,AU 2004/231254 B2,035-579-808-031-842,2009-03-19,2009,AU 2004/231254 A,2004-11-23,AU 2004/231254 A;;AU 2001/054106 A,2001-06-28,Methods of preventing breast cancer,,LILLY CO ELI,NICKELSON NIKOLAUS THOMAS;;GLUSMAN JOAN ELLEN;;ECKERT ROBERT STEPHEN;;COHEN FREDERIC JAY;;KNICKERBOCKER RONALD KEITH;;DRAPER MICHAEL WILLIAM;;SCOTT TERI JAMES,,https://lens.org/035-579-808-031-842,Granted Patent,no,1,0,5,5,0,,A61K31/4535;;A61P35/00,,0,0,,,,EXPIRED
844,AU,B8,AU 2004/231254 B8,187-929-077-178-072,2013-03-14,2013,AU 2004/231254 A,2004-11-23,AU 2004/231254 A;;AU 2001/054106 A,2001-06-28,Methods of preventing breast cancer,"Methods of Preventing Breast Cancer Abstract The invention provides a method for preventing breast cancer in a human which comprises administering to said human for a sufficient term an effective dose of a 5 compound of the formula COCH2CH2 -N (I) or a pharmaceutically acceptable salt or solvate thereof. The invention also provides a method for preventing invasive breast cancer in a 10 human which comprises administering to said human for a sufficient term an effective dose of the compound of formula (I) or a pharmaceutically acceptable salt or solvate thereof; a method for preventing invasive breast cancer in a post-menopausal human female which comprises administering to said post-menopausal human female for a sufficient 15 term an effective dose of the compound of formula (I) or a pharmaceutically acceptable salt or solvate thereof; a method for preventing invasive breast cancer comprising administering to a human for a sufficient term an effective dose of the compound of formula I or a pharmaceutically acceptable salt or solvate thereof, the human being at no particular risk 20 of developing breast cancer; a method for preventing breast cancer in a human, comprising administering to said human for a sufficient term and at an effective dose of raloxifene or a pharmaceutically acceptable salt or solvate thereof, wherein said effective dose is from 60mg to 120mg/day; and 25 a method for reducing the likelihood of the incurrence or development of breast cancer in a post-menopausal woman comprising administering to said woman 60 to 120mg/day of raloxifene or a pharmaceutically acceptable salt or solvate thereof.",LILLY CO ELI,DRAPER MICHAEL WILLIAM;;COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JAMES;;ECKERT ROBERT STEPHEN,,https://lens.org/187-929-077-178-072,Amended Patent,no,1,0,5,5,0,,A61K31/4535;;A61P35/00,,0,0,,,,EXPIRED
845,AU,A8,AU 2004/231254 A8,171-815-468-842-034,2013-03-14,2013,AU 2004/231254 A,2004-11-23,AU 2004/231254 A;;AU 2001/054106 A,2001-06-28,Methods of preventing breast cancer,"Methods of Preventing Breast Cancer Abstract The invention provides a method for preventing breast cancer in a human which comprises administering to said human for a sufficient term an effective dose of a 5 compound of the formula COCH2CH2 -N (I) or a pharmaceutically acceptable salt or solvate thereof. The invention also provides a method for preventing invasive breast cancer in a 10 human which comprises administering to said human for a sufficient term an effective dose of the compound of formula (I) or a pharmaceutically acceptable salt or solvate thereof; a method for preventing invasive breast cancer in a post-menopausal human female which comprises administering to said post-menopausal human female for a sufficient 15 term an effective dose of the compound of formula (I) or a pharmaceutically acceptable salt or solvate thereof; a method for preventing invasive breast cancer comprising administering to a human for a sufficient term an effective dose of the compound of formula I or a pharmaceutically acceptable salt or solvate thereof, the human being at no particular risk 20 of developing breast cancer; a method for preventing breast cancer in a human, comprising administering to said human for a sufficient term and at an effective dose of raloxifene or a pharmaceutically acceptable salt or solvate thereof, wherein said effective dose is from 60mg to 120mg/day; and 25 a method for reducing the likelihood of the incurrence or development of breast cancer in a post-menopausal woman comprising administering to said woman 60 to 120mg/day of raloxifene or a pharmaceutically acceptable salt or solvate thereof.",LILLY CO ELI,DRAPER MICHAEL WILLIAM;;COHEN FREDERIC JAY;;GLUSMAN JOAN ELLEN;;KNICKERBOCKER RONALD KEITH;;NICKELSEN NIKOLAUS THOMAS;;SCOTT TERI JAMES;;ECKERT ROBERT STEPHEN,,https://lens.org/171-815-468-842-034,Patent Application,no,1,0,5,5,0,,A61K31/4535;;A61P35/00,,0,0,,,,EXPIRED
846,CZ,A3,CZ 20032614 A3,062-207-414-610-368,2004-03-17,2004,CZ 20032614 A,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,CZ 20032614 A3,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/062-207-414-610-368,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
847,EP,A1,EP 1859798 A1,077-298-429-129-869,2007-11-28,2007,EP 07015058 A,2002-03-15,EP 02731094 A;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,"The present invention relates to the use compounds of formula I
  
which are antagonists of the 5-HT 6  receptor, for treating a cognitive disorder selected from the group consisting of age-related cognitive decline, mild cognitive impairment and dementia",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;GIETHLEN BRUNO,,https://lens.org/077-298-429-129-869,Patent Application,yes,2,2,3,58,0,A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07F7/0812,A61K31/4045;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07F7/08,,0,0,,,,EXPIRED
848,EP,B1,EP 1859798 B1,182-295-063-596-878,2015-12-30,2015,EP 07015058 A,2002-03-15,EP 02731094 A;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;GIETHLEN BRUNO,,https://lens.org/182-295-063-596-878,Granted Patent,yes,2,1,3,58,0,A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07F7/0812,A61K31/4045;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07F7/08,,0,0,,,,EXPIRED
849,HR,A2,HR P20030771 A2,098-297-765-810-802,2005-08-31,2005,HR P20030771 A,2003-09-24,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT<SUB>6</SUB> RECEPTOR,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/098-297-765-810-802,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
850,CA,C,CA 2737847 C,184-774-450-506-247,2013-08-06,2013,CA 2737847 A,2004-10-04,US 83069304 A;;CA 2483825 A,2004-04-23,TOOTHBRUSH HAVING DIVERSE CLEANING ELEMENT ARRANGEMENT,"The present invention relates to a toothbrush, which includes a head and tooth cleaning elements extending from a top surface of the head. The toothbrush has a diverse cleaning element arrangement, wherein one of the groups of the tooth cleaning elements located toward the inside of the head, and is made of a thermoplastic elastomer, and comprises a plurality of curved walls and/or fins or substructures, which are unitary with one another.",GILLETTE CO,BRAUN PHILIP M;;DUFF RONALD R JR;;SYNODIS JOSEPH;;COHEN RICHARD H;;MASTERMAN THOMAS CRAIG;;CHENVAINU ALEXANDER T;;BROWN WILLIAM RALPH JR,,https://lens.org/184-774-450-506-247,Granted Patent,no,0,0,35,53,0,A46B5/0025;;A46B7/06;;A46B9/045;;A46B9/06;;A46B2200/1066;;A61C17/3481;;B29C45/0055;;B29L2031/425;;A46B13/02;;A61C17/3481;;A46B5/0025;;A46B2200/1066;;A46B7/06;;B29L2031/425;;B29C45/0055;;A46B9/045;;A46B9/06,A46B9/04;;A46B7/06;;A46B9/06;;A46B13/02;;A46D1/00;;A61C17/22;;A61C17/34,,0,0,,,,ACTIVE
851,EP,A2,EP 1379239 A2,010-214-856-278-701,2004-01-14,2004,EP 02731094 A,2002-03-15,US 0205115 W;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/010-214-856-278-701,Patent Application,yes,0,9,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
852,SK,A3,SK 12052003 A3,079-694-705-072-553,2004-09-08,2004,SK 12052003 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-arylethyl) benzylamines as antagonists of 5-HT6 receptor,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/079-694-705-072-553,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
853,NO,L,NO 20034289 L,097-883-270-783-975,2003-11-28,2003,NO 20034289 A,2003-09-25,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-aryletyl)benzylaminer som antagonister av 5-HT6- reseptoren,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/097-883-270-783-975,Abstract,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
854,DK,T3,DK 1859798 T3,147-057-685-996-865,2016-03-21,2016,DK 07015058 T,2002-03-15,US 27992801 P;;US 32944901 P;;EP 02731094 A,2001-03-29,N-(2-ARYLETHYL) -BENZYLAMINER SOM ANTAGONISTER AF 5-HT6-RECEPTOREN,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;GIETHLEN BRUNO,,https://lens.org/147-057-685-996-865,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
855,HR,B1,HR P20030771 B1,031-164-436-484-487,2008-10-31,2008,HR P20030771 A,2003-09-24,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT<SUB>6</SUB> RECEPTOR,"Spoj formulenaznačen time, štoX je odabran iz skupine koju sačinjavaju -O-, -NH-, -S-, -SO2-, -CH2-, -CH(F)-, -CH(OH)-, i-C(O)-; R1 je odabran iz skupine koju sačinjavaju po potrebi supstituirani fenil, po potrebi supstituirani naftil, po potrebi supstituirani 5 do 6 člani monociklički aromatski heterocikl koji ima jedan heteroatom odabran iz skupine koju sačinjavaju dušik, kisik, i sumpor i koji5 do 6 člani monociklički aromatski heterocikl jepo potrebi benzokondenziran; R2 je odabran iz skupine koju sačinjavaju vodik i C1-C3 alkil; R3 je odabran iz skupine koju sačinjavaju vodik, fluor, imetil; R4 je odabran iz skupine koju sačinjavaju vodik, alil, C2-C4 alkil, fluorirani C2-C4 alkil, po potrebi supstituirani fenil, po potrebi supstituirani fenilsulfonil, po potrebi supstituirani benzil, i po potrebi supstituirani 5 do 6 člani monociklički aromatski heterocikl koji ima jedan ili dva heteroatoma odabrana iz skupine koju sačinjavajudušik, kisik, i sumpor, pod uvjetom da R4 nije popotrebi supstituirani fenilsulfonil kad X je -SO2-, -CH2-, CH(F)-, - CH(OH)-, ili-C(O)-; gdje ""po potrebi supstituirani fenil"" označava radikal formulegdje je Ra iz 1 do 3 skupine koje se nezavisno biraju iz skupine koja se sastoji iz vodika, hidroksilne, C1-C4 alkilne, C1-C4 alkoksi, halogena, benziloksi, karboksi, C1-C4 alkoksikarbonil, amido, N-(C1-C4 alkil)amido, sulfonilamido, cijano, trifluorometil, trifluorometoksi, nitro i fenil supstituiran ili nesupstituiran s C1-C4 alkil, C1-C4 alkoksi, halogen, cijano ili trifluorometil; ""po potrebi supstituiran naftil"" označava radikal formulegdje je Rc iz 1 do 2 skupine nezavisno birane iz skupine koja se sastoji iz vodika, C1-C4 alkil, C1-C4alkoksi, halogen, cijano, trifluorometil i nitro;""po potrebi supstituirani 5 do 6 člani monociklički aromatski heterocikl koji ima jedan heteroatom odabran iz skupine koja se sastoji iz dušika, kisika, sumpora i kod kojeg po potrebi 5 do 6 člani monociklički aromatski heterocikl je po potrebi benzokondenziran"" označava radikal formule gdje se se Q1 odabire iz skupine koja se sastoji od -O-, -S-,i -NRg- gdje se Rg bira iz skupine koja se sastoji od vodika i C1-C4 alkila; Q2 je -N=, Rd, svaki Re i Rf nezavisno odabrani iz skupine koja se sastoji od vodika, C1-C4 alkila, C1-C4 alkoksi, halogena, cijano, i trifluorometila i Rd i Re (ili jedan od Re) uzetih zajedno s atomima na koje su pričvršćeni stvarajuću benzenski prsten kod kojih je benzenski prsten nesupstituiran ili supstituiran s 1 do 4 supstituenta nezavisno biranih iz skupine kojase sastoji iz vodika, hidroksi, C1-C4 alkila, C1-C4 alkoksi, trifluorometoksi, 2,2,2-trifluoroetoksi, trifluorometila, halogena, karboksi, C1-C4 alkoksikarbonila, amido, N-(C1-C4 alkil)amido, amino, (C1-C4 alkil)amino, acilamino gdje se acilna skupina bira iz skupine koja se sastoji iz C1-C4 alkilai fenila; cijano, nitro, sulfonilamido, fenil nesupstituirani i supstituirani s C1-C4 alkilom, C1-C4 alkoksi, halogenom, cijano ili trifluorometilom;fenoksi, be",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/031-164-436-484-487,Granted Patent,no,2,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
856,HU,B1,HU 230322 B1,083-846-890-025-672,2016-01-28,2016,HU P0303651 A,2002-03-15,US 32944901 P;;US 0205115 W;;US 27992801 P,2001-03-29,N-(2-arylethyl)-benzylamines as antagonists of the 5-ht6 receptor and pharmaceutical compositions containing them,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/083-846-890-025-672,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
857,NZ,A,NZ 527815 A,100-296-248-794-977,2005-05-27,2005,NZ 52781502 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-arylethyl)benzylamines as antagonists of the 5-HT6 receptor,"Compounds of formula (I) and pharmaceutically acceptable salts thereof, which are antagonists of the 5-HT6 receptor are disclosed, wherein: X is selected from the group consisting of -O-, -NH-, -S-, -SO2-, -CH2-, -CH(F)-, -CH(OH)-, and -C(O)-; R1 is selected from the group consisting of optionally substituted phenyl provided that R1 is not C1-C4 alkoxy optionally substituted phenyl, optionally substituted naphthyl, optionally substituted 5 to 6 membered monocyclic aromatic heterocycle having one heteroatom selected from the group consisting of nitrogen, oxygen, and sulfur and which 5 to 6 membered monocyclic aromatic heterocycle is optionally benzofused; R2 is selected from the group consisting of hydrogen and C1-C3 alkyl; R3 is selected from the group consisting of hydrogen, fluoro, and methyl; R4 is selected from the group consisting of hydrogen, allyl,C2-C4 alkyl, fluorinated C2-C4 alkyl, optionally substituted phenyl, optionally substituted phenylsulfonyl, optionally substituted benzyl, and optionally substituted 5 to 6 membered monocyclic aromatic heterocycle having one or two heteroatoms selected from the group consisting of nitrogen, oxygen, and sulfur, provided that R4 is not optionally substituted phenylsulfonyl when X is -SO2-, -CH2-, CH(F)-, - CH(OH)-, or -C(O)-.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/100-296-248-794-977,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,DISCONTINUED
858,US,A1,US 2009/0306110 A1,113-293-600-070-942,2009-12-10,2009,US 50424209 A,2009-07-16,US 50424209 A;;US 60892206 A;;US 47274104 A;;US 0205115 W;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,"The present invention provides compounds of formula (I), which are antagonists of the 5-HT 6 receptor.",CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/113-293-600-070-942,Patent Application,yes,1,5,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/404;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/435;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/445;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,514/269;;514/415;;514/297;;514/319,0,0,,,,EXPIRED
859,ZA,B,ZA 200306795 B,172-427-059-336-087,2005-02-23,2005,ZA 200306795 A,2003-08-29,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,ZHAOGEN CHEN;;MATTHEW JOSEPH FISHER;;JAMES RONALD GILLIG;;SHAWN CHRISTOPHER MILLER;;MICHAEL PHILIP COHEN;;BRUNO GIETHLEN;;JEFFERSON RAY MCCOWAN;;JOHN MEHNERT SCHAUS,,https://lens.org/172-427-059-336-087,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K/;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P/;;A61P25/18;;A61P25/22;;A61P25/28;;C07C/;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D/;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
860,US,A1,US 2004/0132800 A1,171-363-972-312-310,2004-07-08,2004,US 47274104 A,2004-02-27,US 47274104 A;;US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-arylethyl) benzylamines as antagonists of the 5-ht6 receptor,"
    The present invention provides compounds of formula (I), which are antagonists of the 5-HT ₆ receptor. 
",CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/171-363-972-312-310,Patent Application,yes,2,4,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;C07D233/64;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,514/419;;548/503,0,0,,,,EXPIRED
861,NO,B1,NO 326160 B1,187-739-403-246-767,2008-10-13,2008,NO 20034289 A,2003-09-25,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-aryletyl)benzylaminer som antagonister av 5-HT6-reseptoren,,LILLY CO ELI,MCCOWAN JEFFERSON RAY;;FISHER MATTHEW JOSEPH;;SCHAUS JOHN MEHNERT;;CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MILLER SHAWN CHRISTOPHER,,https://lens.org/187-739-403-246-767,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D209/16;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
862,CZ,B6,CZ 305838 B6,057-992-222-239-379,2016-04-06,2016,CZ 20032614 A,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-arylethyl)benzylamines as 5-HT6 receptor antagonists,"The present invention relates to a compound, which is N-(2-(6-fluoro-1H-indol-3-yl)ethyl)-3-(2,2,3,3-tetrafluoropropoxy)benzylamine or pharmaceutically acceptable salt thereof",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/057-992-222-239-379,Granted Patent,no,2,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,1,1,025-016-564-757-660,10.1021/ja01283a038,"Ide, W. S., et al: J. Am. Chem. Soc. 1937 (59), 726 - 731",EXPIRED
863,WO,A3,WO 2002/078693 A3,081-873-567-496-088,2002-12-05,2002,US 0205115 W,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,"The present invention provides compounds of formula (I), which are antagonists of the 5-HT6 receptor.",LILLY CO ELI;;CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/081-873-567-496-088,Search Report,yes,2,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,3,0,,,"DATABASE CROSSFIRE BEILSTEIN [online] Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; IDE, BUCK, XP002209139, Database accession no. 3365864;;DATABASE CROSSFIRE BEILSTEIN [online] Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; XP002209140, Database accession no. 3365863;;DATABASE CROSSFIRE BEILSTEIN [online] Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; IDE, BUCK, XP002209141, Database accession no. 3380345",PATENTED
864,DE,T2,DE 60222396 T2,013-783-237-100-743,2008-05-15,2008,DE 60222396 T,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINE ALS 5-HT6 REZEPTOR-ANTAGONISTE,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/013-783-237-100-743,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
865,US,B2,US 8044090 B2,126-397-173-683-67X,2011-10-25,2011,US 50424209 A,2009-07-16,US 50424209 A;;US 60892206 A;;US 47274104 A;;US 0205115 W;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-arylethyl)benzylamines as antagonists of the 5-HT6 receptor,"The present invention provides compounds of formula (I), which are antagonists of the 5-HT 6 receptor.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/126-397-173-683-67X,Granted Patent,yes,19,12,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,514/418;;514/654;;548/503,17,11,083-585-927-346-056;;112-610-281-471-879;;157-279-218-008-692;;047-306-566-051-286;;126-095-024-405-293;;025-016-564-757-660;;000-896-608-204-760;;005-636-205-780-457;;023-674-069-451-316;;134-360-960-183-43X;;000-755-952-293-257,10.1016/s0223-5234(00)01209-5;;11311747;;7616396;;11163639;;10.1016/s0166-4328(00)00316-8;;10.1007/s002130100840;;11702084;;8027974;;10.1021/jm00039a004;;10.1021/ja01283a038;;11055342;;10.1016/s0960-894x(00)00453-4;;11140741;;11140722;;11140733;;11140734;;10.1016/s0960-894x(00)00597-7;;10937732;;10.1016/s0960-894x(00)00320-6;;10.1039/jr9630004545;;10.1007/bf00629975,"ACS Chemcats 2000:1020106, Order No. STOCK1S-08349, CAS Registry No. 302795-49-9.;;Bos et al., ""5-HT6 receptor antagonists: lead optimization and biological evaluation of N-aryl and N-heteroaryl 4-amino-benzene sulfonamides,"" Eur J. Med. Chem., vol. 36, pp. 165-178 (2001).;;Bourson et al, ""Determination of the Role of the 5-ht6 Receptor in the Rat Brain: A Study using Antisense Oligonucleotides,"" J. of Pharm. and Experimental Therapeutics, vol. 274, No. 1, pp. 173-180 (1995).;;Meneses, Alfredo, ""Effects of the 5-HT6 receptor antagonist Ro 04-6790 on learning consolidation,"" Behavioral Brain Research, vol. 118, pp. 107-110 (2001).;;Rogers et al., ""5-HT6 receptor antagonists enhance retention of a water maze task in the rat,"" PsvchopharmacoloEy, vol. 158, pp. 114-119 (2001).;;Glennon, et al. ""Influence of Amine Substituents on 5-HT2A versus 5-HT2C-Binding of Phenylakllyl- and Indolylalkylamines"" J. Med. Chem., 1994, 37, 1929-1935.;;Glennon, et al., 5-HT6 Serotonin Receptor Binding of Indolealkylamines: A Preliminary Structure-Affinity Investigation. Med. Chem. Res., 1999, 9, 108-117.;;Ide et al. ""Pharmacologically Active Compounds from Alkoxy-B-phenylethylamines"" Journal of the American Chemical Society 1937, 726-731.;;Tsai et al. ""N1-(Benzenesulfonyl)tryptamines as Novel 5-HT6 Antagonists"" Bioorganic & Medicinal Chemistry Letters 2000, 2295-2299.;;Bromidge et al. ""Phenyl Benzenesulfonamides are Novel and Selective 5-HT6 Antagonists: Identification of . . . "" Bioorganic & Medicinal Chemistry Letters 2001, 55-58.;;Isaac et al. ""6-Bicyclopiperazinyl-1-arylsulfonylindoles and 6-Bicyclopiperidinyl-1-arylsulfonylindoles Derivatives as Novel, Potent, and Selective 5-HT6 Receptor Antagonists"" Bioorganic & Medicinal Chemistry Letters 2000, 1719-1721.;;Database Crossfire Beilstein Online! Beilstein Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(3-ethoxy-phenethyl)-amine), Database accession No. 3365863: XP002209140, 1992.;;Database Crossfire Beilstein Online! Beilstein Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(4-ethoxy-phenethyl)-amine), IDE, BUCK: Database accession No. 3365864; XP002209139, 1992.;;Database Crossfire Beilstein Online! Beilstein Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(2-ethoxy-henethyl)-amine), IDE, BUCK: Database accession No. 3380345; XP002209141, 1992.;;Barton, et al., ""886. Phenol Oxidation and Biosynthesis. Part VI. The Biogenesis of Amaryllidaceae Alkaloids,"" Barton, Kirby, Taylor and Thomas, pp. 4545-4558 (1963).;;Vinogradova, et al., ""Synthesis Based on b-Phenylethylamines. IV. Synthesis and Antiarrhythmic Activity of Substituted Phenylalkylamines and N-Benzyltetrahydroisoquinolines,"" vol. 29, No. 3, pp. 259-414 (1993).;;Vinogradova, et al., ""Syntheses Based on b-Ethylamines. VIII. Synthesis of Substituted 2-Benzyltetrahydroisoquinolines and Their Influence on Bile Secretion,"" vol. 30, No. 3, pp. 368-370 (1994).",EXPIRED
866,WO,A2,WO 2002/078693 A2,166-191-225-915-127,2002-10-10,2002,US 0205115 W,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,"The present invention provides compounds of formula (I), which are antagonists of the 5-HT6 receptor.",LILLY CO ELI;;CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/166-191-225-915-127,Patent Application,yes,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07D233/64;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,PATENTED
867,EC,A,EC SP034781 A,011-130-456-962-393,2003-12-01,2003,EC SP034781 A,2003-09-26,US 27992801 P,2001-03-29,N-(2-ARILETIL) BENCILAMINAS COMO ANTAGONISTAS DEL RECEPTOR 5-HT6,"Un compuesto de fórmula (Grafico) en el que X se selecciona del grupo constituido por -O-, -NH-, -S-, -SO2-, -CH2-, -CH(F)-, CH(OH)-,Y-C(O)-;R1 se selecciona del grupo constituido por fenilo opcionalmente sustituido, heterociclo aromático monociclito de 5 a 6 miembros opccionalmente sustituido que tiene un heteroátomo seleccionado del grupo constituido por nitrógeno, oxigeno y azufre y dicho heterociclo aromático monociclico de 5 a 6 miembros está opcionalmente benzocondensado; R2 se selecciona del grupo constituido por hidrogeno y alquilo C1-C3; R3 se selecciona del grupo constituido por hidrogeno, fluoro, y metilo; R4 se selecciona del grupo constituido por hidrógeno, alilo, alquilo C2- C4, alquilo C2-C4 fluorado, fenilo opcionalmente sustituido, fenilsulfonilo opcionalmente sustituido, bencilo opcionalmente sustituido, y heterociclo aromático monociclico de 5 a 6 miembros opcionalmente sustituido que tiene uno o dos heteroátomos seleccionados del grupo constituido por nitrógeno, oxigeno, y azúfre, con la condición de que R4 no sea fenilsulfonilo opcionalmente sustituido cuando X es -S02-; -CH2-, -CH(F)-, -CH(OH)-, 0- C(0)-; y sales farmacéuticamente aceptables del mismo.",LILLY CO ELI,COHEN MICHAEL PHILIP;;GIETHLEN BRUNO;;MILLER SHAWN CHRISTOPHER;;CHEN ZHAOGEN;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;SCHAUS JOHN MEHNERT,,https://lens.org/011-130-456-962-393,Patent Application,no,0,0,2,58,0,,A61K/;;A61P/;;C07C/;;C07D/;;C07D209/14;;C07D213/64;;C07D233/24;;C07D233/34;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20,,0,0,,,,PENDING
868,PT,E,PT 1859798 E,057-087-382-798-209,2016-03-31,2016,PT 07015058 T,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,JOHN MEHNERT SCHAUS;;JAMES RONALD GILLIG;;MATTHEW JOSEPH FISHER;;SHAWN CHRISTOPHER MILLER;;MICHAEL PHILIP COHEN;;ZHAOGEN CHEN;;BRUNO GIETHLEN;;JEFFERSON RAY MCCOWAN,,https://lens.org/057-087-382-798-209,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
869,NO,D0,NO 20034289 D0,071-748-677-185-998,2003-09-25,2003,NO 20034289 A,2003-09-25,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-aryletylbenzylaminer som antagonister av 5-HT6- reseptoren,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/071-748-677-185-998,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
870,CA,A1,CA 2442114 A1,094-724-615-084-09X,2002-10-10,2002,CA 2442114 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,"The present invention provides compounds of formula (I), which are antagonists of the 5-HT6 receptor.",LILLY CO ELI,SCHAUS JOHN MEHNERT;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;CHEN ZHAOGEN,,https://lens.org/094-724-615-084-09X,Patent Application,no,0,2,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
871,US,B2,US 7157488 B2,103-941-301-267-964,2007-01-02,2007,US 47274104 A,2004-02-27,US 47274104 A;;US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-Arylethyl) benzylamines as antagonists of the 5-HT6 receptor,"The present invention provides compounds of formula I pharmaceutically acceptable salts thereof, and pharmaceutical compositions thereof, which are antagonists of the 5-HT 6 receptor. The present invention further provides a method of treating disorders associated with 5-HT 6 receptors, including schizophrenia, anxiety, Alzheimer's disease, and cognitive disorders selected from the group consisting of age-related cognitive decline, mild cognitive impairment, and dementia, comprising: administering to a patient in need thereof an effective amount of a compound of formula I.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/103-941-301-267-964,Granted Patent,yes,7,28,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/00;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,514/418;;514/654;;548/503;;564/503,16,10,000-896-608-204-760;;005-636-205-780-457;;023-674-069-451-316;;025-016-564-757-660;;134-360-960-183-43X;;000-755-952-293-257;;083-585-927-346-056;;112-610-281-471-879;;157-279-218-008-692;;047-306-566-051-286,11055342;;10.1016/s0960-894x(00)00453-4;;11140741;;11140722;;11140733;;11140734;;10.1016/s0960-894x(00)00597-7;;10937732;;10.1016/s0960-894x(00)00320-6;;10.1021/ja01283a038;;10.1039/jr9630004545;;10.1007/bf00629975;;10.1016/s0223-5234(00)01209-5;;11311747;;7616396;;11163639;;10.1016/s0166-4328(00)00316-8;;10.1007/s002130100840;;11702084,"Database Crossfire Beilstein Online! Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main DE; (3-ethoxy-benzyl)-(3-ethoxy-phenethyl)-amine), Database accession No. 3365863: XP002209140.;;Tsai et al. ""N1-(Benzenesulfonyl)tryptamines as Novel 5-HT6 Antagonists"" Bioorganic & Medicinal Chemistry Letters 2000, 2295-2299.;;Bromidge et al. ""Phenyl Benzenesulfonamides are Novel and Selective 5-HT6 Antagonists: Identification of . . . "" Bioorganic & Medicinal Chemistry Letters, 2001, 55-58.;;Isaac et al. ""6-Bicyclopiperazinyl-1-arylsulfonylindoles and 6-Bicyclopiperidinyl-1-arylsulfonylindoles Derivatives as Novel, Potent, and Selective 5-HT6 Receptor Antagonists"" Bioorganic & Medicinal Chemistry Letters 2000, 1719-1721.;;Ide et al. ""Pharmacologically Active Compounds from Alkoxy-B-phenylethylamines"" Journal of the American Chemical Society 1937, 726-731.;;Database Crossfire Beilstein Online! Beilstein Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(4-ethoxy-phenethyl)-amine), IDE, BUCK: Database accession No. 3365864; XP002209139.;;Database Crossfire Beilstein Online! Beilstein Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(3-ethoxy-phenethyl)-amine), Database accession No. 3365863; XP002209140.;;Database Crossfire Beilstein Online! Beilstein Institut zur Forderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(2-ethoxy-henethyl)-amine), IDE, BUCK: Database accession No. 3380345; XP002209141.;;Barton, et al., ""886. Phenol Oxidation and Biosynthesis. Part VI. The Biogenesis of Amaryllidaceae Alkaloids,"" Barton, Kirby, Taylor and Thomas, pp. 4545-4558 (1963).;;Vinogradova, et al., ""Synthesis Based on b-Phenylethylamines. IV. Synthesis and Antiarrhythmic Activity of Substituted Phenylalkylamines and N-Benzyltetrahydroisoquinolines,"" vol. 29, No. 3, pp. 259-414 (1993).;;Vinogradova, et al., ""Syntheses Based on b-Ethylamines. VIII. Synthesis of Substituted 2-Benzyltetrahydroisoquinolines and Their Influence on Bile Secretion,"" vol. 30, No. 3, pp. 368-370 (1994).;;ACS Chemcats 2000:1020106, Order No. STOCK1S-08349, CAS Registry No. 302795-49-9.;;Bos et al., ""5-HT6 receptor antagonists: lead optimization and biological evaluation of N-aryl and N-heteroaryl 4-amino-benzene sulfonamides,"" Eur J. Med. Chem., vol. 36, pp. 165-178 (2001).;;Bourson et al., ""Determination of the Role of the 5-ht6 Receptor in the Rat Brain: A Study using Antisense Oligonucleotides,"" J. of Pharm. And Experimental Therapeutics, vol. 274, No. 1, pp. 173-180 (1995).;;Meneses, Alfredo, ""Effects of the 5-HT6 receptor antagonist Ro 04-6790 on learning consolidation,"" Behavioral Brain Research, vol. 118, pp. 107-110 (2001).;;Rogers et al., ""5-HT6 receptor antagonists enhance retention of a water maze task in the rat,"" Psychopharmacology, vol. 158, pp. 114-119 (2001).",EXPIRED
872,EP,B1,EP 1379239 B1,163-068-881-384-229,2007-09-12,2007,EP 02731094 A,2002-03-15,US 0205115 W;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/163-068-881-384-229,Granted Patent,yes,2,4,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,3,0,,,"DATABASE CROSSFIRE BEILSTEIN [Online] Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(4-ethoxy-phenethyl)-ami ne), IDE, BUCK: Database accession no. 3365864 XP002209139 & J.AM.CHEM.SOC., vol. 59, 1937, page 726ff;;DATABASE CROSSFIRE BEILSTEIN [Online] Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(3-ethoxy-phenethyl)-ami ne), Database accession no. 3365863 XP002209140 & IDE, BUCK: J.AM.CHEM.SOC, vol. 59, 1937, page 726ff;;DATABASE CROSSFIRE BEILSTEIN [Online] Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(2-ethoxy-phenethyl)-ami ne), IDE, BUCK: Database accession no. 3380345 XP002209141 & J.AM.CHEM.SOC., vol. 59, 1937, page 726ff",EXPIRED
873,DE,C2,DE 2604981 C2,174-744-841-919-014,1985-01-03,1985,DE 2604981 A,1976-02-09,US 54959775 A;;US 54959875 A;;US 54960075 A;;US 54960175 A,1975-02-12,DE 2604981 C2,,"UNITED TECHNOLOGIES CORP., HARTFORD, CONN., US","BLOOMFIELD, DAVID PETER, WHITING LANE, CONN., US;;COHEN, RONALD;;LANDAU, MICHAEL BERNARD, WEST HARTFORD, CONN., US;;MENARD, MAURICE CLEMENT, ENFIELD, CONN., US",,https://lens.org/174-744-841-919-014,Granted Patent,no,0,3,7,38,0,F02C6/00;;F02C6/10;;H01M8/0612;;H01M8/04007;;H01M8/04014;;H01M8/04029;;H01M8/04089;;H01M8/04156;;Y02E60/50;;Y02T50/60,F01K23/00;;F02C6/00;;F02C6/10;;H01M8/04;;H01M8/06,,0,0,,,,EXPIRED
874,CY,T1,CY 1110362 T1,176-001-243-687-407,2015-04-29,2015,CY 071101516 T,2007-11-27,EP 02731094 A;;US 27992801 P;;US 32944901 P,2001-03-29,Ν-(2-ΑΡΥΛΑΙΘΥΛΟ)ΒΕΝΖΥΛΑΜΙΝΕΣ ΩΣ ΑΝΤΑΓΩΝΙΣΤΕΣ ΤΟΥ 5-ΗΤ6 ΥΠΟΔΟΧΕΑ,"Η παρούσα εφεύρεση παρέχει ενώσεις του τύπου (Ι), οι οποίες είναι ανταγωνιστές του 5-ΗΤ6 υποδοχέα.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/176-001-243-687-407,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,ACTIVE
875,HU,A2,HU P0303651 A2,198-430-429-124-964,2004-03-01,2004,HU P0303651 A,2002-03-15,US 32944901 P;;US 0205115 W;;US 27992801 P,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR AND PHARMACEUTICAL COMPOSITIONS CONTAINING THEM,"A találmány (I) általános képletű - ahol X jelentése oxigén-, kénatom,-NH-, -SO2-, -CH2-, -CH(F)-, -CH(OH)- vagy -C(O)képletű csoport; R1jelentése adott esetben helyettesített fenilcsoport, adott esetbenhelyettesített naftilcsoport vagy adott esetben helyettesített, 5-6tagú, egygyűrűs, aromás, egy heteroatomot - mely lehet nitrogén-,oxigén- vagy kénatom - tartalmazó heterociklusos csoport, mely adottesetben benzolgyűrűvel kondenzált; R2 jelentése hidrogénatom vagy 1-3szénatomos alkilcsoport; R3 jelentése hidrogénatom, fluoratom vagy metilcsoport; R4jelentése hidrogénatom, allil-, 2-4 szénatomos alkil-, fluorozott, 2-4szénatomos alkil-, adott esetben helyettesített fenil-, adott esetbenhelyettesített fenil-szulfonil-, adott esetben helyettesítettbenzilcsoport vagy adott esetben helyettesített, 5-6 tagú, egygyűrűs,aromás, egy vagy két heteroatomot - mely lehet nitrogén-, oxigén- vagykénatom - tartalmazó heterociklusos csoport; azzal a feltétellel, hogyamikor X jelentése -SO2-, -CH2-, -CH(F)-, -CH(OH)- vagy -C(O)- képletűcsoport, R4 jelentése nem lehet adott esetben helyettesített fenil-szulfonil-csoport - vegyületekkel foglalkozik, melyek 5-HT6receptorantagonisták. A találmány kiterjed a vegyületeket tartalmazógyógyszerkészítményekre is. Ó",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/198-430-429-124-964,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;C07D233/64;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
876,SI,T1,SI 1859798 T1,040-592-802-114-169,2016-07-29,2016,SI 200231068 A,2002-03-15,US 27992801 P;;US 32944901 P;;EP 07015058 A,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;GIETHLEN BRUNO,,https://lens.org/040-592-802-114-169,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/00;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/00;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/00;;C07C317/32;;C07C317/34;;C07C323/00;;C07C323/32;;C07D209/00;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/00;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/00;;C07D233/24;;C07D239/00;;C07D239/34;;C07D277/00;;C07D277/20;;C07D277/34;;C07D307/00;;C07D307/91;;C07D333/00;;C07D333/20;;C07D401/00;;C07D401/12;;C07D403/00;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
877,PL,B1,PL 220721 B1,089-535-522-430-148,2015-12-31,2015,PL 36445802 A,2002-03-15,US 0205115 W;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/089-535-522-430-148,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D209/16;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/30;;C07D209/32;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
878,BR,A,BR 0208179 A,174-110-203-832-649,2004-03-02,2004,BR 0208179 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,"Composto, composição farmacêutica, métodos para tratar distúrbios associados com o receptor 5-ht6, distúrbios cognitivos, distúrbios da mémoria, psicose, esquizofrenia, e ansiedade, e, uso de um composto","""COMPOSTO, COMPOSIçãO FARMACêUTICA, MéTODOS PARA TRATAR DISTúRBIOS ASSOCIADOS COM O RECEPTOR 5-HT~ 6~, DISTúRBIOS COGNITIVOS DISTúRBIOS DA MEMóRIA PSICOSE ESQUIZOFRENIA, E ANSIEDADE, E, USO DE UM COMPOSTO"". A presente invenção proporciona compostos de fórmula (I), que são antagonistas do receptor 5-HT~ 6~.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/174-110-203-832-649,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,DISCONTINUED
879,SK,B6,SK 287463 B6,004-019-283-179-261,2010-10-07,2010,SK 12052003 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-arylethyl) benzylamines as antagonists of 5-HT6 receptor,"Disclosed are compounds of a general formula (I) and (II), their use in the manufacture of medicaments for the treatment of 5-HT6 receptor mediated diseases and pharmaceutical compositions containing them.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/004-019-283-179-261,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D209/00;;A61K31/00;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/00;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/00;;C07C317/32;;C07C317/34;;C07C323/00;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/00;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/00;;C07D239/34;;C07D277/00;;C07D277/20;;C07D277/34;;C07D307/00;;C07D307/91;;C07D333/00;;C07D333/20;;C07D401/00;;C07D401/12;;C07D403/00;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
880,ES,T3,ES 2566056 T3,057-883-845-589-647,2016-04-08,2016,ES 07015058 T,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ariletil)bencilaminas como antagonistas del receptor 5-HT6,"Un compuesto de estructura:**Fórmula** en la que X está seleccionado del grupo que consiste en -O-, -NH-, -S-, -SO2-, -CH2-, -CH(F)-, -CH(OH)- y -C(O)-; R1 está seleccionado del grupo que consiste en fenilo opcionalmente sustituido, naftilo opcionalmente sustituido, heterociclo aromático monocíclico de 5 a 6 miembros opcionalmente sustituido que tiene un heteroátomo seleccionado del grupo que consiste en nitrógeno, oxígeno y azufre y el heterociclo aromático monocíclico de 5 a 6 miembros está opcionalmente benzocondensado; donde el término ""fenilo opcionalmente sustituido"" se refiere a un radical de la fórmula**Fórmula** en la que Ra es de 1 a 3 grupos seleccionados independientemente del grupo que consiste en hidrógeno, hidroxi, alquilo C1-C4, alcoxi C1-C4, halógeno, benciloxi, carboxi, alcoxicarbonilo C1-C4, amido, N-(alquil C1-C4)amido, sulfonilamido, ciano, trifluorometilo, trifluorometoxi, nitro y fenilo opcionalmente sustituido con alquilo C1-C4, alcoxi C1-C4, halógeno, ciano y trifluorometilo; donde el término ""naftilo opcionalmente sustituido"" se refiere a un radical de la fórmula**Fórmula** en la que Rc es de 1 a 2 grupos seleccionados independientemente del grupo que consiste en hidrógeno, alquilo C1- C4, alcoxi C1-C4, halógeno, ciano, trifluorometilo y nitro; donde el término ""heterociclo aromático monocíclico de 5 a 6 miembros opcionalmente sustituido que tiene un heteroátomo seleccionado del grupo que consiste en nitrógeno, oxígeno y azufre y el heterociclo aromático monocíclico de 5 a 6 miembros está opcionalmente benzocondensado"" se refiere a radicales de la fórmula**Fórmula** en la que Q1 está seleccionado del grupo que consiste en -O-, -S- y -NRg- donde Rg está seleccionado del grupo que consiste en hidrógeno y alquilo C1-C4; y Q2 es -N>=, Rd, cada uno de Re y Rf están seleccionado independientemente del grupo que consiste en hidrógeno, alquilo C1-C4, alcoxi C1-C4, halógeno, ciano y trifluorometilo, o Rd y Re (o uno de Re) se toman junto con los átomos a los que están unidos formando un anillo benzo, anillo benzo que está opcionalmente sustituido con 1 a 4 sustituyentes seleccionados independientemente del grupo que consiste en hidrógeno, hidroxi, alquilo C1-C4, alcoxi C1-C4, trifluorometoxi, 2,2,2-trifluoroetoxi, trifluorometilo, halógeno, carboxi, alcoxicarbonilo C1-C4, amido, N-(alquil C1-C4)amido, amino, (alquil C1-C4)amino, acilamino donde el grupo acilo está seleccionado del grupo que consiste en alquilo C1-C4 y fenilo; ciano, nitro, sulfonilamido, fenilo opcionalmente sustituido con alquilo C1-C4, alcoxi C1-C4, halógeno, ciano y trifluorometilo; fenoxi, benciloxi, -NHS(O)2Rh, donde Rh está seleccionado del grupo que consiste en alquilo C1-C4 y fenilo; y -S(O)pRi, donde p es 0, 1 o 2 y Ri está seleccionado del grupo que consiste en alquilo C1-C4 y fenilo opcionalmente sustituido con alquilo C1-C4, alcoxi C1-C4, halógeno, ciano y trifluorometilo; y Rf está seleccionado del grupo que consiste en hidrógeno, alquilo C1-C4, alcoxi C1-C4, trifluorometilo y halógeno; R2 está seleccionado del grupo que consiste en hidrógeno y alquilo C1-C3; R3 está seleccionado del grupo que consiste en hidrógeno, fluoro y metilo; y R4 está seleccionado del grupo que consiste en hidrógeno, alilo, alquilo C2-C4, alquilo C2-C4 fluorado, fenilo opcionalmente sustituido, fenilsulfonilo opcionalmente sustituido, bencilo opcionalmente sustituido y heterociclo aromático monocíclico de 5 a 6 miembros opcionalmente sustituido que tiene uno o dos heteroátomos seleccionados del grupo que consiste en nitrógeno, oxígeno y azufre, con la condición de que R4 no es fenilsulfonilo opcionalmente sustituido cuando X es -SO2-, -CH2-, - CH(F)-, -CH(OH)- o -C(O)-; donde el término ""fenilsulfonilo opcionalmente sustituido"" se refiere a un radical de la fórmula**Fórmula** en la que Rj es de 1 a 3 grupos seleccionados independientemente del grupo que consiste en hidrógeno, alquilo C1- C4, alcoxi C1-C4, halógeno, ciano, trifluorometilo, nitro y fenilo; donde el término bencilo opcionalmente sustituido"" se refiere a un radical de la fórmula**Fórmula** en la que Rk es de 1 a 3 grupos seleccionados independientemente del grupo que consiste en hidrógeno, alquilo C1- C4, alcoxi C1-C4, ciano, nitro, trifluorometilo y halógeno; donde el término ""heterociclo aromático monocíclico de 5 a 6 miembros opcionalmente sustituido que tiene uno o dos heteroátomos seleccionados del grupo que consiste en nitrógeno, oxígeno y azufre"" se refiere a radicales de la fórmula**Fórmula** en la que Q3 está seleccionado del grupo que consiste en -O-,-S- y -NRg'- donde Rg' está seleccionado del grupo que consiste en hidrógeno y alquilo C1-C4; y Q4 y Q5 son -CRm, donde cada Rm está seleccionado independientemente del grupo que consiste en hidrógeno, alquilo C1-C4, halógeno y trifluorometilo o uno o ambos de Q4 y Q5 es -N>=; y donde uno o dos de Q6 son -N>=, mientras que el resto son -CRn; donde cada Rn está seleccionado independientemente del grupo que consiste en hidrógeno, alquilo C1-C4, alcoxi C1-C4, halógeno, ciano, nitro y trifluorometilo; o una sal farmacéuticamente aceptable del mismo, para su uso en un procedimiento de tratamiento de demencia o un trastorno cognitivo seleccionado del grupo que consiste en deterioro cognitivo relacionado con la edad y deficiencia cognitiva leve.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;GIETHLEN BRUNO,,https://lens.org/057-883-845-589-647,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
881,HK,A1,HK 1061649 A1,159-132-937-631-620,2004-09-30,2004,HK 04104659 A,2004-06-29,US 32944901 P;;US 27992801 P;;US 0205115 W,2001-03-29,N-(2-arylethyl) benzylamines as antagonists of the5-ht6 receptor,,LILLY CO ELI,ZHAOGEN CHEN;;PHILIP COHEN MICHAEL;;JOSEPH FISHER MATTHEW;;BRUNO GIETHLEN;;RONALD GILLING JAMES;;RAY MCCOWAN JEFFERSON;;CHRISTOPHER MILLER SHAWN;;MEHNERT SCHAUS JOHN,,https://lens.org/159-132-937-631-620,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K/;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P/;;A61P25/18;;A61P25/22;;A61P25/28;;C07C/;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D/;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,DISCONTINUED
882,PT,E,PT 1379239 E,190-924-484-915-397,2007-12-06,2007,PT 02731094 T,2002-03-15,US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,SCHAUS JOHN MEHNERT;;GILLIG JAMES RONALD;;FISHER MATTHEW JOSEPH;;MILLER SHAWN CHRISTOPHER;;COHEN MICHAEL PHILIP;;CHEN ZHAOGEN;;GIETHLEN BRUNO;;MCCOWAN JEFFERSON RAY,,https://lens.org/190-924-484-915-397,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
883,CA,C,CA 2442114 C,040-723-142-685-19X,2011-06-21,2011,CA 2442114 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,"The present invention provides compounds of formula (I), which are antagonists of the 5-HT6 receptor.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/040-723-142-685-19X,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,C07D209/14;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/395;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/26;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/36;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
884,CY,T1,CY 1117548 T1,060-935-394-788-726,2017-04-26,2017,CY 161100250 T,2016-03-24,EP 07015058 A;;US 27992801 A;;US 32944901 A,2001-03-29,Ν-(2-ΑΡΥΛΑΙΘΥΛΟ)ΒΕΝΖΥΛΑΜΙΝΕΣ ΩΣ ΑΝΤΑΓΩΝΙΣΤΕΣ ΤΟΥ 5-ΗT6 ΥΠΟΔΟΧΕΑ,"Η παρούσα εφεύρεση σχετίζεται με τη χρήση ενώσεων του τύπου (I), οι οποίες είναι ανταγωνιστές του 5-ΗΤ6 υποδοχέα, για αντιμετώπιση μιας γνωσιακής διαταραχής επιλεγμένης από την ομάδα η οποία αποτελείται από σχετιζόμενη με την ηλικία γνωσιακή έκπτωση, ήπια γνωσιακή βλάβη και άνοια.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;GIETHLEN BRUNO,,https://lens.org/060-935-394-788-726,Granted Patent,no,0,0,1,1,0,,A61K31/4045;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/506;;A61P25/18;;A61P25/28;;C07C217/54;;C07C317/14;;C07C323/01;;C07D209/14;;C07D209/16;;C07D213/64;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/12,,0,0,,,,ACTIVE
885,EA,B1,EA 007493 B1,069-319-160-721-092,2006-10-27,2006,EA 200301073 A,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HTRECEPTOR,"The present invention provides compounds of formula (I), which are antagonists of the 5-HTreceptor.",LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLING JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/069-319-160-721-092,Granted Patent,no,2,1,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,3,0,,,"DATABASE CROSSFIRE BEILSTEIN 'Online! Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(4-ethoxy-phenethyl)-ami ne), IDE, BUCK: Database accession no. 3365864, XP002209139, abstract & J.AM.CHEM.SOC, vol. 59, 1937, page 726ff;;DATABASE CROSSFIRE BEILSTEIN 'Online! Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(3-ethoxy-phenethyl-amine), Database accession no. 3365863, XP002209140, abstract & IDE, BUCK: J.AM.CHEM.SOC, vol. 59, 1937, page 726ff;;DATABASE CROSSFIRE BEILSTEIN 'Online! Beilstein Institut zur Förderung der Chemischen Wissenschaften, Frankfurt am Main, DE; (3-ethoxy-benzyl)-(2-ethoxy-phenethyl)-ami ne), IDE, BUCK: Database accession no. 3380345 XP002209141, abstract & J.AM.CHEM.SOC, vol. 59, 1937, page 726ff",EXPIRED
886,PL,A1,PL 364458 A1,111-584-448-587-310,2004-12-13,2004,PL 36445802 A,2002-03-15,US 0205115 W;;US 27992801 P;;US 32944901 P,2001-03-29,N-(2-ARYLETHYL)BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/111-584-448-587-310,Patent Application,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;C07D233/64;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
887,AU,B2,AU 2002/303094 B2,119-355-946-725-706,2006-11-23,2006,AU 2002/303094 A,2002-03-15,US 32944901 P;;US 27992801 P;;US 0205115 W,2001-03-29,N-(2-arylethyl)benzylamines as antagonists of the 5-HT6 receptor,,LILLY CO ELI,MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT;;FISHER MATTHEW JOSEPH;;MCCOWAN JEFFERSON RAY;;GILLIG JAMES RONALD;;CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;GIETHLEN BRUNO,,https://lens.org/119-355-946-725-706,Granted Patent,no,2,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,1,0,,,"J. Am. Chem. Soc. 1937, pp726 -731",EXPIRED
888,DK,T3,DK 1379239 T3,011-584-075-165-653,2008-01-07,2008,DK 02731094 T,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N(2-aryl-ethyl)-benzyl-aminer som antagonister af 5 HT6 receptoren,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO PRESTWICK;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/011-584-075-165-653,Granted Patent,no,0,1,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/4045;;A61K31/137;;C07D233/64;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/14;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
889,US,A1,US 2016/0330968 A1,041-323-861-095-966,2016-11-17,2016,US 201615013429 A,2016-02-02,US 201615013429 A;;US 201562110889 P,2015-02-02,SANITIZING PRODUCT CREATION SYSTEM,A sanitizing product creation system employing electricity to produce products useful for sanitizing and disinfecting surfaces.,OWENS DAVID;;LUCCI PAT;;MARCINKOWSKI MICHAEL;;POSA SANDY;;GENTILE JOHN;;HAAG RONALD H;;BRODY MIKE;;KAISERMAN TAYLER;;KAISERMAN TERRANCE Z;;COHEN STEVEN MARTIN,OWENS DAVID;;LUCCI PAT;;MARCINKOWSKI MICHAEL;;POSA SANDY;;GENTILE JOHN;;HAAG RONALD H;;BRODY MIKE;;KAISERMAN TAYLER;;KAISERMAN TERRANCE Z;;COHEN STEVEN MARTIN,T+INK INC (2018-01-26);;HCI CLEANING PRODUCTS LLC D/B/A FORCE OF NATURE (2018-08-24);;HCI CLEANING PRODUCTS LLC (2019-06-17),https://lens.org/041-323-861-095-966,Patent Application,yes,0,9,2,12,0,C02F1/283;;C02F1/32;;C02F1/4618;;C02F2001/46142;;C02F2001/46185;;C02F2201/4614;;C02F2209/06;;Y02E10/50;;H01L31/042;;C02F2201/4614;;C02F2001/46142;;C02F2001/46185;;C02F2209/06;;C02F1/4618;;C02F1/283;;C02F1/32;;A01N59/00;;C01B11/04;;C01D1/04,A01N59/00;;C01B11/04;;C01D1/04,,0,0,,,,DISCONTINUED
890,DE,D1,DE 60222396 D1,187-068-341-364-244,2007-10-25,2007,DE 60222396 T,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINE ALS 5-HT6 REZEPTOR-ANTAGONISTE,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO PRESTWICK CH;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/187-068-341-364-244,Granted Patent,no,0,0,53,58,0,C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/0812;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;A61P43/00;;C07D209/14;;C07D213/64;;C07C217/58;;C07D213/65;;C07C211/56;;C07D209/14;;C07D209/16;;C07C311/37;;C07D471/04;;C07D233/24;;C07D333/20;;C07D307/91;;C07C211/52;;C07C217/60;;C07D239/34;;C07D213/68;;C07D213/74;;C07C225/16;;C07D209/08;;C07D277/34;;C07D417/12;;C07D403/06;;C07D213/38;;C07F7/0812;;C07C317/34;;C07C323/32;;C07D401/12;;C07D403/12;;C07D209/86;;C07D405/12,A61K31/137;;A61K31/4045;;A61K31/18;;C07D233/64;;A61K31/343;;A61K31/381;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/54;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/32;;C07C317/34;;C07C323/01;;C07C323/32;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D209/86;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/20;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07D471/04;;C07F7/08,,0,0,,,,EXPIRED
891,SI,T1,SI 1379239 T1,087-907-563-663-88X,2008-02-29,2008,SI 200230644 T,2002-03-15,US 27992801 P;;US 32944901 P;;US 0205115 W;;EP 02731094 A,2001-03-29,N-(2-ARYLETHYL) BENZYLAMINES AS ANTAGONISTS OF THE 5-HT6 RECEPTOR,,LILLY CO ELI,CHEN ZHAOGEN;;COHEN MICHAEL PHILIP;;FISHER MATTHEW JOSEPH;;GIETHLEN BRUNO PRESTWICK CHEMI;;GILLIG JAMES RONALD;;MCCOWAN JEFFERSON RAY;;MILLER SHAWN CHRISTOPHER;;SCHAUS JOHN MEHNERT,,https://lens.org/087-907-563-663-88X,Granted Patent,no,0,0,3,58,0,A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C217/58;;C07C217/60;;C07C225/16;;C07C311/37;;C07C317/34;;C07C323/32;;C07D209/08;;C07D209/14;;C07D213/38;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/24;;C07D239/34;;C07D277/34;;C07D307/91;;C07D333/20;;C07D401/12;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07F7/0812,A61K31/00;;C07D233/64;;A61K31/137;;A61K31/18;;A61K31/343;;A61K31/381;;A61K31/4045;;A61K31/417;;A61K31/426;;A61K31/427;;A61K31/4402;;A61K31/4406;;A61K31/4409;;A61K31/4439;;A61K31/505;;A61K31/506;;A61P25/00;;A61P25/18;;A61P25/22;;A61P25/28;;C07C211/52;;C07C211/56;;C07C215/32;;C07C215/50;;C07C217/00;;C07C217/58;;C07C217/60;;C07C225/16;;C07C309/73;;C07C311/37;;C07C317/00;;C07C317/32;;C07C317/34;;C07C323/00;;C07C323/32;;C07D209/00;;C07D209/00;;C07D209/08;;C07D209/14;;C07D209/16;;C07D213/00;;C07D213/30;;C07D213/38;;C07D213/63;;C07D213/64;;C07D213/65;;C07D213/68;;C07D213/74;;C07D233/00;;C07D233/24;;C07D239/00;;C07D239/34;;C07D277/00;;C07D277/20;;C07D277/34;;C07D307/00;;C07D307/91;;C07D333/00;;C07D333/20;;C07D401/00;;C07D401/12;;C07D403/00;;C07D403/06;;C07D403/12;;C07D405/12;;C07D417/12;;C07F7/08,,0,0,,,,EXPIRED
892,DE,C3,DE 2739388 C3,194-164-790-089-210,1981-07-02,1981,DE 2739388 A,1977-09-01,US 72160476 A,1976-09-07,DE 2739388 C3,,"GTE PRODUCTS CORP., WILMINGTON, DEL., US","ARMSTRONG, DONALD E., WILLIAMSPORT, PA., US;;SINDLINGER, RONALD E., MUNCY, PA., US;;COHEN, BERNARD;;TOZIER, JOHN E., WILLIAMSPORT, PA., US;;AUDESSE, EMERY G., BEVERLY, MASS., US",,https://lens.org/194-164-790-089-210,Granted Patent,no,0,0,12,12,0,F21K5/02;;F21K5/02,F21K5/06;;F21K5/08,,0,0,,,,EXPIRED
893,US,A1,US 2018/0078274 A1,074-945-497-714-567,2018-03-22,2018,US 201715718734 A,2017-09-28,US 201715718734 A;;US 201514634424 A;;US 49029509 A;;US 201414452376 A;;US 201113007578 A;;US 49030109 A;;US 201615277916 A;;US 201213535197 A;;US 201615005994 A;;US 201213659734 A;;US 201213714285 A;;US 201313843462 A;;US 7500608 P;;US 16486409 P;;US 16488309 P;;US 40855810 P;;US 201261731434 P;;US 201261731440 P,2008-06-23,"Miniature Shredding Tools for Use in Medical Applications, Methods for Making, and Procedures for Using","The present disclosure relates generally to the field of tissue removal and more particularly to methods and devices for use in medical applications involving selective tissue removal. One exemplary method includes the steps of providing a tissue cutting instrument capable of distinguishing between target tissue to be removed and non-target tissue, urging the instrument against the target tissue and the non-target tissue, and allowing the instrument to cut the target tissue while automatically avoiding cutting of non-target tissue. Various tools for carrying out this method are also described.",MICROFABRICA INC,LOCKARD MICHAEL S;;FRODIS URI;;COHEN ADAM L;;CHEN RICHARD T;;SCHMITZ GREGORY P;;MILLER ERIC C;;WU MING TING;;VEERAMANI ARUN S;;PEREA JUAN DIEGO;;LEGUIDLEGUID RONALD;;ARCENIO GREGORY B,MICROFABRICA INC (2019-04-26),https://lens.org/074-945-497-714-567,Patent Application,yes,7,2,2,69,0,F16H55/566;;A61B2017/2927;;A61B2017/32006;;A61B2090/3614;;A61B10/0266;;A61B2217/005;;Y10T74/19623;;A61B90/361;;F16H55/18;;A61B2017/320064;;F16H55/06;;A61B2017/00261;;A61B17/1659;;A61B2017/320775;;A61B2017/320048;;A61B2017/2215;;A61B2017/2212;;A61B2017/00553;;A61B2017/00539;;A61B2017/00526;;A61B2017/00327;;A61B2017/003;;A61B17/320758;;A61B17/320725;;A61B17/32002;;A61B17/221;;A61B17/1671;;Y10T74/19623;;B33Y80/00;;A61B17/14;;A61B90/361;;F16H55/18;;A61B2017/320064;;F16H55/06;;A61B2017/00261;;A61B17/1659;;A61B2017/320775;;A61B2017/320048;;A61B2017/2215;;A61B2017/2212;;A61B2017/00553;;A61B2017/00539;;A61B2017/00526;;A61B2017/00327;;A61B2017/003;;A61B17/320758;;A61B17/320725;;A61B17/32002;;A61B17/221;;A61B17/1671;;A61B10/02;;A61B2017/32006;;A61B2017/2927;;F16H55/566;;A61B10/0266;;A61B2217/005;;A61B2090/3614,A61B17/32;;A61B10/02;;A61B17/00;;A61B17/14;;A61B17/16;;A61B17/221;;A61B17/3207;;F16H55/06;;F16H55/18,,0,0,,,,ACTIVE
894,DE,T2,DE 69229079 T2,071-505-797-834-28X,1999-12-16,1999,DE 69229079 T,1992-02-26,US 67892991 A,1991-03-26,Bidirektionale parallele Drucker-Schnittstelle,,IBM,BECK JAMES LEE;;BOOTH JAMES RONALD;;BUCHANAN JAMES CLOYD;;CLAFFEY-COHEN MARGARET ELIZABE;;COLE CARL PRICE;;LOUIE TIMOTHY JUNG-MING;;NEEL II ALAN FOBES;;OLIVER LYNN MARVIN;;WARD JAMES PETER;;WEBB JAMES FRANCIS,,https://lens.org/071-505-797-834-28X,Granted Patent,no,0,0,8,8,0,G06F13/4226;;G06F2213/0004;;G06F3/1203;;G06F3/1229;;G06F3/1236;;G06F3/1284;;G06F13/4226;;G06F2213/0004;;G06F3/1284;;G06F3/1236;;G06F3/1229;;G06F3/1203,G06F3/12;;G06F13/42;;B41J29/38,,0,0,,,,EXPIRED
895,CN,A,CN 103974735 A,006-670-963-899-604,2014-08-06,2014,CN 201280044680 A,2012-09-13,US 2012/0055148 W;;US 201161534044 P;;US 201161558158 P,2011-09-13,Vent arrangement for respiratory mask,"A control system (706) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly.; The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUORAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/006-670-963-899-604,Patent Application,no,9,13,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,DISCONTINUED
896,NZ,A,NZ 780214 A,144-668-474-939-995,2023-07-28,2023,NZ 78021412 A,2012-09-13,US 201161558158 P;;US 201161534044 P;;NZ 76222612 A,2011-09-13,Vent arrangement for respiratory mask,"Disclosed is an air or gas ventilation system a gas washout vent arrangement which allows for adequate venting of carbon dioxide while permitting efficient air delivery to the patient. A control system provides automated control of gas washout of a patient interface (30), such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. A controller including a processor, the controller coupled with the actuator, the controller configured to (a) control operation of a flow generator and (b) operate the actuator to change the exhaust area of the vent assembly to change a vent flow rate of the expiratory gas through the exhaust area. The controller is configured to control an operation of the flow generator to change flow supply, such that a set pressure at the patient interface is maintained.",RESMED PTY LTD,FARRUGIA STEVEN PAUL;;DANTANARAYANA MUDITHA PRADEEP;;MARTIN DION CHARLES CHEWE;;FORMICA JUSTIN JOHN;;VANDYKE JAMES WILLIAM CHARLES;;HUBY RONALD JAMES;;ARMITSTEAD JEFFREY PETER;;SEARS DAVID BRENT;;MAZZONE DAMIEN;;FOOTE ROGER MERVYN LLOYD;;TANG ZHUO RAN;;COHEN LANCE;;SAMPIETRO JOSEPH M;;NAGORNY ALEKSANDR S,,https://lens.org/144-668-474-939-995,Patent Application,no,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00;;A61M16/20,,0,0,,,,PENDING
897,NZ,A,NZ 762226 A,095-112-092-266-001,2021-10-29,2021,NZ 76222612 A,2012-09-13,US 201161558158 P;;US 201161534044 P;;NZ 74520212 A,2011-09-13,Vent arrangement for respiratory mask,"An apparatus for control of gas washout of a patient interface of a respiratory treatment apparatus comprising: a vent assembly (360) having a variable size exhaust opening defined by one or more apertures of the vent assembly, an actuator to manipulate the apertures and a controller to operate the actuator. The controller is configured to switch between a treatment setting for the variable exhaust area and a comfort setting for the variable exhaust area. The comfort setting includes one or more of a humidity setting, a pressure setting and a temperature setting.",RESMED PTY LTD,DANTANARAYANA MUDITHA PRADEEP;;MARTIN DION CHARLES CHEWE;;FARRUGIA STEVEN PAUL;;HUBY RONALD JAMES;;SEARS DAVID BRENT;;ARMITSTEAD JEFFREY PETER;;MAZZONE DAMIEN;;FOOTE ROGER MERVYN LLOYD;;TANG ZHUO RAN;;COHEN LANCE;;SAMPIETRO JOSEPH M;;NAGORNY ALEKSANDR S;;FORMICA JUSTIN JOHN;;VANDYKE JAMES WILLIAM CHARLES,,https://lens.org/095-112-092-266-001,Patent Application,no,0,0,1,29,0,,A61M16/00;;A61M16/20,,0,0,,,,PENDING
898,NZ,A,NZ 729631 A,014-027-099-929-336,2018-09-28,2018,NZ 72963112 A,2012-09-13,US 201161558158 P;;US 201161534044 P;;NZ 71278212 A,2011-09-13,Vent arrangement for respiratory mask,"An apparatus for automated control of gas washout of a patient interface (330) of a respiratory treatment apparatus comprising: a vent assembly (360) having a variable size exhaust area defined by one or more apertures, wherein in use the vent assembly vents expiratory gas from the patient interface; and an actuator (399) to manipulate said one or more overlapping apertures of the vent assembly. A control device, comprising a processor, is used to control the actuator. The variable size exhaust area is configured to be set to a plurality of open positions, the plurality of open positions providing different opening area sizes for venting expiratory gas from the patient interface.",RESMED PTY LTD,DANTANARAYANA MUDITHA PRADEEP;;MARTIN DION CHARLES CHEWE;;FARRUGIA STEVEN PAUL;;HUBY RONALD JAMES;;SEARS DAVID BRENT;;ARMITSTEAD JEFFREY PETER;;MAZZONE DAMIEN;;FOOTE ROGER MERVYN LLOYD;;TANG ZHUO RAN;;COHEN LANCE;;SAMPIETRO JOSEPH M;;NAGORNY ALEKSANDR S;;FORMICA JUSTIN JOHN;;VANDYKE JAMES WILLIAM CHARLES,,https://lens.org/014-027-099-929-336,Patent Application,no,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00;;A61M16/20,,0,0,,,,DISCONTINUED
899,EP,B1,EP 2755710 B1,016-151-016-306-397,2018-05-23,2018,EP 12831096 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,,RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,"RES MED PTY LTD, BELLA VISTA, AU (2019-07-09)",https://lens.org/016-151-016-306-397,Granted Patent,yes,21,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,ACTIVE
900,US,A1,US 2014/0283831 A1,138-767-203-285-762,2014-09-25,2014,US 201214342972 A,2012-09-13,US 201214342972 A;;US 201161558158 P;;US 201161534044 P;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"A control system ( 706 ) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly ( 60 ) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL;;RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,RESMED MOTOR TECHNOLOGIES INC (2012-11-27);;T.Y.L. ENGINEERING CO (2012-11-27);;RESMED PTY LTD (2012-10-01),https://lens.org/138-767-203-285-762,Patent Application,yes,13,74,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00;;A61B5/00;;A61B5/087;;A61B5/091,128/204.19;;128/204.21;;128/204.23,0,0,,,,ACTIVE
901,US,B2,US 10029058 B2,170-287-886-722-614,2018-07-24,2018,US 201214342972 A,2012-09-13,US 201214342972 A;;US 201161558158 P;;US 201161534044 P;;US 2012/0055148 W,2011-09-13,Vent arrangement for respiratory mask,"A control system ( 706 ) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly ( 60 ) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL;;RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,RESMED MOTOR TECHNOLOGIES INC (2012-11-27);;T.Y.L. ENGINEERING CO (2012-11-27);;RESMED PTY LTD (2012-10-01),https://lens.org/170-287-886-722-614,Granted Patent,yes,74,4,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00;;A61B5/00;;A61B5/087;;A61B5/091;;A61M16/06;;A61M16/08;;A61M16/10;;A61M16/20,,7,0,,,"European Search Report for Application No. EP12831096 dated Feb. 17, 2015.;;International Search Report and Written Opinion for Application No. PCT/US2012/055148 dated Feb. 15, 2013.;;U.S. Appl. No. 61/226,069, filed Jul. 16, 2009.;;U.S. Appl. No. 61/369,247, filed Jul. 30, 2010.;;Partial European Search Report for Application No. 13183779.1 dated Dec. 11, 2013.;;Extended European Search Report for Application No. 13183779 dated Mar. 31, 2014.;;Further Examination Report for NZ729631 dated Feb. 19, 2018.",ACTIVE
902,EP,A1,EP 3808399 A1,110-126-063-420-881,2021-04-21,2021,EP 20191437 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;EP 18167169 A;;EP 12831096 A;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"The present invention relates to an apparatus for automated control of gas washout of a patient interface of a respiratory treatment apparatus comprising: a vent assembly having a variable exhaust area defined by one or more apertures of the vent assembly, the vent assembly being associated with a patient interface to vent expiratory gas. The apparatus additionally comprises an actuator to manipulate said one or more apertures of the vent assembly and a controller including a processor, the controller coupled with the actuator, the controller configured to operate the actuator to change the exhaust area of the vent assembly. The controller is configured to switch between a treatment setting for the variable exhaust area and a comfort setting for the variable exhaust area. The comfort setting further includes one or more of a humidity setting, a pressure setting and a temperature setting
",RESMED PTY LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMISTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/110-126-063-420-881,Patent Application,yes,17,1,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/20;;A61M16/06,,0,0,,,,ACTIVE
903,JP,A,JP 2018140193 A,169-469-279-444-079,2018-09-13,2018,JP 2018081141 A,2018-04-20,US 201161558158 P;;US 201161534044 P,2011-09-13,APPARATUS FOR CONTROLLING GAS WASHOUT OF PATIENT INTERFACE OF RESPIRATORY TREATMENT APPARATUS,"PROBLEM TO BE SOLVED: To provide a control system that provides automated control of gas washout of a patient interface, such as a mask or nasal prongs.SOLUTION: A gas washout vent assembly 60 of the system may include a variable exhaust area such as a variable exhaust area defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conical or cylindrical members, where each of the structures may have an opening passage of the overlapping apertures. The vent assembly may be attached substantially near or included in the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly.SELECTED DRAWING: Figure 2A.2B.2C",RESMED LTD,ROGER MERVYN LLOYD FOOTE;;RONALD JAMES HUBY;;MUDITHA PRADEEP DANTANARAYANA;;DAMIEN JULIAN MAZZONE;;DION CHARLES CHEWE MARTIN;;JEFFREY PETER ARMITSTEAD;;JUSTIN JOHN FORMICA;;TANG ZHUO RAN;;LANCE STEVEN COHEN;;JAMES WILLIAM CHARLES VANDYKE;;DAVID BRENT SEARS;;ALEKSANDR S NAGORNY;;JOSEPH M SAMPIETRO;;STEVEN PAUL FARRUGIA,,https://lens.org/169-469-279-444-079,Patent Application,no,6,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/06;;A61M16/20,,0,0,,,,ACTIVE
904,NZ,A,NZ 712782 A,015-783-916-454-933,2017-04-28,2017,NZ 71278212 A,2012-09-13,US 201161558158 P;;US 201161534044 P;;NZ 62146712 A,2011-09-13,Vent arrangement for respiratory mask,"An apparatus for control of gas washout of a patient interface of a respiratory treatment apparatus comprising: a vent assembly having a variable size exhaust opening (3203) defined by a plurality of overlapping blades (3204-1, 3204-2, 3204-3, 3204-4, 3204-5, 3204-6, 3204-7, 3204-8) of the assembly; and an actuator (iris drive lever 3210) to manipulate the size of the exhaust opening of the vent assembly for vent-to-ambient flow, the actuator being coupled with the blades.",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;FARRUGIA STEVEN PAUL;;SAMPIETRO JOSEPH M,,https://lens.org/015-783-916-454-933,Patent Application,no,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/01,,0,0,,,,DISCONTINUED
905,WO,A3,WO 2013/040198 A3,044-748-628-426-290,2014-05-08,2014,US 2012/0055148 W,2012-09-13,US 201161558158 P;;US 201161534044 P,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"A control system (706) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",RESMED LTD;;FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/044-748-628-426-290,Search Report,yes,17,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,PENDING
906,WO,A2,WO 2013/040198 A2,123-861-683-031-134,2013-03-21,2013,US 2012/0055148 W,2012-09-13,US 201161558158 P;;US 201161534044 P,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"A control system (706) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",RESMED LTD;;FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/123-861-683-031-134,Patent Application,yes,0,32,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/01,,0,0,,,,PENDING
907,AU,A1,AU 2015/252055 A1,125-842-930-912-721,2015-11-19,2015,AU 2015/252055 A,2015-11-04,AU 2012/308554 A;;AU 2015/252055 A,2012-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"A control system (706) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection. I.0o (0 LO) U-)) L -O L-",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/125-842-930-912-721,Patent Application,no,0,1,1,1,0,,A61M16/00,,0,0,,,,DISCONTINUED
908,NZ,A,NZ 621467 A,084-352-453-553-035,2016-05-27,2016,NZ 62146712 A,2012-09-13,US 2012/0055148 W;;US 201161534044 P;;US 201161558158 P,2011-09-13,Vent arrangement for respiratory mask,"An apparatus for automated control of gas washout of a patient interface of a respiratory treatment apparatus comprising: a vent assembly having a variable size exhaust area defined by one or more overlapping apertures (90, 95), wherein in use the vent assembly vents expiratory gas from the patient interface; and an actuator to manipulate said one or more overlapping apertures of the vent assembly. The variable size exhaust area is configured to be set to a plurality of open positions, the plurality of open positions providing different opening area sizes for venting expiratory gas from the patient interface.",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;FARRUGIA STEVEN PAUL;;SAMPIETRO JOSEPH M,,https://lens.org/084-352-453-553-035,Patent Application,no,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/01,,0,0,,,,DISCONTINUED
909,JP,A,JP 2020142098 A,176-664-461-502-21X,2020-09-10,2020,JP 2020081709 A,2020-05-07,US 201161558158 P;;US 201161534044 P,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"To provide a vent arrangement for a mask assembly for a respiratory treatment apparatus used for Non-invasive Positive Pressure Ventilation (NPPV) and continuous positive airway pressure (CPAP) therapy.SOLUTION: A gas washout vent assembly (60) of a system may include a variable exhaust area defined by overlapping apertures of the assembly or a variable exhaust area defined by a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or provided with a patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator is configured for control by a controller to change the exhaust area of the vent assembly.SELECTED DRAWING: Figure 2A.2B.2C",RESMED PTY LTD,ROGER MERVYN LLOYD FOOTE;;RONALD JAMES HUBY;;MUDITHA PRADEEP DANTANARAYANA;;DAMIEN JULIAN MAZZONE;;DION CHARLES CHEWE MARTIN;;JEFFREY PETER ARMITSTEAD;;JUSTIN JOHN FORMICA;;TANG ZHUO RAN;;LANCE STEVEN COHEN;;JAMES WILLIAM CHARLES VANDYKE;;DAVID BRENT SEARS;;ALEKSANDR S NAGORNY;;JOSEPH M SAMPIETRO;;STEVEN PAUL FARRUGIA,,https://lens.org/176-664-461-502-21X,Patent Application,no,7,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/06,,0,0,,,,ACTIVE
910,JP,A,JP 2023130365 A,175-856-201-688-003,2023-09-20,2023,JP 2023099901 A,2023-06-19,JP 2021207931 A;;US 201161558158 P;;US 201161534044 P;;JP 2020081709 A,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"To provide a gas washout vent arrangement which allows adequate venting of carbon dioxide while permitting efficient air delivery to a patient.SOLUTION: A control system provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly 60 of the system includes a variable exhaust area, or a variable exhaust area defined by a conduit having a variable gas flow channel. The vent assembly is of nested structures each having an open passage consisting of overlapping apertures. The vent assembly is attached to substantial vicinity of the patient interface, or accompanies the patient interface. An actuator of the assembly manipulates an aperture of the vent assembly. The actuator is controlled by a controller to change the exhaust area of the vent assembly based on various procedures.SELECTED DRAWING: Figure 2A.2B.2C",RESMED PTY LTD,ROGER MERVYN LLOYD FOOTE;;RONALD JAMES HUBY;;MUDITHA PRADEEP DANTANARAYANA;;DAMIEN JULIAN MAZZONE;;DION CHARLES CHEWE MARTIN;;JEFFREY PETER ARMITSTEAD;;JUSTIN JOHN FORMICA;;TANG ZHUO RAN;;LANCE STEVEN COHEN;;JAMES WILLIAM CHARLES VANDYKE;;DAVID BRENT SEARS;;ALEKSANDR S NAGORNY;;JOSEPH M SAMPIETRO;;STEVEN PAUL FARRUGIA,,https://lens.org/175-856-201-688-003,Patent Application,no,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,PENDING
911,EP,B1,EP 3378521 B1,063-570-566-303-749,2020-08-19,2020,EP 18167169 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;EP 12831096 A;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,,RESMED PTY LTD,COHEN LANCE STEVEN;;FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,RESMED PTY LTD (2019-07-10),https://lens.org/063-570-566-303-749,Granted Patent,yes,4,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/20,,0,0,,,,ACTIVE
912,EP,B1,EP 3808399 B1,093-305-667-429-130,2024-02-21,2024,EP 20191437 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;EP 18167169 A;;EP 12831096 A;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,,RESMED PTY LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/093-305-667-429-130,Granted Patent,yes,1,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/20;;A61M16/06,,0,0,,,,ACTIVE
913,EP,A1,EP 3378521 A1,125-901-519-642-757,2018-09-26,2018,EP 18167169 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;EP 12831096 A;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,"The present invention relates to an apparatus for automated control of gas washout of a patient interface (30, 330, 430) of a respiratory treatment apparatus comprising: a vent assembly (60, 360, 460) associated with a patient interface (30, 330, 430) to vent expiratory gas and positioned in an air delivery conduit proximal to the patient interface; an actuator to manipulate the vent assembly (60, 360, 460); and a controller, including a processor, that is coupled to the actuator; wherein the vent assembly (60, 360, 460) has a variable exhaust area defined by overlapping apertures (90, 590, 1090, 1290; 95, 595, 1295), wherein the overlapping apertures (90, 590, 1090, 1290; 95, 595, 1295) allow air to pass through the exhaust area; and the controller is configured to operate the actuator to change the variable exhaust area of the vent assembly (60, 360, 460).
",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,RESMED PTY LTD (2019-07-10),https://lens.org/125-901-519-642-757,Patent Application,yes,16,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,ACTIVE
914,EP,A2,EP 2755710 A2,006-285-017-390-894,2014-07-23,2014,EP 12831096 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,,RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,"RES MED PTY LTD, BELLA VISTA, AU (2019-07-09)",https://lens.org/006-285-017-390-894,Patent Application,yes,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,ACTIVE
915,AU,B2,AU 2012/308554 B2,156-863-357-339-017,2015-08-06,2015,AU 2012/308554 A,2012-09-13,US 201161558158 P;;US 201161534044 P;;US 2012/0055148 W,2011-09-13,Vent arrangement for respiratory mask,"A control system (706) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/156-863-357-339-017,Granted Patent,no,3,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,INACTIVE
916,EP,A4,EP 2755710 A4,036-833-837-426-672,2015-03-25,2015,EP 12831096 A,2012-09-13,US 201161534044 P;;US 201161558158 P;;US 2012/0055148 W,2011-09-13,VENT ARRANGEMENT FOR RESPIRATORY MASK,,RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,"RES MED PTY LTD, BELLA VISTA, AU (2019-07-09)",https://lens.org/036-833-837-426-672,Search Report,no,4,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00,,0,0,,,,ACTIVE
917,AU,A1,AU 2012/308554 A1,126-495-951-403-830,2014-03-13,2014,AU 2012/308554 A,2012-09-13,US 201161558158 P;;US 201161534044 P;;US 2012/0055148 W,2011-09-13,Vent arrangement for respiratory mask,"A control system (706) provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly (60) of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOE;;FARRUGIA STEVEN PAUL,,https://lens.org/126-495-951-403-830,Patent Application,no,0,0,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/01,,0,0,,,,INACTIVE
918,US,A1,US 2019/0099568 A1,008-779-048-550-11X,2019-04-04,2019,US 201816019779 A,2018-06-27,US 201816019779 A;;US 201414342972 A;;US 2012/0055148 W;;US 201161558158 P;;US 201161534044 P,2011-09-13,Vent Arrangement For Respiratory Mask,"A control system provides automated control of gas washout of a patient interface, such as a mask or nasal prongs. A gas washout vent assembly of the system may include a variable exhaust area such as one defined by overlapping apertures of the assembly or a conduit having a variable gas passage channel. The vent assembly may be formed by nested structures, such as conic or cylindrical members, each having an opening of the overlapping apertures. The vent assembly may be attached substantially near or included with the patient interface. An actuator of the assembly, such as a solenoid or voice coil, manipulates an aperture of the vent assembly. The actuator may be configured for control by a controller to change the exhaust area of the vent assembly based on various methodologies including, for example, sleep detection, disordered breathing event detection, rebreathing volume calculation and/or leak detection.",RESMED LTD,FOOTE ROGER MERVYN LLOYD;;HUBY RONALD JAMES;;DANTANARAYANA MUDITHA PRADEEP;;MAZZONE DAMIEN JULIAN;;MARTIN DION CHARLES CHEWE;;ARMITSTEAD JEFFREY PETER;;FORMICA JUSTIN JOHN;;TANG ZHUO RAN;;COHEN LANCE STEVEN;;VANDYKE JAMES WILLIAM CHARLES;;SEARS DAVID BRENT;;NAGORNY ALEKSANDR S;;SAMPIETRO JOSEPH M;;FARRUGIA STEVEN PAUL,T.Y.L. ENGINEERING CO (2012-11-27);;RESMED PTY LTD (2012-11-27);;RESMED MOTOR TECHNOLOGIES (2012-11-27),https://lens.org/008-779-048-550-11X,Patent Application,yes,3,1,28,29,0,A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/026;;A61B5/4836;;A61M16/0069;;A61M16/1095;;A61M16/202;;A61M16/0045;;A61M16/06;;A61M16/0666;;A61M2016/0027;;A61M2016/003;;A61M2202/0225;;A61M2205/15;;A61M2205/3331;;A61M2205/3368;;A61M2205/42;;A61M2205/50;;A61M2230/202;;A61M16/0816;;A61M16/0875;;A61M16/20;;A61M2205/3334;;A61M16/026;;A61B5/087;;A61B5/091;;A61B5/4809;;A61B5/4812;;A61B5/4818;;A61B5/4836;;A61M16/009;;A61M16/0051,A61M16/00;;A61B5/00;;A61B5/087;;A61B5/091;;A61M16/06;;A61M16/08;;A61M16/10;;A61M16/20,,0,0,,,,PENDING
