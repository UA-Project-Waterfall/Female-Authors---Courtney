"#",Jurisdiction,Kind,Display Key,Lens ID,Publication Date,Publication Year,Application Number,Application Date,Priority Numbers,Earliest Priority Date,Title,Abstract,Applicants,Inventors,Owners,URL,Document Type,Has Full Text,Cites Patent Count,Cited by Patent Count,Simple Family Size,Extended Family Size,Sequence Count,CPC Classifications,IPCR Classifications,US Classifications,NPL Citation Count,NPL Resolved Citation Count,NPL Resolved Lens ID(s),NPL Resolved External ID(s),NPL Citations,Legal Status
1,US,A1,US 2008/0184907 A1,036-540-233-795-072,2008-08-07,2008,US 67130307 A,2007-02-05,US 67130307 A,2007-02-05,One Piece Shotshell,"A one-piece shotshell comprising an integral base with an opening at a first end, a sidewall extending from the base defining an open second end, and a crimp integrally disposed between the first end and second end. Apparatus and methods for making the shotshell and shooting a projectile are also disclosed.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/036-540-233-795-072,Patent Application,yes,14,1,1,1,0,F42B5/30;;F42B7/04;;F42B7/10;;F42B5/30;;F42B7/10;;F42B7/04,F42B5/26,102/464,0,0,,,,DISCONTINUED
2,US,B2,US 10841556 B2,161-341-987-436-412,2020-11-17,2020,US 202016919639 A,2020-07-02,US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal procedures using stereoscopic optical see-through head mounted displays with display of virtual surgical guides,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/161-341-987-436-412,Granted Patent,yes,124,24,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713,23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781,"Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, um:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung fur die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjISzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car-Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, Docmed.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;deLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, Intech, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.",ACTIVE
3,US,B2,US 11153549 B2,182-679-844-409-37X,2021-10-19,2021,US 202117332149 A,2021-05-27,US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal surgery,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/182-679-844-409-37X,Granted Patent,yes,130,8,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296,,140,95,048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;157-141-393-691-271;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769,10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.5772/7128;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191,"Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFglLvsRhShqXDrSM63OcvvjlSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car-Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10 1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI: 10.1109/DVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, p. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS—International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.",ACTIVE
4,US,A1,US 2016/0191887 A1,006-173-305-939-558,2016-06-30,2016,US 201514753705 A,2015-06-29,US 201514753705 A;;US 201462097771 P,2014-12-30,IMAGE-GUIDED SURGERY WITH SURFACE RECONSTRUCTION AND AUGMENTED REALITY VISUALIZATION,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",CASAS CARLOS QUILES,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/006-173-305-939-558,Patent Application,yes,4,432,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B34/10;;A61B34/20;;G02B27/01;;G06T7/00;;G06T11/00;;G06T15/00;;G06T15/08;;G06T19/00;;G16Z99/00;;H04N13/239,,0,0,,,,ACTIVE
5,US,A1,US 2022/0030209 A1,126-536-584-019-658,2022-01-27,2022,US 202117496312 A,2021-10-07,US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented Reality Guidance for Spinal Surgery with Display of Structures at Risk for Lesion or Damage by Penetrating Instruments or Devices,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/126-536-584-019-658,Patent Application,yes,0,1,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
6,EP,A4,EP 1893310 A4,168-943-508-384-997,2008-06-25,2008,EP 06749326 A,2006-03-31,US 2006/0012654 W;;US 15096005 A,2005-06-13,MOVING TARGET SYSTEM,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/168-943-508-384-997,Search Report,no,6,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,ACTIVE
7,ES,U,ES 1291595 U,195-079-334-707-337,2022-06-09,2022,ES 202200155 U,2022-05-05,ES 202200155 U,2022-05-05,"Doll scarf (Machine-translation by Google Translate, not legally binding)","Bufanda doll, constituted of one piece, which consists of a scarf that will be held on the wrists thanks to two holes through which we will pass our hands. (Machine-translation by Google Translate, not legally binding)",CASAS USART CARLOS,CASAS USART CARLOS,,https://lens.org/195-079-334-707-337,Patent Application,no,0,0,2,2,0,,A41D23/00,,0,0,,,,ACTIVE
8,US,A,US 3190809 A,099-712-566-076-029,1965-06-22,1965,US 27841563 A,1963-05-06,MX 6756862 A,1962-05-31,Process for the preparation of 11alpha-hydroxy-delta4-3-keto steroids from 11-unsubstituted delta5-3-hydroxy and 3-acyloxy steroids using psilocybe caerulescens var. mazatecorum,,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/099-712-566-076-029,Granted Patent,no,1,0,3,3,0,C12P33/00;;C12P33/00;;Y10S435/911;;Y10S435/911,C12P33/00,,0,0,,,,EXPIRED
9,ES,Y,ES 1291595 Y,128-120-090-464-552,2022-08-31,2022,ES 202200155 U,2022-05-05,ES 202200155 U,2022-05-05,Bufanda muñequera,,CASAS USART CARLOS,CASAS USART CARLOS,,https://lens.org/128-120-090-464-552,Limited Patent,no,0,0,2,2,0,,A41D23/00,,0,0,,,,ACTIVE
10,US,A,US 3379621 A,024-319-620-214-014,1968-04-23,1968,US 45649265 A,1965-05-17,MX 7759664 A,1964-06-12,"Microbiological preparation of delta1, 3, 5(10)-3-hydroxy steroids",,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/024-319-620-214-014,Granted Patent,no,3,2,1,1,0,C12P33/00;;C12P33/00;;Y10S435/866;;Y10S435/866,C12P33/00,195/51,0,0,,,,EXPIRED
11,US,A,US 3149050 A,030-925-797-433-770,1964-09-15,1964,US 21021362 A,1962-07-16,MX 3149050X A,1961-07-24,Process for the production of 11alpha-hydroxylation steroids with panaeolus,,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/030-925-797-433-770,Granted Patent,no,1,0,1,1,0,C12P33/00;;C12P33/00;;Y10S435/911;;Y10S435/911,C12P33/00,,0,0,,,,EXPIRED
12,US,B2,US 11483532 B2,181-746-090-258-261,2022-10-25,2022,US 202217748614 A,2022-05-19,US 202217748614 A;;US 202217667671 A;;US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance system for spinal surgery using inertial measurement units,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,QUILES CASAS CARLOS,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/181-746-090-258-261,Granted Patent,yes,138,4,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357,10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630,"Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauers et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198 W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI: 10.1109/GVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, pp. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve,“Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;Microvision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489:116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markeriess Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”. Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay tor Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China, inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284 Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '9 5), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https.//www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter-1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFglLvsRhShqXDrSM63OcvvjlSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stullgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87- 96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car-Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).",ACTIVE
13,US,A1,US 2020/0107002 A1,192-078-043-471-586,2020-04-02,2020,US 201916703739 A,2019-12-04,US 201916703739 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented Reality Guidance for Spinal Procedures Using Stereoscopic Optical See-Through Head Mounted Displays and Surface Representations,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/192-078-043-471-586,Patent Application,yes,0,10,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
14,EP,B1,EP 1893310 B1,021-342-797-688-983,2010-07-21,2010,EP 06749326 A,2006-03-31,US 2006/0012654 W;;US 15096005 A,2005-06-13,MOVING TARGET SYSTEM,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/021-342-797-688-983,Granted Patent,yes,13,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,ACTIVE
15,US,B1,US 11750788 B1,045-422-905-450-149,2023-09-05,2023,US 202218048942 A,2022-10-24,US 202218048942 A;;US 202217748614 A;;US 202217667671 A;;US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal surgery with stereoscopic display of images and tracked instruments,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,QUILES CASAS CARLOS,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/045-422-905-450-149,Granted Patent,yes,141,0,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/00;;A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,95,090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;157-141-393-691-271;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713,23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.5772/7128;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781,"Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016,1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23. 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China, inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface ”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https.//www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjlSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation ”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, p. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markeriess Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.",ACTIVE
16,US,A1,US 2019/0349559 A1,066-511-664-221-930,2019-11-14,2019,US 201916518426 A,2019-07-22,US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY VISUALIZATION AND GUIDANCE FOR SPINAL PROCEDURES,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/066-511-664-221-930,Patent Application,yes,0,17,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
17,US,B2,US 10602114 B2,072-596-029-913-842,2020-03-24,2020,US 201916598697 A,2019-10-10,US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal surgery and spinal procedures using stereoscopic optical see-through head mounted displays and inertial measurement units,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/072-596-029-913-842,Granted Patent,yes,116,39,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713,10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781,"Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFglLvsRhShqXDrSM63OcvvjISzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS—International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.",ACTIVE
18,US,A1,US 2020/0053335 A1,105-662-481-362-627,2020-02-13,2020,US 201916598697 A,2019-10-10,US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented Reality Guidance for Spinal Surgery and Spinal Procedures using Stereoscopic Optical See-Through Head Mounted Displays and Inertial Measurement Units,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/105-662-481-362-627,Patent Application,yes,3,26,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
19,US,B1,US 11350072 B1,113-955-311-208-781,2022-05-31,2022,US 202217667671 A,2022-02-09,US 202217667671 A;;US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for bone removal and osteotomies in spinal surgery including deformity correction,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,QUILES CASAS CARLOS,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/113-955-311-208-781,Granted Patent,yes,137,6,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,96,048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;030-163-415-744-832;;157-141-393-691-271;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X,10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.1007/0-306-47316-x_13;;10.5772/7128;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013,"Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China, inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom 20.-22. Mar. 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https.//www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, p. 230, Intech, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve,“Stereoscopic Augmented Reality System for Computer Assisted Surgery”, Cars, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;Microvision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulatorand Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. Volume 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and Mckay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23. 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;Delambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI: 10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.",ACTIVE
20,AT,T1,AT E474634 T1,150-903-324-935-440,2010-08-15,2010,AT 06749326 T,2006-03-31,US 15096005 A;;US 2006/0012654 W,2005-06-13,SYSTEM MIT BEWEGLICHEM ZIEL,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/150-903-324-935-440,Granted Patent,no,0,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,,,0,0,,,,INACTIVE
21,US,A1,US 2020/0336721 A1,136-109-284-378-778,2020-10-22,2020,US 202016919639 A,2020-07-02,US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE FOR SPINAL PROCEDURES USING STEREOSCOPIC OPTICAL SEE-THROUGH HEAD MOUNTED DISPLAYS WITH DISPLAY OF VIRTUAL SURGICAL GUIDES,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/136-109-284-378-778,Patent Application,yes,0,11,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
22,ES,Y,ES 1136305 Y,154-308-870-302-375,2015-05-11,2015,ES 201500038 U,2015-01-13,ES 201500038 U,2015-01-13,Peana para el inodoro,,CASAS USART CARLOS,CASAS USART CARLOS,,https://lens.org/154-308-870-302-375,Limited Patent,no,0,0,2,2,0,,A61G5/14;;E03D11/00,,0,0,,,,ACTIVE
23,DE,D1,DE 602006015641 D1,184-682-558-870-843,2010-09-02,2010,DE 602006015641 T,2006-03-31,US 15096005 A;;US 2006/0012654 W,2005-06-13,SYSTEM MIT BEWEGLICHEM ZIEL,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/184-682-558-870-843,Granted Patent,no,0,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,ACTIVE
24,DE,B,DE 1231697 B,073-003-503-404-157,1967-01-05,1967,DE S0085381 A,1963-05-25,MX 6756862 A,1962-05-31,Verfahren zur Herstellung von 11alpha-Oxy-delta 4-3-ketosteroiden,,SYNTEX CORP,CAMPILLO CARLOS CASAS,,https://lens.org/073-003-503-404-157,Patent Application,no,2,0,3,3,0,C12P33/00;;C12P33/00;;Y10S435/911;;Y10S435/911,C12P33/00,,0,0,,,,DISCONTINUED
25,US,A,US 3118822 A,089-222-111-544-354,1964-01-21,1964,US 13906961 A,1961-09-19,MX 3118822X A,1960-10-24,Process for cyclopentanophenanthrene derivatives,,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/089-222-111-544-354,Granted Patent,no,1,1,1,1,0,C12P33/00;;Y10S435/911;;C12P33/00;;Y10S435/911,C12P33/00,,0,0,,,,EXPIRED
26,US,A,US 3119748 A,132-462-849-485-418,1964-01-28,1964,US 15324161 A,1961-11-17,MX 3119748X A,1961-06-07,Process for 11-hydroxylation of steroids,,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/132-462-849-485-418,Granted Patent,no,1,0,1,1,0,C12P33/00;;Y10S435/911;;C12P33/00;;Y10S435/911,C12P33/00,,0,0,,,,EXPIRED
27,US,B2,US 10194131 B2,072-148-603-458-604,2019-01-29,2019,US 201815972649 A,2018-05-07,US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal surgery and spinal procedures,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/072-148-603-458-604,Granted Patent,yes,100,47,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,116,78,090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713,23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781,"Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, um:nbn:de:bvd:29-opus4-54665, dated Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008, New York, MICCAI Soiety, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body'Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23. 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X//12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et aL, “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-Intemational.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.",ACTIVE
28,US,A1,US 2018/0262743 A1,102-204-435-068-710,2018-09-13,2018,US 201815972649 A,2018-05-07,US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,IMAGE-GUIDED SURGERY WITH SURFACE RECONSTRUCTION AND AUGMENTED REALITY VISUALIZATION,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/102-204-435-068-710,Patent Application,yes,2,47,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
29,WO,A3,WO 2006/137972 A3,107-298-701-689-344,2007-07-12,2007,US 2006/0015613 W,2006-04-25,US 15103205 A,2005-06-13,ADJUSTABLE LOCKING WINDAGE AND ELEVATION KNOB ASSEMBLY,"A novel, adjustable locking windage and elevation knob assembly for the improved accuracy of scopes wherein an adjustment turn knob may be raised from its locked positio to rotate freely for desired windage or elevation adjustments and thereafter be pushed back down into a locked position.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/107-298-701-689-344,Search Report,yes,3,0,4,4,0,G05G1/10;;Y10T74/2084;;F41G1/38;;Y10T74/2084;;G05G1/10;;F41G1/44,G05G1/10,,0,0,,,,PENDING
30,US,B2,US 10742949 B2,125-985-892-905-042,2020-08-11,2020,US 202016822062 A,2020-03-18,US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal procedures using stereoscopic optical see-through head mounted displays and tracking of instruments and devices,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/125-985-892-905-042,Granted Patent,yes,123,26,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X,10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013,"Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung faür die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjlSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automatio Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science+Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et aL, “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, The Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et aL, “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et aL, “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et aL, “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science+Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS—International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point loud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.",ACTIVE
31,US,A1,US 2019/0149797 A1,138-456-253-615-901,2019-05-16,2019,US 201916250158 A,2019-01-17,US 201916250158 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented Reality Guidance for Spinal Surgery and Spinal Procedures,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/138-456-253-615-901,Patent Application,yes,5,28,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
32,US,A,US 3203869 A,179-065-359-616-821,1965-08-31,1965,US 28849563 A,1963-06-17,MX 6929862 A,1962-10-11,"11alpha-hydroxylation of 6-substituted-11-desoxy steroids with microorganisms of thegenus fusarium, liseola section",,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/179-065-359-616-821,Granted Patent,no,4,3,1,1,0,C12P33/00;;Y10S435/929;;C12P33/00;;Y10S435/929,C12P33/00,,0,0,,,,EXPIRED
33,US,B2,US 11652971 B2,046-803-134-392-934,2023-05-16,2023,US 202117465980 A,2021-09-03,US 202117465980 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Image-guided surgery with surface reconstruction and augmented reality visualization,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/046-803-134-392-934,Granted Patent,yes,134,0,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/00;;A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,95,056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;030-163-415-744-832,10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.1007/0-306-47316-x_13,"Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Infomnatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Beriin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI: 10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, um:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using vol. Rendering of Intraoperatively Scanned CT Images”. Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489:116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markeriess Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-lnternational Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Aguerreche L et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users ” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China, inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality ”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface ”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284 Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media ”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom 20.-22. März 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https.//www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter-1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM630cvvjSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stullgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation ”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).",ACTIVE
34,PH,A,PH 19190 A,045-660-715-813-256,1986-01-28,1986,PH 30712 A,1984-05-23,PH 30712 A,1984-05-23,A GASIFYING DEVICE,,CARLOS S CASAS,CASAS CARLOS S,,https://lens.org/045-660-715-813-256,Granted Patent,no,0,0,1,1,0,,F24C5/00,,0,0,,,,EXPIRED
35,US,B2,US 10951872 B2,078-472-682-784-370,2021-03-16,2021,US 202017065911 A,2020-10-08,US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal procedures using stereoscopic optical see-through head mounted displays with real time visualization of tracked instruments,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/078-472-682-784-370,Granted Patent,yes,125,21,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X,23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013,"Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen-Systeme-Anwendungen Proceedings des Workshops vom 20.—Mar. 22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al. “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjlSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car-Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine-Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.",ACTIVE
36,US,B2,US 10326975 B2,121-875-719-126-894,2019-06-18,2019,US 201916250158 A,2019-01-17,US 201916250158 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal surgery and spinal procedures,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/121-875-719-126-894,Granted Patent,yes,102,37,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,116,78,061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769,10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191,"Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, InTech, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS—International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;deLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.",ACTIVE
37,US,A1,US 2021/0160472 A1,140-554-642-133-851,2021-05-27,2021,US 202117166440 A,2021-02-03,US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented Reality Guidance For Spinal Procedures Using Stereoscopic Optical See-Through Head Mounted Displays With Cameras and 3D Scanners,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/140-554-642-133-851,Patent Application,yes,0,12,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
38,WO,A3,WO 2006/137960 A3,157-900-701-108-151,2007-12-13,2007,US 2006/0012654 W,2006-03-31,US 15096005 A,2005-06-13,MOVING TARGET SYSTEM,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/157-900-701-108-151,Search Report,yes,7,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,PENDING
39,US,B2,US 10154239 B2,181-960-421-101-152,2018-12-11,2018,US 201514753705 A,2015-06-29,US 201514753705 A;;US 201462097771 P,2014-12-30,Image-guided surgery with surface reconstruction and augmented reality visualization,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/181-960-421-101-152,Granted Patent,yes,10,84,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06T19/00;;G16Z99/00;;H04N13/239,,16,12,065-923-473-535-747;;073-465-936-422-816;;096-806-811-181-091;;127-231-326-122-520;;082-395-148-262-837;;151-674-581-822-076;;034-379-844-936-451;;115-276-506-034-863;;035-079-339-764-769;;090-925-205-046-379;;141-625-316-651-444;;046-923-619-789-362,10.1016/j.compmedimag.2013.01.009;;23490236;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1109/nssmic.2011.6153680;;10.1109/iccvw.2011.6130383;;10.1007/978-3-642-19335-4_33;;24998759;;10.1016/j.compmedimag.2014.06.007;;10.1109/iccv.2011.6126310;;24658253;;10.1109/tbme.2014.2301191;;23952323;;10.3171/2013.7.spine12917;;10.1109/tase.2013.2283775;;23837969;;10.1016/j.media.2013.04.003,"Kersten-Oertel, Marta, Pierre Jannin, and D. Louis Collins. “The state of the art of visualization in mixed reality image guided surgery.” Computerized Medical Imaging and Graphics 37.2 (2013): 98-112.;;Bauer, Sebastian. “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine.”, 2014.;;Hayashibe, Mitsuhiro, et al. “Surgical navigation display system using volume rendering of intraoperatively scanned CT images.” Computer Aided Surgery 11.5 (2006): 240-246.;;Jiang, Long, et al. “A robust automated markerless registration framework for neurosurgery navigation.” The International Journal of Medical Robotics and Computer Assisted Surgery (2014).;;Noonan, P. J., et al. “The design and initial calibration of an optical tracking system using the microsoft kinect.” Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), 2011 IEEE. IEEE, 2011.;;Bauer, Sebastian, et al. “Multi-modal surface registration for markerless initial patient setup in radiation therapy using microsoft's Kinect sensor.” Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on. IEEE, 2011.;;Müller, Kerstin, et al. “Automatic multi-modal ToF/CT organ surface registration.” Bildverarbeitung für die Medizin 2011. Springer Berlin Heidelberg, 2011. 154-158.;;Vagvolgyi, Balazs, et al. “Video to CT registration for image overlay on solid organs.” Proc. Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) (2008): 78-86.;;Pauly, Olivier, et al. “Machine learning-based augmented reality for improved surgical scene understanding.” Computerized Medical Imaging and Graphics (2014).;;Kutter, Oliver, et al. “Real-time volume rendering for high quality visualization in augmented reality.” International Workshop on Augmented environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, USA. 2008.;;Ye, Mao, et al. “Accurate 3d pose estimation from a single depth image.” Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 2011.;;Ferrari, Vincenzo, Mauro Ferrari, and Franco Mosca. “Video see-through in the clinical practice.” EICS4Med 2011 (2011).;;Wang, Junchen, et al. “Augmented reality navigation with automatic marker-free image registration using 3-D image overlay for dental surgery.” Biomedical Engineering, IEEE Transactions on 61.4 (2014): 1295-1304.;;Abe, Yuichiro, et al. “A novel 3D guidance system using augmented reality for percutaneous vertebroplasty: technical note.” Journal of Neurosurgery: Spine 19.4 (2013): 492-501.;;Ren, Hongliang, Wei Liu, and Andy Lim. “Marker-based surgical instrument tracking using dual kinect sensors.” Automation Science and Engineering, IEEE Transactions on 11.3 (2014): 921-924.;;Maier-Hein, Lena, et al. “Optical techniques for 3D surface reconstruction in computer-assisted laparoscopic surgery.” Medical image analysis 17.8 (2013): 974-996.",ACTIVE
40,US,A1,US 2021/0289188 A1,011-458-686-803-290,2021-09-16,2021,US 202117332149 A,2021-05-27,US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE FOR SPINAL SURGERY,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/011-458-686-803-290,Patent Application,yes,0,7,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
41,CN,A,CN 101370559 A,047-717-808-150-17X,2009-02-18,2009,CN 200680020807 A,2006-03-31,US 15096005 A,2005-06-13,Moving target system,"Provided is a novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CARLOS CASAS JUAN,CARLOS CASAS JUAN,,https://lens.org/047-717-808-150-17X,Patent Application,no,0,1,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,DISCONTINUED
42,WO,A2,WO 2006/137960 A2,069-673-986-407-851,2006-12-28,2006,US 2006/0012654 W,2006-03-31,US 15096005 A,2005-06-13,MOVING TARGET SYSTEM,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/069-673-986-407-851,Patent Application,yes,6,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,PENDING
43,US,A1,US 2022/0295033 A1,104-632-685-666-987,2022-09-15,2022,US 202217748614 A,2022-05-19,US 202217748614 A;;US 202217667671 A;;US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE SYSTEM FOR SPINAL SURGERY USING INERTIAL MEASUREMENT UNITS,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,QUILES CASAS CARLOS,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/104-632-685-666-987,Patent Application,yes,4,5,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
44,US,B2,US 11272151 B2,155-719-797-216-130,2022-03-08,2022,US 202117496312 A,2021-10-07,US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal surgery with display of structures at risk for lesion or damage by penetrating instruments or devices,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/155-719-797-216-130,Granted Patent,yes,134,7,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,95,056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357;;030-163-415-744-832;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769,10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;10.1007/0-306-47316-x_13;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191,"Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al.,“ I he Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and Mckay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;Delambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China, inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality ”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media ”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1Iz_TUFgILvsRhShqXDrSM63OcvvjSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time vol. Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.",ACTIVE
45,US,A1,US 2022/0159227 A1,141-353-572-687-036,2022-05-19,2022,US 202217667671 A,2022-02-09,US 202217667671 A;;US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE FOR BONE REMOVAL AND OSTEOTOMIES IN SPINAL SURGERY INCLUDING DEFORMITY CORRECTION,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,QUILES CASAS CARLOS,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/141-353-572-687-036,Patent Application,yes,0,7,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
46,US,A1,US 2021/0037224 A1,000-063-980-168-907,2021-02-04,2021,US 202017065911 A,2020-10-08,US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE FOR SPINAL PROCEDURES USING STEREOSCOPIC OPTICAL SEE-THROUGH HEAD MOUNTED DISPLAYS WITH REAL TIME VISUALIZATION OF TRACKED INSTRUMENTS,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/000-063-980-168-907,Patent Application,yes,0,10,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
47,US,A1,US 2023/0362341 A1,095-141-136-697-720,2023-11-09,2023,US 202318352778 A,2023-07-14,US 202318352778 A;;US 202218048942 A;;US 202217748614 A;;US 202217667671 A;;US 202117496312 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE FOR SPINAL SURGERY WITH STEREOSCOPIC DISPLAYS,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,QUILES CASAS CARLOS,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/095-141-136-697-720,Patent Application,yes,4,0,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/04845;;G06T19/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,PENDING
48,ES,U,ES 1136305 U,144-526-017-127-218,2015-02-18,2015,ES 201500038 U,2015-01-13,ES 201500038 U,2015-01-13,"Base for the toilet (Machine-translation by Google Translate, not legally binding)","Base for the toilet, is a drawer of a solid material, one piece, in a ""U"" shape and on which the toilet will be placed. The toilet will be screwed to the floor through the base. (Machine-translation by Google Translate, not legally binding)",CASAS USART CARLOS,CASAS USART CARLOS,,https://lens.org/144-526-017-127-218,Patent Application,no,0,0,2,2,0,,A61G5/14;;E03D11/00,,0,0,,,,ACTIVE
49,EP,A2,EP 1893310 A2,150-131-285-148-884,2008-03-05,2008,EP 06749326 A,2006-03-31,US 2006/0012654 W;;US 15096005 A,2005-06-13,MOVING TARGET SYSTEM,"A novel, moving target system for the improved practice of hunting and improved shooting skills. The target may be comprised of one or more knockdown target sections moving along a track assembly on a carriage and may be preprogrammed to simulate random, realistic behaviors including running, walking, or grazing to simulate hunting game. The target may be programmed to adjust its speed randomly or in reaction to a gunshot or strike on the target or may be programmed to pause or randomly reverse direction, approximating the random behavior observed in hunting targets. The knockdown sections will react to a strike with preprogrammed behavior as described above, giving immediate feedback to the shooter.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/150-131-285-148-884,Patent Application,yes,0,0,9,9,0,F41J5/205;;F41J9/02;;F41J9/02;;F41J5/205,A63B63/00,,0,0,,,,ACTIVE
50,US,A1,US 2020/0221060 A1,147-159-783-992-937,2020-07-09,2020,US 202016822062 A,2020-03-18,US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,AUGMENTED REALITY GUIDANCE FOR SPINAL PROCEDURES USING STEREOSCOPIC OPTICAL SEE-THROUGH HEAD MOUNTED DISPLAYS AND TRACKING OF INSTRUMENTS AND DEVICES,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/147-159-783-992-937,Patent Application,yes,4,15,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
51,US,A,US 3264194 A,197-759-994-545-224,1966-08-02,1966,US 30929163 A,1963-09-16,MX 6978662 A,1962-11-16,Process for the transformation of steroids using a mutant strain of arthrobacter (corynebacterjum) simplex,,SYNTEX CORP,CARLOS CASAS-CAMPILLO,,https://lens.org/197-759-994-545-224,Granted Patent,no,2,2,1,1,0,C12P33/00;;Y10S435/843;;C12P33/00;;Y10S435/843,C12P33/00,,0,0,,,,EXPIRED
52,FR,A,FR 1417023 A,010-058-027-496-806,1965-11-05,1965,FR 998265 A,1964-12-10,FR 998265 A,1964-12-10,Procédé de préparation de dérivés du cyclopentanopolyhydrophénanthrène,,SYNTEX CORP,CAMPILLO CARLOS CASAS,,https://lens.org/010-058-027-496-806,Granted Patent,no,0,0,1,1,0,C12P33/04,C12P33/04,,0,0,,,,EXPIRED
53,US,B2,US 11050990 B2,017-535-948-271-605,2021-06-29,2021,US 202117166440 A,2021-02-03,US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal procedures using stereoscopic optical see-through head mounted displays with cameras and 3D scanners,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/017-535-948-271-605,Granted Patent,yes,128,11,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357,10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630,"Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: a View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: a Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: a Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: a Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: a Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: a High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;MELZER, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: the How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint Hip: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: a Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, urn:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: a Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom Mar. 20-22, 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: the Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjlSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).",ACTIVE
54,US,A1,US 2021/0400247 A1,051-485-640-515-191,2021-12-23,2021,US 202117465980 A,2021-09-03,US 202117465980 A;;US 202117332149 A;;US 202117166440 A;;US 202017065911 A;;US 202016919639 A;;US 202016822062 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,IMAGE-GUIDED SURGERY WITH SURFACE RECONSTRUCTION AND AUGMENTED REALITY VISUALIZATION,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/051-485-640-515-191,Patent Application,yes,4,8,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,ACTIVE
55,US,A1,US 2019/0246088 A1,092-287-603-276-099,2019-08-08,2019,US 201916240937 A,2019-01-07,US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented Reality Guidance for Spinal Surgery and Spinal Procedures,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/092-287-603-276-099,Patent Application,yes,4,24,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,H04N13/111;;A61B34/10;;A61B34/20;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,0,0,,,,DISCONTINUED
56,US,B2,US 10511822 B2,109-885-230-427-506,2019-12-17,2019,US 201916518426 A,2019-07-22,US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality visualization and guidance for spinal procedures,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/109-885-230-427-506,Granted Patent,yes,116,27,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;099-878-157-608-119;;008-519-130-618-485;;104-271-794-146-357,10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630,"Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, INTECH, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lievin and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint HIP: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable Computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Numberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7, 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”, CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International Conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion Capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;DeLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida D01:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, um:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automation Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography.”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom 20.-22. Mar. 2011 in Lübeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19,2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFgILvsRhShqXDrSM63OcvvjSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car—Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).",ACTIVE
57,WO,A2,WO 2006/137972 A2,099-876-560-098-850,2006-12-28,2006,US 2006/0015613 W,2006-04-25,US 15103205 A,2005-06-13,ADJUSTABLE LOCKING WINDAGE AND ELEVATION KNOB ASSEMBLY,"A novel, adjustable locking windage and elevation knob assembly for the improved accuracy of scopes wherein an adjustment turn knob may be raised from its locked positio to rotate freely for desired windage or elevation adjustments and thereafter be pushed back down into a locked position.",CASAS JUAN CARLOS,CASAS JUAN CARLOS,,https://lens.org/099-876-560-098-850,Patent Application,yes,0,1,4,4,0,G05G1/10;;Y10T74/2084;;F41G1/38;;Y10T74/2084;;G05G1/10;;F41G1/44,G05G1/10,,0,0,,,,PENDING
58,US,B1,US 10594998 B1,120-065-396-223-153,2020-03-17,2020,US 201916703739 A,2019-12-04,US 201916703739 A;;US 201916598697 A;;US 201916518426 A;;US 201916240937 A;;US 201815972649 A;;US 201514753705 A;;US 201462097771 P,2014-12-30,Augmented reality guidance for spinal procedures using stereoscopic optical see-through head mounted displays and surface representations,"Embodiments disclose a real-time surgery method and apparatus for displaying a stereoscopic augmented view of a patient from a static or dynamic viewpoint of the surgeon, which employs real-time three-dimensional surface reconstruction for preoperative and intraoperative image registration. Stereoscopic cameras provide real-time images of the scene including the patient. A stereoscopic video display is used by the surgeon, who sees a graphical representation of the preoperative or intraoperative images blended with the video images in a stereoscopic manner through a see-through display.",ONPOINT MEDICAL INC,CASAS CARLOS QUILES,ONPOINT MEDICAL INC (2018-01-30),https://lens.org/120-065-396-223-153,Granted Patent,yes,119,30,33,33,0,G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G02B27/0172;;G06T19/006;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;H04N13/111;;H04N13/156;;H04N13/296;;G16Z99/00;;G02B27/0172;;G06T19/006;;A61B34/20;;A61B34/10;;G02B2027/0134;;G02B2027/0138;;G02B2027/014;;A61B2090/371;;A61B2034/2057;;A61B1/00;;H04N13/111;;H04N13/156;;H04N13/296;;G06T2210/41;;G06F3/011;;A61B2034/2065;;H04N13/279;;H04N13/239;;G06F3/017;;G06F3/0304;;G06F3/04845;;G06F2203/04804;;G16Z99/00;;H04N13/366,A61B1/00;;A61B34/10;;A61B34/20;;A61B90/00;;G02B27/01;;G06F3/01;;G06F3/03;;G06F3/0484;;G06T19/00;;G16Z99/00;;H04N13/111;;H04N13/156;;H04N13/239;;H04N13/279;;H04N13/296;;H04N13/366,,140,94,048-650-983-630-317;;129-941-718-264-869;;028-769-643-437-396;;097-014-749-641-472;;035-130-906-588-951;;087-469-734-496-231;;023-704-885-024-237;;118-542-751-764-497;;008-473-603-366-724;;147-155-910-275-087;;062-048-685-939-75X;;086-008-686-615-591;;052-123-481-992-342;;005-621-751-044-957;;008-519-130-618-485;;104-271-794-146-357;;090-925-205-046-379;;082-395-148-262-837;;073-465-936-422-816;;096-806-811-181-091;;065-923-473-535-747;;046-923-619-789-362;;151-674-581-822-076;;127-231-326-122-520;;034-379-844-936-451;;035-079-339-764-769;;056-820-789-391-307;;047-824-888-647-349;;075-758-109-065-407;;026-497-274-553-674;;008-461-471-907-729;;104-190-610-490-010;;048-827-926-374-901;;020-139-846-579-661;;047-370-599-733-765;;028-040-554-455-801;;059-353-292-577-711;;047-411-430-420-841;;018-074-544-830-13X;;001-020-412-207-927;;010-000-791-445-834;;019-662-051-289-223;;152-253-449-637-907;;062-564-341-070-932;;048-929-432-459-187;;058-319-340-392-987;;022-871-477-645-925;;023-048-701-299-963;;008-710-267-699-71X;;148-560-386-224-86X;;054-789-581-133-75X;;013-965-405-530-02X;;024-027-778-620-835;;000-254-116-133-340;;017-774-667-190-401;;140-167-142-549-05X;;013-794-621-064-541;;151-790-631-478-110;;052-592-750-701-42X;;132-554-520-027-25X;;045-272-536-020-58X;;061-065-671-433-211;;008-169-807-684-138;;041-894-770-011-543;;005-797-674-934-604;;107-746-071-221-582;;054-586-769-761-440;;037-194-811-537-217;;139-755-878-303-007;;105-610-915-363-009;;014-552-543-459-824;;074-027-646-974-168;;009-268-100-838-201;;024-320-499-227-101;;057-327-417-430-480;;006-763-799-989-714;;051-432-321-865-558;;088-251-985-993-886;;052-196-864-203-790;;052-667-571-865-06X;;063-910-242-435-153;;038-294-241-278-739;;005-513-045-643-110;;014-335-092-750-338;;129-948-108-708-743;;037-174-439-115-879;;046-867-513-335-81X;;022-122-873-295-228;;013-009-144-133-092;;072-849-729-628-439;;042-056-876-447-496;;065-531-598-124-105;;008-710-267-699-71X;;025-242-655-701-713,10.1145/1889863.1889913;;10.1162/pres.1997.6.4.355;;10.1145/142920.134061;;10.1145/223904.223935;;10.1109/ismar.2007.4538837;;10.1016/s0097-8493(01)00117-0;;10.1007/s100550200012;;10.1007/978-3-642-87512-0_15;;10.1145/129888.129892;;10.1145/223904.223964;;10.1259/bjr/80676194;;15677360;;10.3390/s140917212;;pmc4208221;;25230306;;10.1145/179606.179687;;10.1007/978-3-642-19335-4_46;;10.1016/j.suronc.2011.07.002;;21802281;;10.1145/159544.159630;;23952323;;10.3171/2013.7.spine12917;;10.1109/iccvw.2011.6130383;;10.3109/10929080600971104;;17127649;;10.1080/10929080600971104;;10.1002/rcs.1626;;25328118;;10.1016/j.compmedimag.2013.01.009;;23490236;;23837969;;10.1016/j.media.2013.04.003;;10.1007/978-3-642-19335-4_33;;10.1109/nssmic.2011.6153680;;24998759;;10.1016/j.compmedimag.2014.06.007;;24658253;;10.1109/tbme.2014.2301191;;10.1007/978-3-642-33418-4_74;;23286098;;24876445;;pmc4455368;;10.1177/1932296814535561;;10.1007/978-3-642-44964-2;;10.1109/34.121791;;10.1007/978-3-540-75757-3_53;;18051088;;10.1088/0031-9155/48/3/402;;12608617;;11168273;;10.1034/j.1600-0501.2001.012001069.x;;12472271;;10.1109/tmi.2002.803099;;10.1016/s1361-8415(00)00007-4;;10972322;;10.1097/00003086-199809000-00014;;9755770;;10.1007/bfb0056206;;10.1155/2016/9358369;;10.1007/978-3-642-37484-5_12;;10.1016/j.ejvs.2012.03.007;;22487781;;10.1097/brs.0000000000001830;;27513166;;pmc5113235;;22358024;;10.2214/ajr.11.6918;;pmc3447176;;22843764;;10.1148/radiol.12112640;;10.1109/ismar-adjunct.2016.0073;;10.1016/j.patcog.2014.01.005;;10.1007/978-3-642-32630-1_4;;18391274;;pmc4164865;;25036719;;10.3109/17453674.2014.940573;;25882923;;10.1016/j.jbi.2015.04.003;;10.1109/iccv.2011.6126326;;10.1109/cvpr.2009.5206794;;10.1109/tpami.2011.206;;22442120;;10.1007/978-3-642-37331-2_42;;10.1109/icicse.2013.27;;24921542;;10.1364/oe.22.013484;;10.1006/rtim.2002.0279;;10.1007/978-1-4614-7657-3;;10.1109/iwar.1999.803809;;28189409;;10.1016/j.knee.2016.12.007;;10.1136/bmjinnov-2016-000133;;10.15662/ijareeie.2014.0307013;;10.1109/titb.2004.826734;;15217256;;10.1016/s0531-5131(01)00017-6;;16112975;;10.3109/10929080500165476;;10.1080/10929080500165476;;23632059;;10.1016/j.compmedimag.2012.12.002;;pmc3796657;;10.1145/37402.37422;;10.1109/ismar.2008.4637321;;10.1007/3-540-45787-9_10;;10.1201/b17545-19;;10.1109/plans.2014.6851442;;10.1007/978-3-642-04268-3_64;;20426027;;10.1016/s1048-6666(00)80047-6;;10.1007/s00402-007-0500-y;;18000674;;pmc5125765;;10.2147/mder.s119161;;27920583;;25361359;;10.3928/01477447-20141023-05;;10.1162/105474600566808;;10.1007/3-540-45468-3_29;;10.1007/3-540-45787-9_15;;10.1109/isar.2000.880922;;10.1016/j.ocl.2013.11.002;;24684910;;10.1007/978-0-387-73858-1_4;;10.1117/12.2222068;;20172791;;10.1109/tbme.2010.2040278;;10.1145/2159616.2159620;;10.1109/iccv.2015.86;;22402692;;10.1109/tvcg.2012.56;;10.1007/11866565_46;;17354912;;10.1007/s11263-006-7938-1;;10.1109/jdt.2014.2361147;;10.1109/cvpr.2014.513;;21343479;;10.2214/ajr.10.5038;;28664415;;10.1007/s11548-017-1630-5;;25882923;;10.1016/j.jbi.2015.04.003;;10.1002/rcs.1770;;27569781,"Aguerreche L. et al., “Reconfigurable Tangible Devices for 3D Virtual Object Manipulation by Single or Multiple Users.” VRST 2010, Nov. 2010, Hong Kong, Hong Kong SAR China. inria-00534095.;;Azura, R., “A survey of augmented reality.” Teleoperators and Virtual Environments, vol. 6, Issue 4, Aug. 1997, pp. 355-385.;;Bajura, M., et al., “Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient.”, In Proceedings of SIGGRAPH '92, 1992, New York: ACM Press, pp. 203-210.;;Benford, S. et al., “User embodiment in collaborative virtual environments”, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '95, pp. 242-249, 1995.;;Bichlmeier C., et al. “Contextual Anatomic Mimesis Hybrid In-Situ Visualization Method for Improving Multi-Sensory Depth Perception in Medical Augmented Reality.”, IEEE 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.;;Billinghurst, et al., “The MagicBook: A Transitional AR Interface.”, Computers and Graphics, Nov. 2001, pp. 745-753.;;Billinghurst, M., et al., “Experiments with Face to Face Collaborative AR Interfaces.”, Virtual Reality Journal, vol. 4, No. 2, (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality.”, Communications of the ACM 2002, vol. 45 Issue 7, pp. 64-70 (2002).;;Billinghurst, M., et al., “Collaborative Mixed Reality”, First International Symposium on Mixed Reality (ISMR '99). Mixed Reality—Merging Real and Virtual Worlds, pp. 261-284. Berlin: Springer Verlag.;;Cruz-Neira C. et al., “The cave: audio visual experience automatic virtual environment.”, Commun. ACM, vol. 35, No. 6, pp. 64-72, Jun. 1992.;;Fitzmaurice, G., et al., “Bricks: Laying the Foundations for Graspable User Interfaces.”, Proceedings of Conference on Human Factors in Computing Systems (CHI '95), Denver, Colorado, ACM Press, 442-449, (1995).;;Gee A, et al., “Processing and visualizing three-dimensional ultrasound data.”, The British Journal of Radiology, vol. 77, S186-S193, (2004).;;Gonzalez, Smart Multi-Level Tool for Remote Patient Monitoring Based on a Wireless Sensor Network and Mobile Augmented Reality, Sensors, Sep. 2014; 14(9): 17212-17234.;;Gorbert, M. et al., “Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography”, Proceedings of CHI '98, Apr. 18-23, 1998, © 1998 ACM.;;Ishii, H., et al., “Iterative Design of Seamless Collaboration Media.”, Communications of the ACM, vol. 37, No. 8, Aug. 1994, pp. 83-97.;;Maier-Hein, L. et al., “Towards Mobile Augmented Reality for On-Patient Visualization of Medical Images.”, Bildverarbeitung für die Medizin 2011: Algorithmen—Systeme—Anwendungen Proceedings des Workshops vom 20.-22. Mar. 2011 in Lubeck (pp. 389-393).;;Medeiros D. et al., “Proposal and evaluation of a tablet-based tool for 3D virtual environments.”, SBC Journal on 3D Interactive Systems, vol. 4, No. 2, pp. 30-40, (2013).;;Nicolau, “Augmented Reality in Laparoscopic Surgical Oncology.”, Surgical Oncology, vol. 20, pp. 89-201 (2011).;;Salmi Jamali, S. et al., “Utilising Mobile-Augmented Reality for Learning Human Anatomy.”, 7th World Conference on Educational Sciences, (WCES-2015), Feb. 5-7, 2015, Novotel Athens Convention Center, Athens, Greece.;;Schramm, Kinect: The Company Behind the Tech Explains How it Works, Jun. 19, 2010, https://www.engadget.com/2010/06/19/kinect-how-it-works-from-the-company-behind-the-tech/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xILmNvbS8&guce_referrer_sig=AQAAAKHcnRaFMexHHXiiRrcGjKYjWQ2VJGsMA556eCVncvte7f0VM4aN3GpWj1WqU3RfCnTwHcTbxmibv1lz_TUFg1LvsRhShqXDrSM63OcvvjiSzpUoBvsC2LsOmHqf-zifqdYe1ctf0D0MDM78YhH-u7w9JUfxuLDGVUxUi9hDQLZo.;;Watsen, K., et al., “A Handheld Computer as an Interaction Device to a Virtual Environment.”, Proceedings of the International Projection Technologies Workshop, Stuttgart, Germany, May 10-11, 1999.;;Wellner, P., “Interacting with Paper on the DigitalDesk.”, Communications of the ACM. 36, 7, 87-96, (1993).;;Yamazaki, K. et al., “Gesture Laser and Gesture Laser Car-Development of an Embodied Space to Support Remote Instruction.”, In Bodker, S., Kyng, M. and Schmidt, K. (eds.), Proceedings of the Sixth European Conference on Computer Supported Cooperative Work—ECSC W'99, Sep. 12-16, Copenhagen, Denmark. Kluwer Academic Publishers, Dordrecht.;;Yang H. et al., “Exploring collaborative navigation.”, Proceedings of the 4th international conference on Collaborative virtual environments , CVE, pp. 135-142, (2002).;;Abe et al., “A Novel 3D Guidance System Using Augmented Reality for Percutaneous Vertebroplasty”, Journal of Neurological Spine, vol. 19, pp. 492-501, Oct. 2013.;;Bauer, Sebastian, Doctoral Thesis, “Rigid and Non-Rigid Surface Registration for Range Imaging Applications in Medicine”, um:nbn:de:bvb:29-opus4-54665, Nov. 27, 2014.;;Bauer et al., “Multi-Modal Surface Registration for Markerless Initial Patient Setup in Radiation Therapy Using Microsoft's Kinect Sensor”, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Barcelona, Nov. 2011, pp. 1175-1181, Jan. 16, 2012.;;Ferrari et al., “Video See-Through in the Clinical Practice”, 1st International Workshop on Engineering Interactive Computing Systems for Medicine and Health Care, EICS4Med. vol. 727, pp. 19-24, 2011.;;Hayashibe et al., “Surgical Navigation Display System Using Volume Rendering of Intraoperatively Scanned CT Images”, Computer Aided Surgery, vol. 11, No. 5, pp. 240-246, Sep. 2006.;;Jiang et al., “A Robust Automated Markerless Registration Framework for Neurosurgery Navigation”, The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 11, pp. 436-447, Oct. 19, 2014.;;Kersten-Oertel et al., “The State of the Art of Visualization in Mixed Reality Image Guided Surgery”, Computerized Medical Imaging and Graphics, vol. 37, pp. 98-112, Jan. 2013.;;Kutter et al., “Real-time Volume Rendering for High Quality Visualization in Augmented Reality”, International Workshop on Augmented Environments for Medical Imaging including Augmented Reality in Computer-aided Surgery (AMI-ARCS 2008), New York, MICCAI Society, Sep. 2008.;;Maier-Hein et al., “Optical Techniques for 3D Surface Reconstruction in Computer-Assisted Laparoscopic Surgery”, Medical Image Analysis, vol. 17, pp. 974-996, May 3, 2013.;;Muller et al., “Automatic Multi-Modal ToF/CT Organ Surface Registration”, Bildverarbeitung für die Medizin, pp. 154-158, Mar. 2011.;;Noonan et al., “The Design and Initial Calibration of an Optical Tracking System Using the Microsoft Kinect”, IEEE Nuclear Science Symposium Conference Record, pp. 3614-3617, Oct. 2011.;;Pauly et al., “Machine Learning-Based Augmented Reality for Improved Surgical Scene Understanding”, Computerized Medical Imaging and Graphics, vol. 1280, pp. 1-6, Jun. 2014.;;Ren et al., “Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors”, IEEE Transactions on Automatio Science and Engineering, vol. 11, No. 3, pp. 921-924, Jul. 2014.;;Vagvolgyi et al., “Video to CT Registration for Image Overlay on Solid Organs”, Procedural Augmented Reality in Medical Imaging and Augmented Reality in Computer-Aided Surgery (AMIARCS) pp. 78-86, 2008.;;Wang et al., “Augmented Reality Navigation with Automatic Marker-Free Image Registration Using 3-D Image Overlay for Dental Surgery”, IEEE Transactions on Biomedical Engineering, vol. 61, No. 4, pp. 1295-1304, Apr. 2014.;;Ye et al., “Accurate 3D Pose Estimation From a Single Depth Image”, IEEE International Conference on Computer Vision (ICCV), pp. 731-738, Nov. 2011.;;Aichert et al., “Image-Based Tracking of the Teeth for Orthodontic Augmented Reality”, MICCAI 2012, Part II, LNCS 7511, pp. 601-608, Springer-Verlag, Berlin Heidelberg 2012.;;Andersen et al., “Virtual Annotations of the Surgical Field through an Augmented Reality Transparent Display”CrossMark, May 27, 2015, DOI 10.1007/s00371-015-1135-6.;;Armstrong et al., “A Heads-Up Display for Diabetic Limb Salvage Surgery: A View Through teh Google Looking Glass”, Journal of Diabetes Science and Technology, 2014, p. 951-956, vol. 8(5), Sage.;;“A Look Into the Body—Augmented Reality in Computer Aided Surgery”, Fakultat fur Informatik der Technischen Universitat Munchen, DOCMED.tv.;;Baker et al., “The Emergence of Augmented Reality in Orthopaedic Surgery and Education”, The Orthopaedic Journal at Harvard Medical School, Jun. 2015, www.orthojournalhms.org/16/article8_16.html, vol. 16.;;Bauer et al., “Joint ToF Image Denoising and Registration with a CT Surface in Radiation Therapy”, International conference on Scale Space and Variational Methods in Computer Vision, 2011.;;Bauer S. et al. (2013) Real-Time Range Imaging in Health Care: A Survey. In: Grzegorzek M., Theobalt C., Koch R., Kolb A. (eds) Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications. Lecture Notes in Computer Science, vol. 8200. Springer, Berlin, Heidelberg.;;Besl and McKay, “A Method for Registration of 3-D Shapes”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Feb. 1992, p. 239-256, vol. 14, No. 2, IEEE.;;Bichlmeier et al., “Virtually Extended Surgical Drilling Device: Virtual Mirror for Navigated Spine Surgery”, MICCAI, 2007, pp. 434-441, Part I, LNCS 4791, Springer-Verlag, Berlin Heidelberg.;;Birkfellner et al., “Computer-enhanced Stereoscopic Vision in a Head-mounted Operating Binocular”, Physics in Medicine and Biology, 2003, N49-N57, Phys. Med. Biol. 48, Institute of Physics Publishing.;;Birkfellner et al., “In-vitro Assessment of a Registration Protocol for Image Guided Implant Dentistry”, Clin. Oral Impl., Res 12, 2001, p. 69-78, Munksgaard.;;Birkfellner et al., “A Head-Mounted Operating Binocular for Augmented Reality Visualization in Medicine—Design and Initial Evaluation”, IEEE Transactions on Medical Imaging, Aug. 2002, p. 991-997, vol. 21, No. 8, IEEE.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, Medical Image Analysis, 2000, 67-72, vol. 4, Elsevier Science B.V.;;Blackwell et al., “Augmented Reality and Its Future in Orthopaedics”, Clinical Orthopaedics and Related Research, Sep. 1998, pp. 111-122, No. 354, Lippincott Williams & Wilkins.;;Blackwell et al., “An Image Overlay System for Medical Data Visualization”, MICCAI, 1998, p. 232-240.;;“3D Optical Microscopy for Orthopedic Implants”, Bruker Nano Surfaces, AZoM.com, Jun. 17, 2016.;;Daniel and Ramos, “Augmented Reality for Assistance of Total Knee Replacement”, Journal of Electrical and Computer Engineering, 2016, 1-6, vol. 2016, Article ID 9358369, http://dx.doi.org/10.1155/2016/9358369, Hindawi Publishing Corporation.;;Catani et al., “Knee Surgery Using Computer Assisted Surgery and Robotics”, ESSKA, 2013, Library of Congress No. 2012954676, Springer Heidelberg New York Dordrecht London.;;Chandak, “MEMS Based Wireless Controlled Robot with Voice and Video Camera”, International Journal of Scientific & Engineering Research, Apr. 2014, p. 456-460, vol. 5, Issue 4, IJSER.;;Charbonnier, “Real Virtuality: Perspectives Offered by the Combination of Virtual Reality Headsets and Motion capture”, Artanim, Aug. 23, 2015.;;Cui et al., “KinectAvatar: Fully Automatic Body Capture Using a Single Kinect”, 2013, Augmented Vision, DFKI.;;deLambert et al., “Electromagnetic Tracking for Registration and Navigation in Endovascular Aneurysm Repair: A Phantom Study”, European Journal of Vascular and Endovascular Surgery, 2012, p. 684-689, 43, Elsevier Publishing.;;Draelos, “The Kinect Up Close: Modifications for Short-Range Depth Imaging”, A thesis submitted to the Gradate Faculty of North Carolina State University, 2012.;;Elmi-Terander et al., “Surgical Navigation Technology Based on Augmented Reality and Integrated 3D Intraoperative Imaging”, Spine, 2016, pp. E1303-E1311, vol. 41, No. 21, Wolters Kluwer Health, Inc.;;Fischer et al., “Medical Augmented Reality Based on Commercial Image Guided Surgery”, Eurographics Symposium on Virtual Environments, 2004, The Eurographics Association.;;Flusser et al., “Image Fusion: Principles, Methods, and Applications”, Tutorial EUSIPCO, 2007, Lecture Notes.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MRI-Guided Intervention: Accuracy for Lumbar Spinal Procedures with a 1.5-T MRI System”, Vascular and Interventional Radiology, Jun. 22, 2011, AJR2012; 198: W266-W273 0361-803X/12/1983-266, AJR:198, Mar. 2012, American Roentgen Ray Society.;;Fritz et al., “Augmented Reality Visualization with Image Overlay for MR Imaging-Guided Interventions: Assessment of Performance in Cadaveric Shoulder and Hip Arthrography at 1.5T1”, Radiology, Oct. 2012, p. 254-259, vol. 265:No. 1, radiology.rsna.org.;;Garon et al., “Real-Time High Resolution 3D Data on the HoloLens”, IEEE International Symposium on Mixed and Augmented Reality, 2016, DOI: 10.1109/ISMAR-Adjunct.2016.0073.;;Garrido-Jurado et al., “Automatic Generation and Detection of Highly Reliable Fiducial Markers Under Occlusion”, Pattern Recognition, Jun. 2014.;;Gavaghan et al., “Augmented Reality Image Overlay Projection for Image Guided Open Liver Ablation of Metastic Liver Cancer”, AE-CAI 2011, LNCS 7264, pp. 36-46, 2012, Springer-Verlag Berlin Heidelberg.;;George and Kesavadas, “Low Cost Augmented Reality for Training of MRI-Guided Needle Biopsy of the Spine”, Medicine Meets Virtual Reality, 2008, p. 138-140, 16, IOS Press.;;Germano, “Advanced Techniques in Image-Guided Brain and Spine Surgery”, 2002, Thieme Medical Publishers, Inc.;;Gromov et al., “What is the Optimal Alignment of the Tibial and Femoral Components in Knee Arthroplasty”, Acta Orthopaedica, Sep. 2014, 85(5): 480-487, www.ncbi.nlm.nih.gov/pmc/articles/PMC4164865/, Nordic Orthopaedic Federation.;;Xiaojun et al., “Development of a Surgical Navigation System Based on Augmented Reality Using an Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55 (2015) 124-131, Elsevier.;;Hinterstoisser et al., “Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes”, 2011, ICCV.;;Hinterstoisser et al., “Real-Time Learning of Accurate Patch Rectification”, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Jun. 20-25, 2009, Miami, Florida DOI:10.1109/CVPR.2009.5206794.;;Hinterstoisser et al., “Gradient Response Maps for Real-Time Detection of Texture-less Objects”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011.;;Hoff, “Fusion of Data from Head-Mounted and Fixed Sensors”, Submitted to the First International Workshop on Augmented Reality, Nov. 1, 1998, San Francisco, California.;;Hinterstoisser et al., “Model Based Training, Detection and Pose Estimation of Texture-less 3D Objects in Heavily Cluttered Scenes”, ACCV, 2012.;;“Holographic Weapon Sight”, Wikipedia, https://en.wikipedia.org/wiki/Holographic_weapon_sight, Nov. 22, 2016.;;Hu et al., “A Convenient Method of Video See-Through Augmented Reality based on Image-Guided Surgery System”, Internet Computing for Engineering and Science, 2013, p. 100-103, IEEE, Shanghai.;;Hua et al., “A 3D Integral Imaging Optical See-Through Head-Mounted Display”, Optics Express, May 28, 2014, vol. 22, No. 11.;;Ji and Yang, “Real-Time Eye, Gaze, and Face Pose Tracking for Monitoring Driver Vigilance”, Real-Time Imaging, 2002, p. 357-377, 8, Elsevier Science Ltd.;;Jolesz, “Intraoperative Imaging and Image-Guided Therapy”, 2014, Springer Science + Business Media New York.;;Kanade et al., “Simulation, Planning, and Execution of Computer-Assisted Surgery”, 1996.;;Kato et al., “Marker Tracking and HMD Calibration for a Video-Based Augmented Reality Conferencing System”, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality, Oct. 20-21, 1999, DOI: 10.1109/IWAR.1999.803809.;;Kim et al., “Registration Accuracy Enhancement of a Surgical Navigation System for Anterior Cruciate Ligament Reconstruction: A Phantom and Cadaveric Study”, The Knee, 2017, p. 329-339, Elsevier Science.;;Kolodzey et al., “Wearable Technology in the Operating Room: A Systematic Review”, BMJ Innov, 2017, 3:55-63.;;Kumar and Neelima, “A Portable Wireless Head Movement Controlled Human-Computer Interface for People with Disabilities”, International Journal of Advance Research in Electrical, Electronics and Instrumentation Engineering, Jul. 2014, (print): 2320-3765, (online): 2278-8875, vol. 3, Issue 7.;;Lamata et al., “Augmented Reality for Minimally Invasive Surgery: Overview and Some Recent Advances”, Augmented Reality, Jan. 2010, pp. 230, Intech, Croatia.;;Liao et al., “Surgical Navigation by Autostereoscopic Image verlay of Integral Videography”, IEEE Transactions on Information Technology in Biomedicine, Jun. 2004, p. 114-121, vol. 8, No. 2, IEEE.;;Lieven and Keeve, “Stereoscopic Augmented Reality System for Computer Assisted Surgery”, CARS, Jun. 27-30, 2001, Berlin, Germany.;;Lindert et al., “The Use of a Head-Mounted Display for Visualization in Neuroendoscopy”, Computer Aided Surgery, 2004, 9:6, 251-256, Taylor & Francis Group.;;Linte et al., “On Mixed Reality Environments for Minimally Invasive Therapy Guidance: Systems Architecture, Successes and Challenges in Their Implementation from Laboratory to Clinic”, Comput Med Imaging Graph, Mar. 2013, 37(2):83-97.;;Lorensen and Cline, “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”, Computer Graphics, Jul. 1987, p. 163-169, vol. 21, No. 4, Schenectady, New York.;;Liu et al., “An Optical See-Through Head Mounted Display with Addressable Focal Planes”, IEEE International Symposium on Mixed and Augmented Reality, Sep. 15-18, 2008, p. 33-42.;;Masamune et al., “An Image Overlay System with Enhanced Reality for Percutaneous Therapy Performed Inside CT Scanner”, MICCAI, 2002, pp. 77-84, LNCS 2489, Springer-Verlag Berlin Heidelberg.;;Maurer et al., “Augmented Reality Visualization of Brain Structures with Stereo and Kinetic Depth Cues: System Description and Initial Evaluation with Head Phantom”, Medical Imaging 2001: Visualization, Display, and Image-Guided Procedures, Feb. 17-22, 2001, pp. 445-456, Society of Photo-Optical Instrumentation Engineers.;;Melzer, “Head-Mounted Displays”, The Avionics Handbook, 2001, CRC Press LLC.;;Menozzi et al., “Development of Vision-Aided Navigation for a Wearable Outdoor Augmented Reality System”, IEEE, 2014, 760-772.;;MicroVision, 2015 Annual Report.;;“Microvision's Nomad Augmented Vision System: The How and the Why”, SID Pacific Northwest Chapter Meeting, Jun. 11, 2003.;;Moore et al., “Image Guidance for Spinal Facet Injections Using Tracked Ultrasound”, MICCAI, 2009, pp. 516-523, Part I, LNCS 5761, Springer-Verlag Berlin Heidelberg.;;Newcombe et al., “KinectFusion: Real-Time Dense Surface Mapping and Tracking”, IEEE ISMAR, Inproceedings, 2011.;;Nikou et al., “Augmented Reality Imaging Technology for Orthopaedic Surgery”, Operative Techniques in Orthopaedics, Jan. 2000, pp. 82-86, vol. 10, No. 1.;;Okamura, “Lecture 8: Tracking and Surgical Navigation, Registration”, ME 328: Medical Robotics, Spring 2013.;;Ortega et al., “Usefulness of a Head Mounted Monitor Device for Viewing Intraoperative Fluoroscopy During Orthopaedic Procedures”, Arch Orthop Trauma Surg, 2008, 128:1123-1126, Springer-Verlag.;;Paprosky et al., “Intellijoint Hip: a 3D Mini-Optical Navigation Tool for Improving Intraoperative Accuracy During Total Hip Arthroplasty”, Med Devices, 2016, 9: 401-408, Dove Medical Press Limited.;;Peters et al., “Image Guided Interventions: Technology and Applications”, 2008, Springer Science + Business Media, LLC.;;Ponce et al., “Emerging Technology in Surgical Education: Combining Real-Time Augmented reality and Wearable computing Devices”, The Cutting Edge, Nov. 2014, pp. 751-757, vol. 37, No. 11.;;Qian et al., “Comprehensive Tracker Based Display Calibration for Holographic Optical See-Through Head-Mounted Display”, 2017.;;Rhodes, “A Brief History of Wearable Computing”, http://wearables.www.media.mit.edu/projects/wearables/timeline.html.;;Rinaldi et al., “Computer-Guided Applications for Dental Implants, Bone Grafting, and Reconstructive Surgery”, 2009, Elsevier.;;Robinett et al., “A Computer Model for the Stereoscopic Optics of a Head-Mounted Display”, SPIE, vol. 1457, Stereoscopic Displays and Applications II, 1991.;;Rolland et al., “A Comparison of Optical and Video See-Through Head-Mounted Displays”, SPIE, vol. 2351, Telemanipulator and Telepresence Technologies, 1994.;;Rolland et al., “Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization”, Presence, vol. 9, No. 3, pp. 287-309, Jun. 2000.;;Rosenthal et al., “Augmented Reality Guidance for Needle Biopsies: A Randomized, Controlled Trial in Phantoms”, MICCAI, 2001, LNCS 2208: 240-248.;;Rosman et al., “Articulated Motion Segmentation of Point Clouds by Group-Valued Regularization”, Eurographics Workshop on 3D Object Retrieval, 2012.;;Sauer et al., “An Augmented Reality Navigation System with a Single-Camera Tracker: System Design and Needle Biopsy Phantom Trial”, MICCAI, 2002, LNCS 2489: 116-124.;;Sauer et al., “Augmented Workspace: Designing an AR Testbed”, IEEE, 2000, 47-53.;;Scuderi et al.,“Total Knee Arthroplasty with a Novel Navigation System Within the Surgical Field”, Orthop Clin N Am 45, 2014, 167-173, Elsevier.;;Vogt, “Real-Time Augmented Reality for Image-Guided Interventions”, 2009, Erlangen-Nurnberg.;;Shen et al., “3D Augmented Reality with Integral Imaging Display”, SPIE vol. 9867, Three-Dimensional Imaging, Visualization,and Display, 2016.;;Liao et al., “3-D Augmented Reality for MRI-Guided Surgery Using Integral Videography Autostereoscopic Image Overlay”, IEEE 2010.;;Sherstyuk et al., “Dynamic Eye Convergence for Head-Mounted Displays Improves User Performance in Virtual Environments”, the Association for Computing Machinery, Inc., 2012.;;State et al., “Stereo magery from the UNC Augmented Reality System for Breast Biopsy Guidance”, University of North Carolina at Chapel Hill.;;Tan et al., “A Versatile Learning-Based 3D Temporal Tracker: Scalable, Robust, Online”, ICCV, 2015, Computer Vision Foundation.;;Tong et al., “Scanning 3D Full Human Bodies Using Kinects”, PubMed, Apr. 2012 DOI: 10.1109/TVCG.2012.56.;;Traub et al., “Hybrid Navigation Interface for Orthopedic and Trauma Surgery”, MICCAI, 2006, LNCS 4190, pp. 373-380, Springer-Verlog Berlin Heidelberg.;;Trevisan et al., “Towards Markerless Augmented Medical Visualization”, AMI-ARC, 2004, pp. 57-66.;;Vercauteren et al., “Real Time Autonomous Video Image Registration for Endomicroscopy: Fighting thhe Compromises”, SPIEBIOS, 2007.;;Vogt et al., “Reality Augmentation for Medical Procedures: System Architecture, Single Camera Marker Tracking, and System Evaluation”, International Journal of Computer Vision, 2006, p. 179-190, Springer Science + Business Media, LLC.;;Wang et al., “Augmented Reality 3D Displays with Micro Integral Imaging”, Journal of Display Technology, Oct. 2014.;;Wang et al., “3D Modeling from Wide Baseline Range Scans Using Contour Coherence”, IEEE, 2014.;;Davies et al., “Computer Assisted Orthopaedic Surgery”, 8th Annual Meeting of CAOS-International Proceedings, Jun. 4-7 2008, Hong Kong, http://www.CAOS-International.org/.;;Weiss et al., “Augmented Reality Visualization Using Image-Overlay for MR-Guided Interventions: System Description, Feasibility, and Initial Evaluation in a Spine Phantom”, Musculoskeletal Imaging Technical Innovation, AJR2011; 196:W305-W307 0361-803X/11/1963-W305, Mar. 2011, American Roentgen Society.;;Wilson et al., “Validation of Three-Dimensional Models of the Distal Femur Created from Surgical Navigation Point Cloud Data”, CAOS, 2015.;;Chen et al., “Development of a Surgical Navigation System Based on Augmented Reality Using and Optical See-Through Head-Mounted Display”, Journal of Biomedical Informatics, 55, 2015, 124-131.;;Yoon et al., “Technical Feasibility and Safety of an Intraoperative Head-Up Display Device During Spine Instrumentation”, The International Journal of Medical Robotics and Computer Assisted Surgery, 2016.",ACTIVE
59,US,B2,US 7997163 B2,190-907-739-682-720,2011-08-16,2011,US 15103205 A,2005-06-13,US 15103205 A,2005-06-13,Adjustable locking windage and elevation knob,"A novel, adjustable locking windage and elevation knob assembly for the improved accuracy of scopes wherein an adjustment turn knob may be raised from its locked position to rotate freely for desired windage or elevation adjustments and thereafter be pushed back down into a locked position.",GAMO OUTDOOR USA INC,CASAS JUAN CARLOS,DAISY MANUFACTURING COMPANY (2020-03-20);;PLASTICAN INC (2005-05-27);;GAMO OUTDOOR USA INC (2011-05-18),https://lens.org/190-907-739-682-720,Granted Patent,yes,14,53,4,4,0,G05G1/10;;Y10T74/2084;;F41G1/38;;Y10T74/2084;;G05G1/10;;F41G1/44,G05G1/10;;F41G1/38;;G02B23/00,74/553;;42/122;;359/424,2,0,,,"The World Book Encyclopedia, 1988 Ed., p. 223.;;Webster's II New Riverside University Dictionary, 1994 Ed., p. 550.",ACTIVE
60,WO,A1,WO 2019/074705 A1,174-854-316-548-072,2019-04-18,2019,US 2018/0053713 W,2018-10-01,US 201762571964 P,2017-10-13,DYNAMIC HQ FOR CLOSED LOOP CONTROL,"A method of controlling a blood pump having a predefined hydraulic performance including at least from the group consisting of estimating and measuring an instantaneous flow rate during operation of the blood pump at a predetermined rotational speed of an impeller of the blood pump, the instantaneous flow rate including a plurality of flow rate data points. The plurality of flow rate data points define a trajectory around at least one from the group consisting of an operational point of a predefined pressure-flow curve associated with the predetermined rotational speed of the impeller of the blood pump and a target operational point of a target pressure-flow curve different than the predefined pressure-flow curve. The predetermined rotational speed of the impeller is adjusted until the plurality of flow rate data points define a predetermined trajectory around at least one of the operational point and the target operational point.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/174-854-316-548-072,Patent Application,yes,10,0,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,0,0,,,,PENDING
61,EP,A1,EP 3856275 A1,192-068-328-256-442,2021-08-04,2021,EP 19779326 A,2019-09-17,US 2019/0051417 W;;US 201862737244 P,2018-09-27,MAP ESTIMATION ON VAD PATIENTS,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/192-068-328-256-442,Patent Application,yes,0,2,6,6,0,A61M60/178;;A61M60/538;;A61M60/554;;A61M60/531;;A61M60/857;;A61B5/0215;;A61B5/686;;A61B5/746;;A61M60/232;;A61M60/523;;A61M60/585;;A61M60/422;;A61B5/02108;;A61B5/746;;A61M2205/04;;A61M2205/18;;A61M2205/3334;;A61M60/178;;A61M60/411;;A61M60/232;;A61M60/585;;A61M60/538;;A61M60/523;;A61M60/531,A61M1/10;;A61M1/12,,0,0,,,,ACTIVE
62,ES,A1,ES 2229854 A1,058-306-850-811-173,2005-04-16,2005,ES 200201975 A,2002-08-23,US 31448701 P,2001-08-23,"Electronic game module, has transmitter emitting trigger signal to receptor that is connected to game console unit for receiving and processing signals from transmitter, and control panel provided with game console unit",The module has a wireless pointing and shooting unit (1) comprising a barrel (3) that is attached with a trigger mechanism (5). An optical-electronic system (6) is provided with a screen (30). The trigger mechanism generates a trigger signal for obtaining a firing position. A transmitter (7) emits the trigger signal to a receptor (8) that is connected to a game console unit (40) for receiving and processing the signals from the transmitter. A control panel (9) is provided with the game console unit.,GAMO IND SA,CASAS SALVA JUAN CARLOS,,https://lens.org/058-306-850-811-173,Patent Application,no,8,0,2,2,0,A63F13/04;;A63F13/06;;A63F13/12;;F41A33/04;;F41A33/06;;F41G3/2616,A63F13/219;;A63F13/28;;A63F13/843;;F41A33/04;;F41A33/06;;F41G3/26,,0,0,,,,EXPIRED
63,EP,A1,EP 3694573 A1,175-413-494-686-745,2020-08-19,2020,EP 18792700 A,2018-10-01,US 201762571964 P;;US 2018/0053713 W,2017-10-13,DYNAMIC HQ FOR CLOSED LOOP CONTROL,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/175-413-494-686-745,Patent Application,yes,0,0,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,0,0,,,,ACTIVE
64,WO,A3,WO 2005/039384 A3,180-535-418-695-531,2006-12-28,2006,US 2004/0030235 W,2004-09-15,US 50313403 P;;US 94013104 A,2003-09-15,METHOD AND SYSTEM FOR CELLULAR TRANSPLANTATION,"The present invention provides a method for treating an injury of a spinal cord of a patient. The method includes implanting a therapeutic substance in the spinal cord under indirect visualization. The indirect visualization may be provided by an endoscope, and the therapeutic substance may include cells. The present invention also provides a device for treating an injury of the spinal cord. The device includes skin visualization means for visualizing the spinal cord through a skin puncture, and injection means for injecting a therapeutic substance into the spinal cord.",GUEST JAMES;;CASAS CARLOS,GUEST JAMES;;CASAS CARLOS,,https://lens.org/180-535-418-695-531,Search Report,yes,2,0,5,5,0,A61M25/0041;;A61M25/0041;;A61B17/3468;;A61B17/3468;;A61B2017/00969;;A61B2017/00969;;A61M2025/0007;;A61M2025/0007,A61M31/00;;A61B17/00;;A61B17/34;;A61M25/00,,0,0,,,,PENDING
65,WO,A1,WO 2012/100210 A1,036-374-023-024-121,2012-07-26,2012,US 2012/0022096 W,2012-01-20,US 201161434894 P,2011-01-21,FLOW ESTIMATION IN A BLOOD PUMP,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",HEARTWARE INC;;CASAS FERNANDO;;REYES CARLOS,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/036-374-023-024-121,Patent Application,yes,8,1,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,1,0,,,See also references of EP 2665499A4,PENDING
66,EP,B1,EP 3856275 B1,033-499-791-050-605,2023-01-18,2023,EP 19779326 A,2019-09-17,US 2019/0051417 W;;US 201862737244 P,2018-09-27,MAP ESTIMATION ON VAD PATIENTS,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/033-499-791-050-605,Granted Patent,yes,2,0,6,6,0,A61M60/178;;A61M60/538;;A61M60/554;;A61M60/531;;A61M60/857;;A61B5/0215;;A61B5/686;;A61B5/746;;A61M60/232;;A61M60/523;;A61M60/585;;A61M60/422;;A61B5/02108;;A61B5/746;;A61M2205/04;;A61M2205/18;;A61M2205/3334;;A61M60/178;;A61M60/411;;A61M60/232;;A61M60/585;;A61M60/538;;A61M60/523;;A61M60/531,A61M60/178;;A61B5/00;;A61B5/0215;;A61M60/232;;A61M60/422;;A61M60/523;;A61M60/531;;A61M60/538;;A61M60/554;;A61M60/585;;A61M60/857,,0,0,,,,ACTIVE
67,US,B2,US 11653841 B2,063-356-975-931-140,2023-05-23,2023,US 201916573011 A,2019-09-17,US 201916573011 A;;US 201862737244 P,2018-09-27,MAP estimation on VAD patients,A method of determining a mean arterial pressure index of a patient having an implantable blood pump including determining a pump speed and a pump flow value; analyzing the pump speed and the pump flow value to a pump loss constant value; determining a graft hydraulic resistance value during a systolic phase of a cardiac cycle based on the analysis of the pump speed and the pump flow value to the pump loss constant value; determining a mean arterial pressure index during a diastolic phase of the cardiac cycle based on the determined graft hydraulic resistance value; comparing the mean arterial pressure index of the patient to a mean arterial pressure index range; and generating an alert when the mean arterial pressure index varies with respect to a mean arterial pressure index range.,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2020-01-27),https://lens.org/063-356-975-931-140,Granted Patent,yes,31,0,6,6,0,A61M60/178;;A61M60/538;;A61M60/554;;A61M60/531;;A61M60/857;;A61B5/0215;;A61B5/686;;A61B5/746;;A61M60/232;;A61M60/523;;A61M60/585;;A61M60/422;;A61B5/02108;;A61B5/746;;A61M2205/04;;A61M2205/18;;A61M2205/3334;;A61M60/178;;A61M60/411;;A61M60/232;;A61M60/585;;A61M60/538;;A61M60/523;;A61M60/531,A61B5/021;;A61B5/00;;A61M60/178;;A61M60/232;;A61M60/411;;A61M60/523;;A61M60/531;;A61M60/538;;A61M60/585,,3,1,003-219-421-767-804,10.1016/j.healun.2014.08.011;;25438163,"International Search Report and Written Opinion dated Dec. 19, 2019, for corresponding International Application No. PCT/US2019/051417; International Filing Date: Sep. 17, 2019 consisting of 9-pages.;;D. Vickers, et al., Estimation of systemic blood pressure from pump parameters in continuous-flow left ventricular assist devices, St. Vincent's Hospital, Sydney, Australia, http://dx.doi.org/10.1016/j.hlc.2015.06.224.;;Kei Woldendorp, et al., A novel method of blood pressure measurement in patients with continuous-flow left ventricular assist devices, The Journal of Heart and Lung Transplantation, vol. 33, No. 11, Nov. 2014, 4 pages.",ACTIVE
68,US,A1,US 2020/0101209 A1,081-049-323-121-508,2020-04-02,2020,US 201916573011 A,2019-09-17,US 201916573011 A;;US 201862737244 P,2018-09-27,MAP ESTIMATION ON VAD PATIENTS,A method of determining a mean arterial pressure index of a patient having an implantable blood pump including determining a pump speed and a pump flow value; analyzing the pump speed and the pump flow value to a pump loss constant value; determining a graft hydraulic resistance value during a systolic phase of a cardiac cycle based on the analysis of the pump speed and the pump flow value to the pump loss constant value; determining a mean arterial pressure index during a diastolic phase of the cardiac cycle based on the determined graft hydraulic resistance value; comparing the mean arterial pressure index of the patient to a mean arterial pressure index range; and generating an alert when the mean arterial pressure index varies with respect to a mean arterial pressure index range.,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2020-01-27),https://lens.org/081-049-323-121-508,Patent Application,yes,14,0,6,6,0,A61M60/178;;A61M60/538;;A61M60/554;;A61M60/531;;A61M60/857;;A61B5/0215;;A61B5/686;;A61B5/746;;A61M60/232;;A61M60/523;;A61M60/585;;A61M60/422;;A61B5/02108;;A61B5/746;;A61M2205/04;;A61M2205/18;;A61M2205/3334;;A61M60/178;;A61M60/411;;A61M60/232;;A61M60/585;;A61M60/538;;A61M60/523;;A61M60/531,A61M1/12;;A61B5/00;;A61B5/021;;A61M1/10,,0,0,,,,ACTIVE
69,AU,A1,AU 2012/207146 A1,112-322-328-590-888,2013-09-05,2013,AU 2012/207146 A,2012-01-20,US 201161434894 P;;US 2012/0022096 W,2011-01-21,Flow estimation in a blood pump,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/112-322-328-590-888,Patent Application,no,0,0,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,0,0,,,,ACTIVE
70,KR,A,KR 20140040112 A,131-979-602-047-083,2014-04-02,2014,KR 20137022089 A,2012-01-20,US 201161434894 P;;US 2012/0022096 W,2011-01-21,FLOW ESTIMATION IN A BLOOD PUMP,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/131-979-602-047-083,Patent Application,no,0,1,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,0,0,,,,DISCONTINUED
71,WO,A2,WO 2005/039384 A2,149-774-382-322-868,2005-05-06,2005,US 2004/0030235 W,2004-09-15,US 50313403 P;;US 94013104 A,2003-09-15,METHOD AND SYSTEM FOR CELLULAR TRANSPLANTATION,"The present invention provides a method for treating an injury of a spinal cord of a patient. The method includes implanting a therapeutic substance in the spinal cord under indirect visualization. The indirect visualization may be provided by an endoscope, and the therapeutic substance may include cells. The present invention also provides a device for treating an injury of the spinal cord. The device includes skin visualization means for visualizing the spinal cord through a skin puncture, and injection means for injecting a therapeutic substance into the spinal cord.",GUEST JAMES;;CASAS CARLOS,GUEST JAMES;;CASAS CARLOS,,https://lens.org/149-774-382-322-868,Patent Application,yes,0,1,5,5,0,A61M25/0041;;A61M25/0041;;A61B17/3468;;A61B17/3468;;A61B2017/00969;;A61B2017/00969;;A61M2025/0007;;A61M2025/0007,A61B17/00;;A61B17/34;;A61M25/00,,0,0,,,,PENDING
72,EP,B1,EP 3694573 B1,037-573-542-036-640,2022-09-14,2022,EP 18792700 A,2018-10-01,US 201762571964 P;;US 2018/0053713 W,2017-10-13,DYNAMIC HQ FOR CLOSED LOOP CONTROL,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/037-573-542-036-640,Granted Patent,yes,1,0,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/50;;A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,0,0,,,,ACTIVE
73,WO,A1,WO 2019/035823 A1,121-647-083-259-143,2019-02-21,2019,US 2017/0047118 W,2017-08-16,US 2017/0047118 W,2017-08-16,MAP MEASUREMENT ON VAD PATIENTS WITH LOW PULSATILITY,"An implantable blood pump system including a blood pump, an impeller in communication with the blood pump, and a controller in communication with the blood pump. The controller is configured to measure a current drawn by the blood pump and a blood flow from the blood pump during operation, correlate the current to a systolic arterial pressure and a diastolic arterial pressure, and adjust a speed of the impeller relative to a predetermined speed and the blood flow to correspond to an increase in the current correlated to the systolic arterial pressure and a decrease in the current correlated to the diastolic arterial pressure.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/121-647-083-259-143,Patent Application,yes,8,0,3,3,0,A61M60/216;;A61M60/562;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/546;;A61M60/178;;A61M60/531;;A61M60/538;;A61M60/216;;A61M60/562,A61M60/178;;A61M60/216;;A61M60/531;;A61M60/538;;A61M60/562,,0,0,,,,PENDING
74,US,A1,US 2019/0111194 A1,175-858-834-410-801,2019-04-18,2019,US 201816148312 A,2018-10-01,US 201816148312 A;;US 201762571964 P,2017-10-13,DYNAMIC HQ FOR CLOSED LOOP CONTROL,"A method of controlling a blood pump having a predefined hydraulic performance including at least from the group consisting of estimating and measuring an instantaneous flow rate during operation of the blood pump at a predetermined rotational speed of an impeller of the blood pump, the instantaneous flow rate including a plurality of flow rate data points. The plurality of flow rate data points define a trajectory around at least one from the group consisting of an operational point of a predefined pressure-flow curve associated with the predetermined rotational speed of the impeller of the blood pump and a target operational point of a target pressure-flow curve different than the predefined pressure-flow curve. The predetermined rotational speed of the impeller is adjusted until the plurality of flow rate data points define a predetermined trajectory around at least one of the operational point and the target operational point.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2018-11-01),https://lens.org/175-858-834-410-801,Patent Application,yes,3,1,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,0,0,,,,ACTIVE
75,US,A1,US 2019/0054222 A1,058-370-830-063-362,2019-02-21,2019,US 201715678555 A,2017-08-16,US 201715678555 A,2017-08-16,MAP MEASUREMENT ON VAD PATIENTS WITH LOW PULSATILITY,A method of operating an implantable blood pump implanted within a heart of a patient comprising measuring at least one from the group consisting of a current drawn by the implantable blood pump and a blood flow from the implantable blood pump during operation; correlating the at least one from the group consisting the current and the blood flow to a systolic arterial pressure and a diastolic arterial pressure; and adjusting a speed of an impeller of the implantable blood pump relative to a predetermined speed to correspond to an increase the at least one from the group consisting the current during a systolic phase of a cardiac cycle and a decrease in the at least one from the group consisting the current and the blood flow during a diastolic phase of the cardiac cycle.,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2017-08-15),https://lens.org/058-370-830-063-362,Patent Application,yes,1,4,2,2,0,A61M5/1723;;A61M5/14276;;A61M2230/30;;A61M2205/3334;;A61M2205/50;;A61M2205/3365;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M60/569;;A61M2230/30;;A61M2205/3334;;A61M2205/50;;A61M2205/3365;;A61M5/1723;;A61M5/14276;;A61M60/148;;A61M60/178;;A61M60/546;;A61M60/216;;A61M60/569,A61M60/178;;A61M60/216;;A61M60/546;;A61M60/569,,0,0,,,,ACTIVE
76,ES,B1,ES 2229854 B1,080-767-911-611-108,2006-06-16,2006,ES 200201975 A,2002-08-23,US 31448701 P,2001-08-23,MODULO ADAPTABLE A JUEGO ELECTRONICO CON UNIDAD DE APUNTAMIENTO Y DISPARO SIN HILOS.,"Módulo adaptable a juego electrónico con unidad de apuntamiento y disparo sin hilos. Comprende una unidad de apuntamiento y disparo sin hilos (1) que incluye una boca de cañón (3) simulada, y un mecanismo de gatillo (5); un sistema óptico-electrónico de puntería (6) que genera una señal de apuntamiento informativa de un punto de dicha pantalla (30) o blanco móvil apuntado por dicha boca de cañón (3); unos medios para generar una señal de disparo cuando el gatillo (5) alcanza una posición de disparo; un emisor (7) capaz de emitir inalámbricamente dichas señales de apuntamiento y disparo; y unos medios para producir un movimiento y/o un ruido asociados en simultaneidad con cada disparo; y un receptor (8) conectado a una consola de juegos (40) para recibir y procesar las señales emitidas por dicho emisor (7) y transmitirlas a la consola (40). Opcionalmente incluye un panel de control (9) sin hilos.",GAMO IND SA,CASAS SALVA JUAN CARLOS,,https://lens.org/080-767-911-611-108,Granted Patent,no,0,0,2,2,0,A63F13/04;;A63F13/06;;A63F13/12;;F41A33/04;;F41A33/06;;F41G3/2616,A63F13/219;;A63F13/28;;A63F13/843;;F41A33/04;;F41A33/06;;F41G3/26,,0,0,,,,EXPIRED
77,CA,A1,CA 2825354 A1,156-308-456-069-03X,2012-07-26,2012,CA 2825354 A,2012-01-20,US 201161434894 P;;US 2012/0022096 W,2011-01-21,FLOW ESTIMATION IN A BLOOD PUMP,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/156-308-456-069-03X,Patent Application,no,0,0,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,0,0,,,,DISCONTINUED
78,US,B2,US 9511179 B2,167-057-038-643-428,2016-12-06,2016,US 201213355297 A,2012-01-20,US 201213355297 A;;US 201161434894 P,2011-01-21,Flow estimation in a blood pump,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",CASAS FERNANDO;;REYES CARLOS;;HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,HEARTWARE INC (2012-05-30),https://lens.org/167-057-038-643-428,Granted Patent,yes,14,36,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10;;A61M1/12,,5,0,,,"International Search Report issued by the International Searching Authority (ISA/US) on May 23, 2012 in connection with International Application No. PCT/US2012/022096.;;Written Opinion of the International Searching Authority issued by the International Searching Authority (ISA/US) on May 12, 2012 in connection with International Application No. PCT/US2012/022096.;;Notification Concerning Transmittal of International Preliminary Report on Patentability (Chapter I of the Patent Cooperation Treaty), including an International Preliminary Report on Patentability and Written Opinion of the International Searching Authority, mailed Aug. 1, 2013 by The International Bureau of WIPO in connection with PCT International Application No. PCT/US2012/022096, filed Jan. 20, 2012.;;Partial Inernational Search Report for Application No. PCT/US2014/040847 dated Oct. 9, 2014.;;International Search Report and Written Opinion for Application No. PCT/US2014/040847 dated May 27, 2015.",ACTIVE
79,WO,A1,WO 2020/068480 A1,171-302-059-250-907,2020-04-02,2020,US 2019/0051417 W,2019-09-17,US 201862737244 P,2018-09-27,MAP ESTIMATION ON VAD PATIENTS,A method of determining a mean arterial pressure index of a patient having an implantable blood pump including determining a pump speed and a pump flow value; analyzing the pump speed and the pump flow value to a pump loss constant value; determining a graft hydraulic resistance value during a systolic phase of a cardiac cycle based on the analysis of the pump speed and the pump flow value to the pump loss constant value; determining a mean arterial pressure index during a diastolic phase of the cardiac cycle based on the determined graft hydraulic resistance value; comparing the mean arterial pressure index of the patient to a mean arterial pressure index range; and generating an alert when the mean arterial pressure index varies with respect to a mean arterial pressure index range.,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/171-302-059-250-907,Patent Application,yes,12,0,6,6,0,A61M60/178;;A61M60/538;;A61M60/554;;A61M60/531;;A61M60/857;;A61B5/0215;;A61B5/686;;A61B5/746;;A61M60/232;;A61M60/523;;A61M60/585;;A61M60/422;;A61B5/02108;;A61B5/746;;A61M2205/04;;A61M2205/18;;A61M2205/3334;;A61M60/178;;A61M60/411;;A61M60/232;;A61M60/585;;A61M60/538;;A61M60/523;;A61M60/531,A61M1/10;;A61M1/12,,0,0,,,,PENDING
80,US,B2,US 7666177 B2,183-622-970-145-650,2010-02-23,2010,US 94013104 A,2004-09-14,US 94013104 A;;US 50313403 P,2003-09-15,Method and system for cellular transplantation in the spinal cord,"The present invention provides a method for treating an injury of a spinal cord of a patient The method includes implanting a therapeutic substance in the spinal cord under indirect visualization. The indirect visualization may be provided by an endoscope, and the therapeutic substance may include cells. The present invention also provides a device for treating an injury of the spinal cord. The device includes skin visualization means for visualizing the spinal cord through a skin puncture, and injection means for injecting a therapeutic substance into the spinal cord.",GUEST JAMES;;CASAS CARLOS,GUEST JAMES;;CASAS CARLOS,INVIVO THERAPEUTICS HOLDINGS CORP (2015-11-24);;GUEST DR. JAMES (2004-12-03),https://lens.org/183-622-970-145-650,Granted Patent,yes,8,3,5,5,0,A61M25/0041;;A61M25/0041;;A61B17/3468;;A61B17/3468;;A61B2017/00969;;A61B2017/00969;;A61M2025/0007;;A61M2025/0007,A61M31/00;;A61B17/00;;A61B17/34;;A61M25/00,604/506;;604/500,3,1,066-368-253-833-386,10.1046/j.1460-9568.1998.00071.x;;9749723,"""Schwann cell genetically modified to secrete human BDNF promote axonal regowth across transected adult rat spinal cord"". Phililppe Menei et al., European Journal of Neuroscience, vol. 10, pp. 607-621, 1998.;;Casas, CE, EJ Owen, Oliveira M, Guest JD: Endoscopic Transplantation into the conus medullaris. Soc. Neurosci Abstr. 2002 852.8. Nov. 2002.;;Cellular transplantation into the spinal cord using an endoscopic technique. C Casas, E Owen, J Guest. Presented at the AANS/CNS Section on Disorders of the Spine and Peripheral Nerves, Orlando, FL, Feb. 2002.",ACTIVE
81,AU,B2,AU 2012/207146 B2,080-700-881-793-791,2016-10-06,2016,AU 2012/207146 A,2012-01-20,US 201161434894 P;;US 2012/0022096 W,2011-01-21,Flow estimation in a blood pump,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/080-700-881-793-791,Granted Patent,no,2,0,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,0,0,,,,ACTIVE
82,CN,A,CN 111032109 A,151-017-913-157-448,2020-04-17,2020,CN 201780093948 A,2017-08-16,US 2017/0047118 W,2017-08-16,MAP MEASUREMENT ON VAD PATIENTS WITH LOW PULSATILITY,"An implantable blood pump system including a blood pump, an impeller in communication with the blood pump, and a controller in communication with the blood pump. The controller is configured to measure a current drawn by the blood pump and a blood flow from the blood pump during operation, correlate the current to a systolic arterial pressure and a diastolic arterial pressure, and adjust a speed of the impeller relative to a predetermined speed and the blood flow to correspond to an increase in the current correlated to the systolic arterial pressure and a decrease in the current correlated tothe diastolic arterial pressure.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/151-017-913-157-448,Patent Application,no,6,0,3,3,0,A61M60/216;;A61M60/562;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/546;;A61M60/178;;A61M60/531;;A61M60/538;;A61M60/216;;A61M60/562,A61M60/178;;A61M60/216;;A61M60/531;;A61M60/538;;A61M60/562,,0,0,,,,DISCONTINUED
83,US,B2,US 10806840 B2,150-386-573-103-722,2020-10-20,2020,US 201816148312 A,2018-10-01,US 201816148312 A;;US 201762571964 P,2017-10-13,Dynamic HQ for closed loop control,"A method of controlling a blood pump having a predefined hydraulic performance including at least from the group consisting of estimating and measuring an instantaneous flow rate during operation of the blood pump at a predetermined rotational speed of an impeller of the blood pump, the instantaneous flow rate including a plurality of flow rate data points. The plurality of flow rate data points define a trajectory around at least one from the group consisting of an operational point of a predefined pressure-flow curve associated with the predetermined rotational speed of the impeller of the blood pump and a target operational point of a target pressure-flow curve different than the predefined pressure-flow curve. The predetermined rotational speed of the impeller is adjusted until the plurality of flow rate data points define a predetermined trajectory around at least one of the operational point and the target operational point.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2018-11-01),https://lens.org/150-386-573-103-722,Granted Patent,yes,14,0,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,1,0,,,"International Search Report and Written Opinion dated Jan. 21, 2019, for corresponding International Application No. PCT/2018/053713; International Filing Date: Oct. 1, 2018 consisting of 10-pages.",ACTIVE
84,EP,A1,EP 3668559 A1,073-134-768-582-573,2020-06-24,2020,EP 17758006 A,2017-08-16,US 2017/0047118 W,2017-08-16,MAP MEASUREMENT ON VAD PATIENTS WITH LOW PULSATILITY,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/073-134-768-582-573,Patent Application,yes,0,0,3,3,0,A61M60/216;;A61M60/562;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/546;;A61M60/178;;A61M60/531;;A61M60/538;;A61M60/216;;A61M60/562,A61M60/178;;A61M60/216;;A61M60/531;;A61M60/538;;A61M60/562,,0,0,,,,PENDING
85,US,B2,US 10543302 B2,084-009-677-635-314,2020-01-28,2020,US 201715678555 A,2017-08-16,US 201715678555 A,2017-08-16,Map measurement on VAD patients with low pulsatility,A method of operating an implantable blood pump implanted within a heart of a patient comprising measuring at least one from the group consisting of a current drawn by the implantable blood pump and a blood flow from the implantable blood pump during operation; correlating the at least one from the group consisting the current and the blood flow to a systolic arterial pressure and a diastolic arterial pressure; and adjusting a speed of an impeller of the implantable blood pump relative to a predetermined speed to correspond to an increase the at least one from the group consisting the current during a systolic phase of a cardiac cycle and a decrease in the at least one from the group consisting the current and the blood flow during a diastolic phase of the cardiac cycle.,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2017-08-15),https://lens.org/084-009-677-635-314,Granted Patent,yes,13,0,2,2,0,A61M5/1723;;A61M5/14276;;A61M2230/30;;A61M2205/3334;;A61M2205/50;;A61M2205/3365;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M60/569;;A61M2230/30;;A61M2205/3334;;A61M2205/50;;A61M2205/3365;;A61M5/1723;;A61M5/14276;;A61M60/148;;A61M60/178;;A61M60/546;;A61M60/216;;A61M60/569,A61M60/178;;A61M60/216;;A61M60/546;;A61M60/569,,1,0,,,"International Search Report and Written Opinion dated Apr. 19, 2018, for corresponding International Application No. PCT/US2017/047118; International Filing Date: Aug. 16, 2017 consisting of 15-pages.",ACTIVE
86,EP,A4,EP 2665499 A4,196-033-458-934-913,2017-06-07,2017,EP 12736244 A,2012-01-20,US 201161434894 P;;US 2012/0022096 W,2011-01-21,FLOW ESTIMATION IN A BLOOD PUMP,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/196-033-458-934-913,Search Report,no,2,0,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10;;A61M1/12,,1,0,,,See also references of WO 2012100210A1,DISCONTINUED
87,US,B2,US 11376419 B2,063-218-448-298-595,2022-07-05,2022,US 202017017873 A,2020-09-11,US 202017017873 A;;US 201816148312 A;;US 201762571964 P,2017-10-13,Dynamic HQ for closed loop control,"A method of controlling a blood pump having a predefined hydraulic performance including at least from the group consisting of estimating and measuring an instantaneous flow rate during operation of the blood pump at a predetermined rotational speed of an impeller of the blood pump, the instantaneous flow rate including a plurality of flow rate data points. The plurality of flow rate data points define a trajectory around at least one from the group consisting of an operational point of a predefined pressure-flow curve associated with the predetermined rotational speed of the impeller of the blood pump and a target operational point of a target pressure-flow curve different than the predefined pressure-flow curve. The predetermined rotational speed of the impeller is adjusted until the plurality of flow rate data points define a predetermined trajectory around at least one of the operational point and the target operational point.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2018-11-01),https://lens.org/063-218-448-298-595,Granted Patent,yes,14,0,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/50;;A61M60/148;;A61M60/178;;A61M60/216;;A61M60/419;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,1,0,,,"International Search Report and Written Opinion dated Jan. 21, 2019, for corresponding International Application No. PCT/2018/053713; International Filing Date: Oct. 1, 2018 consisting of 10-pages.",ACTIVE
88,US,B2,US 9492601 B2,063-650-887-448-041,2016-11-15,2016,US 201313951302 A,2013-07-25,US 201313951302 A;;US 201213355297 A;;US 201361831027 P;;US 201161434894 P,2011-01-21,Suction detection on an axial blood pump using BEMF data,"The presence or absence of a suction condition in an implantable blood pump is determined at least in part based on a parameter related to flow, such as a parameter related to thrust on the rotor of the pump. A local extreme of the parameter representing the minimum flow during ventricular diastole in an earlier interval is used to establish a threshold value. A value of the parameter representing the minimum flow during ventricular diastole in a later interval is compared to this threshold. If the comparison indicates a substantial decline in the minimum flow between the earlier and later intervals is associated with a suction condition. During the absence of a suction condition, the threshold is continually updated, so that the system does not indicate presence of a suction condition if the flow decreases gradually.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,HEARTWARE INC (2013-08-21),https://lens.org/063-650-887-448-041,Granted Patent,yes,15,34,2,18,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/871;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/523;;A61M2205/3334;;A61M60/871;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/237;;A61M60/523;;A61M60/546,A61M1/12;;A61M1/10,,6,0,,,"Partial Inernational Search Report for Application No. PCT/US2014/040847 dated Oct. 9, 2014.;;International Search Report and Written Opinion for Application No. PCT/US2014/040847 dated May 27, 2015.;;International Search Report issued by the International Searching Authority (ISA/US) on May 23, 2012 in connection with International Application No. PCT/US2012/022096.;;Written Opinion of the International Searching Authority issued by the International Searching Authority (ISA/US) on May 12, 2012 in connection with International Application No. PCT/US2012/022096.;;Office Action issued Mar. 27, 2013 in connection with U.S. Appl. No. 13/355,297.;;Notification Concerning Transmittal of International Preliminary Report on Patentability (Chapter I of the Patent Cooperation Treaty), including International Preliminary Report on Patentability and Written Opinion of the International Searching Authority, mailed Aug. 1, 2013 by the International Bureau of WIPO in connection with PCT International Application No. PCT/US2012/022096, filed Jan. 20, 2012.",ACTIVE
89,US,A1,US 2020/0405931 A1,044-897-494-364-352,2020-12-31,2020,US 202017017873 A,2020-09-11,US 202017017873 A;;US 201816148312 A;;US 201762571964 P,2017-10-13,DYNAMIC HQ FOR CLOSED LOOP CONTROL,"A method of controlling a blood pump having a predefined hydraulic performance including at least from the group consisting of estimating and measuring an instantaneous flow rate during operation of the blood pump at a predetermined rotational speed of an impeller of the blood pump, the instantaneous flow rate including a plurality of flow rate data points. The plurality of flow rate data points define a trajectory around at least one from the group consisting of an operational point of a predefined pressure-flow curve associated with the predetermined rotational speed of the impeller of the blood pump and a target operational point of a target pressure-flow curve different than the predefined pressure-flow curve. The predetermined rotational speed of the impeller is adjusted until the plurality of flow rate data points define a predetermined trajectory around at least one of the operational point and the target operational point.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2018-11-01),https://lens.org/044-897-494-364-352,Patent Application,yes,0,1,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,0,0,,,,ACTIVE
90,CA,A1,CA 2539191 A1,013-111-451-250-37X,2005-05-06,2005,CA 2539191 A,2004-09-15,US 50313403 P;;US 94013104 A;;US 2004/0030235 W,2003-09-15,METHOD AND SYSTEM FOR CELLULAR TRANSPLANTATION,"The present invention provides a method for treating an injury of a spinal cord of a patient. The method includes implanting a therapeutic substance in the spinal cord under indirect visualization. The indirect visualization may be provided by an endoscope, and the therapeutic substance may include cells . The present invention also provides a device for treating an injury of the spinal cord. The device includes skin visualization means for visualizing th e spinal cord through a skin puncture, and injection means for injecting a therapeutic substance into the spinal cord.",GUEST JAMES,CASAS CARLOS;;GUEST JAMES,,https://lens.org/013-111-451-250-37X,Patent Application,no,0,0,5,5,0,A61M25/0041;;A61M25/0041;;A61B17/3468;;A61B17/3468;;A61B2017/00969;;A61B2017/00969;;A61M2025/0007;;A61M2025/0007,A61B17/00;;A61B17/34;;A61B17/94;;A61M25/00,,0,0,,,,DISCONTINUED
91,CN,A,CN 112888476 A,044-147-653-436-390,2021-06-01,2021,CN 201980063986 A,2019-09-17,US 201862737244 P;;US 2019/0051417 W,2018-09-27,MAP ESTIMATION ON VAD PATIENTS,A method of determining a mean arterial pressure index of a patient having an implantable blood pump including determining a pump speed and a pump flow value; analyzing the pump speed and the pump flow value to a pump loss constant value; determining a graft hydraulic resistance value during a systolic phase of a cardiac cycle based on the analysis of the pump speed and the pump flow value to the pump loss constant value; determining a mean arterial pressure index during a diastolic phase of the cardiac cycle based on the determined graft hydraulic resistance value; comparing the mean arterial pressure index of the patient to a mean arterial pressure index range; and generating an alert when the mean arterial pressure index varies with respect to a mean arterial pressure index range.,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/044-147-653-436-390,Patent Application,no,27,1,6,6,0,A61M60/178;;A61M60/538;;A61M60/554;;A61M60/531;;A61M60/857;;A61B5/0215;;A61B5/686;;A61B5/746;;A61M60/232;;A61M60/523;;A61M60/585;;A61M60/422;;A61B5/02108;;A61B5/746;;A61M2205/04;;A61M2205/18;;A61M2205/3334;;A61M60/178;;A61M60/411;;A61M60/232;;A61M60/585;;A61M60/538;;A61M60/523;;A61M60/531,A61M60/148;;A61B5/021;;A61M60/135;;A61M60/205;;A61M60/50,,0,0,,,,PENDING
92,EP,A1,EP 2665499 A1,139-705-281-500-707,2013-11-27,2013,EP 12736244 A,2012-01-20,US 201161434894 P;;US 2012/0022096 W,2011-01-21,FLOW ESTIMATION IN A BLOOD PUMP,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/139-705-281-500-707,Patent Application,yes,0,1,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,0,0,,,,DISCONTINUED
93,CN,A,CN 111201049 A,183-605-130-223-041,2020-05-26,2020,CN 201880066311 A,2018-10-01,US 201762571964 P;;US 2018/0053713 W,2017-10-13,DYNAMIC HQ FOR CLOSED LOOP CONTROL,"A method of controlling a blood pump having a predefined hydraulic performance including at least from the group consisting of estimating and measuring an instantaneous flow rate during operation of the blood pump at a predetermined rotational speed of an impeller of the blood pump, the instantaneous flow rate including a plurality of flow rate data points. The plurality of flow rate data points define a trajectory around at least one from the group consisting of an operational point of a predefined pressure-flow curve associated with the predetermined rotational speed of the impeller of the blood pump and a target operational point of a target pressure-flow curve different than the predefined pressure-flow curve. The predetermined rotational speed of the impeller is adjusted until the plurality of flow rate data points define a predetermined trajectory around at least one of the operational point and the target operational point.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO,,https://lens.org/183-605-130-223-041,Patent Application,no,6,0,9,9,0,A61M60/546;;A61M60/857;;A61M60/422;;A61M60/216;;A61M60/523;;A61M60/178;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/546;;A61M60/523;;A61M60/422;;A61M60/216;;A61M60/178;;A61M2205/3331;;A61M2205/3334;;A61M2205/3365,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/523;;A61M60/546;;A61M60/857,,0,0,,,,ACTIVE
94,CN,A,CN 103328018 A,164-109-023-877-515,2013-09-25,2013,CN 201280006098 A,2012-01-20,US 2012/0022096 W;;US 201161434894 P,2011-01-21,Flow estimation in a blood pump,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,,https://lens.org/164-109-023-877-515,Patent Application,no,4,13,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,,0,0,,,,INACTIVE
95,US,A,US 6038942 A,082-133-864-747-720,2000-03-21,2000,US 93087297 A,1997-10-08,ES 9600634 A;;ES 9700057 W,1996-03-15,Manually adjusted device for control cable terminals,"A manually adjusted device for terminals of control cables having a longitudinal housing provided on a main body of a terminal and open at one end, a regulating rod which is slideable in both directions, and having an interior end and an exterior end, the regulating rod being linked to the longitudinal housing by the interior end so that the exterior end projects outwardly of the main body, device for securing a position of the regulating rod with respect to the terminal, thrust device including at least one thrust spring which works permanently under compression with one end resting against the interior end of the regulating rod and another end resting against the main body so that the regulating rod is permanently subjected to an action of a force directed from outside inwards, and a longitudinal housing in which the thrust spring is fitted, the longitudinal housing in which the thrust spring is fitted extending parallel to the longitudinal housing of the regulating rod and being linked by a guide groove, and a transverse thrust extension which traverses the guide groove and interacts with the thrust spring.",FICO CABLES SA,GABAS CARLOS;;CASAS JORDI,FICO CABLES S.A (1997-09-18),https://lens.org/082-133-864-747-720,Granted Patent,yes,3,11,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,74/500.5;;X192111 R,0,0,,,,EXPIRED
96,US,A1,US 2012/0245681 A1,131-526-427-398-481,2012-09-27,2012,US 201213355297 A,2012-01-20,US 201213355297 A;;US 201161434894 P,2011-01-21,FLOW ESTIMATION IN A BLOOD PUMP,"The flow rate of blood in an implantable blood pump is determined at least in part based on a parameter related to thrust on the rotor of the pump. The parameter may be a parameter related to displacement of the rotor along its axis, such as a function of the back electromotive force generated in one or more coils of the stator. The back electromotive force may be measured during open-phase periods of a particular coil or set of coils, during which no power is applied to the coil or set of coils by the motor drive circuit. The parameter related to thrust may be used in conjunction with the speed of rotation of the rotor, the magnitude of current supplied to the rotor, or both to determine the flow rate. The pump may be controlled responsive to the determined flow rate.",CASAS FERNANDO;;REYES CARLOS,CASAS FERNANDO;;REYES CARLOS,HEARTWARE INC (2012-05-30),https://lens.org/131-526-427-398-481,Patent Application,yes,0,110,12,18,0,A61M2205/3334;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/546;;A61M60/824;;A61M60/422;;A61M60/237;;A61M60/538;;A61M60/178;;A61M60/825;;A61M60/822;;A61M60/546;;A61M60/538;;A61M60/148;;A61M60/585;;A61M60/242;;A61M60/422;;A61M60/237;;A61M60/178;;A61M2205/3334;;A61M2205/3334;;A61M60/148;;A61M60/824;;A61M60/825;;A61M60/822;;A61M60/178;;A61M60/242;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/585,A61M1/10,623/3.28,0,0,,,,ACTIVE
97,ES,U,ES 1067753 U,195-744-470-004-350,2008-06-16,2008,ES 200800809 U,2008-04-18,ES 200800809 U,2008-04-18,"Mechanism of extension and collection of mesh for trucking trucks (Machine-translation by Google Translate, not legally binding)","Mechanism of extension and collection of mesh for dump trucks, characterized in that it consists of a set of elements, coupled to the tilting box (2) of the truck and integral to it, so that they do not interfere in its mechanism of overturned, allowing the extension and collection of the mesh (15) by operating a crank (1); comprising, said set of elements, in addition to the crank (1), a reducer (5) acting on a transverse transmission shaft (9) that turns side pulleys (7) that move cables (10) to which a ferrule (12) is fixed on which the end of the mesh (1) is fastened; and in which one of said pulleys (7), through a chain (16), rotates a pinion (17) which, in turn, rotates a drum (18) on which the mesh is rolled or unrolled ( 1). (Machine-translation by Google Translate, not legally binding)",LUIS CARLOS ESTEBAN CASAS S L,ESTEBAN CASAS LUIS CARLOS,,https://lens.org/195-744-470-004-350,Patent Application,no,0,0,1,1,0,,B60J7/08,,0,0,,,,DISCONTINUED
98,US,A1,US 2005/0085790 A1,025-474-366-619-732,2005-04-21,2005,US 94013104 A,2004-09-14,US 94013104 A;;US 50313403 P,2003-09-15,Method and system for cellular transplantation,"The present invention provides a method for treating an injury of a spinal cord of a patient. The method includes implanting a therapeutic substance in the spinal cord under indirect visualization. The indirect visualization may be provided by an endoscope, and the therapeutic substance may include cells. The present invention also provides a device for treating an injury of the spinal cord. The device includes skin visualization means for visualizing the spinal cord through a skin puncture, and injection means for injecting a therapeutic substance into the spinal cord.",GUEST JAMES;;CASAS CARLOS,GUEST JAMES;;CASAS CARLOS,INVIVO THERAPEUTICS HOLDINGS CORP (2015-11-24);;GUEST DR. JAMES (2004-12-03),https://lens.org/025-474-366-619-732,Patent Application,yes,9,53,5,5,0,A61M25/0041;;A61M25/0041;;A61B17/3468;;A61B17/3468;;A61B2017/00969;;A61B2017/00969;;A61M2025/0007;;A61M2025/0007,A61B17/00;;A61B17/34;;A61M25/00,604/506;;604/116;;600/114,0,0,,,,ACTIVE
99,US,A1,US 2014/0100413 A1,135-223-557-438-717,2014-04-10,2014,US 201313951302 A,2013-07-25,US 201313951302 A;;US 201213355297 A;;US 201361831027 P;;US 201161434894 P,2011-01-21,SUCTION DETECTION ON AN AXIAL BLOOD PUMP USING BEMF DATA,"The presence or absence of a suction condition in an implantable blood pump is determined at least in part based on a parameter related to flow, such as a parameter related to thrust on the rotor of the pump. A local extreme of the parameter representing the minimum flow during ventricular diastole in an earlier interval is used to establish a threshold value. A value of the parameter representing the minimum flow during ventricular diastole in a later interval is compared to this threshold. If the comparison indicates a substantial decline in the minimum flow between the earlier and later intervals is associated with a suction condition. During the absence of a suction condition, the threshold is continually updated, so that the system does not indicate presence of a suction condition if the flow decreases gradually.",CASAS FERNANDO;;REYES CARLOS;;HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS,HEARTWARE INC (2013-08-21),https://lens.org/135-223-557-438-717,Patent Application,yes,0,105,2,18,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/871;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/523;;A61M2205/3334;;A61M60/871;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/237;;A61M60/523;;A61M60/546,A61M1/12,600/16,0,0,,,,ACTIVE
100,GB,A,GB 1083204 A,099-640-670-697-204,1967-09-13,1967,GB 1079165 A,1965-03-15,GB 1079165 A,1965-03-15,Process for the production of 11-hydroxylated steroids,11-Hydroxy-steroids are prepared by microbiological 11-hydroxylation of 11-unsubstituted steroids in the presence of dimethyl sulphoxide.,SYNTEX CORP,ZAFFARONI ALEJANDRO;;CAMPILLO CARLOS CASAS,,https://lens.org/099-640-670-697-204,Granted Patent,no,0,1,11,12,0,C12P33/00;;C12P33/00,C12P33/00,C2U U2            U;;C2U U4A1B         U;;C2U U4A2A         U;;C2U U4A3          U;;C2U U4B2A         U;;C2U U4B2B         U;;C2U U4C1          U;;C2U U4C10A        U;;C2U U4C11         U;;C2U U4C2          U;;C2U U4C4A         U;;C2U U4C4B         U;;C2U U4C5          U;;C2U U4DX          U;;C2U U4D2          U;;C2U U4N1          U;;C2U U4N16A        U;;C2U U4N16B        U;;C2U U4N18         U;;C2U U4N6A         U;;C2U U4N6B         U;;C2U U4N6Y         U;;C2U U6A1          U;;C2U U6A2          U;;C2U U6B           U;;F4G GARK          GARK,0,0,,,,EXPIRED
101,US,A,US 3375174 A,003-202-201-573-118,1968-03-26,1968,US 42708565 A,1965-01-21,US 42708565 A,1965-01-21,Microbiological hydroxylation of steroids,,SYNTEX CORP,PIERRE CRABBE;;CARLOS CASAS-CAMPILLO,,https://lens.org/003-202-201-573-118,Granted Patent,no,2,1,1,1,0,C12P33/00;;Y10S435/929;;C12P33/00;;Y10S435/929,C12P33/00,195/51,0,0,,,,EXPIRED
102,DE,A1,DE 1543462 A1,103-481-940-902-325,1969-09-04,1969,DE 1543462 A,1966-03-12,GB 1079165 A,1965-03-15,Verfahren zur Herstellung von 11-hydroxylierten Steroiden,,SYNTEX CORP,ZAFFARONI ALEJANDRO;;CASAS-CAMPILLO CARLOS,,https://lens.org/103-481-940-902-325,Patent Application,no,0,0,11,12,0,C12P33/00;;C12P33/00,C12P33/00,,0,0,,,,EXPIRED
103,FR,A,FR 1483798 A,173-996-871-915-297,1967-06-09,1967,FR 53438 A,1966-03-15,FR 53438 A;;GB 1079165 A,1965-03-15,Procédé d'hydroxylation microbienne sélective en position 11 de stéroïdes,,SYNTEX CORP,ZAFFARONI ALEJANDRO;;CAMPILLO CARLOS CASAS,,https://lens.org/173-996-871-915-297,Granted Patent,no,0,0,1,12,0,C12P33/00,C12P33/00,,0,0,,,,EXPIRED
104,US,A,US 3419470 A,063-641-507-541-363,1968-12-31,1968,US 53387266 A,1966-03-14,GB 1079165 A,1965-03-15,11-microbiological hydroxylation of steroids in presence of dimethylsulfoxide,,SYNTEX CORP,ALEJANDRO ZAFFARONI;;CASAS CAMPILLO CARLOS,,https://lens.org/063-641-507-541-363,Granted Patent,no,2,3,11,12,0,C12P33/00;;C12P33/00,C12P33/00,195/51,0,0,,,,EXPIRED
105,CH,A,CH 484884 A,144-681-761-286-786,1970-01-31,1970,CH 370066 A,1966-03-15,GB 1079165 A,1965-03-15,Verfahren zur Herstellung von in 11-Stellung die Hydroxygruppe aufweisenden Steroiden,,SYNTEX CORP,ALEJANDRO ZAFFARONI;;CARLOS CASAS-CAMPILLO,,https://lens.org/144-681-761-286-786,Granted Patent,no,0,0,11,12,0,C12P33/00;;C12P33/00,C12P33/00,,0,0,,,,EXPIRED
106,CA,A,CA 767617 A,115-979-071-211-920,1967-09-19,1967,CA 767617D A,,CA 767617T A,,PROCESS FOR THE PRODUCTION OF CYCLOPENTANOPHENANTHRENE DERIVATIVES,,SYNTEX CORP,CASAS-CAMPILLO CARLOS;;ZAFFARONI ALEJANDRO,,https://lens.org/115-979-071-211-920,Granted Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
107,US,B2,US 8156992 B2,103-192-074-554-094,2012-04-17,2012,US 87214607 A,2007-10-15,US 87214607 A;;US 89190104 A,2004-07-13,Garage door apparatus,"A garage door is connected to a track extending from a front wall of the garage to a side wall within the garage. The garage door is horizontally moveable along the track, such as with a chain-driven mechanism, from a generally closed position within the garage vehicle entrance of the garage to a generally open position away from the garage vehicle entrance and disposed adjacent to a side wall of the garage. A second horizontally moving garage door may be used in conjunction with the first garage door to cooperatively close the garage vehicle entrance.",DIAZ CARLOS L;;CASAS BARRIOS LUIS MANUEL;;CASAS BARRIOS GERARDO,DIAZ CARLOS L;;CASAS BARRIOS LUIS MANUEL;;CASAS BARRIOS GERARDO,,https://lens.org/103-192-074-554-094,Granted Patent,yes,13,9,5,5,0,E05D15/36;;E05D15/36;;E05D15/12;;E05D15/12;;E05F15/643;;E05F15/643;;E05Y2900/106;;E05Y2900/106,E05D15/06,160/201;;160/196.1,0,0,,,,INACTIVE
108,EP,B1,EP 3003421 B1,001-040-791-481-528,2021-10-13,2021,EP 14737079 A,2014-06-04,US 201361831027 P;;US 201313951302 A;;US 2014/0040847 W,2013-06-04,SUCTION DETECTION IN A BLOOD PUMP,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/001-040-791-481-528,Granted Patent,yes,7,0,4,18,0,A61M2205/3334;;A61M60/422;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/546;;A61M60/816;;A61M60/816;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/422,A61M60/178;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/546;;A61M60/816,,0,0,,,,ACTIVE
109,US,A1,US 2014/0357937 A1,030-509-016-525-574,2014-12-04,2014,US 201414294448 A,2014-06-03,US 201414294448 A;;US 201361831023 P,2013-06-04,AXIAL FLOW PUMP PRESSURE ALGORITHM,"The presence or absence of a high pressure condition in an implantable blood pump is determined at least in part based on a comparison between a determined amount of differential pressure across the pump and a pressure threshold value. The amount of differential pressure parameter may be determined based at least in part on a parameter related to flow, such as a parameter related to thrust on the rotor of the pump. In response to determining the presence of a high pressure condition, an updated speed of rotation of the rotor that is less than the rotor's initial speed may be determined. The rotor's speed may be increased when the flow rate of blood is determined to be at least equal to a flow recovery threshold value.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,HEARTWARE INC (2014-11-10),https://lens.org/030-509-016-525-574,Patent Application,yes,1,71,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61M1/10;;A61M1/12,600/17,0,0,,,,ACTIVE
110,EP,A1,EP 3515526 A1,161-372-811-842-283,2019-07-31,2019,EP 17778411 A,2017-09-20,US 201662398667 P;;US 2017/0052492 W,2016-09-23,FIELD-ORIENTED CONTROL FOR CONTROL OF BLOOD PUMP MOTOR,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/161-372-811-842-283,Patent Application,yes,0,0,5,5,0,A61M60/82;;A61M60/419;;A61M60/232;;A61M60/814;;A61M60/824;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/857;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/824;;A61M60/82;;A61M60/237;;A61M60/232;;A61M60/178;;A61M60/538;;A61M60/814,A61M60/178;;A61M60/232;;A61M60/237;;A61M60/419;;A61M60/538;;A61M60/814;;A61M60/82;;A61M60/824;;A61M60/857,,0,0,,,,DISCONTINUED
111,WO,A1,WO 2018/064437 A1,180-083-980-462-722,2018-04-05,2018,US 2017/0054220 W,2017-09-29,US 201662401508 P,2016-09-29,IMPLANTABLE PUMP IMPELLER THERMAL KNOCKDOWN,"The present invention relates to kits and methods for calibrating a pump through performance of a thermal knockdown process including demagnetization of an impeller of the pump where the impeller is separate from the pump. By heat treating the impeller, a property of magnetic interaction of the pump is reduced in a repeatable manner. A kit includes a pump with impeller, a controller and an oven. The method generally involves an iterative process of testing the pump for a property related to magnetic interaction of the elements of the pump, removing the impeller from the pump, heating the impeller under controlled conditions, then placing the impeller back into the pump to repeat the test performed initially.",HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,,https://lens.org/180-083-980-462-722,Patent Application,yes,5,7,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538,,0,0,,,,PENDING
112,US,A1,US 2018/0028737 A1,057-917-411-834-679,2018-02-01,2018,US 201715663265 A,2017-07-28,US 201715663265 A;;US 201662369326 P,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signal in the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,HEARTWARE INC (2017-07-27),https://lens.org/057-917-411-834-679,Patent Application,yes,1,1,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61B5/029;;A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,ACTIVE
113,AU,A,AU 1997/019275 A,098-782-256-469-609,1997-10-10,1997,AU 1997/019275 A,1997-03-11,ES 9600634 A;;ES 9700057 W,1996-03-15,Self-adjusting device for terminals of control cables,,FICO CABLES SA,CEBOLLERO CARLOS GABAS;;GOMILA JORDI CASAS,,https://lens.org/098-782-256-469-609,Patent Application,no,0,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,PENDING
114,US,A1,US 2022/0203083 A1,157-738-101-081-810,2022-06-30,2022,US 202217654724 A,2022-03-14,US 202217654724 A;;US 201816221768 A;;US 201762607478 P,2017-12-19,HEART RATE MEASUREMENT USING BLOOD PUMP IMPELLER LOCATION,"A method of determining a heart rate of a patient having an implanted blood pump including applying a voltage to a plurality of coils of a stator of the blood pump to produce an electromagnetic force to rotate a rotor in communication with the plurality of coils; displaying a waveform associated with a back electromotive force in the plurality of coils of the blood pump, the waveform being proportional to an axial position of the rotor relative to the stator; determining a time interval between a first alteration in the waveform relative to a baseline and a second alteration in the waveform relative to the baseline; and determining the heart rate of the patient based on the time interval.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS,HEARTWARE. INC (2017-12-18),https://lens.org/157-738-101-081-810,Patent Application,yes,0,0,7,7,0,A61M60/857;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/515;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/216;;A61M60/857;;A61M60/515;;A61M60/538,A61M60/148;;A61M60/122;;A61M60/422;;A61M60/50,,0,0,,,,PENDING
115,ES,A1,ES 2562492 A1,167-965-380-123-050,2016-03-04,2016,ES 201400736 A,2014-09-04,ES 201400736 A,2014-09-04,"Process of making mold fondant cakes by pressing (Machine-translation by Google Translate, not legally binding)","Process of making mold fondant cakes by pressing. It is a manufacturing process for fondant cakes that avoids the main problems of its preparation, ensuring a perfect shape on the outside and allowing a fondant economy by using small thicknesses of the order of 1 to 5 mm. Compound molds are used as well as forming presses applying a sufficient load until the fondant takes the shape of the mold. This method allows the use of spongy and juicy fillings as they do not need to have a high carrying capacity. (Machine-translation by Google Translate, not legally binding)",LAPETRA CODERQUE CARLOS;;CASAS SILVA ALICIA,LAPETRA CODERQUE CARLOS;;CASAS SILVA ALICIA,,https://lens.org/167-965-380-123-050,Patent Application,no,4,0,2,2,0,A23G3/004,A23G3/18,,0,0,,,,INACTIVE
116,ES,T3,ES 2185913 T3,178-255-329-815-214,2003-05-01,2003,ES 97907109 T,1997-03-11,ES 9600634 A;;ES 9700057 W,1996-03-15,TERMINAL AUTOAJUSTADOR PARA UN CABLE DE MANDO.,"ESTE DISPOSITIVO AUTOAJUSTADOR ES APLICABLE A TERMINALES (1) QUE CONSISTEN EN UN CUERPO PRINCIPAL (5) PROVISTOS DE MEDIOS DE ENLACE A UN ACCIONAMIENTO DE MANDOS (8), Y COMPRENDE UN VASTAGO DE REGULACION (17) PARCIALMENTE ALOJADO EN EL CUERPO PRINCIPAL (5), UN MEDIO DE EMPUJE (18) QUE COMPRENDE COMO MINIMO UN RESORTE DE EMPUJE (27) QUE PERMANENTEMENTE SOMETE AL VASTAGO (17) A UNA FUERZA DIRIGIDA EN SENTIDO DE FUERA A DENTRO, Y MEDIOS DE FIJACION (19) QUE COMPRENDEN, EN EL VASTAGO DE REGULACION (17), UNA PORCION DE FIJACION (21) PROVISTA DE UNA RANURA DE FIJACION (24) Y UN DENTADO DE FIJACION (39), UN TORNILLO DE FIJACION (41) QUE ATRAVIESA LA PORCION DE FIJACION (21), UNA ARANDELA DE FIJACION (42) PROVISTA DE UN DENTADO DE FIJACION (43) Y UNA TUERCA DE FIJACION (44) INCLUIDA EN EL CUERPO PRINCIPAL (5). APLICABLE A LA INDUSTRIA DEL AUTOMOVIL.",FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,,https://lens.org/178-255-329-815-214,Granted Patent,no,0,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
117,CN,A,CN 113499538 A,109-403-043-402-229,2021-10-15,2021,CN 202110779051 A,2017-07-28,US 201662369326 P;;CN 201780047404 A,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signalin the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter. The invention provides heart rate determination based on VAD current waveform.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/109-403-043-402-229,Patent Application,no,10,0,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M60/165;;A61B5/024;;A61M60/178;;A61M60/216;;A61M60/508;;A61M60/515;;A61M60/855;;A61M60/876,,0,0,,,,PENDING
118,WO,A1,WO 2016/085985 A1,146-316-110-253-179,2016-06-02,2016,US 2015/0062430 W,2015-11-24,US 201462084742 P,2014-11-26,FIDUCIAL POINT OPTIMIZATION,"A flow rate of blood through an implantable blood pump (101) is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value (F1) and a second flow rate value (F2). Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWRE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS,,https://lens.org/146-316-110-253-179,Patent Application,yes,4,0,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,PENDING
119,CN,A,CN 109789258 A,186-750-938-594-646,2019-05-21,2019,CN 201780058627 A,2017-09-20,US 201662398667 P;;US 2017/0052492 W,2016-09-23,FIELD-ORIENTED CONTROL FOR CONTROL OF BLOOD PUMP MOTOR,"A ventricular assist device includes a pump configured to pump blood of a patient. A motor is configured to operate the pump. First, second, and third conductors are coupled to the motor and are configured to supply electric current from a power supply to the motor in first, second, and third phases, respectively. A controller is configured to operate the motor using a Field Oriented Control (FOC)method, and if one from the group consisting of first, second and third conductors becomes unable to supply electric current to the motor, the controller continues to operate the motor using the FOCmethod using the phases of the two conductors that are able to supply electric current to the motor.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/186-750-938-594-646,Patent Application,no,12,0,5,5,0,A61M60/82;;A61M60/419;;A61M60/232;;A61M60/814;;A61M60/824;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/857;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/824;;A61M60/82;;A61M60/237;;A61M60/232;;A61M60/178;;A61M60/538;;A61M60/814,A61M60/178;;A61M60/232;;A61M60/237;;A61M60/419;;A61M60/538;;A61M60/814;;A61M60/82;;A61M60/824;;A61M60/857,,0,0,,,,PENDING
120,US,B2,US 8904698 B2,004-416-441-504-154,2014-12-09,2014,US 201213406354 A,2012-02-27,US 201213406354 A;;US 201161446518 P,2011-02-25,Modular power supply for use in a weapon mountable designator/illuminator unit,"A weapon-mountable designator/illuminator unit having a light source adapted to generate a light beam in a direction away from the unit. The light beam is variable between a collimated light beam and a divergent light beam for, respectively, designating a target and illuminating a target area of the weapon. At least a first modular power supply is adapted for installation in the designator/illuminator unit. The power supply includes a cage adapted to receive a power source, a first end adapted to be received within the designator/illuminator unit, and an end cap adapted to be exposed when the power supply is assembled with the unit. The power supply is adapted to deliver power from its power source to the light source of the designator/illuminator unit. The end cap may contain a light source for generating a light beam in addition to the light beam generated by the designator/illuminator unit.",RILEY LOUIS F;;CASAS JUAN CARLOS;;JUAN CARLOS CASAS,RILEY LOUIS F;;CASAS JUAN CARLOS,CASAS JUAN CARLOS (2012-05-14),https://lens.org/004-416-441-504-154,Granted Patent,yes,27,37,2,2,0,F41G1/35;;F41G1/35,F41G1/00;;F41G1/35,42/146;;362/110;;362/113;;362/114,0,0,,,,INACTIVE
121,WO,A3,WO 2014/197541 A3,001-583-829-454-99X,2015-05-07,2015,US 2014/0040803 W,2014-06-04,US 201361831023 P,2013-06-04,AXIAL FLOW PUMP PRESSURE ALGORITHM,"The presence or absence of a high pressure condition in an implantable blood pump (101, 1001) is determined at least in part based on a comparison between a determined amount of differential pressure across the pump and a pressure threshold value. The amount of differential pressure parameter may be determined based at least in part on a parameter related to flow, such as a parameter related to thrust on the rotor (120, 1020) of the pump. In response to determining the presence of a high pressure condition, an updated speed of rotation of the rotor that is less than the rotor's initial speed may be determined. The rotor's speed may be increased when the flow rate of blood is determined to be at least equal to a flow recovery threshold value.",HEARTWARE INC;;REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/001-583-829-454-99X,Search Report,yes,6,0,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61M1/10;;A61M1/12,,0,0,,,,PENDING
122,US,B2,US 9427508 B2,046-714-720-830-971,2016-08-30,2016,US 201414294448 A,2014-06-03,US 201414294448 A;;US 201361831023 P,2013-06-04,Axial flow pump pressure algorithm,"The presence or absence of a high pressure condition in an implantable blood pump is determined at least in part based on a comparison between a determined amount of differential pressure across the pump and a pressure threshold value. The amount of differential pressure parameter may be determined based at least in part on a parameter related to flow, such as a parameter related to thrust on the rotor of the pump. In response to determining the presence of a high pressure condition, an updated speed of rotation of the rotor that is less than the rotor's initial speed may be determined. The rotor's speed may be increased when the flow rate of blood is determined to be at least equal to a flow recovery threshold value.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,HEARTWARE INC (2014-11-10),https://lens.org/046-714-720-830-971,Granted Patent,yes,5,19,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61B5/04;;A61M1/10;;A61M1/12,,1,0,,,"Partial Intenational Search Report for Application No. PCT/US3014/040803 dated Sep. 25, 2014.",ACTIVE
123,US,B2,US 10744247 B2,191-097-726-267-389,2020-08-18,2020,US 201715719719 A,2017-09-29,US 201715719719 A;;US 201662401508 P,2016-09-29,Implantable pump impeller thermal knockdown,"The present invention relates to kits and methods for calibrating a pump through performance of a thermal knockdown process including demagnetization of an impeller of the pump where the impeller is separate from the pump. By heat treating the impeller, a property of magnetic interaction of the pump is reduced in a repeatable manner. A kit includes a pump with impeller, a controller and an oven. The method generally involves an iterative process of testing the pump for a property related to magnetic interaction of the elements of the pump, removing the impeller from the pump, heating the impeller under controlled conditions, then placing the impeller back into the pump to repeat the test performed initially.",HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2017-09-27),https://lens.org/191-097-726-267-389,Granted Patent,yes,7,0,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538;;C22C5/04;;C22F1/14;;F04D13/06;;F04D27/00;;F04D29/02;;F04D29/18,,3,1,013-108-366-656-466,10.1109/tmag.1983.1062796,"Trout, Improving the Distribution of Magnetic Properties in Rare Earth-Cobalt Magnets by the use of Selective Thermal Stabilization. IEEE Transactions on Magnetics, vol. MAG-19, No. 5, Sep. 1983. (Year: 1983).;;Hughes, Thomas A. Measurement and Control Basics (5th Edition)—11.7.1 DC Motors. (pp. 331-332) ISA. (2015) (Year: 2015).;;International Search Report and Written Opinion dated Dec. 18, 2017, for corresponding International Application No. PCT/US2017/054220; International Filing Date: Sep. 29, 2017 consisting of 12-pages.",ACTIVE
124,WO,A1,WO 1997/035118 A1,187-177-171-704-172,1997-09-25,1997,ES 9700057 W,1997-03-11,ES 9600634 A,1996-03-15,SELF-ADJUSTING DEVICE FOR TERMINALS OF CONTROL CABLES,"The disclosed self-adjusting device is applicable to terminals (1) which are comprised of a main body (5) provided with means for interconnection to a control actuation element (8), and has a regulation rod (17) which is partially housed in the main body (5), pushing means (18) having at least one pusher spring (27) which exert permanently the rod (17) to a force directed outwards-inwards, and fixing means (19) which comprise, in the regulation rod (17), a fixing portion (21) provided with a fixing groove (24) in a fixing toothing (39), a fixing bolt (41) which traverses the fixing portion (21), a fixing washer (42) provided with a fixing toothing (43) and a fixing nut (44) incorporated in the main body (5). Application to the motor car industry.",FICO CABLES SA;;GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,,https://lens.org/187-177-171-704-172,Patent Application,yes,6,3,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,PATENTED
125,ES,A1,ES 2128233 A1,020-239-669-337-327,1999-05-01,1999,ES 9600634 A,1996-03-15,ES 9600634 A,1996-03-15,SELF-ADJUSTING DEVICE FOR TERMINALS OF CONTROL CABLES,"The disclosed self-adjusting device is applicable to terminals (1) which are comprised of a main body (5) provided with means for interconnection to a control actuation element (8), and has a regulation rod (17) which is partially housed in the main body (5), pushing means (18) having at least one pusher spring (27) which exert permanently the rod (17) to a force directed outwards-inwards, and fixing means (19) which comprise, in the regulation rod (17), a fixing portion (21) provided with a fixing groove (24) in a fixing toothing (39), a fixing bolt (41) which traverses the fixing portion (21), a fixing washer (42) provided with a fixing toothing (43) and a fixing nut (44) incorporated in the main body (5). Application to the motor car industry.",FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILLA JORDI,,https://lens.org/020-239-669-337-327,Patent Application,no,5,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
126,US,A1,US 2019/0184082 A1,022-748-009-403-702,2019-06-20,2019,US 201816221768 A,2018-12-17,US 201816221768 A;;US 201762607478 P,2017-12-19,HEART RATE MEASUREMENT USING BLOOD PUMP IMPELLER LOCATION,"A method of determining a heart rate of a patient having an implanted blood pump including applying a voltage to a plurality of coils of a stator of the blood pump to produce an electromagnetic force to rotate a rotor in communication with the plurality of coils; displaying a waveform associated with a back electromotive force in the plurality of coils of the blood pump, the waveform being proportional to an axial position of the rotor relative to the stator; determining a time interval between a first alteration in the waveform relative to a baseline and a second alteration in the waveform relative to the baseline; and determining the heart rate of the patient based on the time interval.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS,HEARTWARE INC (2019-03-14),https://lens.org/022-748-009-403-702,Patent Application,yes,0,0,7,7,0,A61M60/857;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/515;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/216;;A61M60/857;;A61M60/515;;A61M60/538,A61M1/12;;A61M1/10,,0,0,,,,ACTIVE
127,WO,A2,WO 2014/197558 A2,077-744-602-602-793,2014-12-11,2014,US 2014/0040847 W,2014-06-04,US 201361831027 P;;US 201313951302 A,2013-06-04,SUCTION DETECTION IN AN AXIAL BLOOD PUMP USING BEMF DATA,"The presence or absence of a suction condition in an implantable blood pump (101, 1001) is determined at least in part based on a parameter related to flow, such as a parameter related to thrust on the rotor (120, 1020) of the pump. A local extreme of the parameter representing the minimum flow during ventricular diastole in an earlier interval is used to establish a threshold value. A value of the parameter representing the minimum flow during ventricular diastole in a later interval is compared to this threshold. If the comparison indicates a substantial decline in the minimum flow between the earlier and later intervals is associated with a suction condition. During the absence of a suction condition, the threshold is continually updated, so that the system (100, 1000) does not indicate presence of a suction condition if the flow decreases gradually.",HEARTWARE INC;;CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/077-744-602-602-793,Patent Application,yes,0,10,4,18,0,A61M2205/3334;;A61M60/422;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/546;;A61M60/816;;A61M60/816;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/422,A61M60/178;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/816,,0,0,,,,PENDING
128,EP,A1,EP 3223879 A1,143-539-187-518-322,2017-10-04,2017,EP 15813175 A,2015-11-24,US 201462084742 P;;US 2015/0062430 W,2014-11-26,FIDUCIAL POINT OPTIMIZATION,,HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS,,https://lens.org/143-539-187-518-322,Patent Application,yes,0,0,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,DISCONTINUED
129,US,B2,US 11273299 B2,111-927-154-664-036,2022-03-15,2022,US 201816221768 A,2018-12-17,US 201816221768 A;;US 201762607478 P,2017-12-19,Heart rate measurement using blood pump impeller location,"A method of determining a heart rate of a patient having an implanted blood pump including applying a voltage to a plurality of coils of a stator of the blood pump to produce an electromagnetic force to rotate a rotor in communication with the plurality of coils; displaying a waveform associated with a back electromotive force in the plurality of coils of the blood pump, the waveform being proportional to an axial position of the rotor relative to the stator; determining a time interval between a first alteration in the waveform relative to a baseline and a second alteration in the waveform relative to the baseline; and determining the heart rate of the patient based on the time interval.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS,HEARTWARE INC (2019-03-14),https://lens.org/111-927-154-664-036,Granted Patent,yes,12,0,7,7,0,A61M60/857;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/515;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/216;;A61M60/857;;A61M60/515;;A61M60/538,A61M60/122;;A61M60/148;;A61M60/205;;A61M60/422;;A61M60/50,,1,0,,,"International Search Report and Written Opinion dated Mar. 27, 2019, for corresponding International Application No. PCT/US2018/065936; International Filing Date: Dec. 17, 2018 consisting of 12 pages.",ACTIVE
130,EP,A2,EP 3490629 A2,119-524-893-210-841,2019-06-05,2019,EP 17749330 A,2017-07-28,US 201662369326 P;;US 2017/0044459 W,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/119-524-893-210-841,Patent Application,yes,0,0,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,ACTIVE
131,EP,B1,EP 3519007 B1,167-428-105-657-425,2020-12-30,2020,EP 17784141 A,2017-09-29,US 201662401508 P;;US 2017/0054220 W,2016-09-29,IMPLANTABLE PUMP IMPELLER THERMAL KNOCKDOWN,,HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,,https://lens.org/167-428-105-657-425,Granted Patent,yes,3,0,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538,,0,0,,,,ACTIVE
132,WO,A1,WO 2018/057608 A1,183-553-378-273-606,2018-03-29,2018,US 2017/0052492 W,2017-09-20,US 201662398667 P,2016-09-23,FIELD-ORIENTED CONTROL FOR CONTROL OF BLOOD PUMP MOTOR,"A ventricular assist device includes a pump configured to pump blood of a patient. A motor is configured to operate the pump. First, second, and third conductors are coupled to the motor and are configured to supply electric current from a power supply to the motor in first, second, and third phases, respectively. A controller is configured to operate the motor using a Field Oriented Control (FOC) method, and if one from the group consisting of first, second and third conductors becomes unable to supply electric current to the motor, the controller continues to operate the motor using the FOC method using the phases of the two conductors that are able to supply electric current to the motor.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/183-553-378-273-606,Patent Application,yes,15,0,5,5,0,A61M60/82;;A61M60/419;;A61M60/232;;A61M60/814;;A61M60/824;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/857;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/824;;A61M60/82;;A61M60/237;;A61M60/232;;A61M60/178;;A61M60/538;;A61M60/814,A61M60/178;;A61M60/232;;A61M60/237;;A61M60/419;;A61M60/538;;A61M60/814;;A61M60/82;;A61M60/824;;A61M60/857,,0,0,,,,PENDING
133,EP,A1,EP 0831240 A1,004-195-993-786-341,1998-03-25,1998,EP 97907109 A,1997-03-11,ES 9700057 W;;ES 9600634 A,1996-03-15,SELF-ADJUSTING DEVICE FOR TERMINALS OF CONTROL CABLES,"The disclosed self-adjusting device is applicable to terminals (1) which are comprised of a main body (5) provided with means for interconnection to a control actuation element (8), and has a regulation rod (17) which is partially housed in the main body (5), pushing means (18) having at least one pusher spring (27) which exert permanently the rod (17) to a force directed outwards-inwards, and fixing means (19) which comprise, in the regulation rod (17), a fixing portion (21) provided with a fixing groove (24) in a fixing toothing (39), a fixing bolt (41) which traverses the fixing portion (21), a fixing washer (42) provided with a fixing toothing (43) and a fixing nut (44) incorporated in the main body (5). Application to the motor car industry.",FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,,https://lens.org/004-195-993-786-341,Patent Application,yes,0,4,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
134,MX,A,MX 9708772 A,065-751-558-891-582,1998-03-31,1998,MX 9708772 A,1997-03-11,ES 9600634 A;;ES 9700057 W,1996-03-15,SELF-ADJUSTING DEVICE FOR TERMINALS OF CONTROL CABLES.,"The disclosed self-adjusting device is applicable to terminals (1) which are comprised of a main body (5) provided with means for interconnection to a control actuation element (8), and has a regulation rod (17) which is partially housed in the main body (5), pushing means (18) having at least one pusher spring (27) which exert permanently the rod (17) to a force directed outwards-inwards, and fixing means (19) which comprise, in the regulation rod (17), a fixing portion (21) provided with a fixing groove (24) in a fixing toothing (39), a fixing bolt (41) which traverses the fixing portion (21), a fixing washer (42) provided with a fixing toothing (43) and a fixing nut (44) incorporated in the main body (5). Application to the motor car industry.",FICO CABLES SA,CEBOLLERO CARLOS GABAS;;GOMILA JORDI CASAS,,https://lens.org/065-751-558-891-582,Patent Application,no,0,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
135,EP,A1,EP 3519007 A1,081-841-826-024-83X,2019-08-07,2019,EP 17784141 A,2017-09-29,US 201662401508 P;;US 2017/0054220 W,2016-09-29,IMPLANTABLE PUMP IMPELLER THERMAL KNOCKDOWN,,HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,,https://lens.org/081-841-826-024-83X,Patent Application,yes,0,0,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538,,0,0,,,,ACTIVE
136,ES,B1,ES 2562492 B1,168-493-118-270-307,2016-12-22,2016,ES 201400736 A,2014-09-04,ES 201400736 A,2014-09-04,Proceso de fabricación de tartas de fondant en molde mediante prensado,,LAPETRA CODERQUE CARLOS;;CASAS SILVA ALICIA,LAPETRA CODERQUE CARLOS;;CASAS SILVA ALICIA,,https://lens.org/168-493-118-270-307,Granted Patent,no,0,0,2,2,0,A23G3/004,A23G3/18,,0,0,,,,INACTIVE
137,CN,A,CN 109789256 A,163-945-189-312-052,2019-05-21,2019,CN 201780059177 A,2017-09-29,US 201662401508 P;;US 2017/0054220 W,2016-09-29,IMPLANTABLE PUMP IMPELLER THERMAL KNOCKDOWN,"The present invention relates to kits and methods for calibrating a pump through performance of a thermal knockdown process including demagnetization of an impeller of the pump where the impeller is separate from the pump. By heat treating the impeller, a property of magnetic interaction of the pump is reduced in a repeatable manner. A kit includes a pump with impeller, a controller and an oven. The method generally involves an iterative process of testing the pump for a property related to magnetic interaction of the elements of the pump, removing the impeller from the pump, heating the impeller under controlled conditions, then placing the impeller back into the pump to repeat the test performed initially.",HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,,https://lens.org/163-945-189-312-052,Patent Application,no,8,0,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538,,1,1,013-108-366-656-466,10.1109/tmag.1983.1062796,"STANLEY R. TROUT: ""improving the distribution of magnetic properties in rare earth-cobalt magnets by the use of selective thermal stabilization"", 《IEEE TRANSACTIONS ON MAGNETICS》",ACTIVE
138,CN,A,CN 107614029 A,199-809-768-773-785,2018-01-19,2018,CN 201580074531 A,2015-11-24,US 201462084742 P;;US 2015/0062430 W,2014-11-26,FIDUCIAL POINT OPTIMIZATION,"A flow rate of blood through an implantable blood pump (101) is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value (F1) and a second flow rate value (F2). Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWRE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS,,https://lens.org/199-809-768-773-785,Patent Application,no,6,2,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,ACTIVE
139,EP,A1,EP 3727492 A1,012-669-140-737-750,2020-10-28,2020,EP 18830655 A,2018-12-17,US 201762607478 P;;US 2018/0065936 W,2017-12-19,HEART RATE MEASUREMENT USING BLOOD PUMP IMPELLER LOCATION,,HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS,,https://lens.org/012-669-140-737-750,Patent Application,yes,0,0,7,7,0,A61M60/857;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/515;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/216;;A61M60/857;;A61M60/515;;A61M60/538,A61M1/12;;A61M1/10,,0,0,,,,PENDING
140,ES,B1,ES 2128233 B1,096-917-320-351-721,2000-02-01,2000,ES 9600634 A,1996-03-15,ES 9600634 A,1996-03-15,DISPOSITIVO AUTOAJUSTADOR PARA TERMINALES DE CABLES DE MANDO.,"Dispositivo autoajustador para terminales de cables de mando. Este dispositivo autoajustador es aplicable a terminales (1) que consisten en un cuerpo principal (5) provisto de medios de enlace a un accionamiento de mando (8), y comprende un vástago de regulación (17) parcialmente alojado en el cuerpo principal (5), medios de empuje (18) que comprenden como mínimo un resorte de empuje (27) que permanentemente somete al vástago (17) a una fuerza dirigida en el sentido de fuera a dentro, y medios de fijación (19) que comprenden, en el vástago de regulación (17), una porción de fijación (21) provista de una ranura de fijación (24) y un dentado de fijación (39), un tornillo de fijación (41) que atraviesa la porción de fijación (21), una arandela de fijación (42) provista de un dentado de fijación (43) y una tuerca de fijación (44) incluida en el cuerpo principal (5). Aplicable a la industria del automóvil.",FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILLA JORDI,,https://lens.org/096-917-320-351-721,Granted Patent,no,0,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
141,EP,B1,EP 3490629 B1,124-485-066-084-871,2020-05-13,2020,EP 17749330 A,2017-07-28,US 201662369326 P;;US 2017/0044459 W,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/124-485-066-084-871,Granted Patent,yes,2,0,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,ACTIVE
142,WO,A4,WO 2014/197541 A4,042-365-930-010-068,2015-07-02,2015,US 2014/0040803 W,2014-06-04,US 201361831023 P,2013-06-04,AXIAL FLOW PUMP PRESSURE ALGORITHM,"The presence or absence of a high pressure condition in an implantable blood pump (101, 1001) is determined at least in part based on a comparison between a determined amount of differential pressure across the pump and a pressure threshold value. The amount of differential pressure parameter may be determined based at least in part on a parameter related to flow, such as a parameter related to thrust on the rotor (120, 1020) of the pump. In response to determining the presence of a high pressure condition, an updated speed of rotation of the rotor that is less than the rotor's initial speed may be determined. The rotor's speed may be increased when the flow rate of blood is determined to be at least equal to a flow recovery threshold value.",HEARTWARE INC;;REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/042-365-930-010-068,Patent Application,yes,0,0,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61M1/10;;A61M1/12,,0,0,,,,PENDING
143,US,A1,US 2012/0216440 A1,089-420-336-244-325,2012-08-30,2012,US 201213406354 A,2012-02-27,US 201213406354 A;;US 201161446518 P,2011-02-25,MODULAR POWER SUPPLY FOR USE IN A WEAPON MOUNTABLE DESIGNATOR/ILLUMINATOR UNIT,"A weapon-mountable designator/illuminator unit having a light source adapted to generate a light beam in a direction away from the unit. The light beam is variable between a collimated light beam and a divergent light beam for, respectively, designating a target and illuminating a target area of the weapon. At least a first modular power supply is adapted for installation in the designator/illuminator unit. The power supply includes a cage adapted to receive a power source, a first end adapted to be received within the designator/illuminator unit, and an end cap adapted to be exposed when the power supply is assembled with the unit. The power supply is adapted to deliver power from its power source to the light source of the designator/illuminator unit. The end cap may contain a light source for generating a light beam in addition to the light beam generated by the designator/illuminator unit.",RILEY LOUIS F;;CASAS JUAN CARLOS,RILEY LOUIS F;;CASAS JUAN CARLOS,CASAS JUAN CARLOS (2012-05-14),https://lens.org/089-420-336-244-325,Patent Application,yes,16,8,2,2,0,F41G1/35;;F41G1/35,F41G11/00,42/146,0,0,,,,INACTIVE
144,DE,T2,DE 69716849 T2,109-209-146-531-26X,2003-07-17,2003,DE 69716849 T,1997-03-11,ES 9600634 A;;ES 9700057 W,1996-03-15,SELBSTEINSTELLENDES ENDSTÜCK FÜR BOWDENZUGKABEL,,FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,,https://lens.org/109-209-146-531-26X,Granted Patent,no,0,2,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
145,WO,A8,WO 2016/085985 A8,108-632-925-302-10X,2017-10-26,2017,US 2015/0062430 W,2015-11-24,US 201462084742 P,2014-11-26,FIDUCIAL POINT OPTIMIZATION,"A flow rate of blood through an implantable blood pump (101) is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value (F1) and a second flow rate value (F2). Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS,,https://lens.org/108-632-925-302-10X,Amended Application,yes,0,0,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,PENDING
146,WO,A2,WO 2014/197541 A2,126-915-557-406-88X,2014-12-11,2014,US 2014/0040803 W,2014-06-04,US 201361831023 P,2013-06-04,AXIAL FLOW PUMP PRESSURE ALGORITHM,"The presence or absence of a high pressure condition in an implantable blood pump (101, 1001) is determined at least in part based on a comparison between a determined amount of differential pressure across the pump and a pressure threshold value. The amount of differential pressure parameter may be determined based at least in part on a parameter related to flow, such as a parameter related to thrust on the rotor (120, 1020) of the pump. In response to determining the presence of a high pressure condition, an updated speed of rotation of the rotor that is less than the rotor's initial speed may be determined. The rotor's speed may be increased when the flow rate of blood is determined to be at least equal to a flow recovery threshold value.",HEARTWARE INC;;REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/126-915-557-406-88X,Patent Application,yes,0,2,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61M1/10,,0,0,,,,PENDING
147,US,B2,US 10420870 B2,181-183-789-518-403,2019-09-24,2019,US 201715663265 A,2017-07-28,US 201715663265 A;;US 201662369326 P,2016-08-01,Heart rate determination based on VAD current waveform,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signal in the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,HEARTWARE INC (2017-07-27),https://lens.org/181-183-789-518-403,Granted Patent,yes,4,1,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M1/00;;A61B5/00;;A61B5/024;;A61B5/029;;A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,1,0,,,"International Search Report and Written Opinion dated Mar. 1, 2018, for corresponding International Application No. PCT/US2017/044459; International Filing Date: Jul. 28, 2017 consisting of 12-pages.",ACTIVE
148,DE,D1,DE 69716849 D1,009-951-218-569-963,2002-12-12,2002,DE 69716849 T,1997-03-11,ES 9600634 A;;ES 9700057 W,1996-03-15,SELBSTEINSTELLENDES ENDSTÜCK FÜR BOWDENZUGKABEL,,FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,,https://lens.org/009-951-218-569-963,Granted Patent,no,0,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
149,US,A1,US 2020/0345912 A1,010-172-742-691-01X,2020-11-05,2020,US 202016923375 A,2020-07-08,US 202016923375 A;;US 201715719719 A;;US 201662401508 P,2016-09-29,IMPLANTABLE PUMP IMPELLER THERMAL KNOCKDOWN,"The present invention relates to kits and methods for calibrating a pump through performance of a thermal knockdown process including demagnetization of an impeller of the pump where the impeller is separate from the pump. By heat treating the impeller, a property of magnetic interaction of the pump is reduced in a repeatable manner. A kit includes a pump with impeller, a controller and an oven. The method generally involves an iterative process of testing the pump for a property related to magnetic interaction of the elements of the pump, removing the impeller from the pump, heating the impeller under controlled conditions, then placing the impeller back into the pump to repeat the test performed initially.",HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2017-09-27),https://lens.org/010-172-742-691-01X,Patent Application,yes,0,0,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538;;C22C5/04;;C22F1/14;;F04D7/00;;F27B17/00;;G01F1/58;;H05B1/02,,0,0,,,,DISCONTINUED
150,WO,A3,WO 2018/026655 A3,127-265-161-929-718,2018-03-29,2018,US 2017/0044459 W,2017-07-28,US 201662369326 P,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signal in the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/127-265-161-929-718,Search Report,yes,2,0,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,PENDING
151,US,A1,US 2018/0085507 A1,133-128-559-691-881,2018-03-29,2018,US 201715710323 A,2017-09-20,US 201715710323 A;;US 201662398667 P,2016-09-23,FIELD-ORIENTED CONTROL FOR CONTROL OF BLOOD PUMP MOTOR,"A ventricular assist device includes a pump configured to pump blood of a patient. A motor is configured to operate the pump. First, second, and third conductors are coupled to the motor and are configured to supply electric current from a power supply to the motor in first, second, and third phases, respectively. A controller is configured to operate the motor using a Field Oriented Control (FOC) method, and if one from the group consisting of first, second and third conductors becomes unable to supply electric current to the motor, the controller continues to operate the motor using the FOC method using the phases of the two conductors that are able to supply electric current to the motor.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,HEARTWARE INC (2016-09-27),https://lens.org/133-128-559-691-881,Patent Application,yes,4,17,5,5,0,A61M60/82;;A61M60/419;;A61M60/232;;A61M60/814;;A61M60/824;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/857;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/824;;A61M60/82;;A61M60/237;;A61M60/232;;A61M60/178;;A61M60/538;;A61M60/814,A61M60/178;;A61M60/232;;A61M60/237;;A61M60/419;;A61M60/538;;A61M60/814;;A61M60/82;;A61M60/824;;A61M60/857,,0,0,,,,ACTIVE
152,WO,A2,WO 2018/026655 A2,089-095-265-800-948,2018-02-08,2018,US 2017/0044459 W,2017-07-28,US 201662369326 P,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signal in the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/089-095-265-800-948,Patent Application,yes,2,4,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,PENDING
153,WO,A3,WO 2014/197558 A3,092-317-484-795-703,2015-07-02,2015,US 2014/0040847 W,2014-06-04,US 201361831027 P;;US 201313951302 A,2013-06-04,SUCTION DETECTION IN AN AXIAL BLOOD PUMP USING BEMF DATA,"The presence or absence of a suction condition in an implantable blood pump (101, 1001) is determined at least in part based on a parameter related to flow, such as a parameter related to thrust on the rotor (120, 1020) of the pump. A local extreme of the parameter representing the minimum flow during ventricular diastole in an earlier interval is used to establish a threshold value. A value of the parameter representing the minimum flow during ventricular diastole in a later interval is compared to this threshold. If the comparison indicates a substantial decline in the minimum flow between the earlier and later intervals is associated with a suction condition. During the absence of a suction condition, the threshold is continually updated, so that the system (100, 1000) does not indicate presence of a suction condition if the flow decreases gradually.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/092-317-484-795-703,Search Report,yes,7,0,4,18,0,A61M2205/3334;;A61M60/422;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/546;;A61M60/816;;A61M60/816;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/422,A61M60/178;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/816,,0,0,,,,PENDING
154,US,S,US D0563100 S,141-760-683-846-501,2008-03-04,2008,US 25851306 F,2006-04-20,US 25851306 F,2006-04-20,Ammunition container,,GAMO USA CORP,EPLING J PATRICK;;CASAS JUAN CARLOS,DAISY MANUFACTURING COMPANY (2020-03-20);;GAMO OUTDOOR USA INC (2009-01-30),https://lens.org/141-760-683-846-501,Design Right,no,0,12,1,1,0,,,0301;;D 3262,0,0,,,,EXPIRED
155,EP,B1,EP 3003420 B1,142-019-905-622-314,2023-02-22,2023,EP 14737077 A,2014-06-04,US 201361831023 P;;US 2014/0040803 W,2013-06-04,AXIAL FLOW PUMP PRESSURE ALGORITHM,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/142-019-905-622-314,Granted Patent,yes,6,0,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61M60/178;;A61M60/237;;A61M60/422;;A61M60/531;;A61M60/538;;A61M60/546;;A61M60/585,,0,0,,,,ACTIVE
156,US,A1,US 2019/0358383 A1,035-643-299-224-710,2019-11-28,2019,US 201916534615 A,2019-08-07,US 201916534615 A;;US 201715663265 A;;US 201662369326 P,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signal in the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,HEARTWARE INC (2019-09-06),https://lens.org/035-643-299-224-710,Patent Application,yes,0,3,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61B5/024;;A61B5/029;;A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,ACTIVE
157,US,A1,US 2012/0206799 A1,059-284-802-244-129,2012-08-16,2012,US 201213371868 A,2012-02-13,US 201213371868 A;;US 201161441681 P,2011-02-11,BINOCULARS WITH INTEGRATED LASER DESIGNATOR/ILLUMINATOR FOR ILLUMINATING AN OPTICAL FIELD OF VIEW,Binoculars with an integrated laser light source capable of illuminating the optical field of view through the binoculars to provide concise and effective viewing under limited visibility conditions. The integrated light source generates a coherent laser light beam that has variably adjustable divergence.,RILEY LOUIS F;;CASAS JUAN CARLOS,RILEY LOUIS F;;CASAS JUAN CARLOS,CASAS JUAN CARLOS (2011-02-23),https://lens.org/059-284-802-244-129,Patent Application,yes,2,7,1,1,0,G02B23/18;;G02B23/18;;G02B27/20;;G02B27/20,G02B23/18,359/418,1,0,,,"Insight Technology, Inc. U.S. Militatry AN/PEQ-2 &2A Infrared Target Pointer /Illuminator/Aiming Laser. NSN: 5855-01-422-5253 & NSN: 5855-01-447-8992. Copyright 1998.",DISCONTINUED
158,EP,B1,EP 0831240 B1,123-920-504-382-279,2002-11-06,2002,EP 97907109 A,1997-03-11,ES 9700057 W;;ES 9600634 A,1996-03-15,SELF-ADJUSTING TERMINAL FOR A CONTROL CABLES,,FICO CABLES SA,GABAS CEBOLLERO CARLOS;;CASAS GOMILA JORDI,,https://lens.org/123-920-504-382-279,Granted Patent,yes,6,0,14,14,0,F16C1/14;;F16C1/223;;Y10T74/20402;;Y10T74/20402;;F16C1/223;;F16C1/14,F16C1/14;;F16C1/22,,0,0,,,,EXPIRED
159,US,A1,US 2016/0144092 A1,170-563-606-564-892,2016-05-26,2016,US 201514950213 A,2015-11-24,US 201514950213 A;;US 201462084742 P,2014-11-26,FIDUCIAL POINT OPTIMIZATION,"A flow rate of blood through an implantable blood pump is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value and second flow rate values. Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS,,https://lens.org/170-563-606-564-892,Patent Application,yes,1,16,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,ACTIVE
160,US,A1,US 2018/0085508 A1,169-509-156-424-696,2018-03-29,2018,US 201715719719 A,2017-09-29,US 201715719719 A;;US 201662401508 P,2016-09-29,IMPLANTABLE PUMP IMPELLER THERMAL KNOCKDOWN,"The present invention relates to kits and methods for calibrating a pump through performance of a thermal knockdown process including demagnetization of an impeller of the pump where the impeller is separate from the pump. By heat treating the impeller, a property of magnetic interaction of the pump is reduced in a repeatable manner. A kit includes a pump with impeller, a controller and an oven. The method generally involves an iterative process of testing the pump for a property related to magnetic interaction of the elements of the pump, removing the impeller from the pump, heating the impeller under controlled conditions, then placing the impeller back into the pump to repeat the test performed initially.",HEARTWARE INC,WOLMAN JUSTIN;;REYES CARLOS;;CASAS FERNANDO,HEARTWARE INC (2017-09-27),https://lens.org/169-509-156-424-696,Patent Application,yes,0,1,8,8,0,C22C5/04;;C22F1/14;;A61M60/422;;A61M60/216;;A61M60/538;;A61M60/515;;A61M60/122;;F04D29/18;;F04D27/001;;F04D29/026;;F04D13/0653;;A61M2205/70;;C22C5/04;;A61M2205/3368;;A61M2205/36;;C22F1/14;;A61M2205/332;;A61M2205/50;;F04D7/00;;F27B17/0016;;G01F1/58;;H02K7/14;;H05B1/025;;A61M60/419;;A61M60/538;;A61M60/515;;A61M60/422;;A61M60/216;;A61M60/122,A61M60/122;;A61M60/216;;A61M60/422;;A61M60/515;;A61M60/538;;C22C5/04;;C22F1/14;;F04D13/06;;F04D27/00;;F04D29/02;;F04D29/18,,0,0,,,,ACTIVE
161,EP,A2,EP 3003421 A2,080-135-892-438-673,2016-04-13,2016,EP 14737079 A,2014-06-04,US 201361831027 P;;US 201313951302 A;;US 2014/0040847 W,2013-06-04,SUCTION DETECTION IN AN AXIAL BLOOD PUMP USING BEMF DATA,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,,https://lens.org/080-135-892-438-673,Patent Application,yes,0,0,4,18,0,A61M2205/3334;;A61M60/422;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/546;;A61M60/816;;A61M60/816;;A61M60/178;;A61M60/237;;A61M60/538;;A61M60/422,A61M60/178;;A61M60/237;;A61M60/422;;A61M60/538;;A61M60/816,,0,0,,,,ACTIVE
162,EP,A2,EP 3003420 A2,117-210-076-390-868,2016-04-13,2016,EP 14737077 A,2014-06-04,US 201361831023 P;;US 2014/0040803 W,2013-06-04,AXIAL FLOW PUMP PRESSURE ALGORITHM,,HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/117-210-076-390-868,Patent Application,yes,0,2,7,7,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/531;;A61M60/585;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/585;;A61M60/546;;A61M60/538;;A61M60/178;;A61M60/531,A61M1/10;;A61M1/12,,0,0,,,,ACTIVE
163,CN,A,CN 109562211 A,123-943-892-214-665,2019-04-02,2019,CN 201780047404 A,2017-07-28,US 201662369326 P;;US 2017/0044459 W,2016-08-01,HEART RATE DETERMINATION BASED ON VAD CURRENT WAVEFORM,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signalin the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,,https://lens.org/123-943-892-214-665,Patent Application,no,12,0,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61M60/178;;A61M60/216;;A61M60/515;;A61M60/876,,0,0,,,,INACTIVE
164,CN,A,CN 111526899 A,151-745-302-023-534,2020-08-11,2020,CN 201880081949 A,2018-12-17,US 201762607478 P;;US 2018/0065936 W,2017-12-19,HEART RATE MEASUREMENT USING BLOOD PUMP IMPELLER LOCATION,"A method of determining a heart rate of a patient having an implanted blood pump including applying a voltage to a plurality of coils of a stator of the blood pump to produce an electromagnetic forceto rotate a rotor in communication with the plurality of coils; displaying a waveform associated with a back electromotive force in the plurality of coils of the blood pump, the waveform being proportional to an axial position of the rotor relative to the stator; determining a time interval between a first alteration in the waveform relative to a baseline and a second alteration in the waveform relative to the baseline; and determining the heart rate of the patient based on the time interval.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS,,https://lens.org/151-745-302-023-534,Patent Application,no,10,0,7,7,0,A61M60/857;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/515;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/216;;A61M60/857;;A61M60/515;;A61M60/538,A61M1/12;;A61M1/10,,0,0,,,,ACTIVE
165,US,B2,US 8636383 B2,184-129-366-374-075,2014-01-28,2014,US 201213370437 A,2012-02-10,US 201213370437 A;;US 201161441329 P,2011-02-10,Laser signaling buoy and method of using,"A signaling buoy and method suitable for emitting a light signal over long distances in marine environments. The buoy includes a watertight enclosure having a compartment, an aperture at an upper end of the enclosure for emitting a laser light beam therethrough, a laser light source disposed within the enclosure for generating the light beam, and a battery within the enclosure for powering the light source. Electrical contacts are disposed on an exterior of the enclosure and are adapted to complete an electrical circuit when an electrical short exists therebetween to conduct electrical power from the battery to the laser light source. The buoy is configured to float upright in water with the electrical contacts submersed in the water.",RILEY LOUIS F;;CASAS JUAN CARLOS,RILEY LOUIS F;;CASAS JUAN CARLOS,CASAS JUAN CARLOS (2012-02-23),https://lens.org/184-129-366-374-075,Granted Patent,yes,13,1,2,2,0,B63B22/00;;B63B22/00;;B63B22/20;;B63B22/20;;B63B45/04;;B63B45/04;;B63B2201/08;;B63B2201/08;;B63B2209/02;;B63B2209/02;;B63B2209/14;;B63B2209/14;;B63C9/21;;B63C9/21,F21L4/00;;B63B22/20;;B63B45/00,362/259;;362/183;;362/477,0,0,,,,INACTIVE
166,US,A1,US 2012/0198745 A1,001-468-025-889-45X,2012-08-09,2012,US 201213367857 A,2012-02-07,US 201213367857 A;;US 201161440128 P,2011-02-07,RAPID ATTACHMENT/DETACHMENT MECHANISM FOR WEAPON-MOUNTABLE LIGHTING DEVICES,"A mechanism adapted for rapid attachment/detachment of a lighting device to a rail system of a host weapon system. The mechanism includes a body, a fixed rail clamp, and a floating rail clamp that is adjustably attached to the body in an opposing manner to the fixed rail clamp to provide a clamping effect therebetween. The floating rail clamp has a recess in a surface opposite the fixed rail clamp. A holding screw passes through a bore in the fixed rail clamp, and a clamp screw passes through a slot in the floating rail clamp and is threaded into one end of the holding screw. An oppositely-disposed end of the clamp screw protrudes within the recess of the floating rail clamp, and a cam arm has a first end pivotably coupled to the second end of the clamp screw and an oppositely-disposed distal end that protrudes from the recess.",RILEY LOUIS F;;CASAS JUAN CARLOS,RILEY LOUIS F;;CASAS JUAN CARLOS,CASAS JUAN CARLOS (2012-02-23),https://lens.org/001-468-025-889-45X,Patent Application,yes,6,23,1,1,0,F41C27/00;;F41G1/35;;F41G11/003;;F41C27/00;;F41G1/35;;F41G11/003,F41C27/00,42/90,0,0,,,,DISCONTINUED
167,US,B2,US 11154701 B2,151-819-447-283-82X,2021-10-26,2021,US 201916534615 A,2019-08-07,US 201916534615 A;;US 201715663265 A;;US 201662369326 P,2016-08-01,Heart rate determination based on VAD current waveform,"The present disclosure provides for methods and systems for determining heart rate of a patient. Based on motor current signals of a ventricular assist device (VAD), each of first, second and third events in the measured current signal may be detected, the first event being indicative of a rise or fall in the current signal, the second event being indicative of a rise or fall in the current signal in the opposite direction as the first event, and the third event being indicative of a rise or fall in the current signal in the same direction as the first event. A timer counter may be initiated upon detection of the first event, and an elapsed time may be measured upon detection of the third event. Heart rate may be determined based on the elapsed time of the timer counter.",HEARTWARE INC,REYES CARLOS;;CASAS FERNANDO;;WOLMAN JUSTIN,HEARTWARE INC (2019-09-06),https://lens.org/151-819-447-283-82X,Granted Patent,yes,9,0,11,11,0,A61M60/165;;A61M60/216;;A61M60/515;;A61M60/508;;A61M60/855;;A61B5/024;;A61B5/02438;;A61M60/216;;A61M60/178;;A61M60/515;;A61M60/876;;A61B5/02438;;A61M60/148;;A61M60/178;;A61M60/876;;A61M60/216;;A61M60/515;;A61B5/029;;A61B5/7235,A61B5/02;;A61B5/00;;A61B5/024;;A61B5/029;;A61M60/148;;A61M60/178;;A61M60/216;;A61M60/40;;A61M60/50;;A61M60/515;;A61M60/876,,2,0,,,"International Search Report and Written Opinion dated Mar. 1, 2018, for corresponding International Application No. PCT/US2017/044459; International Filing Date: Jul. 28, 2017 consisting of 12-pages.;;China Intellectual Property Admininstration, Notice on the First Office Action and Search Report for corresponding CN Application No. 201780047404.8, dated Oct. 12, 2020, 21 pages.",ACTIVE
168,US,B2,US 10589011 B2,180-996-228-545-999,2020-03-17,2020,US 201715710323 A,2017-09-20,US 201715710323 A;;US 201662398667 P,2016-09-23,Field-oriented control for control of blood pump motor,"A ventricular assist device includes a pump configured to pump blood of a patient. A motor is configured to operate the pump. First, second, and third conductors are coupled to the motor and are configured to supply electric current from a power supply to the motor in first, second, and third phases, respectively. A controller is configured to operate the motor using a Field Oriented Control (FOC) method, and if one from the group consisting of first, second and third conductors becomes unable to supply electric current to the motor, the controller continues to operate the motor using the FOC method using the phases of the two conductors that are able to supply electric current to the motor.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN,HEARTWARE INC (2016-09-27),https://lens.org/180-996-228-545-999,Granted Patent,yes,21,0,5,5,0,A61M60/82;;A61M60/419;;A61M60/232;;A61M60/814;;A61M60/824;;A61M60/237;;A61M60/178;;A61M60/538;;A61M60/857;;A61M60/148;;A61M60/419;;A61M60/857;;A61M60/824;;A61M60/82;;A61M60/237;;A61M60/232;;A61M60/178;;A61M60/538;;A61M60/814,A61M60/178;;A61M60/232;;A61M60/237;;A61M60/419;;A61M60/538;;A61M60/814;;A61M60/82;;A61M60/824;;A61M60/857,,9,0,,,"Renesas Electronics, YMCRPRX52t: RX62T Motor Control Evaluation Kit Quick Start Guide, D011011_11_V0100.;;Renesas Electronics, RX600 Motor Control Evaluation Kit, Ready-to-use Platform for Evaluating Sensorless Vector Control and Position Control.;;Renesas Electronics, RX62T, Three Shunt Sensorless Vector Control of PMSM with Internal Programmable Gain Amplifier (PGA), R01AN0902EU0200, Rev. 2.00, Jan. 31, 2014, pp. 16.;;Renesas Electronics, RX62T Motor Control Evaluation Kit, User Manual: Hardware, RX Family / RX600 Series / RX62T Group, Rev.1.00, Jan. 2012.;;Texas Instruments, DRV830x-HC-C2-KIT Hardware Reference Guide, Version 1.0—Aug. 2011.;;Bilal Akin and Manish Bhardwaj, Texas Instruments, Trapezoidal Control of BLDC Motors Using Hall Effect Sensors, Version 1.0—Feb. 2010.;;Copely Controls Corp.—Article, What is ‘Filed Oriented Control’ and what good is it?;;Texas Instruments, RM48L952 16- and 32 Bit RISC Flash Microcontroller, SPNS177B—Sep. 2011—Revised Jul. 2013.;;International Search Report and Written Opinion dated Dec. 18, 2017 for corresponding International Application No. PCT/US2017052492; International Filing Date: Sep. 20, 2017 consisting of 12-pages.",ACTIVE
169,US,A1,US 2012/0206908 A1,179-514-047-392-102,2012-08-16,2012,US 201213370437 A,2012-02-10,US 201213370437 A;;US 201161441329 P,2011-02-10,LASER SIGNALING BUOY AND METHOD OF USING,"A signaling buoy and method suitable for emitting a light signal over long distances in marine environments. The buoy includes a watertight enclosure having a compartment, an aperture at an upper end of the enclosure for emitting a laser light beam therethrough, a laser light source disposed within the enclosure for generating the light beam, and a battery within the enclosure for powering the light source. Electrical contacts are disposed on an exterior of the enclosure and are adapted to complete an electrical circuit when an electrical short exists therebetween to conduct electrical power from the battery to the laser light source. The buoy is configured to float upright in water with the electrical contacts submersed in the water.",RILEY LOUIS F;;CASAS JUAN CARLOS,RILEY LOUIS F;;CASAS JUAN CARLOS,CASAS JUAN CARLOS (2012-02-23),https://lens.org/179-514-047-392-102,Patent Application,yes,11,4,2,2,0,B63B22/00;;B63B22/00;;B63B22/20;;B63B22/20;;B63B45/04;;B63B45/04;;B63B2201/08;;B63B2201/08;;B63B2209/02;;B63B2209/02;;B63B2209/14;;B63B2209/14;;B63C9/21;;B63C9/21,F21L4/00,362/183;;362/157,0,0,,,,INACTIVE
170,WO,A1,WO 2019/125999 A1,192-891-875-387-872,2019-06-27,2019,US 2018/0065936 W,2018-12-17,US 201762607478 P,2017-12-19,HEART RATE MEASUREMENT USING BLOOD PUMP IMPELLER LOCATION,"A method of determining a heart rate of a patient having an implanted blood pump including applying a voltage to a plurality of coils of a stator of the blood pump to produce an electromagnetic force to rotate a rotor in communication with the plurality of coils; displaying a waveform associated with a back electromotive force in the plurality of coils of the blood pump, the waveform being proportional to an axial position of the rotor relative to the stator; determining a time interval between a first alteration in the waveform relative to a baseline and a second alteration in the waveform relative to the baseline; and determining the heart rate of the patient based on the time interval.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS,,https://lens.org/192-891-875-387-872,Patent Application,yes,6,0,7,7,0,A61M60/857;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/515;;A61M2205/3334;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/216;;A61M60/857;;A61M60/515;;A61M60/538,A61M1/10;;A61M1/12,,0,0,,,,PENDING
171,DE,B,DE 1118196 B,077-477-229-119-168,1961-11-30,1961,DE S0059852 A,1958-09-16,MX 1118196X A,1957-09-23,Verfahren zur Herstellung von Hydroxypregnanverbindungen,,SYNTEX SA,RINGOLD HOWARD J;;BOWERS ALBERT;;CAMPILLO CARLOS CASAS,,https://lens.org/077-477-229-119-168,Patent Application,no,0,0,1,1,0,C12P33/00,C12P33/00,,0,0,,,,DISCONTINUED
172,CN,A,CN 111757761 A,037-815-103-038-926,2020-10-09,2020,CN 201980014995 A,2019-05-07,US 201862669525 P;;US 2019/0031123 W,2018-05-10,AXIAL PUMP PRESSURE ALGORITHM WITH FIELD ORIENTED CONTROL,"A method of controlling an implantable blood pump including a housing having a proximal portion including an inlet, a distal portion including an outlet, and an impeller therein, the method includingdetecting when a pressure in the housing exceeds a pressure threshold and executing a first vector control command to displace the impeller axially in a distal direction from a primary position to a secondary position different than the primary position in response to the pressure exceeding the pressure threshold.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS;;JOHNSON THOMAS R,,https://lens.org/037-815-103-038-926,Patent Application,no,15,0,6,6,0,A61M2205/3331;;A61M60/554;;A61M60/824;;A61M60/422;;A61M60/178;;A61M60/242;;A61M60/822;;A61M2205/3331;;A61M60/82;;A61M60/419;;A61M60/857;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/554;;A61M60/824;;A61M60/50,A61M1/12,,0,0,,,,PENDING
173,US,A1,US 2019/0343999 A1,036-453-040-351-349,2019-11-14,2019,US 201916405483 A,2019-05-07,US 201916405483 A;;US 201862669525 P,2018-05-10,AXIAL PUMP PRESSURE ALGORITHM WITH FIELD ORIENTED CONTROL,"A method of controlling an implantable blood pump including a housing having a proximal portion including an inlet, a distal portion including an outlet, and an impeller therein, the method including detecting when a pressure in the housing exceeds a pressure threshold and executing a first vector control command to displace the impeller axially in a distal direction from a primary position to a secondary position different than the primary position in response to the pressure exceeding the pressure threshold.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS;;JOHNSON THOMAS R,HEARTWARE INC (2019-05-21),https://lens.org/036-453-040-351-349,Patent Application,yes,0,1,6,6,0,A61M2205/3331;;A61M60/554;;A61M60/824;;A61M60/422;;A61M60/178;;A61M60/242;;A61M60/822;;A61M2205/3331;;A61M60/82;;A61M60/419;;A61M60/857;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/554;;A61M60/824;;A61M60/50,A61M1/10,,0,0,,,,ACTIVE
174,US,B2,US 11311711 B2,090-526-713-636-254,2022-04-26,2022,US 201916260648 A,2019-01-29,US 201916260648 A;;US 201862624255 P,2018-01-31,Axial blood pump with impeller rinse operation,"A method of controlling a blood pump including executing a control command to temporarily displace an impeller of the blood pump within a pump housing from a first axial position relative to the pump housing to a second axial position a distance away from the first axial position using a vector control method, and causing the impeller to move from the second axial position to a third axial position, the third axial position including a positive and a negative displacement of the impeller relative to the first axial position.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN;;JOHNSON THOMAS R,HEARTWARE INC (2019-01-30),https://lens.org/090-526-713-636-254,Granted Patent,yes,42,3,6,6,0,A61M60/82;;A61M60/824;;A61M60/422;;A61M60/562;;A61M60/178;;A61M60/508;;A61M60/814;;A61M60/242;;A61M2205/50;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/562;;A61M60/82;;A61M60/824;;A61M60/508;;A61M60/814,A61M60/40;;A61M60/148;;A61M60/205;;A61M60/50,,1,0,,,"International Search Report and Written Opinion dated May 6, 2019, for corresponding International Application No. PCT/US2019/015561; International Filing Date: Jan. 29, 2019 consisting of 10 pages.",ACTIVE
175,WO,A1,WO 2019/217426 A1,138-090-861-492-892,2019-11-14,2019,US 2019/0031123 W,2019-05-07,US 201862669525 P,2018-05-10,AXIAL PUMP PRESSURE ALGORITHM WITH FIELD ORIENTED CONTROL,"A method of controlling an implantable blood pump including a housing having a proximal portion including an inlet, a distal portion including an outlet, and an impeller therein, the method including detecting when a pressure in the housing exceeds a pressure threshold and executing a first vector control command to displace the impeller axially in a distal direction from a primary position to a secondary position different than the primary position in response to the pressure exceeding the pressure threshold.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS;;JOHNSON THOMAS R,,https://lens.org/138-090-861-492-892,Patent Application,yes,16,0,6,6,0,A61M2205/3331;;A61M60/554;;A61M60/824;;A61M60/422;;A61M60/178;;A61M60/242;;A61M60/822;;A61M2205/3331;;A61M60/82;;A61M60/419;;A61M60/857;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/554;;A61M60/824;;A61M60/50,A61M1/12,,0,0,,,,PENDING
176,US,B2,US 11446481 B2,015-175-859-677-17X,2022-09-20,2022,US 201916405483 A,2019-05-07,US 201916405483 A;;US 201862669525 P,2018-05-10,Axial pump pressure algorithm with field oriented control,"A method of controlling an implantable blood pump including a housing having a proximal portion including an inlet, a distal portion including an outlet, and an impeller therein, the method including detecting when a pressure in the housing exceeds a pressure threshold and executing a first vector control command to displace the impeller axially in a distal direction from a primary position to a secondary position different than the primary position in response to the pressure exceeding the pressure threshold.",HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS;;JOHNSON THOMAS R,HEARTWARE INC (2019-05-21),https://lens.org/015-175-859-677-17X,Granted Patent,yes,41,3,6,6,0,A61M2205/3331;;A61M60/554;;A61M60/824;;A61M60/422;;A61M60/178;;A61M60/242;;A61M60/822;;A61M2205/3331;;A61M60/82;;A61M60/419;;A61M60/857;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/554;;A61M60/824;;A61M60/50,A61M60/857;;A61M60/419;;A61M60/50;;A61M60/82,,3,0,,,"International Search Report and Written Opinion dated Aug. 6, 2019, for corresponding International Application No. PCT/US2019/031123; International Filing Date: May 7, 2019 consisting of 13-pages.;;International Preliminary Report on Patentability from International Application No. PCT/US2019/031123, dated Nov. 10, 2020, 7 pp.;;Response to Communication Pursuant to Rules 161(1) and 162 EPC dated Dec. 17, 2020, from counterpart European Application No. 19725522.7, filed May 31, 2021, 16 pp.",ACTIVE
177,EP,A1,EP 3790606 A1,057-672-084-948-624,2021-03-17,2021,EP 19725522 A,2019-05-07,US 201862669525 P;;US 2019/0031123 W,2018-05-10,AXIAL PUMP PRESSURE ALGORITHM WITH FIELD ORIENTED CONTROL,,HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS;;JOHNSON THOMAS R,,https://lens.org/057-672-084-948-624,Patent Application,yes,0,0,6,6,0,A61M2205/3331;;A61M60/554;;A61M60/824;;A61M60/422;;A61M60/178;;A61M60/242;;A61M60/822;;A61M2205/3331;;A61M60/82;;A61M60/419;;A61M60/857;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/554;;A61M60/824;;A61M60/50,A61M1/12,,0,0,,,,ACTIVE
178,US,A1,US 2019/0231952 A1,064-492-732-116-304,2019-08-01,2019,US 201916260648 A,2019-01-29,US 201916260648 A;;US 201862624255 P,2018-01-31,AXIAL BLOOD PUMP WITH IMPELLER RINSE OPERATION,"A method of controlling a blood pump including executing a control command to temporarily displace an impeller of the blood pump within a pump housing from a first axial position relative to the pump housing to a second axial position a distance away from the first axial position using a vector control method, and causing the impeller to move from the second axial position to a third axial position, the third axial position including a positive and a negative displacement of the impeller relative to the first axial position.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN;;JOHNSON THOMAS R,HEARTWARE INC (2019-01-30),https://lens.org/064-492-732-116-304,Patent Application,yes,0,3,6,6,0,A61M60/82;;A61M60/824;;A61M60/422;;A61M60/562;;A61M60/178;;A61M60/508;;A61M60/814;;A61M60/242;;A61M2205/50;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/562;;A61M60/82;;A61M60/824;;A61M60/508;;A61M60/814,A61M1/10;;A61M1/12,,0,0,,,,ACTIVE
179,EP,A1,EP 3746146 A1,186-680-429-785-953,2020-12-09,2020,EP 19705019 A,2019-01-29,US 201862624255 P;;US 2019/0015561 W,2018-01-31,AXIAL BLOOD PUMP WITH IMPELLER RINSE OPERATION,,HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN;;JOHNSON THOMAS R,,https://lens.org/186-680-429-785-953,Patent Application,yes,0,0,6,6,0,A61M60/82;;A61M60/824;;A61M60/422;;A61M60/562;;A61M60/178;;A61M60/508;;A61M60/814;;A61M60/242;;A61M2205/50;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/562;;A61M60/82;;A61M60/824;;A61M60/508;;A61M60/814,A61M1/10;;A61M1/12,,0,0,,,,DISCONTINUED
180,CN,A,CN 114747161 A,172-372-140-081-047,2022-07-12,2022,CN 202080081393 A,2020-10-08,US 201916660536 A;;US 2020/0054840 W,2019-10-22,Parallel rate de-matching and layer de-mapping for physical uplink shared channels,"Apparatus, systems, and techniques such that information received from a plurality of 5th-Generation (5G) new radio (NR) antennas is decoded in parallel. In at least one embodiment, the information includes data that has been processed by soft demapping, and decoding the information includes layer demapping, descrambling and rate dematching of the data in parallel.",NVIDIA CORP,IBARS CASAS CARLOS;;MULLER ANDREAS;;BANYUR GOWDA H D,,https://lens.org/172-372-140-081-047,Patent Application,no,4,0,9,9,0,H04L1/06;;H04L1/0052;;H04L1/0052;;H04L1/06;;H04L1/0052;;H04L1/0071;;H04L1/0046;;H04L1/1812;;H04L1/0057;;H04L1/06;;H04B7/0413;;H03M13/1105;;H03M13/45;;H04B7/0413;;H04L1/0009;;H04L1/1812;;H04L27/2649,H04L1/00;;H04L1/06,,3,2,004-432-246-402-216;;001-730-273-777-861,10.1109/sips.2013.6674508;;10.1109/tvt.2012.2210576,"SATYENDRA SINGH: ""Performance Evaluation of STBC-OFDM WiMAX System using Graphics Processing Unit (GPU)"", IEEE, pages 1 - 6;;Q. ZHENG: ""ARCHITECTING AN LTE BASE STATION WITH GRAPHICS PROCESSING UNITS"", IEEE, pages 1 - 4;;SANDRA ROGER: ""Fully Parallel GPU Implementation of a Fixed-Complexity Soft-Output MIMO Detector"", IEEE, pages 3796 - 3800",PENDING
181,MX,E,MX 6568 E,197-863-811-876-638,1985-07-16,1985,MX 10158881 U,1981-10-06,MX 18950781 A,1981-10-06,PROCEDIMIENTO MEJORADO DE FERMENTACION PARA LA PRODUCCION DE PROTEINA UNICELULAR A PARTIR DE RESIDUOS LIGNOCELULOSICOS AGROINDUSTRIALES,,INVEST Y DE ESTUDIOS AVANZADOS,CAMPILLO CARLOS CASAS;;MARTINEZ MA MAYRA DE LA TORRE,,https://lens.org/197-863-811-876-638,Limited Patent,no,0,0,1,1,0,,A23J1/16;;C12N1/22,09-9,0,0,,,,EXPIRED
182,WO,A1,WO 2019/152363 A1,092-691-390-925-714,2019-08-08,2019,US 2019/0015561 W,2019-01-29,US 201862624255 P,2018-01-31,AXIAL BLOOD PUMP WITH IMPELLER RINSE OPERATION,"A method of controlling a blood pump including executing a control command to temporarily displace an impeller of the blood pump within a pump housing from a first axial position relative to the pump housing to a second axial position a distance away from the first axial position using a vector control method, and causing the impeller to move from the second axial position to a third axial position, the third axial position including a positive and a negative displacement of the impeller relative to the first axial position.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN;;JOHNSON THOMAS R,,https://lens.org/092-691-390-925-714,Patent Application,yes,10,0,6,6,0,A61M60/82;;A61M60/824;;A61M60/422;;A61M60/562;;A61M60/178;;A61M60/508;;A61M60/814;;A61M60/242;;A61M2205/50;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/562;;A61M60/82;;A61M60/824;;A61M60/508;;A61M60/814,A61M1/10;;A61M1/12,,0,0,,,,PENDING
183,WO,A2,WO 2006/017366 A2,024-762-122-816-588,2006-02-16,2006,US 2005/0025123 W,2005-07-13,US 89190104 A,2004-07-13,GARAGE DOOR,"A garage door is connected to a track extending from a front wall of the garage to a sidewall within the garage. The garage door is horizontally moveable along the track, such as with a chain-driven mechanism, from a generally closed position within the garage vehicle entrance of the garage to a generally open position awayfrom the garage vehicle entrance and disposed adjacent to a sidewall of the garage. A second horizontally moving garage door may be used in conjunction with the first garage door to cooperatively close the garage vehicle entrance.",DIAZ CARLOS ENRIQUE;;RUIZ JOSE L;;CASAS LUIS M;;CASAS GERARDO B;;VEGA JOSEPH G,DIAZ CARLOS ENRIQUE;;RUIZ JOSE L;;CASAS LUIS M;;CASAS GERARDO B;;VEGA JOSEPH G,,https://lens.org/024-762-122-816-588,Patent Application,yes,0,0,5,5,0,E05D15/36;;E05D15/36;;E05D15/12;;E05D15/12;;E05F15/643;;E05F15/643;;E05Y2900/106;;E05Y2900/106,E05D15/00,,0,0,,,,PENDING
184,BR,B1,BR 102013009771 B1,126-433-083-963-956,2021-08-31,2021,BR 102013009771 A,2013-04-22,BR 102013009771 A,2013-04-22,Disposição construtiva de uma estrutura semimonocoque confeccionada em material composto polimérico para aplicação na fabricação de postes,"disposição construtiva de uma estrutura semimonocoque confeccionada em material composto polimerico para aplicação na fabricação de postes o presente pedido de patente de modelo de utilidade refere-se a uma disposição construtiva de uma estrutura semimonocoque confeccionada em material composto polimérico reforçado por fibras para aplicação na fabricação de postes. a invenção proposta tem por aplicação a manufatura de postes a serem utilizados em transmissão e distribuição de energia elétrica, iluminação pública, redes e telefonia móvel, estruturas de suporte de aerogeradores (turbinas eólicas), sendo que o uso desta configuração viabiliza a obtenção de estruturas mais leves e econômicas.",UNIV ESTADUAL CAMPINAS UNICAMP;;UNIV FEDERAL DE MINAS GERAIS UFMG,CARLOS ALBERTO CIMINI JUNIOR;;ESTEVAM BARBOSA DE LAS CASAS,,https://lens.org/126-433-083-963-956,Granted Patent,no,0,0,2,2,0,B29C70/32;;B29C70/86;;E04H12/02,B29C70/32;;B29C70/86;;E04H12/02,,0,0,,,,ACTIVE
185,EP,B1,EP 3790606 B1,109-989-901-627-872,2024-02-21,2024,EP 19725522 A,2019-05-07,US 201862669525 P;;US 2019/0031123 W,2018-05-10,AXIAL PUMP PRESSURE ALGORITHM WITH FIELD ORIENTED CONTROL,,HEARTWARE INC,WOLMAN JUSTIN;;CASAS FERNANDO;;REYES CARLOS;;JOHNSON THOMAS R,,https://lens.org/109-989-901-627-872,Granted Patent,yes,4,0,6,6,0,A61M2205/3331;;A61M60/554;;A61M60/824;;A61M60/422;;A61M60/178;;A61M60/242;;A61M60/822;;A61M2205/3331;;A61M60/82;;A61M60/419;;A61M60/857;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/554;;A61M60/824;;A61M60/50,A61M60/178;;A61M60/242;;A61M60/422;;A61M60/554;;A61M60/822;;A61M60/824,,0,0,,,,ACTIVE
186,CN,A,CN 111655307 A,199-649-966-852-265,2020-09-11,2020,CN 201980010988 A,2019-01-29,US 201862624255 P;;US 2019/0015561 W,2018-01-31,AXIAL BLOOD PUMP WITH IMPELLER RINSE OPERATION,"A method of controlling a blood pump including executing a control command to temporarily displace an impeller of the blood pump within a pump housing from a first axial position relative to the pumphousing to a second axial position a distance away from the first axial position using a vector control method, and causing the impeller to move from the second axial position to a third axial position, the third axial position including a positive and a negative displacement of the impeller relative to the first axial position.",HEARTWARE INC,CASAS FERNANDO;;REYES CARLOS;;WOLMAN JUSTIN;;JOHNSON THOMAS R,,https://lens.org/199-649-966-852-265,Patent Application,no,7,1,6,6,0,A61M60/82;;A61M60/824;;A61M60/422;;A61M60/562;;A61M60/178;;A61M60/508;;A61M60/814;;A61M60/242;;A61M2205/50;;A61M60/148;;A61M60/422;;A61M60/237;;A61M60/178;;A61M60/562;;A61M60/82;;A61M60/824;;A61M60/508;;A61M60/814,A61M1/10;;A61M1/12,,0,0,,,,ACTIVE
187,WO,A3,WO 2006/017366 A3,159-818-286-284-245,2006-07-27,2006,US 2005/0025123 W,2005-07-13,US 89190104 A,2004-07-13,GARAGE DOOR,"A garage door is connected to a track extending from a front wall of the garage to a sidewall within the garage. The garage door is horizontally moveable along the track, such as with a chain-driven mechanism, from a generally closed position within the garage vehicle entrance of the garage to a generally open position awayfrom the garage vehicle entrance and disposed adjacent to a sidewall of the garage. A second horizontally moving garage door may be used in conjunction with the first garage door to cooperatively close the garage vehicle entrance.",DIAZ CARLOS ENRIQUE;;RUIZ JOSE L;;CASAS LUIS M;;CASAS GERARDO B;;VEGA JOSEPH G,DIAZ CARLOS ENRIQUE;;RUIZ JOSE L;;CASAS LUIS M;;CASAS GERARDO B;;VEGA JOSEPH G,,https://lens.org/159-818-286-284-245,Search Report,yes,5,0,5,5,0,E05D15/36;;E05D15/36;;E05D15/12;;E05D15/12;;E05F15/643;;E05F15/643;;E05Y2900/106;;E05Y2900/106,E05D15/06,,0,0,,,,PENDING
188,BR,A2,BR 102013009771 A2,062-344-705-810-707,2014-12-23,2014,BR 102013009771 A,2013-04-22,BR 102013009771 A,2013-04-22,DISPOSIÇÃO CONSTRUTIVA DE UMA ESTRUTURA SEMIMONOCOQUE CONFECCIONADA EM MATERIAL COMPOSTO POLIMÉRICO PARA APLICAÇÃO NA FABRICAÇÃO DE POSTES,"DISPOSIÇÃO CONSTRUTIVA DE UMA ESTRUTURA SEMIMONOCOQUE CONFECCIONADA EM MATERIAL COMPOSTO POLIMERICO PARA APLICAÇÃO NA FABRICAÇÃO DE POSTES O presente pedido de patente de modelo de utilidade refere-se a uma disposição construtiva de uma estrutura semimonocoque confeccionada em material composto polimérico reforçado por fibras para aplicação na fabricação de postes. A invenção proposta tem por aplicação a manufatura de postes a serem utilizados em transmissão e distribuição de energia elétrica, iluminação pública, redes e telefonia móvel, estruturas de suporte de aerogeradores (turbinas eôlicas), sendo que o uso desta configuração viabiliza a obtenção de estruturas mais leves e econômicas.",UNICAMP;;UNIV MINAS GERAIS,CIMINI CARLOS ALBERTO JUNIOR;;CASAS ESTEVAM BARBOSA DE LAS,,https://lens.org/062-344-705-810-707,Patent Application,no,0,0,2,2,0,B29C70/32;;B29C70/86;;E04H12/02,E04H12/02,,0,0,,,,ACTIVE
189,CN,A,CN 111491677 A,163-944-934-570-760,2020-08-04,2020,CN 201880078562 A,2018-11-26,US 201762594697 P;;US 2018/0062431 W,2017-12-05,Blood pump with impeller rinse operation,"The invention discloses a method of operating an implantable blood pump having a first stator, a second stator, and an impeller movably disposed there between. The method includes applying a first voltage waveform at first phase to the first stator to generate a magnetic field to rotate the impeller. A second voltage waveform is applied at a second phase shifted from the first phase to the secondstator to rotate the impeller, the second voltage waveform is asymmetric to the first voltage waveform.",HEARTWARE INC,EGLER MARK S;;CASAS FERNANDO;;REYES CARLOS;;LAROSE JEFFREY A,,https://lens.org/163-944-934-570-760,Patent Application,no,23,0,7,7,0,A61M60/82;;A61M60/824;;A61M60/857;;A61M60/422;;A61M60/878;;A61M60/178;;A61M60/508;;A61M60/232;;A61M60/82;;A61M60/148;;A61M60/824;;A61M60/419;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/878;;A61M60/508;;A61M60/857,A61M1/12;;A61M1/10,,0,0,,,,ACTIVE
190,EP,A1,EP 3720520 A1,081-913-783-771-447,2020-10-14,2020,EP 18816424 A,2018-11-26,US 201762594697 P;;US 2018/0062431 W,2017-12-05,BLOOD PUMP WITH IMPELLER RINSE OPERATION,,HEARTWARE INC,EGLER MARK S;;CASAS FERNANDO;;REYES CARLOS;;LAROSE JEFFREY A,,https://lens.org/081-913-783-771-447,Patent Application,yes,0,0,7,7,0,A61M60/82;;A61M60/824;;A61M60/857;;A61M60/422;;A61M60/878;;A61M60/178;;A61M60/508;;A61M60/232;;A61M60/82;;A61M60/148;;A61M60/824;;A61M60/419;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/878;;A61M60/508;;A61M60/857,A61M1/12;;A61M1/10,,0,0,,,,PENDING
191,DE,B2,DE 1543462 B2,095-339-697-781-344,1974-03-28,1974,DE 1543462 A,1966-03-12,GB 1079165 A,1965-03-15,DE 1543462 B2,,"SYNTEX CORP., PANAMA","ZAFFARONI, ALEJANDRO, PALO ALTO, CALIF.;;CASAS-CAMPILLO, CARLOS, MEXICO, D.F.MEX.",,https://lens.org/095-339-697-781-344,Patent Application,no,0,0,11,12,0,C12P33/00;;C12P33/00,C12P33/00,,0,0,,,,EXPIRED
192,US,B2,US 10737006 B2,056-089-445-463-389,2020-08-11,2020,US 201816124944 A,2018-09-07,US 201816124944 A;;US 201715599115 A;;US 201514950213 A;;US 201462084742 P,2014-11-26,Fiducial point optimization,"A flow rate of blood through an implantable blood pump is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value and second flow rate values. Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS;;FERREIRA ANTONIO LUIZ SILVA,HEARTWARE INC (2017-05-19),https://lens.org/056-089-445-463-389,Granted Patent,yes,10,0,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,2,0,,,"International Search Report and Written Opinion for Application No. PCT/US2015/062430 dated Mar. 7, 2016, 11 pages.;;China National Intellectual Property Administration, Notice on the First Office Action and Search Report, for corresponding Chinese Application No. 201580074531.8, dated Aug. 14, 2019, 20 pages.",ACTIVE
193,US,A1,US 2020/0390503 A1,085-999-080-957-427,2020-12-17,2020,US 202016899075 A,2020-06-11,US 202016899075 A;;US 201962860905 P,2019-06-13,SYSTEMS AND METHODS FOR SURGICAL NAVIGATION AND ORTHOPAEDIC FIXATION,"Systems and methods are described for the use of external fixators with intraoperative tracking of bone and/or attached devices and display of real-time information to the surgeon, for example for the treatment of bone deformities. Such systems and/or methods may include determining the deformity to be corrected; estimating the appropriate number, shape, and size of base members, transosseous fixations, and connecting elements to be used; suggesting optimal positions of said items relative to the bone segments; and calculating the necessary correction based on the final position of the attached external fixator components relative to the bone segments.",CASAS CARLOS QUILES;;CABRERA JUAN ANTONIO CONSTANTINO;;MELENDEZ MIGUEL DOMINGUEZ,CASAS CARLOS QUILES;;CABRERA JUAN ANTONIO CONSTANTINO;;MELENDEZ MIGUEL DOMINGUEZ,,https://lens.org/085-999-080-957-427,Patent Application,yes,8,14,1,1,0,A61B2090/3916;;A61B2090/3983;;A61B2090/502;;A61B2090/365;;A61B2090/376;;A61B2034/105;;A61B2034/2063;;A61B2034/2059;;A61B2034/2055;;A61B2034/2051;;A61B2034/2048;;A61B34/20;;A61B2090/3945;;A61B2090/367;;A61B2090/3966;;A61B2034/2065;;A61B2034/107;;A61B2090/372;;A61B17/62;;A61B17/744;;A61B17/66;;A61B17/921;;A61B2090/3762;;A61B2090/3764;;A61B2090/374;;A61B17/72;;A61B2017/00207;;A61B2017/00216;;A61B2090/371;;A61B90/37;;A61B2017/00221;;A61B17/8061;;A61B34/20;;A61B2090/3764;;A61B17/62;;A61B17/72;;A61B2090/3983;;A61B2090/365;;A61B2090/3916;;A61B2090/367;;A61B2090/3945;;A61B2034/2051;;A61B2034/2055;;A61B2034/2063;;A61B2034/2048;;A61B2034/2059;;A61B2090/3762;;A61B2090/374;;A61B2090/378;;A61B2034/105;;A61B2017/564;;A61B2090/502;;A61B2017/00907;;A61B90/37,A61B34/20;;A61B17/62;;A61B17/72;;A61B90/00,,1,1,099-834-295-872-589,10581524;;10.1002/(sici)1097-0150(1999)4:5<264::aid-igs4>3.0.co;2-e;;10.3109/10929089909148179,"Ellis et al., ""A Surgical Planning and Guidance System for High Tibial Osteotomy"", 1999, Computer Aided Surgery, pages 264-274 (Year: 1999)",DISCONTINUED
194,DE,C3,DE 1543462 C3,135-481-448-320-623,1974-10-31,1974,DE 1543462 A,1966-03-12,GB 1079165 A,1965-03-15,DE 1543462 C3,,"SYNTEX CORP., PANAMA","ZAFFARONI, ALEJANDRO, PALO ALTO, CALIF.;;CASAS-CAMPILLO, CARLOS, MEXICO, D.F.MEX.",,https://lens.org/135-481-448-320-623,Granted Patent,no,0,0,11,12,0,C12P33/00;;C12P33/00,C12P33/00,,0,0,,,,EXPIRED
195,US,B2,US 9675742 B2,148-922-772-845-854,2017-06-13,2017,US 201514950213 A,2015-11-24,US 201514950213 A;;US 201462084742 P,2014-11-26,Fiducial point optimization,"A flow rate of blood through an implantable blood pump is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value and second flow rate values. Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS;;SILVA FERREIRA ANTONIO LUIZ,,https://lens.org/148-922-772-845-854,Granted Patent,yes,7,7,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61N1/362;;A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,1,0,,,"International Search Report and Written Opinion for Application No. PCT/US2015/062430 dated Mar. 7, 2016.",ACTIVE
196,US,A1,US 2021/0322755 A1,184-282-005-981-276,2021-10-21,2021,US 202117356704 A,2021-06-24,US 202117356704 A;;US 201816199684 A;;US 201762594697 P,2017-12-05,BLOOD PUMP WITH IMPELLER RINSE OPERATION,"A method of operating an implantable blood pump having a first stator, a second stator, and an impeller movably disposed there between. The method includes applying a first voltage waveform at first phase to the first stator to generate a magnetic field to rotate the impeller. A second voltage waveform is applied at a second phase shifted from the first phase to the second stator to rotate the impeller, the second voltage waveform is asymmetric to the first voltage waveform.",HEARTWARE INC,EGLER MARK S;;CASAS FERNANDO;;REYES CARLOS;;LAROSE JEFFREY A,HEARTWARE INC (2019-02-01),https://lens.org/184-282-005-981-276,Patent Application,yes,3,0,7,7,0,A61M60/82;;A61M60/824;;A61M60/857;;A61M60/422;;A61M60/878;;A61M60/178;;A61M60/508;;A61M60/232;;A61M60/82;;A61M60/148;;A61M60/824;;A61M60/419;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/878;;A61M60/508;;A61M60/857,A61M60/40;;A61M60/148;;A61M60/50;;A61M60/82;;A61M60/824,,0,0,,,,PENDING
197,US,B2,US 11065434 B2,086-829-737-393-801,2021-07-20,2021,US 201816199684 A,2018-11-26,US 201816199684 A;;US 201762594697 P,2017-12-05,Blood pump with impeller rinse operation,"A method of operating an implantable blood pump having a first stator, a second stator, and an impeller movably disposed there between. The method includes applying a first voltage waveform at first phase to the first stator to generate a magnetic field to rotate the impeller. A second voltage waveform is applied at a second phase shifted from the first phase to the second stator to rotate the impeller, the second voltage waveform is asymmetric to the first voltage waveform.",HEARTWARE INC,EGLER MARK S;;CASAS FERNANDO;;REYES CARLOS;;LAROSE JEFFREY A,HEARTWARE INC (2019-02-01),https://lens.org/086-829-737-393-801,Granted Patent,yes,23,3,7,7,0,A61M60/82;;A61M60/824;;A61M60/857;;A61M60/422;;A61M60/878;;A61M60/178;;A61M60/508;;A61M60/232;;A61M60/82;;A61M60/148;;A61M60/824;;A61M60/419;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/878;;A61M60/508;;A61M60/857,A61M60/40;;A61M60/148;;A61M60/50;;A61M60/82;;A61M60/824,,1,0,,,"International Search Report and Written Opinion dated Feb. 28, 2019, for corresponding International Application No. PCT/US2018/062431; International Filing Date: Nov. 26, 2018 consisting of 14 pages.",ACTIVE
198,CH,A,CH 387630 A,140-277-147-771-28X,1965-02-15,1965,CH 7249659 A,1959-04-24,MX 5080958 A,1958-04-24,Verfahren zur Herstellung von Equilin,,SYNTEX SA,ALBERT BOWERS;;CARLOS CASAS CAMPILLO;;JOHN A ZDERIC;;CARL DJERASSI,,https://lens.org/140-277-147-771-28X,Granted Patent,no,0,0,3,3,0,C12P33/00,C12P33/00,"12O,25/07",0,0,,,,EXPIRED
199,US,A1,US 2017/0333610 A1,177-864-145-285-615,2017-11-23,2017,US 201715599115 A,2017-05-18,US 201715599115 A;;US 201514950213 A;;US 201462084742 P,2014-11-26,FIDUCIAL POINT OPTIMIZATION,"A flow rate of blood through an implantable blood pump is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value and second flow rate values. Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS;;FERREIRA ANTONIO LUIZ SILVA,HEARTWARE INC (2017-05-19),https://lens.org/177-864-145-285-615,Patent Application,yes,0,0,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,INACTIVE
200,DE,B,DE 1143199 B,042-005-740-318-863,1963-02-07,1963,DE S0062724 A,1959-04-23,MX 5080958 A,1958-04-24,Verfahren zur Herstellung von Equilin,,SYNTEX SA,BOWERS ALBERT;;CAMPILLO CARLOS CASAS;;ZDERIC JOHN ANTHONY;;DJERASSI CARL,,https://lens.org/042-005-740-318-863,Patent Application,no,0,0,3,3,0,C12P33/00,C12P33/00,,1,0,,,None,DISCONTINUED
201,US,B2,US 10080829 B2,175-235-401-042-90X,2018-09-25,2018,US 201715599115 A,2017-05-18,US 201715599115 A;;US 201514950213 A;;US 201462084742 P,2014-11-26,Fiducial point optimization,"A flow rate of blood through an implantable blood pump is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value and second flow rate values. Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS;;FERREIRA ANTONIO LUIZ SILVA,HEARTWARE INC (2017-05-19),https://lens.org/175-235-401-042-90X,Granted Patent,yes,7,0,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61N1/362;;A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,1,0,,,"International Search Report and Written Opinion for Application No. PCT/US2015/062430 dated Mar. 7, 2016, 11 pages.",INACTIVE
202,US,A1,US 2019/0167874 A1,096-705-753-547-653,2019-06-06,2019,US 201816199684 A,2018-11-26,US 201816199684 A;;US 201762594697 P,2017-12-05,BLOOD PUMP WITH IMPELLER RINSE OPERATION,"A method of operating an implantable blood pump having a first stator, a second stator, and an impeller movably disposed there between. The method includes applying a first voltage waveform at first phase to the first stator to generate a magnetic field to rotate the impeller. A second voltage waveform is applied at a second phase shifted from the first phase to the second stator to rotate the impeller, the second voltage waveform is asymmetric to the first voltage waveform.",HEARTWARE INC,EGLER MARK S;;CASAS FERNANDO;;REYES CARLOS;;LAROSE JEFFREY A,HEARTWARE INC (2019-02-01),https://lens.org/096-705-753-547-653,Patent Application,yes,13,1,7,7,0,A61M60/82;;A61M60/824;;A61M60/857;;A61M60/422;;A61M60/878;;A61M60/178;;A61M60/508;;A61M60/232;;A61M60/82;;A61M60/148;;A61M60/824;;A61M60/419;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/878;;A61M60/508;;A61M60/857,A61M1/10,,0,0,,,,ACTIVE
203,US,A1,US 2019/0001036 A1,127-473-409-345-625,2019-01-03,2019,US 201816124944 A,2018-09-07,US 201816124944 A;;US 201715599115 A;;US 201514950213 A;;US 201462084742 P,2014-11-26,FIDUCIAL POINT OPTIMIZATION,"A flow rate of blood through an implantable blood pump is determined based on a parameter related to the flow, such as a parameter related to thrust on the rotor of the pump. An amount of current supplied to the pump is used to determine each of a first flow rate value and second flow rate values. Each of the first and second flow rate values, in combination with the parameter related to thrust on the rotor of the pump, are used to calculate a flow rate of blood through the pump.",HEARTWARE INC,CASAS FERNANDO;;WOLMAN JUSTIN;;REYES CARLOS;;FERREIRA ANTONIO LUIZ SILVA,HEARTWARE INC (2017-05-19),https://lens.org/127-473-409-345-625,Patent Application,yes,1,1,12,12,0,A61M2205/3334;;A61M60/422;;A61M60/148;;A61M60/546;;A61M60/216;;A61M60/178;;A61M2205/3334;;A61M2205/3365;;A61M2205/50;;A61M2205/702;;A61M60/148;;A61M60/422;;A61M60/178;;A61M60/546;;A61M60/216,A61M60/178;;A61M60/216;;A61M60/422;;A61M60/546,,0,0,,,,ACTIVE
204,WO,A1,WO 2019/112825 A1,199-706-866-725-515,2019-06-13,2019,US 2018/0062431 W,2018-11-26,US 201762594697 P,2017-12-05,BLOOD PUMP WITH IMPELLER RINSE OPERATION,"A method of operating an implantable blood pump having a first stator, a second stator, and an impeller movably disposed there between. The method includes applying a first voltage waveform at first phase to the first stator to generate a magnetic field to rotate the impeller. A second voltage waveform is applied at a second phase shifted from the first phase to the second stator to rotate the impeller, the second voltage waveform is asymmetric to the first voltage waveform.",HEARTWARE INC,EGLER MARK S;;CASAS FERNANDO;;REYES CARLOS;;LAROSE JEFFREY A,,https://lens.org/199-706-866-725-515,Patent Application,yes,7,0,7,7,0,A61M60/82;;A61M60/824;;A61M60/857;;A61M60/422;;A61M60/878;;A61M60/178;;A61M60/508;;A61M60/232;;A61M60/82;;A61M60/148;;A61M60/824;;A61M60/419;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/878;;A61M60/508;;A61M60/857,A61M1/12;;A61M1/10,,0,0,,,,PENDING
205,CH,A,CH 383370 A,046-388-818-601-172,1964-10-31,1964,CH 6404658 A,1958-09-17,MX 4890057 A;;MX 5188758 A,1957-09-23,Verfahren zur Herstellung von Hydroxypregnanverbindungen,,SYNTEX SA,HOWARD JOSEPH DR RINGOLD;;BOWERS ALBERT DR;;CARLOS CASAS DR CAMPILLO,,https://lens.org/046-388-818-601-172,Granted Patent,no,0,0,2,2,0,C12P33/12;;C12P33/00,C12P33/00;;C12P33/12,"12O,25/06",0,0,,,,EXPIRED
206,ES,U,ES 1066823 U,160-223-587-924-974,2008-03-16,2008,ES 200701740 U,2007-08-10,ES 200701740 U,2007-08-10,"Fixed structure of support for photovoltaic modules (Machine-translation by Google Translate, not legally binding)","Fixed structure of support for photovoltaic modules, intended to serve as support and support for a number of photovoltaic panels for the production of electrical energy by capturing the incident solar radiation on them, characterized in that it comprises a frame (4), structurally rigid, supported laterally by means of an anchoring plate (3) on each side, of which each of the anchoring plates is in turn joined to the upper end of a respective upright (2) that at the end opposite is anchored in a base (1) cemented on the floor of the installation site, including in addition said frame a multiplicity of transverse elements (5) constituted by profiles with a configuration in cross section such that they present the formation of a pair of lateral seats (5a) for the support of the edge of the photovoltaic panels (6), one in each seat, whose fixation is made med with a contact adhesive applied directly to said seats (5a) of each transverse element (5). (Machine-translation by Google Translate, not legally binding)",COENAL SOLAR S A,GONZALEZ MINGUEZ FIDEL;;YUSTE DEL OLMO JUAN CARLOS;;CASAS ALMENARA JOSE LUIS,,https://lens.org/160-223-587-924-974,Patent Application,no,0,2,2,2,0,F24S25/70;;F24S25/12;;F24S2020/23;;Y02E10/47,F24J2/54,,0,0,,,,EXPIRED
207,ES,Y,ES 1066823 Y,180-955-470-151-209,2008-06-16,2008,ES 200701740 U,2007-08-10,ES 200701740 U,2007-08-10,ESTRUCTURA FIJA DE SOPORTE PARA MODULOS FOTOVOLTAICOS,,COENAL SOLAR S A,GONZALEZ MINGUEZ FIDEL;;YUSTE DEL OLMO JUAN CARLOS;;CASAS ALMENARA JOSE LUIS,,https://lens.org/180-955-470-151-209,Limited Patent,no,0,0,2,2,0,F24S25/70;;F24S25/12;;F24S2020/23;;Y02E10/47,F24J2/54,,0,0,,,,EXPIRED
208,MX,B,MX 174072 B,180-211-313-983-499,1994-04-19,1994,MX 2675689 A,1989-11-10,MX 2675689 A,1989-11-10,PROCEDIMIENTO PARA OBTENER UN BIOCATALIZADOR CON CELULAS CON UNA PERMEABILIDAD CONTROLADA PARA LA HIDROLISIS DE LA LACTOSA,"La presente invención se refiere a procedimiento para obtener un biocatalizador con celulas con una permeabilidad controlada para la hidrólisis de la lactosa, caracterizado porque comprende los pesos de: 1) preparar cultivo para crecimiento de celulas de K. fragilis ó lactis en un medio de suero lácteo y nutrientes a base de sales de sulfato a temperatura comprendida entre 26 grados a 30 grados C y a un pH ligeramente ácido en un rango entre 4.5 y 5.5 unidades; 2) separación de las celulas crecidas; 3) permeabilización controlada de las celulas mediante mezclado de las mismas con sales de Mg y Mn, en concentraciones de 0.05 a 0.2 mM de Mn Cl2 y 0.005 a 0.02 M de Mg cl2, a temperaturas bajas en un rango entre 45 grados a 60 grados C. ó un secado sin sales por aspersión a temperaturas comprendidas entre 110 y 140 grados C; las celulas con permeabilidad controlada pueden reutilizarse en forma libre ó inmovilizado al permitir la entrada de sustratos y salida de productos sin que la enzima se libere de las celulas hacia la mezcla de reacción.",UNIV MEXICO,ROSALES EDMUNDO CASTILLO;;TERRES LIDIA TERESITA CASAS DE;;MALACARA CARLOS FELIPE PENA,,https://lens.org/180-211-313-983-499,Granted Patent,no,0,0,1,1,0,,C12N9/14;;C12N9/38;;C12N11/04;;C12P19/04;;C12Q1/34,,0,0,,,,EXPIRED
209,ES,B1,ES 2403549 B1,060-221-267-914-027,2014-05-29,2014,ES 201231049 A,2012-07-04,EP 11384003 A,2011-07-28,Co-cristales de agomelatina con formadores de co-cristales,,ESTEVE LABOR DR,PLATA SALAMAN CARLOS RAMÓN;;TESSON NICOLÁS;;CARDENAS ROMANA LYDIA;;CASAS CARTAGENA MARÇAL,"ESTEVE PHARMACEUTICALS, S.A. (2018-10-16)",https://lens.org/060-221-267-914-027,Granted Patent,no,0,0,4,4,0,A61K31/165;;C07C233/18;;C07C57/145;;C07C57/145;;C07C59/265;;C07C59/265;;C07C65/05;;C07C231/22;;C07C233/18;;C07C275/02;;C07C275/02,C07C233/18;;A61K31/165;;C07C57/145;;C07C59/265;;C07C275/02,,0,0,,,,INACTIVE
210,ES,A2,ES 2403549 A2,024-303-160-310-665,2013-05-20,2013,ES 201231049 A,2012-07-04,EP 11384003 A,2011-07-28,Co-crystals of agomelatine with co-crystal-formers,"The present invention relates to co-crystals of agomelatine and co-crystal-formers, processes for preparation of the same and their use as medicament or in pharmaceutical formulations, more particularly for the treatment of depression.",ESTEVE LABOR DR,PLATA SALAMAN CARLOS RAMON;;TESSON NICOLAS;;CARDENAS ROMANA LYDIA;;CASAS CARTAGENA MARCAL,"ESTEVE PHARMACEUTICALS, S.A. (2018-10-16)",https://lens.org/024-303-160-310-665,Patent Application,no,0,0,4,4,0,A61K31/165;;C07C233/18;;C07C57/145;;C07C57/145;;C07C59/265;;C07C59/265;;C07C65/05;;C07C231/22;;C07C233/18;;C07C275/02;;C07C275/02,A61K31/165,,0,0,,,,INACTIVE
211,ES,B1,ES 2457721 B1,054-800-454-184-786,2015-02-03,2015,ES 201231646 A,2012-10-25,ES 201231646 A,2012-10-25,Procedimiento de fabricación de ventanas y ventana obtenida por medio de adición de tableros de madera adheridos a una base de vidrio con cámara de lunas desiguales,,ASENSIO-WANDOSELL GARCIA CARLOS;;DE LAS CASAS RODRIGUEZ ICIAR;;ORTIZ MARTIN VEGA,ASENSIO-WANDOSELL GARCIA CARLOS;;DE LAS CASAS RODRIGUEZ ICIAR;;ORTIZ MARTIN VEGA,,https://lens.org/054-800-454-184-786,Granted Patent,no,0,0,2,2,0,E06B3/301;;E06B3/54;;E06B3/66,E06B3/30;;E06B3/54;;E06B3/66,,0,0,,,,INACTIVE
212,ES,R1,ES 2403549 R1,097-334-545-536-382,2013-07-16,2013,ES 201231049 A,2012-07-04,EP 11384003 A,2011-07-28,Co-cristales de agomelatina con formadores de co-cristales,"La presente invención se refiere a co-cristales de agomelatina y formadores de co-cristales, a procedimientos para la preparación de los mismos y a su uso como medicamento o en formulaciones farmacéuticas, más particularmente para el tratamiento de la depresión.",ESTEVE LABOR DR,PLATA SALAMAN CARLOS RAMON;;TESSON NICOLAS;;CARDENAS ROMANA LYDIA;;CASAS CARTAGENA MARCAL,"ESTEVE PHARMACEUTICALS, S.A. (2018-10-16)",https://lens.org/097-334-545-536-382,Unknown,no,4,0,4,4,0,A61K31/165;;C07C233/18;;C07C57/145;;C07C57/145;;C07C59/265;;C07C59/265;;C07C65/05;;C07C231/22;;C07C233/18;;C07C275/02;;C07C275/02,C07C233/18;;A61K31/165;;C07C57/145;;C07C59/265;;C07C275/02,,2,0,,,"ZHENG, S. et al ¿ Structures of Polymorphic Agomelatine and Its Cocrystals with Acetic Acid and Ethylene Glycol¿. Crystal Growth and Design, 2011, Vol. 11, páginas 466-471. Ver Resumen y Experimental.;;SEKHON, B. S. ¿ Pharmaceutical co-crystals - a review¿. ARS Pharmaceutica, 2009, Vol. 50, páginas 99-117. Ver Resumen; página 100, párrafo 5; página 102, párrafos 3 y 4; página 103, párrafo 2; página 106, párrafo 2.",INACTIVE
213,ES,A1,ES 2457721 A1,139-778-988-571-434,2014-04-28,2014,ES 201231646 A,2012-10-25,ES 201231646 A,2012-10-25,"Window and window fabrication procedure obtained by adding wooden boards attached to a glass base with unequal moons chamber (Machine-translation by Google Translate, not legally binding)","Window and window manufacturing process obtained by means of adding wooden boards adhered to a glass base with unequal glass chamber, whose glass base confers dimensional stability and where sheet and frame are constituted by sheets of wood adhered to a base formed by two safety glasses, composed of sheet and frame and characterized because the sheet is composed of the glass base of unequal moons constituted by an outer sheet of safety glass (1), larger than another inner glass sheet of security (2), existing between them an air chamber (4) and a pour-water (3) in the upper part to which three pieces of wood are adhered together by two separate boards, then pressed and whose three boards they are composed of an outer board (7) that closes an intermediate board (6) that abuts the rubber gasket (8) that conceals a conventional mechanism of closure (9). On the inner board (5) that abuts the outer glass (1). (Machine-translation by Google Translate, not legally binding)",ASENSIO-WANDOSELL GARCIA CARLOS;;DE LAS CASAS RODRIGUEZ ICIAR;;ORTIZ MARTIN VEGA,ASENSIO-WANDOSELL GARCIA CARLOS;;DE LAS CASAS RODRIGUEZ ICIAR;;ORTIZ MARTIN VEGA,,https://lens.org/139-778-988-571-434,Patent Application,no,4,0,2,2,0,E06B3/301;;E06B3/54;;E06B3/66,E06B3/30;;E06B3/54;;E06B3/66,,0,0,,,,INACTIVE
214,EP,A1,EP 2551257 A1,149-713-951-631-232,2013-01-30,2013,EP 11384003 A,2011-07-28,EP 11384003 A,2011-07-28,Co-crystals of agomelatine with co-crystal-formers,"The present invention relates to co-crystals of agomelatine and co-crystal-formers, processes for preparation of the same and their use as medicament or in pharmaceutical formulations, more particularly for the treatment of depression.",ESTEVE LABOR DR,PLATA SALAMAN CARLOS RAMON;;TESSON NICOLAS;;CARDENAS ROMANA LYDIA;;CASAS CARTAGENA MARCAL,,https://lens.org/149-713-951-631-232,Patent Application,yes,3,6,4,4,0,A61K31/165;;C07C233/18;;C07C57/145;;C07C57/145;;C07C59/265;;C07C59/265;;C07C65/05;;C07C231/22;;C07C233/18;;C07C275/02;;C07C275/02,C07C57/145;;C07C59/265;;C07C65/05;;C07C233/18;;C07C275/02,,6,4,030-583-109-534-678;;054-666-536-730-272;;012-649-395-635-213;;006-574-274-392-162,10.1039/b313552g;;10.1039/b315687g;;10.1021/cg0680172;;10.1107/s0021889807067908,"DATABASE CA [online] CHEMICAL ABSTRACTS SERVICE, COLUMBUS, OHIO, US; ZHENG, SAI-LI ET AL: ""Structures of Polymorphic Agomelatine and Its Cocrystals with Acetic Acid and Ethylene Glycol"", XP002668559, retrieved from STN Database accession no. 2011:22291;;CRYST. GROWTH DES., vol. 11, no. 2, 2011, pages 466 - 471;;DESIRAJU, CRYST. ENG. COMM., vol. 5, no. 82, 2003, pages 466 - 467;;DUNITZ, CRYSTENGCOMM, vol. 5, no. 91, 2003, pages 506;;ZAWOROTKO, CRYSTAL GROWTH & DESIGN, vol. 7, no. 1, 2007, pages 4 - 9;;C.F. MACRAE, I.J. BRUNO, J.A. CHISHOLM, P.R. EDGINGTON, P. MCCABE, E. PIDCOCK, L. RODRIGUEZ-MONGE, R. TAYLOR, J. VAN DE STREEK, P., J. APPL. CRYST., vol. 41, 2008, pages 466 - 470",DISCONTINUED
215,WO,A1,WO 2024/022659 A1,183-607-095-992-951,2024-02-01,2024,EP 2023065203 W,2023-06-07,EP 22382712 A,2022-07-26,SYSTEM AND METHOD FOR POWER SUPPLY OF A SOLAR TRACKER POSITION CONTROL SYSTEM,"System and method for power supplying a solar tracker position control system. The power supply system (10) comprises: a position control system (5), with a power input (8) connected in parallel with direct voltage lines (3) of a set of solar panels (4) and a voltage conversion unit (9) that obtains a direct supply voltage (V + ); an alternating voltage generation unit (1) to generate an alternating voltage V AC ) of configurable amplitude; a coupling unit (2) to couple the alternating voltage (V AC ) to the direct voltage lines (3); a measurement unit (6) to obtain voltage measurements (V string ) on direct voltage lines (3); and a power supply control unit (7) configured to couple or decouple the alternating voltage (V AC ) to the direct voltage lines (3) and control the amplitude (V ACp ) of the alternating voltage (V AC ) depending on the measurements (15) of the measurement unit (6).",GONVARRI MS R&D SL,PÉREZ GARCÍA MIGUEL ÁNGEL;;ÁLVAREZ ANTÓN JUAN CARLOS;;GRANDA CANDÁS JUAN CARLOS;;CARLEOS ARTIME CARLOS ENRIQUE;;PÉREZ CASTAÑO LUIS;;FERNÁNDEZ CASAS ROBERTO,,https://lens.org/183-607-095-992-951,Patent Application,yes,4,0,2,2,0,H02J3/381;;H02J2300/24,H02J3/38,,0,0,,,,PENDING
216,EP,A1,EP 4312334 A1,164-352-894-062-274,2024-01-31,2024,EP 22382712 A,2022-07-26,EP 22382712 A,2022-07-26,SYSTEM AND METHOD FOR POWER SUPPLY OF A SOLAR TRACKER POSITION CONTROL SYSTEM,"System and method for power supplying a solar tracker position control system. The power supply system (10) comprises: 
a position control system (5), with a power input (8) connected in parallel with direct voltage lines (3) of a set of solar panels (4) and a voltage conversion unit (9) that obtains a direct supply voltage ( V + ); 
an alternating voltage generation unit (1) to generate an alternating voltage  V AC ) of configurable amplitude; 
a coupling unit (2) to couple the alternating voltage ( V AC ) to the direct voltage lines (3); 
a measurement unit (6) to obtain voltage measurements ( V string ) on direct voltage lines (3); and 
a power supply control unit (7) configured to couple or decouple the alternating voltage  (V AC )  to the direct voltage lines (3) and control the amplitude ( V ACp ) of the alternating voltage  (V AC )  depending on the measurements (15) of the measurement unit (6).
",GONVARRI MS R&D SL,PÉREZ GARCÍA MIGUEL ÁNGEL;;ÁLVAREZ ANTÓN JUAN CARLOS;;GRANDA CANDÁS JUAN CARLOS;;CARLEOS ARTIME CARLOS ENRIQUE;;PÉREZ CASTAÑO LUIS;;FERNÁNDEZ CASAS ROBERTO,,https://lens.org/164-352-894-062-274,Patent Application,yes,4,0,2,2,0,H02J3/381;;H02J2300/24,H02J3/38,,0,0,,,,PENDING
217,ES,B1,ES 2325824 B1,012-298-355-346-167,2010-07-08,2010,ES 200703252 A,2007-12-07,ES 200703252 A,2007-12-07,UTILIZACION DE VALPROATO PARA EL TRATAMIENTO DEL MIEDO Y LA FOBIA EN SUJETOS CON LA ENFERMEDAD DE ALZHEIMER.,,UNIV BARCELONA AUTONOMA,SAURA ANTOLIN CARLOS ALBERTO;;CASAS LOUZAO CATALINA;;GIMENEZ LLORT LYDIA;;ESPANA AGUSTI JUDIT,,https://lens.org/012-298-355-346-167,Granted Patent,no,0,0,4,4,0,A61K31/19;;A61K31/19;;A61P25/18,A61K31/19;;A61P25/18,,0,0,,,,ACTIVE
218,WO,A2,WO 2009/071725 A2,168-311-597-171-284,2009-06-11,2009,ES 2008000765 W,2008-12-05,ES 200703252 A,2007-12-07,USE OF VALPROATE FOR THE TREATMENT OF FEAR AND PHOBIA IN SUBJECTS WITH ALZHEIMER'S DISEASE,"The invention relates to the use of valproate for the production of a drug for the treatment of fear and phobia in a subject with Alzheimer's disease. The invention also relates to a method for the treatment of fear and phobia in a subject with Alzheimer's disease, whereby the subject is administered an effective quantity of valproate.",UNIV BARCELONA AUTONOMA;;SAURA ANTOLIN CARLOS ALBERTO;;CASAS LOUZAO CATALINA;;GIMENEZ LLORT LYDIA;;ESPANA AGUSTI JUDIT,SAURA ANTOLIN CARLOS ALBERTO;;CASAS LOUZAO CATALINA;;GIMENEZ LLORT LYDIA;;ESPANA AGUSTI JUDIT,,https://lens.org/168-311-597-171-284,Patent Application,yes,0,0,4,4,0,A61K31/19;;A61K31/19;;A61P25/18,A61K31/19;;A61P25/18,,0,0,,,,PENDING
219,ES,A1,ES 2325824 A1,019-222-528-712-801,2009-09-18,2009,ES 200703252 A,2007-12-07,ES 200703252 A,2007-12-07,USE OF VALPROATE FOR THE TREATMENT OF FEAR AND PHOBIA IN SUBJECTS WITH ALZHEIMER'S DISEASE,"The invention relates to the use of valproate for the production of a drug for the treatment of fear and phobia in a subject with Alzheimer's disease. The invention also relates to a method for the treatment of fear and phobia in a subject with Alzheimer's disease, whereby the subject is administered an effective quantity of valproate.",UNIV BARCELONA AUTONOMA,SAURA ANTOLIN CARLOS ALBERTO;;CASAS LOUZAO CATALINA;;GIMENEZ LLORT LYDIA;;ESPANA AGUSTI JUDIT,,https://lens.org/019-222-528-712-801,Patent Application,no,0,0,4,4,0,A61K31/19;;A61K31/19;;A61P25/18,A61K31/19;;A61P25/18,,3,3,037-647-615-322-517;;040-169-808-774-485;;074-958-256-264-449,10.1097/01.yic.0000064261.66765.9f;;12702897;;10.1097/00004850-200305000-00008;;10.1016/j.comppsych.2004.11.005;;16122537;;2111204;;10.1177/070674379003500309,"KINRYS, G. et al.: ""Valproic acid for the treatment of social anxiety disorder"" International Clinical Psychopharmacology, 2003, vol. 18, páginas 169-172, todo el documento.;;TOWNSEND, M.H. et al.: ""Comorbid anxiety disorders an divalproex sodium use among partial hospital patients with psychotic disorders"". Comprehensive Psychiatry, 2005, vol. 46, páginas 368-370, todo el documento.;;PRIMEAU, F. et al.: ""Valproic acid and panic disorder"". Can. J. Psychiatry, 1990, vol. 35, páginas 248-250, todo el documento.",ACTIVE
220,CO,A1,CO 2017008043 A1,158-325-187-033-932,2018-02-20,2018,CO 2017008043 A,2017-08-09,CO 2017008043 A,2017-08-09,Dispositivo inspector visual de 360° de alta velocidad para control de calidad de contenedores y método para detección de defectos por medio de dicho dispositivo,"La presente invención se refiere a una recámara para llevar a cabo un procedimiento de control de calidad de recipientes metálicos mediante el análisis de imágenes especializado en cuantificar y detectar defectos automáticamente basado en el reconocimiento de los patrones lineales de un sistema de iluminación. Así, la tecnología de la presente invención logra identificar algún tipo de daño en las latas en condiciones adversas de proceso como lo son los ambientes de producción de alta humedad, donde dicha condición genera sobre la lata un condensado que dificulta a los sistemas existentes la fácil identificación de daños en las latas por golpes sufridos en el proceso de fabricación.",INTEGRACION TECNOLOGICA IND INTECOL S A S,LOPEZ LUIS FERNANDO;;EMBUS CASAS CARLOS MARIO;;MONTES VALENCIA YEISON;;AHUMADA JHON ALEXANDER,,https://lens.org/158-325-187-033-932,Patent Application,no,0,0,1,1,0,,B08B9/46;;G03F1/84;;G11B7/24097,,0,0,,,,PENDING
221,ES,U,ES 1068202 U,107-207-196-505-922,2008-09-01,2008,ES 200801362 U,2008-06-20,ES 200801362 U,2008-06-20,"Semaforo modular led (Machine-translation by Google Translate, not legally binding)","Modular led traffic light that is specially applicable to make sets for the control of traffic of vehicles or people that is constituted in any material and essentially characterized because each module is determined by a cylindrical housing to which a cylindrical front cover is attached with the softened front lip that rotates on a hidden and removable hinge and has a closure through multiple elastic tabs that is secured by one or two special head screws. The cover supports the led optics by means of a rubber gasket that supports it and allows its disassembly assembly. In the closed position, the front cover presses another elastic seal that ensures tightness. its design allows the optional incorporation of a visor to eliminate the reflection of ambient light and direct the light signal. the invention is applied to modules with different sizes of led optics and allows making different traffic light sets with different sizes and signals. (Machine-translation by Google Translate, not legally binding)",SANCHO PONS RAMON,SANCHO PONS RAMON;;PINYOL CORT ANTONIO;;BARBERA CASAS JOAN MANEL;;SANCHO PONS CARLOS,,https://lens.org/107-207-196-505-922,Patent Application,no,0,0,2,2,0,,G08G1/095,,0,0,,,,EXPIRED
222,ES,Y,ES 1068202 Y,012-797-008-087-267,2008-12-01,2008,ES 200801362 U,2008-06-20,ES 200801362 U,2008-06-20,SEMAFORO MODULAR LED,,SANCHO PONS RAMON,SANCHO PONS RAMON;;PINYOL CORT ANTONIO;;BARBERA CASAS JOAN MANEL;;SANCHO PONS CARLOS,,https://lens.org/012-797-008-087-267,Limited Patent,no,0,0,2,2,0,,G08G1/095,,0,0,,,,EXPIRED
223,WO,A3,WO 2009/071725 A3,048-693-913-711-082,2009-07-23,2009,ES 2008000765 W,2008-12-05,ES 200703252 A,2007-12-07,USE OF VALPROATE FOR THE TREATMENT OF FEAR AND PHOBIA IN SUBJECTS WITH ALZHEIMER'S DISEASE,"The invention relates to the use of valproate for the production of a drug for the treatment of fear and phobia in a subject with Alzheimer's disease. The invention also relates to a method for the treatment of fear and phobia in a subject with Alzheimer's disease, whereby the subject is administered an effective quantity of valproate.",UNIV BARCELONA AUTONOMA;;SAURA ANTOLIN CARLOS ALBERTO;;CASAS LOUZAO CATALINA;;GIMENEZ LLORT LYDIA;;ESPANA AGUSTI JUDIT,SAURA ANTOLIN CARLOS ALBERTO;;CASAS LOUZAO CATALINA;;GIMENEZ LLORT LYDIA;;ESPANA AGUSTI JUDIT,,https://lens.org/048-693-913-711-082,Search Report,yes,0,0,4,4,0,A61K31/19;;A61K31/19;;A61P25/18,A61K31/19;;A61P25/18,,4,4,037-647-615-322-517;;040-169-808-774-485;;074-958-256-264-449;;045-585-721-044-820,10.1097/01.yic.0000064261.66765.9f;;12702897;;10.1097/00004850-200305000-00008;;10.1016/j.comppsych.2004.11.005;;16122537;;2111204;;10.1177/070674379003500309;;10.1097/00004714-200002001-00001;;10646685,"KINRYS, G. ET AL.: ""Valproic acid for the treatment of social anxiety disorder"", INTERNATIONAL CLINICAL PSYCHOPHARMACOLOGY, vol. 18, 2003, pages 169 - 172;;TOWNSEND, M.H. ET AL.: ""Comorbid anxiety disorders and divalproex sodium use among partial hospital patients with psychotic disorders"", COMPREHENSIVE PSYCHIATRY, vol. 46, 2005, pages 368 - 370;;PRIMEAU, F. ET AL.: ""Valproic acid and panic disorder"", CAN. J. PSYCHIATRY, vol. 35, 1990, pages 248 - 250;;DAVIS, L.L. ET AL.: ""Comprehensive review of the psychiatric uses of valproate"", JOURNAL OF CLINICAL PSYCHOPHARMACOLOGY, vol. 20, no. SUP. 1, 2000, pages 1S - 17S",PENDING
224,BR,A2,BR 112014013325 A2,081-316-627-481-696,2017-06-13,2017,BR 112014013325 A,2011-12-27,ES 2011070908 W,2011-12-27,"composição polimérica para a estabilização do solo, o controle da poeira e da erosão de taludes","resumo patente de invenção: ""composição polimérica para a estabilização do solo, o controle da poeira e da erosão de taludes"". a presente invenção refere-se a composição polimérica em base aquosa, a qual compreende um terpolímero formado por pelo menos três tipos de monômeros e um sistema estabilizante que compreende tensoativos aniônicos, não iônicos e poliméricos, pelo menos um coloide protetor, pelo menos um agente coalescente que favorece a formação de película, e pelo menos um agente reológico, para a estabilização do solo, o controle da poeira e da erosão de taludes. essas composições demonstraram uma boa estabilidade da dispersão polimérica que é transmitida ao elemento aplicado, uma alta capacidade aglutinante, gerando uma melhor compactação do elemento ao qual são aplicadas; uma resistência muito boa aos agentes atmosféricos da dispersão polimérica, em que o elemento ao qual são aplicadas mantém as propriedades que a dispersão polimérica confere ao mesmo.",ACCIONA INFRAESTRUCTURAS SA;;FORESA IND QUÍMICAS DEL NOROESTE S A U,ANDREA CASAS OCAMPO;;CARLOS RIAL PÉREZ;;FAIVER BOTELLO ROJAS;;MIGUEL GARCÍA HERMIDAS;;STEFANO PRIMI,,https://lens.org/081-316-627-481-696,Patent Application,no,0,0,6,6,0,C09K3/22;;C09K17/22;;E02B3/12,C09K3/22;;C09K17/22,,0,0,,,,DISCONTINUED
225,WO,A1,WO 2021/089606 A1,160-030-897-155-073,2021-05-14,2021,EP 2020080933 W,2020-11-04,EP 19382960 A,2019-11-04,METHOD FOR ISOLATING NUCLEIC ACIDS,"The invention relates to an in vitro method for isolating nucleic acids associated to or contained inside extracellular vesicles (EVs) from a sample based on the formation of a DMB-EVs precipitate and the isolation of the nucleic acids present in the precipitate. The invention also relates to the use of the method of the invention for diagnosing or for determining the susceptibility of a subject to a disease, for determining the prognosis or for monitoring the progression of a disease, for monitoring the effect of a therapy, for identifying compounds suitable for the treatment of a disease, or for designing a personalized therapy or selecting a patient susceptible to being treated with a therapy for the prevention and/or treatment of a disease. In addition, the invention also relates to a kit comprising dimethylmethylene blue (DMB) and a reagent capable of isolating nucleic acids from EVs, and to its use.",NASASBIOTECH S L,DE LA FUENTE GONZÁLEZ ALEXANDRE;;ABAL POSADA MIGUEL;;MUINELO ROMAY LAURA;;CASAS AROZAMENA CARLOS,,https://lens.org/160-030-897-155-073,Patent Application,yes,2,0,4,4,0,C12Q1/6806;;G01N33/57488;;G01N2800/52;;G01N2800/56;;C12Q1/6806;;C12Q1/686,G01N33/50;;C12Q1/6806,,8,6,046-279-366-119-381;;023-305-269-356-977;;033-000-802-142-885;;112-733-440-493-769;;117-191-034-396-101;;007-968-009-957-714,pmc4916259;;27330048;;10.3402/jev.v5.31655;;10.1016/j.pharmthera.2018.08.002;;30081050;;10.1002/1097-0142(19810101)47:1<207::aid-cncr2820470134>3.0.co;2-6;;7459811;;27924586;;10.1007/978-1-4939-6685-1_2;;pmc5550740;;23874201;;pmc3715412;;10.1371/journal.ppat.1003484;;pmc5796851;;28770472;;10.1007/s11010-017-3130-x,"SBI SYSTEM BIOSCIENCES: ""ExoQuick-TC(TM) Exosome Precipitation Solution"", 14 November 2016 (2016-11-14), XP055691448, Retrieved from the Internet <URL:https://www.bioscience.co.uk/userfiles/pdf/ExoQuick-TC%20Manual.pdf> [retrieved on 20200504];;MITSUHASHI M ET AL: ""LEVELS OF SERUM GLYCOSAMINOGLYCANS IN RENAL FAILURE"", RESEARCH COMMUNICATIONS IN MOLECULAR PATHOLOGY AND PHARMACOLOGY, PJD PUBLICATIONS LTD, US, vol. 99, no. 2, 1 February 1998 (1998-02-01), pages 225 - 232, XP001115035, ISSN: 1078-0297;;ZORAIDA ANDREU ET AL: ""Comparative analysis of EV isolation procedures for miRNAs detection in serum samples"", JOURNAL OF EXTRACELLULAR VESICLES, vol. 5, no. 0, 20 June 2016 (2016-06-20), XP055290559, DOI: 10.3402/jev.v5.31655;;FATEMEH MOMEN-HERAVI ET AL., PHARMACOLOGY & THERAPEUTICS, vol. 192, December 2018 (2018-12-01), pages 170 - 187;;MILLER ET AL., CANCER, vol. 47, no. 1, 1981, pages 207 - 14;;MAJEM BLI FSUN JWONG DT: ""RNA Sequencing Analysis of Salivary Extracellular RNA"", METHODS MOL BIOL, vol. 1537, 2017, pages 17 - 36;;CHUGH PE ET AL., PLOS PATHOG, vol. 9, no. 7, 2013, pages e1003484;;LI Z. ET AL., MOLECULAR AND CELLULAR BIOCHEMISTRY, vol. 439, no. 1-2, pages 1 - 9",PENDING
226,US,A1,US 2022/0411849 A1,133-618-500-823-036,2022-12-29,2022,US 202017773895 A,2020-11-04,EP 19382960 A;;EP 2020080933 W,2019-11-04,METHOD FOR ISOLATING NUCLEIC ACIDS,"The invention relates to an in vitro method for isolating nucleic acids associated to or contained inside extracellular vesicles (EVs) from a sample based on the formation of a DMB-EVs precipitate and the isolation of the nucleic acids present in the precipitate. The invention also relates to the use of the method of the invention for diagnosing or for determining the susceptibility of a subject to a disease, for determining the prognosis or for monitoring the progression of a disease, for monitoring the effect of a therapy, for identifying compounds suitable for the treatment of a disease, or for designing a personalized therapy or selecting a patient susceptible to being treated with a therapy for the prevention and/or treatment of a disease. In addition, the invention also relates to a kit comprising dimethylmethylene blue (DMB) and a reagent capable of isolating nucleic acids from EVs, and to its use.",NASASBIOTECH S L,DE LA FUENTE GONZÁLEZ ALEXANDRE;;ABAL POSADA MIGUEL;;MUINELO ROMAY LAURA;;CASAS AROZAMENA CARLOS,NASASBIOTECH S.L (2021-02-19),https://lens.org/133-618-500-823-036,Patent Application,yes,0,0,4,4,0,C12Q1/6806;;G01N33/57488;;G01N2800/52;;G01N2800/56;;C12Q1/6806;;C12Q1/686,C12Q1/6806,,0,0,,,,PENDING
227,EP,A1,EP 4055186 A1,149-193-654-755-03X,2022-09-14,2022,EP 20799710 A,2020-11-04,EP 19382960 A;;EP 2020080933 W,2019-11-04,METHOD FOR ISOLATING NUCLEIC ACIDS,,NASASBIOTECH S L,DE LA FUENTE GONZÁLEZ ALEXANDRE;;ABAL POSADA MIGUEL;;MUINELO ROMAY LAURA;;CASAS AROZAMENA CARLOS,,https://lens.org/149-193-654-755-03X,Patent Application,yes,0,0,4,4,0,C12Q1/6806;;G01N33/57488;;G01N2800/52;;G01N2800/56;;C12Q1/6806;;C12Q1/686,C12Q1/6806;;G01N33/50,,0,0,,,,PENDING
228,CN,A,CN 113271997 A,000-927-534-155-829,2021-08-17,2021,CN 201980086961 A,2019-07-17,IB 2019056103 W,2019-07-17,NASAL OXYGEN CANNULA WITH DEVICE FOR MEASURING USE TIME,"The present invention relates to a nasal oxygen cannula, which has a simple and economic design that reduces drug wastage and allows the effective use time to be measured in order to effectively monitor oxygen therapy treatment in patients with spontaneous breathing. Structurally, the cannula is formed by a mechanical system that is only activated when it comes into physical contact with the patient's columella, and an electronic component that allows the real use time of the device to be measured by means of an electric actuator that triggers an electric pulse the moment the cannula is in place on the user.",FUND ABOOD SHAIO EN REESTRUCTURACION,LATORRE ROJAS CARLOS JAVIER;;ARANGO CORTES MARIA LUCIA;;CORTES MUNOZ FABIAN;;SANCHEZ CASAS JENNY CAROLINA,,https://lens.org/000-927-534-155-829,Patent Application,no,8,0,3,3,0,A61M16/0672;;A61M2202/0208;;A61M2205/13;;A61M2205/52;;A61M16/0677;;A61M16/024;;A61M2205/3592;;A61M16/201;;A61M16/0003;;A61M16/0666;;A61M2205/3553;;A61M2205/50,A61M16/00;;A61M16/06,,0,0,,,,PENDING
229,US,A1,US 2022/0096771 A1,149-312-532-328-952,2022-03-31,2022,US 201917416641 A,2019-07-17,IB 2019056103 W,2019-07-17,NASAL OXYGEN CANNULA WITH DEVICE FOR MEASURING USE TIME,"The present invention relates to a nasal oxygen cannula, which has a simple and economic design that reduces drug wastage and allows the effective use time to be measured in order to effectively monitor oxygen therapy treatment in patients with spontaneous breathing. Structurally, the cannula is formed by a mechanical system that is only activated when it comes into physical contact with the patientís columella, and an electronic component that allows the real use time of the device to be measured by means of an electric actuator that triggers an electric pulse the moment the cannula is in place on the user.",FUND ABOOD SHAIO EN REESTRUCTURACION,LATORRE ROJAS CARLOS JAVIER;;ARANGO CORTES MARIA LUCIA;;CORTES MUNOZ FABIAN;;SANCHEZ CASAS JENNY CAROLINA,,https://lens.org/149-312-532-328-952,Patent Application,yes,0,0,3,3,0,A61M16/0672;;A61M2202/0208;;A61M2205/13;;A61M2205/52;;A61M16/0677;;A61M16/024;;A61M2205/3592;;A61M16/201;;A61M16/0003;;A61M16/0666;;A61M2205/3553;;A61M2205/50,A61M16/06;;A61M16/00,,0,0,,,,PENDING
230,WO,A1,WO 2021/009546 A1,028-430-044-896-31X,2021-01-21,2021,IB 2019056103 W,2019-07-17,IB 2019056103 W,2019-07-17,NASAL OXYGEN CANNULA WITH DEVICE FOR MEASURING USE TIME,"The present invention relates to a nasal oxygen cannula, which has a simple and economic design that reduces drug wastage and allows the effective use time to be measured in order to effectively monitor oxygen therapy treatment in patients with spontaneous breathing. Structurally, the cannula is formed by a mechanical system that is only activated when it comes into physical contact with the patient's columella, and an electronic component that allows the real use time of the device to be measured by means of an electric actuator that triggers an electric pulse the moment the cannula is in place on the user.",FUND ABOOD SHAIO EN REESTRUCTURACION,LATORRE ROJAS CARLOS JAVIER;;ARANGO CORTÉS MARÍA LUCIA;;SÁNCHEZ CASAS JENNY CAROLINA;;CORTÉS MUÑOZ FABIAN,,https://lens.org/028-430-044-896-31X,Patent Application,yes,4,0,3,3,0,A61M16/0672;;A61M2202/0208;;A61M2205/13;;A61M2205/52;;A61M16/0677;;A61M16/024;;A61M2205/3592;;A61M16/201;;A61M16/0003;;A61M16/0666;;A61M2205/3553;;A61M2205/50,A61M16/06;;A61M16/00,,0,0,,,,PENDING
231,CN,A,CN 111989127 A,128-811-347-477-731,2020-11-24,2020,CN 201980024810 A,2019-03-20,US 201862653958 P;;US 2019/0023181 W,2018-04-06,MULTI-INPUT SPEED RESPONSE ALGORITHM FOR BLOOD PUMP,"A method of responding to an adverse event associated with an implantable blood pump includes the steps: detecting the adverse event, reducing a pump speed of the blood pump relative to a set pump speed in response to the detected adverse event, and determining whether at least one of a group consisting of the adverse event and a second adverse event is present following the reducing of the pump speed of the blood pump. If the at least one of the group consisting of the adverse event and a second adverse event is not present, the method includes increasing the pump speed to the set pump speedand if the at least one of the group consisting of the adverse event and a second adverse event is present while increasing the pump speed to the set pump speed, the method includes reducing the pumpspeed to a maximum safe operating speed.",HEARTWARE INC,REYES CARLOS;;CHORPENNING KATHERINE;;FERREIRA ANTONIO LUIZ SILVA;;VASUDEVAN JALAJA NEETHU LEKSHMI;;WOLMAN JUSTIN;;CASAS FERNANDO,,https://lens.org/128-811-347-477-731,Patent Application,no,3,0,5,5,0,A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/50;;A61M60/205,A61M1/10;;A61M1/12,,0,0,,,,PENDING
232,EP,A1,EP 3773783 A1,175-506-946-700-644,2021-02-17,2021,EP 19715647 A,2019-03-20,US 201862653958 P;;US 2019/0023181 W,2018-04-06,MULTI-INPUT SPEED RESPONSE ALGORITHM FOR A BLOOD PUMP,,HEARTWARE INC,REYES CARLOS;;CHORPENNING KATHERINE;;FERREIRA ANTONIO LUIZ SILVA;;VASUDEVAN JALAJA NEETHU LEKSHMI;;WOLMAN JUSTIN;;CASAS FERNANDO,,https://lens.org/175-506-946-700-644,Patent Application,yes,0,0,5,5,0,A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/50;;A61M60/205,A61M1/10;;A61M1/12,,0,0,,,,PENDING
233,US,A1,US 2019/0307938 A1,186-589-290-659-559,2019-10-10,2019,US 201916359501 A,2019-03-20,US 201916359501 A;;US 201862653958 P,2018-04-06,MULTI-INPUT SPEED RESPONSE ALGORITHM FOR A BLOOD PUMP,"A method of responding to an adverse event associated with an implantable blood pump including detecting the adverse event, reducing a pump speed of the blood pump relative to a set pump speed in response to the detected adverse event, and determining whether at least one of a group consisting of the adverse event and a second adverse event is present following the reducing of the pump speed of the blood pump. If the at least one of the group consisting of the adverse event and a second adverse event is not present, the method includes increasing the pump speed to the set pump speed and if the at least one of the group consisting of the adverse event and a second adverse event is present while increasing the pump speed to the set pump speed, the method includes reducing the pump speed to a maximum safe operating speed.",HEARTWARE INC,REYES CARLOS;;CHORPENNING KATHERINE;;FERREIRA ANTONIO LUIZ SILVA;;VASUDEVAN JALAJA NEETHU LEKSHMI;;WOLMAN JUSTIN;;CASAS FERNANDO,HEARTWARE INC (2019-03-26),https://lens.org/186-589-290-659-559,Patent Application,yes,0,3,5,5,0,A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/50;;A61M60/205,A61M1/10;;A61M1/12,,0,0,,,,ACTIVE
234,US,B2,US 11554260 B2,095-289-020-851-459,2023-01-17,2023,US 201916359501 A,2019-03-20,US 201916359501 A;;US 201862653958 P,2018-04-06,Multi-input speed response algorithm for a blood pump,"A method of responding to an adverse event associated with an implantable blood pump including detecting the adverse event, reducing a pump speed of the blood pump relative to a set pump speed in response to the detected adverse event, and determining whether at least one of a group consisting of the adverse event and a second adverse event is present following the reducing of the pump speed of the blood pump. If the at least one of the group consisting of the adverse event and a second adverse event is not present, the method includes increasing the pump speed to the set pump speed and if the at least one of the group consisting of the adverse event and a second adverse event is present while increasing the pump speed to the set pump speed, the method includes reducing the pump speed to a maximum safe operating speed.",HEARTWARE INC,REYES CARLOS;;CHORPENNING KATHERINE;;FERREIRA ANTONIO LUIZ SILVA;;VASUDEVAN JALAJA NEETHU LEKSHMI;;WOLMAN JUSTIN;;CASAS FERNANDO,HEARTWARE INC (2019-03-26),https://lens.org/095-289-020-851-459,Granted Patent,yes,17,0,5,5,0,A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/50;;A61M60/205,A61M60/148;;A61M60/178;;A61M60/205;;A61M60/216;;A61M60/422;;A61M60/50;;A61M60/538,,3,0,,,"International Search Report and Written Opinion dated Jun. 12, 2019 for International Application No. PCT/US2019/023181, International filing date Mar. 20, 2019; consisting of 12 pages.;;International Preliminary Report on Patentability from International Application No. PCT/US2019/023181, dated Oct. 6, 2020, 7 pp.;;Response to Communication Pursuant to Rules 161(1) and 162 EPC dated Nov. 13, 2020, from counterpart European Application No. 19715647.4, filed May 4, 2021, 27 pp.",ACTIVE
235,WO,A1,WO 2019/194976 A1,031-633-225-305-361,2019-10-10,2019,US 2019/0023181 W,2019-03-20,US 201862653958 P,2018-04-06,MULTI-INPUT SPEED RESPONSE ALGORITHM FOR A BLOOD PUMP,"A method of responding to an adverse event associated with an implantable blood pump including detecting the adverse event, reducing a pump speed of the blood pump relative to a set pump speed in response to the detected adverse event, and determining whether at least one of a group consisting of the adverse event and a second adverse event is present following the reducing of the pump speed of the blood pump. If the at least one of the group consisting of the adverse event and a second adverse event is not present, the method includes increasing the pump speed to the set pump speed and if the at least one of the group consisting of the adverse event and a second adverse event is present while increasing the pump speed to the set pump speed, the method includes reducing the pump speed to a maximum safe operating speed.",HEARTWARE INC,REYES CARLOS;;CHORPENNING KATHERINE;;FERREIRA ANTONIO LUIZ SILVA;;VASUDEVAN JALAJA NEETHU LEKSHMI;;WOLMAN JUSTIN;;CASAS FERNANDO,,https://lens.org/031-633-225-305-361,Patent Application,yes,13,0,5,5,0,A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/148;;A61M60/422;;A61M60/216;;A61M60/178;;A61M60/538;;A61M60/50;;A61M60/205,A61M1/10;;A61M1/12,,0,0,,,,PENDING
236,CH,A,CH 380121 A,049-837-409-339-089,1964-07-31,1964,CH 6346358 A,1958-09-01,MX 4873057 A;;MX 4889857 A;;MX 4911157 A;;MX 4911457 A;;MX 4916657 A;;MX 5008658 A;;MX 5008758 A;;MX 5075958 A,1957-09-03,Verfahren zur Herstellung neuer Halogenpregnanverbindungen,,SYNTEX SA,HOWARD JOSEPH DR RINGOLD;;MANCERA OCTAVIO DR;;ROSENKRANZ JORGE DR;;ZAFFARONI ALEJANDRO DR;;CASAS CARLOS DR,,https://lens.org/049-837-409-339-089,Granted Patent,no,0,0,2,20,0,C12P33/10;;C07J5/00;;C07J75/00;;C12P33/08,C07J5/00;;C07J75/00;;C12P33/08;;C12P33/10,"12O,25/06",0,0,,,,EXPIRED
237,BR,B1,BR 102017011634 B1,175-750-858-668-052,2023-11-21,2023,BR 102017011634 A,2017-06-01,BR 102017011634 A,2017-06-01,Sistema para reabilitação de paciente com lesão no joelho,"sistema para reabilitação de paciente com lesão no joelho. a invenção refere-se a um sistema utilizado na reabilitação de pacientes submetidos a cirurgia no joelho. o aparelho apresenta-se como um híbrido entre um aparelho de movimento passivo contínuo e movimento ativo controlado, a fim de trabalhar com o paciente dos primeiros momentos após uma cirurgia até o final do tratamento, com o trabalho de fortalecimento dos músculos que estabilizam a articulação ao redor do joelho, processando e fornecendo dados eletromiográficos ao usuário.",UNIV MINAS GERAIS;;UNIV FED SAO JOAO DEL REI,CARLOS ALBERTO CIMINI JUNIOR;;ESTEVAM BARBOSA DE LAS CASAS;;MARCIO FALCÃO SANTOS BARROSO;;MARCOS ANTÔNIO ABDALLA JÚNIOR,,https://lens.org/175-750-858-668-052,Granted Patent,no,0,0,2,2,0,A61H1/024,A61H1/02,,0,0,,,,ACTIVE
238,CN,A,CN 114731163 A,149-378-639-120-336,2022-07-08,2022,CN 202080080904 A,2020-12-11,US 201916716350 A;;US 2020/0064705 W,2019-12-16,Accelerated parallel processing of 5G NR signal information,"Apparatus, systems, and techniques for performing signal processing operations in a fifth generation (5G) new radio (NR) network using one or more parallel processing units (PPUs). In at least one embodiment, one or more PPUs implement signal processing in a baseband unit (BBU) that performs 5G NR physical layer operations in a communication network.",NVIDIA CORP,IBARS CASAS CARLOS;;BANYUR GOWDA H D;;FORTKE JAMES D;;DELFELD JOHN H;;MULLER ANDREAS;;TIJA VINEET,,https://lens.org/149-378-639-120-336,Patent Application,no,0,0,9,9,0,H04B7/2603;;H03M13/6561;;H03M13/13;;H03M13/1102;;H03M13/6561;;H03M13/1102;;H03M13/13;;H04B7/2603;;H03M13/6561;;H04L1/0061;;G06F9/46;;H04W88/06;;H04W88/08;;H03M13/1102;;H04W4/40;;G06T1/20;;H04L1/0061;;H04W88/06;;H04W88/08;;H04W92/02,H03M13/00,,0,0,,,,PENDING
239,BR,A2,BR 102017011634 A2,164-025-536-829-06X,2018-12-18,2018,BR 102017011634 A,2017-06-01,BR 102017011634 A,2017-06-01,sistema para reabilitação de paciente com lesão no joelho,"sistema para reabilitação de paciente com lesão no joelho. a invenção refere-se a um sistema utilizado na reabilitação de pacientes submetidos a cirurgia no joelho. o aparelho apresenta-se como um híbrido entre um aparelho de movimento passivo contínuo e movimento ativo controlado, a fim de trabalhar com o paciente dos primeiros momentos após uma cirurgia até o final do tratamento, com o trabalho de fortalecimento dos músculos que estabilizam a articulação ao redor do joelho, processando e fornecendo dados eletromiográficos ao usuário.",UNIV MINAS GERAIS;;UNIV FED SAO JOAO DEL REI,CARLOS ALBERTO CIMINI JUNIOR;;ESTEVAM BARBOSA DE LAS CASAS;;MARCIO FALCÃO SANTOS BARROSO;;MARCOS ANTÔNIO ABDALLA JÚNIOR,,https://lens.org/164-025-536-829-06X,Patent Application,no,0,0,2,2,0,A61H1/024,A61H1/02,,0,0,,,,ACTIVE
240,DE,B,DE 1088487 B,144-018-203-396-496,1960-09-08,1960,DE S0059656 A,1958-09-02,MX 1088487X A,1957-09-23,Verfahren zur Herstellung neuer Halogenpregnanverbindungen,,SYNTEX SA,RINGOLD DR HOWARD JOSEPH;;MANCERA DR OCTAVIO;;ROSENKRANZ DR JORGE;;ZAFFARONI DR ALEJANDRO;;CAMPILLO DR CARLOS CASAS,,https://lens.org/144-018-203-396-496,Patent Application,no,0,0,1,1,0,C07J5/00,C07J5/00,,0,0,,,,DISCONTINUED
241,EP,B1,EP 2770034 B1,169-668-524-077-201,2018-08-08,2018,EP 11822844 A,2011-12-27,ES 2011070908 W,2011-12-27,POLYMERIC COMPOSITION FOR SOIL STABILIZATION AND FOR CONTROLLING DUST AND EMBANKMENT EROSION,,ACCIONA INFRAESTRUCTURAS SA;;FORESA INDUSTRIAS QUIM DEL NOROESTE S A U,BOTELLO ROJAS FAIVER;;CASAS OCAMPO ANDREA;;GARCÍA HERMIDA MIGUEL;;OTERO VÁZQUEZ LUIS ALBERTO;;RIAL PÉREZ CARLOS;;PRIMI STEFANO,,https://lens.org/169-668-524-077-201,Granted Patent,yes,3,0,6,6,0,C09K3/22;;C09K17/22;;E02B3/12,C09K3/22;;C09K17/22;;E02B3/12,,0,0,,,,ACTIVE
242,PT,T,PT 2770034 T,183-826-772-533-809,2018-11-14,2018,PT 11822844 T,2011-12-27,EP 11822844 A;;ES 2011070908 W,2011-12-27,POLYMERIC COMPOSITION FOR SOIL STABILIZATION AND FOR CONTROLLING DUST AND EMBANKMENT EROSION,,ACCIONA INFRAESTRUCTURAS SA;;FORESA IND QUA­MICAS DEL NOROESTE S A U,FAIVER BOTELLO ROJAS;;ANDREA CASAS OCAMPO;;MIGUEL GARCIA HERMIDA;;LUIS ALBERTO OTERO VÁZQUEZ;;CARLOS RIAL PÉREZ;;STEFANO PRIMI,,https://lens.org/183-826-772-533-809,Patent Application,no,0,0,6,6,0,C09K3/22;;C09K17/22;;E02B3/12,C09K3/22;;C09K17/22;;E02B3/12,,0,0,,,,PENDING
243,WO,A1,WO 2013/098425 A1,039-860-108-993-821,2013-07-04,2013,ES 2011070908 W,2011-12-27,ES 2011070908 W,2011-12-27,POLYMERIC COMPOSITION FOR SOIL STABILIZATION AND FOR CONTROLLING DUST AND EMBANKMENT EROSION,"Aqueous-base polymeric composition that comprises a terpolymer formed by at least three types of monomer and a stabilizing system that comprises anionic, non-ionic and polymeric surfactants, at least one protective colloid, at least one coalescing agent that promotes film formation, and at least one rheological agent, for soil stabilization and for controlling dust and embankment erosion. Said compositions have demonstrated good stability in terms of the polymeric dispersion which is transmitted to the element applied, with a high binding capacity, thereby generating greater compaction of the element to which it is applied, and very good resistance to atmospheric agents in terms of the polymer dispersion, the element to which it is applied retaining the properties conferred thereon by the polymeric dispersion.",ACCIONA INFRAESTRUCTURAS SA;;FORESA IND QUIMICAS DEL NOROESTE S A U;;BOTELLO ROJAS FAIVER;;CASAS OCAMPO ANDREA;;GARCIA HERMIDA MIGUEL;;OTERO VAZQUEZ LUIS ALBERTO;;RIAL PEREZ CARLOS;;PRIMI STEFANO,BOTELLO ROJAS FAIVER;;CASAS OCAMPO ANDREA;;GARCIA HERMIDA MIGUEL;;OTERO VAZQUEZ LUIS ALBERTO;;RIAL PEREZ CARLOS;;PRIMI STEFANO,,https://lens.org/039-860-108-993-821,Patent Application,yes,6,3,6,6,0,C09K3/22;;C09K17/22;;E02B3/12,C09K17/22;;C09K3/22,,1,0,,,"PROC S AFR SUG TECHNOL ASS, 1998, pages 72",PENDING
244,ES,T3,ES 2693533 T3,173-603-348-327-116,2018-12-12,2018,ES 11822844 T,2011-12-27,ES 2011070908 W,2011-12-27,"Composición polimérica para la estabilización de suelos, control de polvo y erosión de taludes","Composición polimérica en base acuosa que comprende un terpolímero formado por al menos tres tipos de monómero y un sistema estabilizante que comprende tensioactivos aniónicos, no iónicos y poliméricos, al menos un coloide protector, al menos un agente coalescente que favorece la formación de película, y al menos un agente reólogico, para la estabilización de suelos, el control de polvo y de la erosión de taludes. Estas composiciones han demostrado una buena estabilidad de la dispersión polimérica que se transmite al elemento aplicado, una alta capacidad aglutinante, generando una mejor compactación del elemento a que se aplica; una muy buena resistencia a los agentes atmosféricos de la dispersión polimérica, manteniendo el elemento a que se aplica las propiedades que le confiere la dispersión polimérica.",ACCIONA INFRAESTRUCTURAS SA;;FORESA INDUSTRIAS QUIM DEL NOROESTE S A U,BOTELLO ROJAS FAIVER;;CASAS OCAMPO ANDREA;;GARCIA HERMIDA MIGUEL;;OTERO VAZQUEZ LUIS ALBERTO;;RIAL PEREZ CARLOS;;PRIMI STEFANO,,https://lens.org/173-603-348-327-116,Granted Patent,no,0,0,6,6,0,C09K3/22;;C09K17/22;;E02B3/12,C09K3/22;;C09K17/22;;E02B3/12,,0,0,,,,ACTIVE
245,WO,A1,WO 2018/178881 A1,136-681-674-715-79X,2018-10-04,2018,IB 2018052105 W,2018-03-27,US 201762477997 P;;CO 2017007433 A,2017-03-28,LOW COST GLASS BENDING MOLD,"A large percentage of the bent glass laminates manufactured worldwide each year is produced using the gravity bending process. Inherent drawbacks to the process include the expense of the molds required, marking of the glass by the mold and the lack of precise surface control. By using an inexpensive ceramic mold to bend a sheet of glass having a higher bending temperature than the glass to be used in the fabricated product, a glass female is produced which is then provides the means to produce a full surface gravity bending mold which produces parts having superior quality, optics and dimensional control.",AGP AMERICA SA,MANNHEIM ASTETE MARIO ARTURO;;CASAS JUAN CARLOS;;GONZALES EDWIN;;MONCADA ELIECER;;RAMIRES TIAGO;;POZZEBON JAIRTON;;VOELTZEL CHARLES STEPHEN,,https://lens.org/136-681-674-715-79X,Patent Application,yes,6,0,1,1,0,C03B40/00;;C03B23/023;;C03B23/027;;C03B23/0357,C03B40/00;;C03B23/023;;C03B23/027;;C03B23/035;;C03C3/00,,0,0,,,,PENDING
246,EP,A1,EP 2770034 A1,099-652-213-394-492,2014-08-27,2014,EP 11822844 A,2011-12-27,ES 2011070908 W,2011-12-27,POLYMERIC COMPOSITION FOR SOIL STABILIZATION AND FOR CONTROLLING DUST AND EMBANKMENT EROSION,"A water based polymer composition that comprises a terpolymer formed by at least three types of monomers and a stabilising system that comprises anionic surfactants and nonionic polymers, at least one protector colloid, at least one coalescing agent that favours film formation, and at least one rheological agent for stabilising soils, dust control and embankment erosion. These compositions have demonstrated good stability of the polymer dispersion that is transmitted to the element on which it is applied, a high binding capacity, creating improved compacting of the element on which it is applied; a very good resistance to the atmospheric agents of the polymer dispersion, with the element on which it is applied maintaining the properties that the polymer dispersion provides.",ACCIONA INFRAESTRUCTURAS SA;;FORESA IND QUÍMICAS DEL NOROESTE S A U,BOTELLO ROJAS FAIVER;;CASAS OCAMPO ANDREA;;GARCÍA HERMIDA MIGUEL;;OTERO VÁZQUEZ LUIS ALBERTO;;RIAL PÉREZ CARLOS;;PRIMI STEFANO,,https://lens.org/099-652-213-394-492,Patent Application,yes,0,5,6,6,0,C09K3/22;;C09K17/22;;E02B3/12,C09K3/22;;C09K17/22;;E02B3/12,,1,0,,,See references of WO 2013098425A1,ACTIVE
247,CO,A1,CO 2017007433 A1,127-174-574-506-728,2017-11-10,2017,CO 2017007433 A,2017-07-26,US 201762477997 P,2017-03-28,Molde de curvado de vidrio de bajo costo,"Un gran porcentaje de vidrios laminados curvados que se fabrican cada año en todo el mundo se producen utilizando el proceso de curvado por gravedad. Inconvenientes inherentes al proceso incluyen el costo de los moldes requeridos, la marcación del vidrio por el molde y la falta de control preciso de superficie. Mediante el uso de un molde cerámico económico para curvar una hoja de vidrio que tiene una temperatura de curvado más alta que la del vidrio a utilizar en el producto fabricado, se produce una hembra de vidrio que luego proporciona los medios para producir un molde de curvatura completa de superficie por gravedad que produce partes que tienen calidad superior, óptica y control dimensional.",AGP AMERICA SA,MANNHEIM ASTETE MARIO ARTURO;;VOELTZEL CHARLES STEPHEN;;CASAS JUAN CARLOS;;GONZALES EDWIN;;MONCADA ELIECER;;POZZEBON JAIRTON;;RAMIRES TIAGO,,https://lens.org/127-174-574-506-728,Patent Application,no,0,0,1,1,0,,C03C4/00;;C03C4/02;;C03C4/08,,0,0,,,,PENDING
248,CN,A,CN 113226212 A,149-823-296-988-012,2021-08-06,2021,CN 201980086935 A,2019-04-24,IB 2019053356 W,2019-04-24,GUIDE AND SUPPORT FOR PERFORMING CRANIOFACIAL PUNCTIONS,"The present invention is for use in the field of instruments and devices adapted for surgery and diagnostics with instruments. Specifically, it relates to a device for enabling the punction of particular anatomical structures in the craniofacial area. The device comprises a support frame in the form of an adjustable headband which may be adapted to the user's anatomy, and a sphere with two arms that holds a placement fastener onto the face or cranium of the user. Applying pressure to a specific position through the use of screws or rings allows free movement on the hinges of the arms.",FUND ABOOD SHAIO EN REESTRUCTURACION,ARANGO CORTES MARIA LUCIA;;LATORRE ROJAS CARLOS JAVIER;;CORTES MUNOZ FABIAN;;ARANGO CORTES MARIA LUCIA;;SANCHEZ CASAS JENNY CAROLINA,,https://lens.org/149-823-296-988-012,Patent Application,no,17,0,3,3,0,A61B90/14;;A61B90/11;;A61B2090/502;;A61B90/11;;A61B90/14;;A61B2090/502;;A61B17/34,A61B90/00;;A61B17/34;;A61B90/10;;A61B90/14,,0,0,,,,PENDING
249,WO,A2,WO 2013/140011 A2,176-048-696-096-405,2013-09-26,2013,ES 2013070180 W,2013-03-19,ES 201230426 A,2012-03-21,WIRELESS COMMUNICATION DEVICE FOR PERSONS HAVING SPEECH IMPEDIMENTS,"The invention relates to a wireless communication device for persons having speed impediments which is made up of communication sheets, which comprise a symbol selector (a), and a device for reproducing messages (b) between which communication takes place wirelessly, at a distance of < 5 m in order to minimise power consumption. The symbol selector (a) comprises a low-voltage battery (105), microcontroller (101), transceiver (103), and passive selection grid (102); and the reproduction device is portable and capable of reproducing sounds of the signals from the symbol selector (a) into an augmentative audio signal (approximately 1.0 W), with sound recording which can be associated with one or more symbols.",UNIV CATALUNYA POLITECNICA,CASAS PIEDRAFITA JAIME OSCAR;;HORNERA OCANA GEMMA;;QUILEZ FIGUEROLA MARCOS;;DOMINGO HERNANDO SERGIO;;ROMERO SALORD CARLOS;;ROMERO SALORD BORJA,,https://lens.org/176-048-696-096-405,Patent Application,yes,0,0,5,5,0,G09B21/00;;H04W52/0241;;H04M1/72475;;H04W4/80;;Y02D30/70,,,0,0,,,,PENDING
250,US,A1,US 2022/0054219 A1,122-370-562-569-293,2022-02-24,2022,US 201917416588 A,2019-04-24,IB 2019053356 W,2019-04-24,GUIDE AND SUPPORT FOR PERFORMING CRANIOFACIAL PUNCTIONS,"The present invention is for use in the field of instruments and devices adapted for surgery and diagnostics with instruments. Specifically, it relates to a device for enabling the punction of particular anatomical structures in the craniofacial area. The device comprises a support frame in the form of an adjustable headband which may be adapted to the user's anatomy, a sphere with two arms that hold a placement fastener onto the face or cranium of the user, applying pressure to a specific position through the use of screws or rings that allow free movement on the hinges of the arms.",FUND ABOOD SHAIO EN REESTRUCTURACION,ARANGO CORTES MARIA LUCIA;;LATORRE ROJAS CARLOS JAVIER;;CORTES MUNOZ FABIAN;;BOHORQUEZ ESCOBAR CELSO ERNESTO;;SANCHEZ CASAS JENNY CAROLINA,,https://lens.org/122-370-562-569-293,Patent Application,yes,0,0,3,3,0,A61B90/14;;A61B90/11;;A61B2090/502;;A61B90/11;;A61B90/14;;A61B2090/502;;A61B17/34,A61B17/34;;A61B90/11;;A61B90/14,,0,0,,,,PENDING
251,ES,B1,ES 2426663 B1,182-848-670-605-374,2014-09-15,2014,ES 201230426 A,2012-03-21,ES 201230426 A,2012-03-21,EQUIPO COMUNICADOR INALAMBRICO PARA PERSONAS CON DIFICULTADES EN EL HABLA,,UNI POLITÈCNICA DE CATALUNYA,CASAS PIEDRAFITA JAIME OSCAR;;HORNERA OCAÑA GEMMA;;QUILEZ FIGUEROLA MARCOS;;DOMINGO HERNANDO SERGIO;;ROMERO SALORD CARLOS;;ROMERO SALORD BORJA,,https://lens.org/182-848-670-605-374,Granted Patent,no,0,0,5,5,0,G09B21/00;;H04W52/0241;;H04M1/72475;;H04W4/80;;Y02D30/70,G10L13/033,,0,0,,,,ACTIVE
252,WO,A1,WO 2020/217086 A1,061-359-331-021-724,2020-10-29,2020,IB 2019053356 W,2019-04-24,IB 2019053356 W,2019-04-24,GUIDE AND SUPPORT FOR PERFORMING CRANIOFACIAL PUNCTIONS,"The present invention is for use in the field of instruments and devices adapted for surgery and diagnostics with instruments. Specifically, it relates to a device for enabling the punction of particular anatomical structures in the craniofacial area. The device comprises a support frame in the form of an adjustable headband which may be adapted to the user's anatomy, a sphere with two arms that hold a placement fastener onto the face or cranium of the user, applying pressure to a specific position through the use of screws or rings that allow free movement on the hinges of the arms.",FUND ABOOD SHAIO EN REESTRUCTURACION,BOHORQUEZ ESCOBAR CELSO ERNESTO;;SANCHEZ CASAS JENNY CAROLINA;;LATORRE ROJAS CARLOS JAVIER;;ARANGO CORTES MARÍA LUCIA;;CORTES MUÑOZ FABIÁN,,https://lens.org/061-359-331-021-724,Patent Application,yes,5,1,3,3,0,A61B90/14;;A61B90/11;;A61B2090/502;;A61B90/11;;A61B90/14;;A61B2090/502;;A61B17/34,A61B90/00;;A61B17/34;;A61B90/10;;A61B90/14,,0,0,,,,PENDING
253,ES,R2,ES 2426663 R2,125-204-500-913-031,2013-11-21,2013,ES 201230426 A,2012-03-21,ES 201230426 A,2012-03-21,EQUIPO COMUNICADOR INALAMBRICO PARA PERSONAS CON DIFICULTADES EN EL HABLA,"Equipo comunicador inalámbrico para personas con dificultades en el habla que está formado por hojas de comunicación, consistentes en un selector de símbolos (a), y un dispositivo reproductor de mensajes (b) entre los que la comunicación se realiza sin hilos, a una distancia < 5 m para reducir su consumo. El selector de símbolos (a) tiene batería (105) de baja tensión, microcontrolador (101) transceptor (103) y matriz de selección pasiva (102); y el dispositivo reproductor es portátil y con capacidad para la reproducción de sonidos de las señales del selector de símbolos (a) en señal de audio aumentativa (1,0 W aproximadamente) y con grabación de sonidos asociable a uno o más símbolos.",UNIV CATALUNYA POLITECNICA,CASAS PIEDRAFITA JAIME OSCAR;;HORNERA OCANA GEMMA;;QUILEZ FIGUEROLA MARCOS;;DOMINGO HERNANDO SERGIO;;ROMERO SALORD CARLOS;;ROMERO SALORD BORJA,,https://lens.org/125-204-500-913-031,Unknown,no,0,0,5,5,0,G09B21/00;;H04W52/0241;;H04M1/72475;;H04W4/80;;Y02D30/70,G10L13/033,,0,0,,,,ACTIVE
254,MX,A,MX 2022014075 A,121-441-565-086-253,2022-12-19,2022,MX 2022014075 A,2022-11-08,MX 2022014075 A,2022-11-08,ELECTRONIC DEVICE TO EXTRACT DATA FROM VIDEOS IN REAL-TIME.,"The present invention relates to an electronic device that implements a method to extract video data in real time. Said device includes an image unit capturing a video for extracting the data, an image sensor, a lens, a motorized adjustment mechanism, a control card, and a PoE card that supplies electricity to operate in communication with the external server. Also, a carrier module with an analysis computer allows interconnecting with the imaging unit and the PoE card, processing data in real-time, capturing the video, and extracting the data sent to the external server through the PoE card to a user. Further, it consists of various stages that detect, identify, and classify objects of interest, their characteristics, and events in the frames analyzed using artificial intelligence models, such as deep neural networks.",INTELLION TECH S A P I DE C V,CARRIZOSA CORRAL FERNANDO;;VEGA LÓPEZ INÉS FERNANDO;;CASTRO PADILLA JOSÉ CARLOS;;QUINTERO VILLEGAS JESÚS ALBERTO;;MORALES CASAS ZURIEL ERNESTO,,https://lens.org/121-441-565-086-253,Patent Application,no,0,0,1,1,0,,G06V10/40,,0,0,,,,PENDING
255,ES,A2,ES 2426663 A2,188-273-547-162-946,2013-10-24,2013,ES 201230426 A,2012-03-21,ES 201230426 A,2012-03-21,WIRELESS COMMUNICATION DEVICE FOR PERSONS HAVING SPEECH IMPEDIMENTS,"The invention relates to a wireless communication device for persons having speed impediments which is made up of communication sheets, which comprise a symbol selector (a), and a device for reproducing messages (b) between which communication takes place wirelessly, at a distance of < 5 m in order to minimise power consumption. The symbol selector (a) comprises a low-voltage battery (105), microcontroller (101), transceiver (103), and passive selection grid (102) and the reproduction device is portable and capable of reproducing sounds of the signals from the symbol selector (a) into an augmentative audio signal (approximately 1.0 W), with sound recording which can be associated with one or more symbols.",UNIV CATALUNYA POLITECNICA,CASAS PIEDRAFITA JAIME OSCAR;;HORNERA OCANA GEMMA;;QUILEZ FIGUEROLA MARCOS;;DOMINGO HERNANDO SERGIO;;ROMERO SALORD CARLOS;;ROMERO SALORD BORJA,,https://lens.org/188-273-547-162-946,Patent Application,no,0,0,5,5,0,G09B21/00;;H04W52/0241;;H04M1/72475;;H04W4/80;;Y02D30/70,G10L13/033,,0,0,,,,ACTIVE
256,WO,A3,WO 2013/140011 A3,006-417-426-966-710,2013-11-07,2013,ES 2013070180 W,2013-03-19,ES 201230426 A,2012-03-21,WIRELESS COMMUNICATION DEVICE FOR PERSONS HAVING SPEECH IMPEDIMENTS,"The invention relates to a wireless communication device for persons having speed impediments which is made up of communication sheets, which comprise a symbol selector (a), and a device for reproducing messages (b) between which communication takes place wirelessly, at a distance of < 5 m in order to minimise power consumption. The symbol selector (a) comprises a low-voltage battery (105), microcontroller (101), transceiver (103), and passive selection grid (102); and the reproduction device is portable and capable of reproducing sounds of the signals from the symbol selector (a) into an augmentative audio signal (approximately 1.0 W), with sound recording which can be associated with one or more symbols.",UNIV CATALUNYA POLITECNICA,CASAS PIEDRAFITA JAIME OSCAR;;HORNERA OCANA GEMMA;;QUILEZ FIGUEROLA MARCOS;;DOMINGO HERNANDO SERGIO;;ROMERO SALORD CARLOS;;ROMERO SALORD BORJA,,https://lens.org/006-417-426-966-710,Search Report,yes,1,0,5,5,0,G09B21/00;;H04W52/0241;;H04M1/72475;;H04W4/80;;Y02D30/70,G10L13/033,,1,0,,,"AFFORDA SPEECH: ""BoardSpeaker - A new alternative augmentative communication device"", WHITE PAPER, 2005, Retrieved from the Internet <URL:www.affordaspeech.com/PDF/AlternativeCommunicationDevices3.pdf>",PENDING
257,MX,A,MX 2015002223 A,161-524-829-988-889,2016-03-08,2016,MX 2015002223 A,2015-02-19,MX 2015002223 A,2015-02-19,PROCESS FOR THE TREATMENT OF SOLID WASTE.,"The present invention relates to a process for the treatment of urban solid waste, characterized in that it comprises the following steps: (A) conditioning the urban solid waste, (B) crushing the urban solid waste; (C) microbiologically stabilizing the same through the application of a peracetic acid biocidal solution to the material thus obtained. (D) drying the material obtained in step (C) and adding a preserving agent; (E) irradiating the material obtained in step (D) with ultraviolet light. (F) pulverizing the material obtained in step (E); (G) sifting the material of step (F) to obtain a microbiologically inactive powder. Said process enables the treatment of urban solid wastes to be safe and suitable for obtaining a product useful as construction material.",INAMBTEC S A DE C V,REYES VILLEGAS CARLOS AUGUSTO;;ESTRADA MENA RICARDO ENRIQUE;;GARRIDO CASAS MÓNICA;;LOAIZA YAÑEZ JOSÉ LUIS;;PALACIOS GARAY HARI SIMRAN SINGH,,https://lens.org/161-524-829-988-889,Patent Application,no,0,1,1,1,0,,B03B5/00;;C02F11/14,,0,0,,,,PENDING
258,MX,A,MX 2016016702 A,041-384-762-667-93X,2018-06-14,2018,MX 2016016702 A,2016-12-15,MX 2016016702 A,2016-12-15,BRICK ELABORATED WITH A PERCENTAGE OF FINE ADDED PRODUCT OF THE TRANSFORMATION OF SOLID URBAN WASTE.,"The present disclosure is related to a process to generate a building block using among its components, the product of the transformation of urban solid waste, called Technosolid, and a polymer consisting of a self-crosslinkable acrylic styrene resin, comprising the following stages: a) raw material reception; b) Mixing the Tecnosolid and the polymer; c) addition and homogenization of the rest of the raw materials: gravel, cement, sand, and water; d) mold filling; e) vibro-compaction; f) demolding; g) Curing in a humidity chamber with a water mist system; h) temporary storage of the blocks.",INAMBTEC S A DE C V,CARLOS AUGUSTO REYES VILLEGAS;;RICARDO ENRIQUE ESTRADA MENA;;MONICA CASAS GARRIDO;;JOSÉ LUIS LOAIZA YAÑEZ;;HARI SIMRAN SINGH PALACIOS GARAY,,https://lens.org/041-384-762-667-93X,Patent Application,no,0,0,1,1,0,Y02W30/62,E04C1/40;;B29B17/00,,0,0,,,,PENDING
259,ES,A1,ES 2579027 A1,038-516-871-468-407,2016-08-03,2016,ES 201500092 A,2015-02-03,ES 201500092 A,2015-02-03,"Module for the formation of artificial reefs (Machine-translation by Google Translate, not legally binding)","Module for the formation of artificial reefs, which is constituted by a series of independent prefabricated pieces of concrete, a base piece (1) and a series of wall pieces (2), which have mutual coupling and fixation and limit a cavity central (3) and have in their free surfaces blind holes (11) and through holes (5) between the external surface and the central void (3). (Machine-translation by Google Translate, not legally binding)",UNIV CORUNA,CARRAL COUCE LUIS;;RODRIGUEZ GUERREIRO MARÍA JESÚS;;FRAGUELA FORMOSO JOSÉ ANGEL;;DIAZ CASAS VICENTE;;ALVAREZ FEAL JOSÉ CARLOS JUAN;;FERRENO GONZALEZ SARA,,https://lens.org/038-516-871-468-407,Patent Application,no,6,1,2,2,0,A01K61/70;;E02B3/046;;Y02A10/26;;Y02A40/81,E02B3/14;;A01K61/00,,0,0,,,,ACTIVE
260,ES,B1,ES 2579027 B1,152-752-482-386-958,2017-02-07,2017,ES 201500092 A,2015-02-03,ES 201500092 A,2015-02-03,Módulo para la formación de arrecifes artificiales,,UNIV CORUNA,CARRAL COUCE LUIS;;RODRIGUEZ GUERREIRO MARÍA JESÚS;;FRAGUELA FORMOSO JOSÉ ANGEL;;DIAZ CASAS VICENTE;;ALVAREZ FEAL JOSÉ CARLOS JUAN;;FERRENO GONZALEZ SARA,,https://lens.org/152-752-482-386-958,Granted Patent,no,0,0,2,2,0,A01K61/70;;E02B3/046;;Y02A10/26;;Y02A40/81,E02B3/14;;A01K61/00,,0,0,,,,ACTIVE
261,MX,A,MX 2020000538 A,098-296-688-206-024,2021-07-16,2021,MX 2020000538 A,2020-01-15,MX 2020000538 A,2020-01-15,"NEW PSTS1 O- MANNOSYLATED (PSTS1-OM) PROTEIN, DESIGN BASED ON TUBERCULOSIS PSTS-1 MYCOBACTERIUM, PRODUCTION PROCESS IN PICHIA PASTORIS AND USE IN DIAGNOSIS, THERAPY, AND TO GENERATE ANTIBODIES.","The present disclosure is related to some protein antigens modified by the addition of carbohydrates produced by microbial pathogens; modify the host's humoral and cellular immune response against bacteria. It is of interest to produce M. tuberculosis glycoproteins (Mtb) without involving the pathogen, hence they have been expressed in Escherichia coli. However, the proteins produced are different from the native ones. The present invention relates to the design and production of the recombinant antigen PstS-1 O-mannosylated (PstS1-OM) highly similar to that produced by Mtb, expressed in Pichia pastoris. Presenting methods for its production, purification and uses. Addressing the design of the nucleotide sequence for the synthesis of PstS1-OM. The gene sequence encoding the PstS1-OM protein was designed and synthesized (SEQ ID NO: 1), according to the preferential use of codons in P. pastoris. The synthesized DNA excluded the nucleotide sequences encoding amino acids 1-21 of the 23 that make up the signal peptide, while amino acids 22 and 23 were maintained in the PstS1-OM protein to avoid lipidation of the Cys24 residue, present in the amino of the native protein. N57Q and N247Q mutations were performed to avoid N-glycosylation. The synthesized sequence was cloned into the vector pPICZaB, with which the P. pastoris strain X-33 was transformed. The PstS1-OM protein was successfully produced in a bioreactor, demonstrating the purification of 4.0 mg of PstS1-OM with 98% purity per liter of culture. The secondary structure of PstS1-OM was shown to be different from the recombinant protein produced in bacteria. Purified PstS1-OM served to demonstrate its better antibody recognition from patients with active tuberculosis (TB) compared to that of the antigen produced in E. coli. Demonstrating high conformational similarity of PstS1-OM with that of the native Mtb antigen. The detection of PstS1-OM by sera from active TB patients, emphasizes the potential utility of this recombinant antigen produced in P. pastoris for the development of a sensitive serological diagnostic kit for the detection of TB. As well as for the generation of antibodies in sera from other animals and for obtaining monoclonal antibodies, and to be used as a possible human or veterinary vaccine.",UNIV MEXICO NAC AUTONOMA,VALDEZ CRUZ NORMA ADRIANA;;BANDO CAMPOS CARLOS GIROSHI;;JUÁREZ LÓPEZ DANIEL;;LÓPEZ VIDAL YOLANDA;;ESPITIA PINZÓN CLARA INÉS;;CARRILLO CASAS ERIKA MARGARITA;;TRUJILLO ROLDÁN MAURICIO ALBERTO,,https://lens.org/098-296-688-206-024,Patent Application,no,0,0,1,1,0,,A61K38/16;;A61P31/06;;C12N15/79;;C12N15/80;;C12N15/85;;C12P21/02;;C12Q1/04,,0,0,,,,PENDING
262,US,A1,US 2024/0022581 A1,176-024-267-834-135,2024-01-18,2024,US 202318345626 A,2023-06-30,PT 11807822 A,2022-07-01,CONTINUOUS ACTIVE DEFENSE FOR DIGITAL SERVICES,"A method and system for securing an online client-server session between a client device and a server device by application of at least a countermeasure, comprising the server device collecting client behavior pattern during the online session, the server device marking the online session as an affected session according to a pre-agreed client-server protocol, independently of any server-client contact, the client device requesting a client-initiated countermeasure according to the pre-agreed client-server protocol, the server device responding with an indication of a particular countermeasure to be carried out by the client device, the client device carrying out the indicated particular countermeasure and sending to the server device a reaction to the countermeasure, and the server device verifying the client reaction to the countermeasure, and if verified, marking the online session as non-affected.",FEEDZAI CONSULTADORIA E INOVACAO TECNOLOGICA S A,CARLOS CORRALES CASAS JOSE;;MORÁN ANTÓN DAVID;;ALCOJOR DEL SASTRE GUILLERMO;;LIÉBANA DE LA BARRERA JAVIER;;PLA FERNÁNDEZ FERRAN;;ADDELKADE MARTÍNEZ PÉREZ ROBERTO;;TIAGO BARRIGA NEGRA ASCENSÃO JOÃO,,https://lens.org/176-024-267-834-135,Patent Application,yes,0,0,1,1,0,H04L63/20;;H04L63/1425;;H04L63/1416;;H04L63/0876;;H04L63/1416;;H04L63/0876;;H04L63/20;;H04L63/1425,H04L9/40,,0,0,,,,PENDING
263,EP,A4,EP 3779849 A4,143-550-278-886-363,2021-12-08,2021,EP 19776863 A,2019-03-27,ES 201830305 A;;ES 2019070205 W,2018-03-28,DEVICE AND METHOD FOR MONITORING ACTIVITY IN FISH,,CONSEJO SUPERIOR INVESTIGACION;;UNIV DE LAS PALMAS DE GRAN CANARIA,CABRUJA CASAS ENRIC;;LOZANO FANTOBA MANUEL;;PÉREZ SÁNCHEZ JAUME;;CALDUCH GINER JOSEP;;SOSA GONZÁLEZ CARLOS JAVIER;;FERRER BALLESTER MIGUEL ÁNGEL;;MONTIEL NELSON JUAN ANTONIO;;AFONSO LÓPEZ JUAN MANUEL,,https://lens.org/143-550-278-886-363,Search Report,no,3,0,5,5,0,A01K61/10;;Y02A40/81;;A61B2503/40;;A61B2562/0219;;A61B5/0816;;A61B5/1118;;A61B5/6867;;A01K29/005;;G06Q50/00;;G06F17/00;;A61B5/11;;A01K61/10,G06Q50/00;;A01K61/10;;A61B5/11;;G06F17/00,,2,1,069-151-167-096-633,10.1016/j.aquaculture.2016.09.018,"ERIKSON ULF ET AL: ""Crowding of Atlantic salmon in net-pen before slaughter"", AQUACULTURE, ELSEVIER, AMSTERDAM, NL, vol. 465, 16 September 2016 (2016-09-16), pages 395 - 400, XP029758478, ISSN: 0044-8486, DOI: 10.1016/J.AQUACULTURE.2016.09.018;;See also references of WO 2019185965A1",PENDING
264,ES,B2,ES 2725913 B2,133-850-589-927-232,2020-03-27,2020,ES 201830305 A,2018-03-28,ES 201830305 A,2018-03-28,DISPOSITIVO Y METODO DE MONITORIZACION DE ACTIVIDAD EN PECES,,CONSEJO SUPERIOR INVESTIGACION;;UNIV DE LAS PALMAS DE GRAN CANARIA,CABRUJA CASAS ENRIC;;LOZANO FANTOBA MANUEL;;PÉREZ SÁNCHEZ JAUME;;CALDUCH GINER JOSEP;;SOSA GONZÁLEZ CARLOS JAVIER;;FERRER BALLESTER MIGUEL ANGEL;;MONTIEL NELSON JUAN ANTONIO;;AFONSO LÓPEZ JUAN MANUEL,,https://lens.org/133-850-589-927-232,Granted Patent,no,0,0,5,5,0,A61B5/0816;;A01K29/005;;A01K61/10;;A01K61/10;;A61B5/11;;A61B5/1118;;A61B5/6867;;A61B2503/40;;A61B2562/0219;;G06Q50/00;;G06F17/00;;Y02A40/81,G06Q50/00;;A01K61/10;;A61B5/11;;G06F17/00,,0,0,,,,ACTIVE
265,EP,A1,EP 4300334 A1,074-362-216-736-539,2024-01-03,2024,EP 23183123 A,2023-07-03,PT 2022118078 A;;US 202318345626 A,2022-07-01,METHOD AND SYSTEM FOR SECURING AN ON-LINE CLIENT-SERVER SESSION BY APPLYING COUNTERMEASURES,"Method and system (100) for securing an online client-server session between a client device (220) and a server device (110) by application of at least a countermeasure, comprising the server device collecting client behaviour pattern during the online session, the server device marking the online session as an affected session according to a pre-agreed client-server protocol, independently of any server-client contact, the client device requesting a client-initiated countermeasure according to the pre-agreed client-server protocol, the server device responding with an indication of a particular countermeasure to be carried out by the client device, the client device carrying out the indicated particular countermeasure and sending to the server device a reaction to the countermeasure, and the server device verifying the client reaction to the countermeasure, and if verified, marking the online session as non-affected.
",FEEDZAI CONSULTADORIA E INOVACAO TECNOLOGICA S A,CORRALES CASAS JOSE CARLOS;;MORÁN ANTÓN DAVID;;ALCOJOR DEL SASTRE GUILLERMO;;LIÉBANA DE LA BARRERA JAVIER;;PLA FERNÁNDEZ FERRAN;;ADDELKADE MARTÍNEZ PÉREZ ROBERTO;;BARRIGA NEGRA ASCENSÃO JOÃO TIAGO,,https://lens.org/074-362-216-736-539,Patent Application,yes,6,0,1,1,0,G06F21/554;;G06F2221/2103;;G06F2221/2111;;G06F2221/2113;;G06F2221/2133;;G06F21/552;;G06F21/577,G06F21/55,,8,6,091-777-010-917-052;;041-692-887-806-926;;065-885-760-486-090;;126-531-997-554-963;;012-559-813-795-852;;120-875-513-047-625,10.1016/j.jnca.2016.04.007;;10.1016/j.cose.2012.02.006;;10.1109/icdh.2012.59;;10.1016/s1389-1286(98)00017-6;;10.1109/icsa-c.2018.00032;;10.3390/fi12100160,"JOURNAL OF NETWORK AND COMPUTER APPLICATIONS, vol. 68, 2016, pages 90 - 113;;RIAZ AHMED SHAIKHKAMEL ADILUIGI LOGRIPPO., DYNAMIC RISK-BASED DECISION METHODS FOR ACCESS CONTROL SYSTEMS. COMPUTERS & SECURITY, vol. 31, no. 4, 2012, pages 447 - 464;;ISSA TRAOREISAAC WOUNGANGMOHAMMAD S OBAIDATYOUSSEF NAKKABIRIS LAI.: ""Combining mouse and keystroke dynamics biometrics for risk-based authentication in web environments. In 2012 fourth international conference on digital home"", IEEE, 2012, pages 138 - 145;;HERVE DEBARMARC DACIERANDREAS WESPI: ""Towards a taxonomy of intrusion-detection systems"", COMPUTER NETWORK, vol. 31, no. 8, 1999, pages 805 - 822, XP055426820, DOI: 10.1016/S1389-1286(98)00017-6;;LAURENS SIONDIMITRI VAN LANDUYTKOEN YSKOUWOUTERJOOSEN: ""Sparta: Security & privacy architecture through risk-driven threat assessment. In 2018 IEEE International Conference on Software Architecture Companion (ICSA-C"", IEEE, 2018, pages 89 - 92;;RABIE A RAMADANBASSAM W ABOSHOSHAJALAWI SULAIMAN ALSHUDUKHIABDULLAH J ALZAHRANIAYMAN EI-SAYEDMOHAMED M DESSOUKY: ""Cybersecurity and countermeasures at the time of pandemic"", JOURNAL OF ADVANCED TRANSPORTATION, 2021;;A JESUDOSSN SUBRAMANIAM.: ""A survey on authentication attacks and countermeasures in a distributed environment"", INDIAN JOURNAL OF COMPUTER SCIENCE AND ENGINEERING (IJCSE, vol. 5, no. 2, 2014, pages 71 - 77;;GUMA ALIMUSSA ALLY DIDAANAEL ELIKANA SAM.: ""Two-factor authentication scheme for mobile money: A review of threat models and countermeasures"", FUTURE INTERNET, vol. 12, no. 10, 2020, pages 160",PENDING
266,ES,A1,ES 2725913 A1,030-086-778-636-818,2019-09-30,2019,ES 201830305 A,2018-03-28,ES 201830305 A,2018-03-28,"DEVICE AND METHOD OF MONITORING OF ACTIVITY IN FISH (Machine-translation by Google Translate, not legally binding)","Device and method of monitoring activity in fish. Device located in the operculum to monitor the metabolic state and well-being of fish through joint and simultaneous measures of respiratory rate and physical activity by means of a plurality of coplanar accelerations (x, y) and normal to the operculum (z axis). The substrate is flexible and covered with a waterproof coating, where an electronic circuit with acceleration sensor (208), a control unit (202), a microcontroller (206) configured to run at least one activity monitoring routine is located, a memory (210) and a battery (204). The data collection is carried out through an external unit (201) that can eventually process them totally or partially. These types of measurements can be processed together with other types of measurements, obtained from other environmental parameters sensors. (Machine-translation by Google Translate, not legally binding)",CONSEJO SUPERIOR INVESTIGACION;;UNIV DE LAS PALMAS DE GRAN CANARIA,CABRUJA CASAS ENRIC;;LOZANO FANTOBA MANUEL;;PÉREZ SÁNCHEZ JAUME;;CALDUCH GINER JOSEP;;SOSA GONZÁLEZ CARLOS JAVIER;;FERRER BALLESTER MIGUEL ANGEL;;MONTIEL NELSON JUAN ANTONIO;;AFONSO LÓPEZ JUAN MANUEL,,https://lens.org/030-086-778-636-818,Patent Application,no,1,0,5,5,0,A01K61/10;;Y02A40/81;;A61B2503/40;;A61B2562/0219;;A61B5/0816;;A61B5/1118;;A61B5/6867;;A01K29/005;;G06Q50/00;;G06F17/00;;A61B5/11;;A01K61/10,G06Q50/00;;A01K61/10;;A61B5/11;;G06F17/00,,5,5,104-367-347-419-794;;032-977-878-537-413;;086-943-012-333-51X;;069-151-167-096-633;;044-394-482-886-300,10.1111/jfb.12804;;26592370;;pmc3203837;;22035321;;10.1089/tmj.2011.0022;;10.1016/j.aquaeng.2016.03.002;;10.1016/j.aquaculture.2016.09.018;;10.1016/0923-2508(94)90073-6;;8090989,"J. D. METCALFE , S. WRIGHT , C. TUDORACHE , R. P. WILSON: ""Recent advances in telemetry for estimating the energy metabolism of wild fishes"", JOURNAL OF FISH BIOLOGY, vol. 88, no. 1, 22 November 2015 (2015-11-22), pages 284 - 297, ISSN: 0022-1112, DOI: 10.1111/jfb.12804;;GUAN-ZHENG LIU; YAN-WEI GUO; QING-SONG ZHU; BANG-YU HUANG; LEI WANG: ""Estimation of Respiration Rate from Three-Dimensional Acceleration Data Based on Body Sensor Network"", TELEMEDICINE AND E-HEALTH, vol. 17, no. 9, 30 November 2011 (2011-11-30), pages 705 - 711, XP055084098, ISSN: 1530-5627, DOI: 10.1089/tmj.2011.0022;;J KOLAREVIC , AAS-HANSSEN , A ESPMARK , G BAEVERFJORD , B FYHN TERJESEN , B DAMSGARD : ""The use of acoustic acceleration transmitter tags for monitoring of Atlantic salmon swimming activity in recirculating aquaculture systems (RAS)"", AQUACULTURAL ENGENEERING, vol. 72, 14 March 2016 (2016-03-14), pages 30 - 39, XP029639998, ISSN: 0144-8609, DOI: 10.1016/j.aquaeng.2016.03.002;;ERIKSON ULF; GANSEL LARS; FRANK KEVIN; SVENDSEN EIRIK; DIGRE HANNE: ""Crowding of Atlantic salmon in net-pen before slaughter"", AQUACULTURE, vol. 465, 16 September 2016 (2016-09-16), pages 395 - 400, XP029758478, ISSN: 0044-8486, DOI: 10.1016/j.aquaculture.2016.09.018;;D VAN DER LELIE , P CORBISIER ,W BAEYENS , S WUERTZ , L DIELS ,M MERGEAY : ""The use of biosensors for environmental monitoring"", RESEARCH IN MICROBIOLOGY , vol. 145, no. 1, 1 January 1994 (1994-01-01), pages 67 - 74, XP023925053, ISSN: 0923-2508, DOI: :10.1016/0923-2508(94)90073-6",ACTIVE
267,EP,A1,EP 3779849 A1,099-771-782-107-889,2021-02-17,2021,EP 19776863 A,2019-03-27,ES 201830305 A;;ES 2019070205 W,2018-03-28,DEVICE AND METHOD FOR MONITORING ACTIVITY IN FISH,"The invention relates to a device placed on the operculum to monitor the metabolic state and well-being of fish through joint, simultaneous measurements of breathing frequency and physical activity via a plurality of accelerations that are coplanar (x and y axes) and normal to the operculum (z axis). The substrate is flexible and is covered with an water-resistant coating, which contains an electronic circuit with an acceleration sensor (208), a control unit (202), a microcontroller (206) configured to execute at least one activity-monitoring routine, a memory (210) and a battery (204). Data are collected via an external unit (201) which can optionally process them in a complete or partial manner. This type of measurement can be processed jointly with another type of measurement, obtained from other sensors of environmental parameters.",CONSEJO SUPERIOR INVESTIGACION;;UNIV DE LAS PALMAS DE GRAN CANARIA,CABRUJA CASAS ENRIC;;LOZANO FANTOBA MANUEL;;PÉREZ SÁNCHEZ JAUME;;CALDUCH GINER JOSEP;;SOSA GONZÁLEZ CARLOS JAVIER;;FERRER BALLESTER MIGUEL ÁNGEL;;MONTIEL NELSON JUAN ANTONIO;;AFONSO LÓPEZ JUAN MANUEL,,https://lens.org/099-771-782-107-889,Patent Application,yes,0,2,5,5,0,A61B5/0816;;A01K29/005;;A01K61/10;;A01K61/10;;A61B5/11;;A61B5/1118;;A61B5/6867;;A61B2503/40;;A61B2562/0219;;G06Q50/00;;G06F17/00;;Y02A40/81,G06Q50/00;;A01K61/10;;A61B5/11;;G06F17/00,,0,0,,,,PENDING
268,WO,A1,WO 2019/185965 A1,006-738-078-490-281,2019-10-03,2019,ES 2019070205 W,2019-03-27,ES 201830305 A,2018-03-28,DEVICE AND METHOD FOR MONITORING ACTIVITY IN FISH,"The invention relates to a device placed on the gill cover to monitor the metabolic state and well-being of fish through joint, simultaneous measurements of breathing frequency and physical activity via a plurality of accelerations that are coplanar (x and y axes) and normal to the gill cover (z axis). The substrate is flexible and is covered with an impervious coating, which contains an electronic circuit with an acceleration sensor (208), a control unit (202), a microcontroller (206) configured to execute at least one activity-monitoring routine, a memory (210) and a battery (204). Data are collected via an external unit (201) which can optionally process them in a complete or partial manner. This type of measurement can be processed jointly with another type of measurement, obtained from other sensors of environmental parameters.",CONSEJO SUPERIOR INVESTIGACION;;UNIV DE LAS PALMAS DE GRAN CANARIA,CABRUJA CASAS ENRIC;;LOZANO FANTOBA MANUEL;;PÉREZ SÁNCHEZ JAUME;;CALDUCH GINER JOSEP;;SOSA GONZÁLEZ CARLOS JAVIER;;FERRER BALLESTER MIGUEL ÁNGEL;;MONTIEL NELSON JUAN ANTONIO;;AFONSO LÓPEZ JUAN MANUEL,,https://lens.org/006-738-078-490-281,Patent Application,yes,6,1,5,5,0,A61B5/0816;;A01K29/005;;A01K61/10;;A01K61/10;;A61B5/11;;A61B5/1118;;A61B5/6867;;A61B2503/40;;A61B2562/0219;;G06Q50/00;;G06F17/00;;Y02A40/81,G06Q50/00;;A01K61/10;;A61B5/11;;G06F17/00,,9,8,104-367-347-419-794;;032-977-878-537-413;;086-943-012-333-51X;;069-151-167-096-633;;044-394-482-886-300;;008-173-930-496-193;;028-637-525-983-199;;104-367-347-419-794,10.1111/jfb.12804;;26592370;;pmc3203837;;22035321;;10.1089/tmj.2011.0022;;10.1016/j.aquaeng.2016.03.002;;10.1016/j.aquaculture.2016.09.018;;10.1016/0923-2508(94)90073-6;;8090989;;10.1145/1964897.1964918;;23197088;;10.1242/jeb.077396;;10.1111/jfb.12804;;26592370,"METCALFE J D; WRIGHT S; TUDORACHE C; WILSON R P: ""Recent advances in telemetry for estimating the energy metabolism of wild fishes"", JOURNAL OF FISH BIOLOGY, vol. 88, no. 1, 22 November 2015 (2015-11-22), pages 284 - 297, XP055745760, ISSN: 0022-1112, DOI: 10.1111/jfb.12804;;GUAN-ZHENG LIU; YAN-WEI GUO; QING-SONG ZHU; BANG-YU HUANG; LEI WANG: ""Estimation of respiration rate from three-dimensional acceleration data based on body sensor network"", TELEMEDICINE JOURNAL AND E-HEALTH, vol. 17, no. 9, November 2011 (2011-11-01), pages 705 - 711, XP055084098, ISSN: 1530-5627, DOI: 10.1089/tmj.2011.0022;;J KOLAREVIC , AAS-HANSSEN , A ESPMARK , G BAEVERFJORD , B FYHN TERJESEN , B DAMSGARD: ""The use of acoustic acceleration transmitter tags for monitoring of Atlantic salmon swimming activity in recirculating aquaculture systems (RAS"", AQUACULTURAL ENGINEERING, vol. 72, no. 73, 2016, pages 30 - 39, XP029639998, ISSN: 0144-8609, DOI: 10.1016/j.aquaeng.2016.03.002;;ERIKSON ULF; GANSEL LARS; FRANK KEVIN; SVENDSEN EIRIK; DIGRE HANNE: ""Crowding of Atlantic salmon in net-pen before slaughter"", AQUACULTURE, vol. 465, 2016, pages 395 - 400, XP029758478, ISSN: 0044-8486, DOI: 10.1016/j.aquaculture.2016.09.018;;D VAN DER LELIE , P CORBISIER ,W BAEYENS , S WUERTZ , L DIELS ,M MERGEAY: ""The use of biosensors for environmental monitoring"", RESEARCH IN MICROBIOLOGY, vol. 145, no. 1, 1994, pages 67 - 74, XP023925053, ISSN: 0923-2508, DOI: 10.1016/0923-2508(94)90073-6;;See also references of EP 3779849A4;;KWAPISZ ET AL., ACTIVITY RECOGNITION USING CELL PHONE ACCELEROMETERS, 2010;;BROELL ET AL., ACCELEROMETER TAGS: DETECTING AND IDENTIFYING ACTIVITIES IN FISH AND THE EFFECT OF SAMPLING FREQUENCY, 2013;;METCALFE ET AL., RECENT ADVANCES IN TELEMETRY FOR ESTIMATING THE ENERGY METABOLISM OF WILD FISHES, 2016",PENDING
269,CU,A1,CU 23142 A1,017-250-728-354-186,2006-05-22,2006,CU 20030153 A,2003-07-11,CU 20030153 A,2003-07-11,COSECHADORA DE CANA DE AZuCAR,"Cosechadora de cana de azUcar, relacionada con la rama mecAnica y en particular con los equipos destinados para la cosecha de la cana, autopropulsada, cosecha de canas verdes o quemadas en una hilera y en ambos sentidos, desmenuza los cogollos, corta las canas en sus bases, las secciona en trozos pequenos, separa y expulsa las materias extranas fuera de la mAquina y deposita el resto de la masa cosechada en el transporte que se desplaza paralelo a la cosechadora. En el proceso tecnologico de esta mAquina se interrelacionan un transportador longitudinal pivoteante en su parte inferior con un movimiento angular en el plano vertical, una esctructura movil regulable en el plano horizontal en donde estAn dispuestos tambores dispersores de la masa cosechada regulables independientemente uno del otro en el plano vertical y una cAmara de separacion neumAtica en posicion vertical en la que se instala el extractor primario accionado hidrAulicamente.",60 ANIVERSARIO DE LA REVOLUCIO,ROJAS PEREZ MANUEL;;GONZALEZ MARTINEZ PEDRO C;;BATISTA SUAREZ EMILIO;;CARRION GUTIERREZ FREDDY;;JARAMILLO CASAS REYNALDO;;HERNANDEZ SILVA MAURICIO;;RIVERO ALMARALES RENAN;;SANCHEZ MARIN CARLOS M;;RODRIGUEZ TARRAGO JOSE LUIS,,https://lens.org/017-250-728-354-186,Limited Patent,no,0,0,1,1,0,,,,0,0,,,,EXPIRED
270,MX,A,MX 2016015478 A,065-569-195-560-299,2018-05-24,2018,MX 2016015478 A,2016-11-25,MX 2016015478 A,2016-11-25,A PROCESS FOR THE GREEN EXFOLIATION OF GRAPHITE BY MECHANICAL TREATMENT.,"The present invention relates to a method for the preparation of graphene nano-platelets from graphite. The mechanical grinding treatment of graphite mixtures with glycerol leads to the formation of stable graphene suspensions of a low number of layers from which graphene powders can be obtained by removing the glycerol, washing it with different solvents. The present invention is a novelty by employing recyclable treatment means of natural origin to achieve the exfoliation. It avoids the use of hazardous chemicals and the treatment of waste streams containing toxic residues. The method also uses acceptable environmental solvents that can be reused in the process. The use of glycerol allows a quantitative yield of graphene nano-platelets with a low number of layers and enables the full use of the graphite used as raw material. The process possesses the advantage of recovering and reusing glycerol and the green solvents used in the treatment, thus practically nulling its environmental impact.",CENTRO DE INVESTIGACION EN QUIM APLICADA,RAFAEL AGUIRRE FLORES;;OLIVERIO SANTIAGO RODRIGUEZ FERNANDEZ;;SALVADOR FERNÁNDEZ TAVIZÓN;;EDGAR GERARDO DE CASAS ORTIZ;;CARLOS ALBERTO GALLARDO VEGA;;ARXEL DE LEÓN SANTILLÁN;;JESÚS ALFONSO MERCADO SILVA;;JOELIS RODRÍGUEZ HERNÁNDEZ,,https://lens.org/065-569-195-560-299,Patent Application,no,0,0,1,1,0,,C01B32/16;;C01B32/00,,0,0,,,,PENDING
271,MX,A,MX 2016015475 A,042-448-873-553-739,2018-05-24,2018,MX 2016015475 A,2016-11-25,MX 2016015475 A,2016-11-25,MECHANOCHEMICAL PROCESS FOR THE MANUFACTURE OF NP GRAPHENE COMPOSITES OF METAL OXIDES.,"The present invention discloses a process for obtaining composite materials of graphene nanoplatelets doped with different metal oxides of nanometric size. The synthesis process is performed by providing high energy milling treatments to graphite mixtures with metal oxide nanoparticles. The present invention is a novelty by possessing the ability of doping the graphite and its delamination with nanoparticles of metal oxides in a single step. Additionally, it prevents the transformation of the nanoparticles used to other polymorphs by coating with Teflon the treatment container or by using containers made entirely of Teflon. In the case of a treatment with unstable nanoparticles, is required to add at the grinding medium auxiliary liquids for reducing the impacts received by the nanoparticles in the treatment medium.",CENTRO DE INVESTIGACION EN QUIM APLICADA,OLIVERIO SANTIAGO RODRIGUEZ FERNANDEZ;;SALVADOR FERNÁNDEZ TAVIZÓN;;EDGAR GERARDO DE CASAS ORTIZ;;CARLOS ALBERTO GALLARDO VEGA;;ARXEL DE LEÓN SANTILLÁN;;JESÚS ALFONSO MERCADO SILVA;;JOELIS RODRÍGUEZ HERNÁNDEZ;;MANUEL EDUARDO MARTINEZ CARTAGENA,,https://lens.org/042-448-873-553-739,Patent Application,no,0,1,1,1,0,,B82Y40/00;;B82Y30/00,,0,0,,,,PENDING
272,ES,A1,ES 2860352 A1,199-542-936-668-256,2021-10-04,2021,ES 202030264 A,2020-04-01,ES 202030264 A,2020-04-01,"SECURITY SYSTEM, ACCESS CONTROL AND BOARDING AT AIRPORTS (Machine-translation by Google Translate, not legally binding)","Security system, access control and boarding at airports. The system of the invention makes it possible to substantially speed up the process of access control and boarding at airports.The system links a biometric data of the passenger (in this case the facial one) with his boarding pass and his identification document (DNI or Similary). In this way, once the data has been linked from an APP and/or at a registration kiosk (2), the passenger can access the security control and the boarding gate with the facial identification systems installed at the gates. automatic access (3-4) of these points, without the need to show identification documents. (Machine-translation by Google Translate, not legally binding)",INETUM ESPANA S A,CRESPO ZARAGOZA JUAN CARLOS;;ARANDA ESTEPA MANUEL;;MONESMA FRANCISCO JOSÉ;;ORTIZ GONZÁLEZ ALEJANDRA;;CALDERÓN PALACIOS MANUEL;;CASAS GOMÉZ IGNACIO;;ALVAREZ BUENO CARLOS;;ESTALAYO MILLÁN IÑIGO;;PLAZA RODRÍGUEZ ANGEL;;MARTÍNEZ PERIS JORGE;;MURIEL IZQUIERDO ALFONSO;;BAUTISTA LEÓN ANTONIO;;SUÁREZ PARRA ADRIÁN;;ALVAREZ PINGUINHA RAFAEL;;PRESA GARCÍA AGUSTÍN,"INETUM ESPANA, S.A. (2021-04-08)",https://lens.org/199-542-936-668-256,Patent Application,no,6,1,1,1,0,G06F21/32;;G07C9/37;;G07C9/38;;G07C9/257;;G07C9/10;;G07C2209/02;;G06Q50/40,G06Q50/30;;G06F21/32;;G07C9/10;;G07C9/25;;G07C9/37;;G07C9/38,,0,0,,,,DISCONTINUED
273,ES,B2,ES 2526747 B2,033-261-348-679-521,2015-07-31,2015,ES 201300670 A,2013-07-13,ES 201300670 A,2013-07-13,Procedimiento para la preparación de catalizadores de oro soportado de elevada carga y alta dispersión metálica mediante técnicas de impregnación a humedad incipiente partiendo de ácido tetracloroaurico como precursor,,UNIV CADIZ,GATICA CASAS JOSÉ MANUEL;;RIO SANCHEZ ELOY;;CALVINO GAMEZ JOSÉ JUAN;;HERNANDEZ GARRIDO JUAN CARLOS;;GARCIA BASALLOTE MANUEL;;FERNANDEZ-TRUJILLO REY MARÍA JESÚS;;PEREZ OMIL JOSÉ ANTONIO;;CAUQUI LOPEZ MIGUEL ANGEL;;GAONA SOTO DIANA;;BERNAL MARQUEZ SERAFÍN,,https://lens.org/033-261-348-679-521,Granted Patent,no,0,0,2,2,0,B01J23/52;;B01D53/864;;B01J37/02,B01J23/52;;B01D53/86;;B01J37/02,,0,0,,,,ACTIVE
274,ES,A1,ES 2526747 A1,151-369-360-875-392,2015-01-14,2015,ES 201300670 A,2013-07-13,ES 201300670 A,2013-07-13,"Process for the preparation of high load metal and high metal dispersion supported gold catalysts by incipient wet impregnation techniques starting from tetrachloroauric acid as a precursor (Machine-translation by Google Translate, not legally binding)","Process for the preparation of high loaded and high metal dispersion supported gold catalysts by incipient wet impregnation techniques starting from tetrachloroauric acid as a precursor. It is based on the control of the speciation suffered by the gold precursor by hydrolysis in aqueous solution, by controlling the ph, in order to minimize the concentration of species rich in chlorine ([aucl4] -) and increase the species with the lowest amount of chlorine ([aucl2 (oh)2] -). This procedure makes it possible to obtain supported gold catalysts with high metal dispersion (average particle size less than 1 nm and dispersion greater than 80%) by means of simple impregnation techniques at incipient humidity, at room temperature, with a high degree of utilization of the metal ( 92%) from haucl4 commercial, and easily scalable in terms of the amount to be prepared. (Machine-translation by Google Translate, not legally binding)",UNIV CADIZ,GATICA CASAS JOSÉ MANUEL;;RIO SANCHEZ ELOY;;CALVINO GAMEZ JOSÉ JUAN;;HERNANDEZ GARRIDO JUAN CARLOS;;GARCIA BASALLOTE MANUEL;;FERNANDEZ-TRUJILLO REY MARÍA JESÚS;;PEREZ OMIL JOSÉ ANTONIO;;CAUQUI LOPEZ MIGUEL ANGEL;;GAONA SOTO DIANA;;BERNAL MARQUEZ SERAFÍN,,https://lens.org/151-369-360-875-392,Patent Application,no,2,0,2,2,0,B01J23/52;;B01D53/864;;B01J37/02,B01J23/52;;B01D53/86;;B01J37/02,,2,2,044-705-804-719-675;;081-520-304-372-469,10.1016/j.jcat.2005.01.030;;10.1016/j.jcat.2008.06.008,"MOREAU F et al. Gold on titania catalysts for the oxidation of carbon monoxide: control of pH during preparation with various gold contents.JOURNAL OF CATALYSIS, 20050401 ACADEMIC PRESS, DULUTH, MN, US 01/04/2005 VOL: 231 No: 1 Pags: 105 - 114 ISSN 0021-9517 Doi: doi:10.1016/j.jcat.2005.01.030 Copret Christophe. Apartado: ""Experimental"" y Fig.1.;;BAATZ C et al. New innovative gold catalysts prepared by an improved incipient wetness method.JOURNAL OF CATALYSIS, 20080815 ACADEMIC PRESS, DULUTH, MN, US 15/08/2008 VOL: 258 No: 1 Pags: 165 - 169 ISSN 0021-9517 Doi: doi:10.1016/j.jcat.2008.06.008 Copret Christophe. Apartado ""Experimental"".",ACTIVE
275,ES,Y,ES 1162061 Y,151-388-315-184-684,2016-10-24,2016,ES 201630916 U,2016-07-14,ES 201630916 U,2016-07-14,RUEDA TRACTORA PARA BICICLETA,,INST DE EDUCACION SECUNDARIA EMILIO CANALEJO OLMEDA,AGUILAR REY CARLA;;BARANESCU MÓNICA BIANCA;;BARBA POZO ALBA;;BELLIDO TEJADA MARIA;;CASAS ESPEJO MATÍAS;;CRUZ GÓMEZ CELIA;;DELGADO MÁRQUEZ SARA;;ESPEJO MÁRMOL FRANCISCO JOSÉ;;ESPEJO MARQUÉS Mª VICTORIA;;GÓMEZ ALGABA JUAN CARLOS;;JIMÉNEZ AGUILAR MARINA;;MÁRQUEZ BAENA FRANCISCO JAVIER;;MESA HERNÁNDEZ ESTHER;;NAVARRO PECCI ISABEL CLARA;;POLONIO RAYA ROCÍO;;PORTERO PEDRAZA MIGUEL;;RAIGÓN BELLIDO INÉS;;RÍOS RODRÍGUEZ RUBÉN;;RODRÍGUEZ POLO MARINA;;ROLDÁN CUÉLLAR SERGIO;;RUZ BARRANCO LOURDES;;SÁNCHEZ RUZ ANTONIO DAVID;;SÁNCHEZ ZAFRA MARÍA;;VAQUERO RUIZ Mª DEL MAR;;ZAFRA ESPEJO JOAQUÍN,,https://lens.org/151-388-315-184-684,Limited Patent,no,0,0,2,2,0,,B60B1/00,,0,0,,,,INACTIVE
276,ES,U,ES 1162061 U,114-329-555-883-220,2016-08-03,2016,ES 201630916 U,2016-07-14,ES 201630916 U,2016-07-14,"Tractor wheel for bike (Machine-translation by Google Translate, not legally binding)","Wheel (1) bicycle tractor, of the type comprising a first pinion (3) with at least one first pinion (3a) in a first side (4) of the bushing (5) to be coupled to a chain (6) ) traction characterized in that it comprises a second pinion (30) with at least one second pinion (30a), which is arranged on the second side (40) of the bushing (5) to be able to be coupled to the chain (6) by means of the reversibility of the wheel (1) and change the gear ratios and/or the traction or rolling capacity of the wheel (1). (Machine-translation by Google Translate, not legally binding)",INST DE EDUCACION SECUNDARIA EMILIO CANALEJO OLMEDA,AGUILAR REY CARLA;;BARANESCU MÓNICA BIANCA;;BARBA POZO ALBA;;BELLIDO TEJADA MARIA;;CASAS ESPEJO MATÍAS;;CRUZ GÓMEZ CELIA;;DELGADO MÁRQUEZ SARA;;ESPEJO MÁRMOL FRANCISCO JOSÉ;;ESPEJO MARQUÉS Mª VICTORIA;;GÓMEZ ALGABA JUAN CARLOS;;JIMÉNEZ AGUILAR MARINA;;MÁRQUEZ BAENA FRANCISCO JAVIER;;MESA HERNÁNDEZ ESTHER;;NAVARRO PECCI ISABEL CLARA;;POLONIO RAYA ROCÍO;;PORTERO PEDRAZA MIGUEL;;RAIGÓN BELLIDO INÉS;;RÍOS RODRÍGUEZ RUBÉN;;RODRÍGUEZ POLO MARINA;;ROLDÁN CUÉLLAR SERGIO;;RUZ BARRANCO LOURDES;;SÁNCHEZ RUZ ANTONIO DAVID;;SÁNCHEZ ZAFRA MARÍA;;VAQUERO RUIZ Mª DEL MAR;;ZAFRA ESPEJO JOAQUÍN,,https://lens.org/114-329-555-883-220,Patent Application,no,0,0,2,2,0,,B60B1/00,,0,0,,,,INACTIVE
